{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "E5BBXLk-TeO2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7zobnA_-ToFR"
   },
   "outputs": [],
   "source": [
    "# __all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "#            'resnet152', 'resnext50_32x4d', 'resnext101_32x8d',\n",
    "#            'wide_resnet50_2', 'wide_resnet101_2']\n",
    "\n",
    "\n",
    "# model_urls = {\n",
    "#     'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "#     'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "#     'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "#     'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "#     'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "#     'resnext50_32x4d': 'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth',\n",
    "#     'resnext101_32x8d': 'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth',\n",
    "#     'wide_resnet50_2': 'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth',\n",
    "#     'wide_resnet101_2': 'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth',\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, k, kernel_size = 5, stride = 1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels*k, kernel_size, stride)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.pool = nn.AvgPool2d(kernel_size = 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        out = self.pool(self.tanh(x))\n",
    "        \n",
    "        return out    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tjZdPfhdRaDL"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=84, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "61NDv8d0RZ1q"
   },
   "outputs": [],
   "source": [
    "class Wide_LeNet4(nn.Module):\n",
    "    def __init__(self, n_classes, k):\n",
    "        super(Wide_LeNet4, self).__init__()\n",
    "        self.k = k\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6*k, kernel_size=5, stride=1)\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6*k, out_channels=16*k, kernel_size=5, stride=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.tanh(self.conv1(x)))\n",
    "        x = self.tanh(self.conv2(x))\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.tanh(F.linear(x.shape[1], 256)(x))\n",
    "        logits = self.fc2(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide_LeNet4(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "  (conv2): Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (tanh): Tanh()\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(Wide_LeNet4(10, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LBb0VapiRZdN"
   },
   "outputs": [],
   "source": [
    "def wide_lenet4_2() -> Wide_LeNet4:\n",
    "    # Wide LeNet4 with base_width k=2\n",
    "    return Wide_LeNet4(10, 2)\n",
    "\n",
    "def wide_lenet4_3():\n",
    "    # Wide LeNet4 with base_width k=3\n",
    "    return Wide_LeNet4(10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "id": "LaZU2G7cVEN8",
    "outputId": "fce6dc6b-fbd7-4cda-86c2-b83d16992ab9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BJMjCq9MVb5e"
   },
   "outputs": [],
   "source": [
    "best_train_acc = best_test_acc = start_epoch = 0\n",
    "\n",
    "model = LeNet5(10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "-lYDgrytZLuL"
   },
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    global best_train_acc, best_test_acc\n",
    "    device = 'cuda'\n",
    "    model.to(device)\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print(f'Epoch {epoch} Step {batch_idx}/{len(trainloader)}', 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "        acc = 100.*correct/total\n",
    "        if acc>best_train_acc:\n",
    "            best_train_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "d6FV6aJiZb7t"
   },
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    global best_train_acc, best_test_acc\n",
    "    device = 'cuda'\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            print(f'Epoch {epoch} Step {batch_idx}/{len(testloader)}', 'Test Loss: %.3f | Test Acc: %.3f%% (%d/%d)'\n",
    "                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_test_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'model': model.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, '/home/tr33/Downloads/checkpoint/ckpt.pth')\n",
    "        best_test_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FIDSc4c0bF99"
   },
   "outputs": [],
   "source": [
    "best_acc = []\n",
    "WideModel = wide_lenet4_2()\n",
    "optimizer1 = optim.Adam(WideModel.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.ones((1, 3, 224, 224))\n",
    "# print(WideModel(x.cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "jeY_S2e-Z1PK",
    "outputId": "98bc6a9f-d5b0-400f-bfd4-c1e2b83d650e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Epoch 0 Step 0/1563 Loss: 2.311 | Acc: 6.250% (2/32)\n",
      "Epoch 0 Step 1/1563 Loss: 2.306 | Acc: 6.250% (4/64)\n",
      "Epoch 0 Step 2/1563 Loss: 2.301 | Acc: 10.417% (10/96)\n",
      "Epoch 0 Step 3/1563 Loss: 2.306 | Acc: 10.156% (13/128)\n",
      "Epoch 0 Step 4/1563 Loss: 2.302 | Acc: 10.000% (16/160)\n",
      "Epoch 0 Step 5/1563 Loss: 2.301 | Acc: 9.896% (19/192)\n",
      "Epoch 0 Step 6/1563 Loss: 2.305 | Acc: 9.821% (22/224)\n",
      "Epoch 0 Step 7/1563 Loss: 2.302 | Acc: 10.547% (27/256)\n",
      "Epoch 0 Step 8/1563 Loss: 2.298 | Acc: 11.458% (33/288)\n",
      "Epoch 0 Step 9/1563 Loss: 2.292 | Acc: 12.812% (41/320)\n",
      "Epoch 0 Step 10/1563 Loss: 2.290 | Acc: 13.352% (47/352)\n",
      "Epoch 0 Step 11/1563 Loss: 2.290 | Acc: 13.802% (53/384)\n",
      "Epoch 0 Step 12/1563 Loss: 2.287 | Acc: 13.702% (57/416)\n",
      "Epoch 0 Step 13/1563 Loss: 2.278 | Acc: 14.286% (64/448)\n",
      "Epoch 0 Step 14/1563 Loss: 2.268 | Acc: 15.208% (73/480)\n",
      "Epoch 0 Step 15/1563 Loss: 2.258 | Acc: 16.602% (85/512)\n",
      "Epoch 0 Step 16/1563 Loss: 2.259 | Acc: 16.360% (89/544)\n",
      "Epoch 0 Step 17/1563 Loss: 2.257 | Acc: 16.319% (94/576)\n",
      "Epoch 0 Step 18/1563 Loss: 2.252 | Acc: 16.283% (99/608)\n",
      "Epoch 0 Step 19/1563 Loss: 2.248 | Acc: 15.938% (102/640)\n",
      "Epoch 0 Step 20/1563 Loss: 2.248 | Acc: 15.625% (105/672)\n",
      "Epoch 0 Step 21/1563 Loss: 2.242 | Acc: 15.625% (110/704)\n",
      "Epoch 0 Step 22/1563 Loss: 2.236 | Acc: 16.033% (118/736)\n",
      "Epoch 0 Step 23/1563 Loss: 2.232 | Acc: 16.016% (123/768)\n",
      "Epoch 0 Step 24/1563 Loss: 2.228 | Acc: 16.375% (131/800)\n",
      "Epoch 0 Step 25/1563 Loss: 2.219 | Acc: 16.587% (138/832)\n",
      "Epoch 0 Step 26/1563 Loss: 2.218 | Acc: 16.667% (144/864)\n",
      "Epoch 0 Step 27/1563 Loss: 2.223 | Acc: 16.518% (148/896)\n",
      "Epoch 0 Step 28/1563 Loss: 2.214 | Acc: 16.703% (155/928)\n",
      "Epoch 0 Step 29/1563 Loss: 2.207 | Acc: 17.188% (165/960)\n",
      "Epoch 0 Step 30/1563 Loss: 2.210 | Acc: 17.137% (170/992)\n",
      "Epoch 0 Step 31/1563 Loss: 2.211 | Acc: 16.797% (172/1024)\n",
      "Epoch 0 Step 32/1563 Loss: 2.205 | Acc: 16.761% (177/1056)\n",
      "Epoch 0 Step 33/1563 Loss: 2.196 | Acc: 17.004% (185/1088)\n",
      "Epoch 0 Step 34/1563 Loss: 2.188 | Acc: 17.321% (194/1120)\n",
      "Epoch 0 Step 35/1563 Loss: 2.185 | Acc: 17.361% (200/1152)\n",
      "Epoch 0 Step 36/1563 Loss: 2.177 | Acc: 17.821% (211/1184)\n",
      "Epoch 0 Step 37/1563 Loss: 2.178 | Acc: 17.599% (214/1216)\n",
      "Epoch 0 Step 38/1563 Loss: 2.184 | Acc: 17.628% (220/1248)\n",
      "Epoch 0 Step 39/1563 Loss: 2.181 | Acc: 17.656% (226/1280)\n",
      "Epoch 0 Step 40/1563 Loss: 2.176 | Acc: 17.835% (234/1312)\n",
      "Epoch 0 Step 41/1563 Loss: 2.175 | Acc: 17.857% (240/1344)\n",
      "Epoch 0 Step 42/1563 Loss: 2.173 | Acc: 17.878% (246/1376)\n",
      "Epoch 0 Step 43/1563 Loss: 2.172 | Acc: 17.756% (250/1408)\n",
      "Epoch 0 Step 44/1563 Loss: 2.165 | Acc: 17.986% (259/1440)\n",
      "Epoch 0 Step 45/1563 Loss: 2.161 | Acc: 18.139% (267/1472)\n",
      "Epoch 0 Step 46/1563 Loss: 2.159 | Acc: 18.085% (272/1504)\n",
      "Epoch 0 Step 47/1563 Loss: 2.157 | Acc: 17.969% (276/1536)\n",
      "Epoch 0 Step 48/1563 Loss: 2.151 | Acc: 18.431% (289/1568)\n",
      "Epoch 0 Step 49/1563 Loss: 2.151 | Acc: 18.438% (295/1600)\n",
      "Epoch 0 Step 50/1563 Loss: 2.150 | Acc: 18.566% (303/1632)\n",
      "Epoch 0 Step 51/1563 Loss: 2.150 | Acc: 18.570% (309/1664)\n",
      "Epoch 0 Step 52/1563 Loss: 2.150 | Acc: 18.514% (314/1696)\n",
      "Epoch 0 Step 53/1563 Loss: 2.149 | Acc: 18.461% (319/1728)\n",
      "Epoch 0 Step 54/1563 Loss: 2.143 | Acc: 18.977% (334/1760)\n",
      "Epoch 0 Step 55/1563 Loss: 2.142 | Acc: 18.973% (340/1792)\n",
      "Epoch 0 Step 56/1563 Loss: 2.141 | Acc: 19.243% (351/1824)\n",
      "Epoch 0 Step 57/1563 Loss: 2.135 | Acc: 19.612% (364/1856)\n",
      "Epoch 0 Step 58/1563 Loss: 2.132 | Acc: 19.862% (375/1888)\n",
      "Epoch 0 Step 59/1563 Loss: 2.131 | Acc: 19.740% (379/1920)\n",
      "Epoch 0 Step 60/1563 Loss: 2.131 | Acc: 19.877% (388/1952)\n",
      "Epoch 0 Step 61/1563 Loss: 2.131 | Acc: 19.909% (395/1984)\n",
      "Epoch 0 Step 62/1563 Loss: 2.127 | Acc: 19.891% (401/2016)\n",
      "Epoch 0 Step 63/1563 Loss: 2.124 | Acc: 20.068% (411/2048)\n",
      "Epoch 0 Step 64/1563 Loss: 2.122 | Acc: 20.385% (424/2080)\n",
      "Epoch 0 Step 65/1563 Loss: 2.121 | Acc: 20.360% (430/2112)\n",
      "Epoch 0 Step 66/1563 Loss: 2.120 | Acc: 20.382% (437/2144)\n",
      "Epoch 0 Step 67/1563 Loss: 2.119 | Acc: 20.450% (445/2176)\n",
      "Epoch 0 Step 68/1563 Loss: 2.120 | Acc: 20.426% (451/2208)\n",
      "Epoch 0 Step 69/1563 Loss: 2.118 | Acc: 20.714% (464/2240)\n",
      "Epoch 0 Step 70/1563 Loss: 2.118 | Acc: 20.775% (472/2272)\n",
      "Epoch 0 Step 71/1563 Loss: 2.119 | Acc: 20.573% (474/2304)\n",
      "Epoch 0 Step 72/1563 Loss: 2.117 | Acc: 20.548% (480/2336)\n",
      "Epoch 0 Step 73/1563 Loss: 2.117 | Acc: 20.397% (483/2368)\n",
      "Epoch 0 Step 74/1563 Loss: 2.116 | Acc: 20.417% (490/2400)\n",
      "Epoch 0 Step 75/1563 Loss: 2.115 | Acc: 20.477% (498/2432)\n",
      "Epoch 0 Step 76/1563 Loss: 2.114 | Acc: 20.455% (504/2464)\n",
      "Epoch 0 Step 77/1563 Loss: 2.111 | Acc: 20.473% (511/2496)\n",
      "Epoch 0 Step 78/1563 Loss: 2.111 | Acc: 20.570% (520/2528)\n",
      "Epoch 0 Step 79/1563 Loss: 2.110 | Acc: 20.703% (530/2560)\n",
      "Epoch 0 Step 80/1563 Loss: 2.108 | Acc: 20.756% (538/2592)\n",
      "Epoch 0 Step 81/1563 Loss: 2.109 | Acc: 20.732% (544/2624)\n",
      "Epoch 0 Step 82/1563 Loss: 2.109 | Acc: 20.633% (548/2656)\n",
      "Epoch 0 Step 83/1563 Loss: 2.106 | Acc: 20.796% (559/2688)\n",
      "Epoch 0 Step 84/1563 Loss: 2.105 | Acc: 20.809% (566/2720)\n",
      "Epoch 0 Step 85/1563 Loss: 2.102 | Acc: 20.894% (575/2752)\n",
      "Epoch 0 Step 86/1563 Loss: 2.103 | Acc: 20.905% (582/2784)\n",
      "Epoch 0 Step 87/1563 Loss: 2.102 | Acc: 20.987% (591/2816)\n",
      "Epoch 0 Step 88/1563 Loss: 2.101 | Acc: 20.997% (598/2848)\n",
      "Epoch 0 Step 89/1563 Loss: 2.101 | Acc: 20.868% (601/2880)\n",
      "Epoch 0 Step 90/1563 Loss: 2.101 | Acc: 20.982% (611/2912)\n",
      "Epoch 0 Step 91/1563 Loss: 2.100 | Acc: 20.958% (617/2944)\n",
      "Epoch 0 Step 92/1563 Loss: 2.097 | Acc: 21.069% (627/2976)\n",
      "Epoch 0 Step 93/1563 Loss: 2.096 | Acc: 21.144% (636/3008)\n",
      "Epoch 0 Step 94/1563 Loss: 2.096 | Acc: 21.118% (642/3040)\n",
      "Epoch 0 Step 95/1563 Loss: 2.094 | Acc: 21.289% (654/3072)\n",
      "Epoch 0 Step 96/1563 Loss: 2.093 | Acc: 21.327% (662/3104)\n",
      "Epoch 0 Step 97/1563 Loss: 2.092 | Acc: 21.365% (670/3136)\n",
      "Epoch 0 Step 98/1563 Loss: 2.092 | Acc: 21.402% (678/3168)\n",
      "Epoch 0 Step 99/1563 Loss: 2.091 | Acc: 21.469% (687/3200)\n",
      "Epoch 0 Step 100/1563 Loss: 2.091 | Acc: 21.473% (694/3232)\n",
      "Epoch 0 Step 101/1563 Loss: 2.090 | Acc: 21.538% (703/3264)\n",
      "Epoch 0 Step 102/1563 Loss: 2.090 | Acc: 21.572% (711/3296)\n",
      "Epoch 0 Step 103/1563 Loss: 2.089 | Acc: 21.605% (719/3328)\n",
      "Epoch 0 Step 104/1563 Loss: 2.088 | Acc: 21.577% (725/3360)\n",
      "Epoch 0 Step 105/1563 Loss: 2.087 | Acc: 21.610% (733/3392)\n",
      "Epoch 0 Step 106/1563 Loss: 2.089 | Acc: 21.554% (738/3424)\n",
      "Epoch 0 Step 107/1563 Loss: 2.089 | Acc: 21.644% (748/3456)\n",
      "Epoch 0 Step 108/1563 Loss: 2.087 | Acc: 21.789% (760/3488)\n",
      "Epoch 0 Step 109/1563 Loss: 2.086 | Acc: 21.847% (769/3520)\n",
      "Epoch 0 Step 110/1563 Loss: 2.084 | Acc: 22.072% (784/3552)\n",
      "Epoch 0 Step 111/1563 Loss: 2.082 | Acc: 22.266% (798/3584)\n",
      "Epoch 0 Step 112/1563 Loss: 2.081 | Acc: 22.235% (804/3616)\n",
      "Epoch 0 Step 113/1563 Loss: 2.080 | Acc: 22.314% (814/3648)\n",
      "Epoch 0 Step 114/1563 Loss: 2.080 | Acc: 22.391% (824/3680)\n",
      "Epoch 0 Step 115/1563 Loss: 2.081 | Acc: 22.441% (833/3712)\n",
      "Epoch 0 Step 116/1563 Loss: 2.080 | Acc: 22.463% (841/3744)\n",
      "Epoch 0 Step 117/1563 Loss: 2.078 | Acc: 22.564% (852/3776)\n",
      "Epoch 0 Step 118/1563 Loss: 2.076 | Acc: 22.715% (865/3808)\n",
      "Epoch 0 Step 119/1563 Loss: 2.075 | Acc: 22.734% (873/3840)\n",
      "Epoch 0 Step 120/1563 Loss: 2.076 | Acc: 22.701% (879/3872)\n",
      "Epoch 0 Step 121/1563 Loss: 2.075 | Acc: 22.695% (886/3904)\n",
      "Epoch 0 Step 122/1563 Loss: 2.074 | Acc: 22.713% (894/3936)\n",
      "Epoch 0 Step 123/1563 Loss: 2.075 | Acc: 22.707% (901/3968)\n",
      "Epoch 0 Step 124/1563 Loss: 2.075 | Acc: 22.575% (903/4000)\n",
      "Epoch 0 Step 125/1563 Loss: 2.074 | Acc: 22.569% (910/4032)\n",
      "Epoch 0 Step 126/1563 Loss: 2.073 | Acc: 22.638% (920/4064)\n",
      "Epoch 0 Step 127/1563 Loss: 2.072 | Acc: 22.681% (929/4096)\n",
      "Epoch 0 Step 128/1563 Loss: 2.071 | Acc: 22.699% (937/4128)\n",
      "Epoch 0 Step 129/1563 Loss: 2.071 | Acc: 22.668% (943/4160)\n",
      "Epoch 0 Step 130/1563 Loss: 2.070 | Acc: 22.758% (954/4192)\n",
      "Epoch 0 Step 131/1563 Loss: 2.070 | Acc: 22.751% (961/4224)\n",
      "Epoch 0 Step 132/1563 Loss: 2.069 | Acc: 22.791% (970/4256)\n",
      "Epoch 0 Step 133/1563 Loss: 2.068 | Acc: 22.808% (978/4288)\n",
      "Epoch 0 Step 134/1563 Loss: 2.068 | Acc: 22.847% (987/4320)\n",
      "Epoch 0 Step 135/1563 Loss: 2.066 | Acc: 22.955% (999/4352)\n",
      "Epoch 0 Step 136/1563 Loss: 2.067 | Acc: 22.901% (1004/4384)\n",
      "Epoch 0 Step 137/1563 Loss: 2.065 | Acc: 22.962% (1014/4416)\n",
      "Epoch 0 Step 138/1563 Loss: 2.064 | Acc: 22.977% (1022/4448)\n",
      "Epoch 0 Step 139/1563 Loss: 2.063 | Acc: 23.058% (1033/4480)\n",
      "Epoch 0 Step 140/1563 Loss: 2.061 | Acc: 23.050% (1040/4512)\n",
      "Epoch 0 Step 141/1563 Loss: 2.061 | Acc: 23.063% (1048/4544)\n",
      "Epoch 0 Step 142/1563 Loss: 2.061 | Acc: 23.099% (1057/4576)\n",
      "Epoch 0 Step 143/1563 Loss: 2.061 | Acc: 23.112% (1065/4608)\n",
      "Epoch 0 Step 144/1563 Loss: 2.063 | Acc: 23.125% (1073/4640)\n",
      "Epoch 0 Step 145/1563 Loss: 2.063 | Acc: 23.159% (1082/4672)\n",
      "Epoch 0 Step 146/1563 Loss: 2.063 | Acc: 23.151% (1089/4704)\n",
      "Epoch 0 Step 147/1563 Loss: 2.061 | Acc: 23.290% (1103/4736)\n",
      "Epoch 0 Step 148/1563 Loss: 2.060 | Acc: 23.301% (1111/4768)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 149/1563 Loss: 2.060 | Acc: 23.354% (1121/4800)\n",
      "Epoch 0 Step 150/1563 Loss: 2.060 | Acc: 23.344% (1128/4832)\n",
      "Epoch 0 Step 151/1563 Loss: 2.059 | Acc: 23.376% (1137/4864)\n",
      "Epoch 0 Step 152/1563 Loss: 2.059 | Acc: 23.386% (1145/4896)\n",
      "Epoch 0 Step 153/1563 Loss: 2.058 | Acc: 23.458% (1156/4928)\n",
      "Epoch 0 Step 154/1563 Loss: 2.058 | Acc: 23.367% (1159/4960)\n",
      "Epoch 0 Step 155/1563 Loss: 2.057 | Acc: 23.417% (1169/4992)\n",
      "Epoch 0 Step 156/1563 Loss: 2.056 | Acc: 23.428% (1177/5024)\n",
      "Epoch 0 Step 157/1563 Loss: 2.055 | Acc: 23.477% (1187/5056)\n",
      "Epoch 0 Step 158/1563 Loss: 2.055 | Acc: 23.526% (1197/5088)\n",
      "Epoch 0 Step 159/1563 Loss: 2.055 | Acc: 23.516% (1204/5120)\n",
      "Epoch 0 Step 160/1563 Loss: 2.052 | Acc: 23.641% (1218/5152)\n",
      "Epoch 0 Step 161/1563 Loss: 2.052 | Acc: 23.669% (1227/5184)\n",
      "Epoch 0 Step 162/1563 Loss: 2.051 | Acc: 23.754% (1239/5216)\n",
      "Epoch 0 Step 163/1563 Loss: 2.051 | Acc: 23.780% (1248/5248)\n",
      "Epoch 0 Step 164/1563 Loss: 2.050 | Acc: 23.750% (1254/5280)\n",
      "Epoch 0 Step 165/1563 Loss: 2.049 | Acc: 23.814% (1265/5312)\n",
      "Epoch 0 Step 166/1563 Loss: 2.048 | Acc: 23.784% (1271/5344)\n",
      "Epoch 0 Step 167/1563 Loss: 2.048 | Acc: 23.772% (1278/5376)\n",
      "Epoch 0 Step 168/1563 Loss: 2.046 | Acc: 23.761% (1285/5408)\n",
      "Epoch 0 Step 169/1563 Loss: 2.045 | Acc: 23.824% (1296/5440)\n",
      "Epoch 0 Step 170/1563 Loss: 2.045 | Acc: 23.830% (1304/5472)\n",
      "Epoch 0 Step 171/1563 Loss: 2.045 | Acc: 23.801% (1310/5504)\n",
      "Epoch 0 Step 172/1563 Loss: 2.044 | Acc: 23.790% (1317/5536)\n",
      "Epoch 0 Step 173/1563 Loss: 2.045 | Acc: 23.779% (1324/5568)\n",
      "Epoch 0 Step 174/1563 Loss: 2.045 | Acc: 23.804% (1333/5600)\n",
      "Epoch 0 Step 175/1563 Loss: 2.042 | Acc: 23.899% (1346/5632)\n",
      "Epoch 0 Step 176/1563 Loss: 2.041 | Acc: 23.905% (1354/5664)\n",
      "Epoch 0 Step 177/1563 Loss: 2.041 | Acc: 23.964% (1365/5696)\n",
      "Epoch 0 Step 178/1563 Loss: 2.040 | Acc: 24.022% (1376/5728)\n",
      "Epoch 0 Step 179/1563 Loss: 2.040 | Acc: 24.045% (1385/5760)\n",
      "Epoch 0 Step 180/1563 Loss: 2.039 | Acc: 24.068% (1394/5792)\n",
      "Epoch 0 Step 181/1563 Loss: 2.038 | Acc: 24.124% (1405/5824)\n",
      "Epoch 0 Step 182/1563 Loss: 2.038 | Acc: 24.095% (1411/5856)\n",
      "Epoch 0 Step 183/1563 Loss: 2.037 | Acc: 24.100% (1419/5888)\n",
      "Epoch 0 Step 184/1563 Loss: 2.036 | Acc: 24.122% (1428/5920)\n",
      "Epoch 0 Step 185/1563 Loss: 2.035 | Acc: 24.210% (1441/5952)\n",
      "Epoch 0 Step 186/1563 Loss: 2.035 | Acc: 24.265% (1452/5984)\n",
      "Epoch 0 Step 187/1563 Loss: 2.034 | Acc: 24.318% (1463/6016)\n",
      "Epoch 0 Step 188/1563 Loss: 2.035 | Acc: 24.256% (1467/6048)\n",
      "Epoch 0 Step 189/1563 Loss: 2.035 | Acc: 24.276% (1476/6080)\n",
      "Epoch 0 Step 190/1563 Loss: 2.035 | Acc: 24.346% (1488/6112)\n",
      "Epoch 0 Step 191/1563 Loss: 2.034 | Acc: 24.430% (1501/6144)\n",
      "Epoch 0 Step 192/1563 Loss: 2.033 | Acc: 24.433% (1509/6176)\n",
      "Epoch 0 Step 193/1563 Loss: 2.032 | Acc: 24.468% (1519/6208)\n",
      "Epoch 0 Step 194/1563 Loss: 2.031 | Acc: 24.487% (1528/6240)\n",
      "Epoch 0 Step 195/1563 Loss: 2.031 | Acc: 24.522% (1538/6272)\n",
      "Epoch 0 Step 196/1563 Loss: 2.030 | Acc: 24.556% (1548/6304)\n",
      "Epoch 0 Step 197/1563 Loss: 2.030 | Acc: 24.558% (1556/6336)\n",
      "Epoch 0 Step 198/1563 Loss: 2.029 | Acc: 24.607% (1567/6368)\n",
      "Epoch 0 Step 199/1563 Loss: 2.029 | Acc: 24.594% (1574/6400)\n",
      "Epoch 0 Step 200/1563 Loss: 2.029 | Acc: 24.611% (1583/6432)\n",
      "Epoch 0 Step 201/1563 Loss: 2.028 | Acc: 24.629% (1592/6464)\n",
      "Epoch 0 Step 202/1563 Loss: 2.027 | Acc: 24.708% (1605/6496)\n",
      "Epoch 0 Step 203/1563 Loss: 2.025 | Acc: 24.816% (1620/6528)\n",
      "Epoch 0 Step 204/1563 Loss: 2.024 | Acc: 24.817% (1628/6560)\n",
      "Epoch 0 Step 205/1563 Loss: 2.023 | Acc: 24.863% (1639/6592)\n",
      "Epoch 0 Step 206/1563 Loss: 2.023 | Acc: 24.864% (1647/6624)\n",
      "Epoch 0 Step 207/1563 Loss: 2.022 | Acc: 24.880% (1656/6656)\n",
      "Epoch 0 Step 208/1563 Loss: 2.024 | Acc: 24.850% (1662/6688)\n",
      "Epoch 0 Step 209/1563 Loss: 2.022 | Acc: 24.881% (1672/6720)\n",
      "Epoch 0 Step 210/1563 Loss: 2.021 | Acc: 24.926% (1683/6752)\n",
      "Epoch 0 Step 211/1563 Loss: 2.021 | Acc: 24.926% (1691/6784)\n",
      "Epoch 0 Step 212/1563 Loss: 2.021 | Acc: 24.971% (1702/6816)\n",
      "Epoch 0 Step 213/1563 Loss: 2.021 | Acc: 24.971% (1710/6848)\n",
      "Epoch 0 Step 214/1563 Loss: 2.021 | Acc: 24.956% (1717/6880)\n",
      "Epoch 0 Step 215/1563 Loss: 2.021 | Acc: 24.986% (1727/6912)\n",
      "Epoch 0 Step 216/1563 Loss: 2.019 | Acc: 25.072% (1741/6944)\n",
      "Epoch 0 Step 217/1563 Loss: 2.019 | Acc: 25.057% (1748/6976)\n",
      "Epoch 0 Step 218/1563 Loss: 2.018 | Acc: 25.057% (1756/7008)\n",
      "Epoch 0 Step 219/1563 Loss: 2.017 | Acc: 25.085% (1766/7040)\n",
      "Epoch 0 Step 220/1563 Loss: 2.018 | Acc: 25.042% (1771/7072)\n",
      "Epoch 0 Step 221/1563 Loss: 2.018 | Acc: 25.070% (1781/7104)\n",
      "Epoch 0 Step 222/1563 Loss: 2.018 | Acc: 25.126% (1793/7136)\n",
      "Epoch 0 Step 223/1563 Loss: 2.019 | Acc: 25.070% (1797/7168)\n",
      "Epoch 0 Step 224/1563 Loss: 2.018 | Acc: 25.111% (1808/7200)\n",
      "Epoch 0 Step 225/1563 Loss: 2.018 | Acc: 25.097% (1815/7232)\n",
      "Epoch 0 Step 226/1563 Loss: 2.018 | Acc: 25.124% (1825/7264)\n",
      "Epoch 0 Step 227/1563 Loss: 2.017 | Acc: 25.164% (1836/7296)\n",
      "Epoch 0 Step 228/1563 Loss: 2.018 | Acc: 25.150% (1843/7328)\n",
      "Epoch 0 Step 229/1563 Loss: 2.018 | Acc: 25.149% (1851/7360)\n",
      "Epoch 0 Step 230/1563 Loss: 2.017 | Acc: 25.203% (1863/7392)\n",
      "Epoch 0 Step 231/1563 Loss: 2.016 | Acc: 25.350% (1882/7424)\n",
      "Epoch 0 Step 232/1563 Loss: 2.016 | Acc: 25.322% (1888/7456)\n",
      "Epoch 0 Step 233/1563 Loss: 2.015 | Acc: 25.334% (1897/7488)\n",
      "Epoch 0 Step 234/1563 Loss: 2.015 | Acc: 25.293% (1902/7520)\n",
      "Epoch 0 Step 235/1563 Loss: 2.015 | Acc: 25.291% (1910/7552)\n",
      "Epoch 0 Step 236/1563 Loss: 2.015 | Acc: 25.303% (1919/7584)\n",
      "Epoch 0 Step 237/1563 Loss: 2.014 | Acc: 25.368% (1932/7616)\n",
      "Epoch 0 Step 238/1563 Loss: 2.013 | Acc: 25.379% (1941/7648)\n",
      "Epoch 0 Step 239/1563 Loss: 2.012 | Acc: 25.404% (1951/7680)\n",
      "Epoch 0 Step 240/1563 Loss: 2.012 | Acc: 25.415% (1960/7712)\n",
      "Epoch 0 Step 241/1563 Loss: 2.012 | Acc: 25.426% (1969/7744)\n",
      "Epoch 0 Step 242/1563 Loss: 2.011 | Acc: 25.476% (1981/7776)\n",
      "Epoch 0 Step 243/1563 Loss: 2.010 | Acc: 25.512% (1992/7808)\n",
      "Epoch 0 Step 244/1563 Loss: 2.010 | Acc: 25.497% (1999/7840)\n",
      "Epoch 0 Step 245/1563 Loss: 2.010 | Acc: 25.534% (2010/7872)\n",
      "Epoch 0 Step 246/1563 Loss: 2.010 | Acc: 25.519% (2017/7904)\n",
      "Epoch 0 Step 247/1563 Loss: 2.010 | Acc: 25.529% (2026/7936)\n",
      "Epoch 0 Step 248/1563 Loss: 2.011 | Acc: 25.502% (2032/7968)\n",
      "Epoch 0 Step 249/1563 Loss: 2.010 | Acc: 25.512% (2041/8000)\n",
      "Epoch 0 Step 250/1563 Loss: 2.009 | Acc: 25.535% (2051/8032)\n",
      "Epoch 0 Step 251/1563 Loss: 2.009 | Acc: 25.508% (2057/8064)\n",
      "Epoch 0 Step 252/1563 Loss: 2.009 | Acc: 25.506% (2065/8096)\n",
      "Epoch 0 Step 253/1563 Loss: 2.009 | Acc: 25.529% (2075/8128)\n",
      "Epoch 0 Step 254/1563 Loss: 2.009 | Acc: 25.502% (2081/8160)\n",
      "Epoch 0 Step 255/1563 Loss: 2.008 | Acc: 25.537% (2092/8192)\n",
      "Epoch 0 Step 256/1563 Loss: 2.007 | Acc: 25.596% (2105/8224)\n",
      "Epoch 0 Step 257/1563 Loss: 2.006 | Acc: 25.618% (2115/8256)\n",
      "Epoch 0 Step 258/1563 Loss: 2.006 | Acc: 25.652% (2126/8288)\n",
      "Epoch 0 Step 259/1563 Loss: 2.005 | Acc: 25.685% (2137/8320)\n",
      "Epoch 0 Step 260/1563 Loss: 2.004 | Acc: 25.778% (2153/8352)\n",
      "Epoch 0 Step 261/1563 Loss: 2.002 | Acc: 25.811% (2164/8384)\n",
      "Epoch 0 Step 262/1563 Loss: 2.003 | Acc: 25.796% (2171/8416)\n",
      "Epoch 0 Step 263/1563 Loss: 2.002 | Acc: 25.840% (2183/8448)\n",
      "Epoch 0 Step 264/1563 Loss: 2.002 | Acc: 25.849% (2192/8480)\n",
      "Epoch 0 Step 265/1563 Loss: 2.002 | Acc: 25.834% (2199/8512)\n",
      "Epoch 0 Step 266/1563 Loss: 2.003 | Acc: 25.854% (2209/8544)\n",
      "Epoch 0 Step 267/1563 Loss: 2.002 | Acc: 25.875% (2219/8576)\n",
      "Epoch 0 Step 268/1563 Loss: 2.003 | Acc: 25.836% (2224/8608)\n",
      "Epoch 0 Step 269/1563 Loss: 2.003 | Acc: 25.856% (2234/8640)\n",
      "Epoch 0 Step 270/1563 Loss: 2.002 | Acc: 25.876% (2244/8672)\n",
      "Epoch 0 Step 271/1563 Loss: 2.001 | Acc: 25.954% (2259/8704)\n",
      "Epoch 0 Step 272/1563 Loss: 2.000 | Acc: 25.996% (2271/8736)\n",
      "Epoch 0 Step 273/1563 Loss: 2.000 | Acc: 25.992% (2279/8768)\n",
      "Epoch 0 Step 274/1563 Loss: 2.000 | Acc: 25.966% (2285/8800)\n",
      "Epoch 0 Step 275/1563 Loss: 2.000 | Acc: 26.030% (2299/8832)\n",
      "Epoch 0 Step 276/1563 Loss: 1.999 | Acc: 26.038% (2308/8864)\n",
      "Epoch 0 Step 277/1563 Loss: 1.999 | Acc: 26.034% (2316/8896)\n",
      "Epoch 0 Step 278/1563 Loss: 1.999 | Acc: 26.030% (2324/8928)\n",
      "Epoch 0 Step 279/1563 Loss: 1.998 | Acc: 26.038% (2333/8960)\n",
      "Epoch 0 Step 280/1563 Loss: 1.998 | Acc: 26.068% (2344/8992)\n",
      "Epoch 0 Step 281/1563 Loss: 1.997 | Acc: 26.053% (2351/9024)\n",
      "Epoch 0 Step 282/1563 Loss: 1.998 | Acc: 26.049% (2359/9056)\n",
      "Epoch 0 Step 283/1563 Loss: 1.997 | Acc: 26.023% (2365/9088)\n",
      "Epoch 0 Step 284/1563 Loss: 1.997 | Acc: 26.031% (2374/9120)\n",
      "Epoch 0 Step 285/1563 Loss: 1.997 | Acc: 26.071% (2386/9152)\n",
      "Epoch 0 Step 286/1563 Loss: 1.997 | Acc: 26.034% (2391/9184)\n",
      "Epoch 0 Step 287/1563 Loss: 1.998 | Acc: 26.053% (2401/9216)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 288/1563 Loss: 1.997 | Acc: 26.092% (2413/9248)\n",
      "Epoch 0 Step 289/1563 Loss: 1.997 | Acc: 26.121% (2424/9280)\n",
      "Epoch 0 Step 290/1563 Loss: 1.997 | Acc: 26.117% (2432/9312)\n",
      "Epoch 0 Step 291/1563 Loss: 1.997 | Acc: 26.134% (2442/9344)\n",
      "Epoch 0 Step 292/1563 Loss: 1.997 | Acc: 26.173% (2454/9376)\n",
      "Epoch 0 Step 293/1563 Loss: 1.997 | Acc: 26.180% (2463/9408)\n",
      "Epoch 0 Step 294/1563 Loss: 1.997 | Acc: 26.229% (2476/9440)\n",
      "Epoch 0 Step 295/1563 Loss: 1.997 | Acc: 26.267% (2488/9472)\n",
      "Epoch 0 Step 296/1563 Loss: 1.996 | Acc: 26.294% (2499/9504)\n",
      "Epoch 0 Step 297/1563 Loss: 1.995 | Acc: 26.321% (2510/9536)\n",
      "Epoch 0 Step 298/1563 Loss: 1.995 | Acc: 26.359% (2522/9568)\n",
      "Epoch 0 Step 299/1563 Loss: 1.995 | Acc: 26.375% (2532/9600)\n",
      "Epoch 0 Step 300/1563 Loss: 1.996 | Acc: 26.360% (2539/9632)\n",
      "Epoch 0 Step 301/1563 Loss: 1.995 | Acc: 26.397% (2551/9664)\n",
      "Epoch 0 Step 302/1563 Loss: 1.994 | Acc: 26.454% (2565/9696)\n",
      "Epoch 0 Step 303/1563 Loss: 1.994 | Acc: 26.460% (2574/9728)\n",
      "Epoch 0 Step 304/1563 Loss: 1.994 | Acc: 26.455% (2582/9760)\n",
      "Epoch 0 Step 305/1563 Loss: 1.993 | Acc: 26.481% (2593/9792)\n",
      "Epoch 0 Step 306/1563 Loss: 1.993 | Acc: 26.486% (2602/9824)\n",
      "Epoch 0 Step 307/1563 Loss: 1.993 | Acc: 26.481% (2610/9856)\n",
      "Epoch 0 Step 308/1563 Loss: 1.992 | Acc: 26.507% (2621/9888)\n",
      "Epoch 0 Step 309/1563 Loss: 1.991 | Acc: 26.532% (2632/9920)\n",
      "Epoch 0 Step 310/1563 Loss: 1.991 | Acc: 26.517% (2639/9952)\n",
      "Epoch 0 Step 311/1563 Loss: 1.991 | Acc: 26.512% (2647/9984)\n",
      "Epoch 0 Step 312/1563 Loss: 1.989 | Acc: 26.577% (2662/10016)\n",
      "Epoch 0 Step 313/1563 Loss: 1.989 | Acc: 26.602% (2673/10048)\n",
      "Epoch 0 Step 314/1563 Loss: 1.989 | Acc: 26.607% (2682/10080)\n",
      "Epoch 0 Step 315/1563 Loss: 1.989 | Acc: 26.582% (2688/10112)\n",
      "Epoch 0 Step 316/1563 Loss: 1.989 | Acc: 26.607% (2699/10144)\n",
      "Epoch 0 Step 317/1563 Loss: 1.988 | Acc: 26.641% (2711/10176)\n",
      "Epoch 0 Step 318/1563 Loss: 1.988 | Acc: 26.646% (2720/10208)\n",
      "Epoch 0 Step 319/1563 Loss: 1.988 | Acc: 26.670% (2731/10240)\n",
      "Epoch 0 Step 320/1563 Loss: 1.988 | Acc: 26.684% (2741/10272)\n",
      "Epoch 0 Step 321/1563 Loss: 1.987 | Acc: 26.718% (2753/10304)\n",
      "Epoch 0 Step 322/1563 Loss: 1.986 | Acc: 26.771% (2767/10336)\n",
      "Epoch 0 Step 323/1563 Loss: 1.987 | Acc: 26.736% (2772/10368)\n",
      "Epoch 0 Step 324/1563 Loss: 1.986 | Acc: 26.769% (2784/10400)\n",
      "Epoch 0 Step 325/1563 Loss: 1.986 | Acc: 26.764% (2792/10432)\n",
      "Epoch 0 Step 326/1563 Loss: 1.986 | Acc: 26.778% (2802/10464)\n",
      "Epoch 0 Step 327/1563 Loss: 1.986 | Acc: 26.753% (2808/10496)\n",
      "Epoch 0 Step 328/1563 Loss: 1.985 | Acc: 26.786% (2820/10528)\n",
      "Epoch 0 Step 329/1563 Loss: 1.985 | Acc: 26.828% (2833/10560)\n",
      "Epoch 0 Step 330/1563 Loss: 1.985 | Acc: 26.832% (2842/10592)\n",
      "Epoch 0 Step 331/1563 Loss: 1.986 | Acc: 26.807% (2848/10624)\n",
      "Epoch 0 Step 332/1563 Loss: 1.985 | Acc: 26.830% (2859/10656)\n",
      "Epoch 0 Step 333/1563 Loss: 1.985 | Acc: 26.853% (2870/10688)\n",
      "Epoch 0 Step 334/1563 Loss: 1.985 | Acc: 26.875% (2881/10720)\n",
      "Epoch 0 Step 335/1563 Loss: 1.985 | Acc: 26.869% (2889/10752)\n",
      "Epoch 0 Step 336/1563 Loss: 1.984 | Acc: 26.882% (2899/10784)\n",
      "Epoch 0 Step 337/1563 Loss: 1.984 | Acc: 26.923% (2912/10816)\n",
      "Epoch 0 Step 338/1563 Loss: 1.984 | Acc: 26.917% (2920/10848)\n",
      "Epoch 0 Step 339/1563 Loss: 1.984 | Acc: 26.912% (2928/10880)\n",
      "Epoch 0 Step 340/1563 Loss: 1.983 | Acc: 26.943% (2940/10912)\n",
      "Epoch 0 Step 341/1563 Loss: 1.983 | Acc: 26.928% (2947/10944)\n",
      "Epoch 0 Step 342/1563 Loss: 1.984 | Acc: 26.895% (2952/10976)\n",
      "Epoch 0 Step 343/1563 Loss: 1.984 | Acc: 26.935% (2965/11008)\n",
      "Epoch 0 Step 344/1563 Loss: 1.984 | Acc: 26.929% (2973/11040)\n",
      "Epoch 0 Step 345/1563 Loss: 1.984 | Acc: 26.942% (2983/11072)\n",
      "Epoch 0 Step 346/1563 Loss: 1.983 | Acc: 26.936% (2991/11104)\n",
      "Epoch 0 Step 347/1563 Loss: 1.983 | Acc: 26.967% (3003/11136)\n",
      "Epoch 0 Step 348/1563 Loss: 1.983 | Acc: 26.979% (3013/11168)\n",
      "Epoch 0 Step 349/1563 Loss: 1.983 | Acc: 26.964% (3020/11200)\n",
      "Epoch 0 Step 350/1563 Loss: 1.983 | Acc: 26.959% (3028/11232)\n",
      "Epoch 0 Step 351/1563 Loss: 1.982 | Acc: 26.962% (3037/11264)\n",
      "Epoch 0 Step 352/1563 Loss: 1.983 | Acc: 26.983% (3048/11296)\n",
      "Epoch 0 Step 353/1563 Loss: 1.983 | Acc: 26.969% (3055/11328)\n",
      "Epoch 0 Step 354/1563 Loss: 1.982 | Acc: 26.998% (3067/11360)\n",
      "Epoch 0 Step 355/1563 Loss: 1.982 | Acc: 26.975% (3073/11392)\n",
      "Epoch 0 Step 356/1563 Loss: 1.982 | Acc: 26.996% (3084/11424)\n",
      "Epoch 0 Step 357/1563 Loss: 1.981 | Acc: 27.043% (3098/11456)\n",
      "Epoch 0 Step 358/1563 Loss: 1.982 | Acc: 27.011% (3103/11488)\n",
      "Epoch 0 Step 359/1563 Loss: 1.982 | Acc: 27.040% (3115/11520)\n",
      "Epoch 0 Step 360/1563 Loss: 1.982 | Acc: 27.034% (3123/11552)\n",
      "Epoch 0 Step 361/1563 Loss: 1.981 | Acc: 27.089% (3138/11584)\n",
      "Epoch 0 Step 362/1563 Loss: 1.981 | Acc: 27.135% (3152/11616)\n",
      "Epoch 0 Step 363/1563 Loss: 1.981 | Acc: 27.146% (3162/11648)\n",
      "Epoch 0 Step 364/1563 Loss: 1.981 | Acc: 27.123% (3168/11680)\n",
      "Epoch 0 Step 365/1563 Loss: 1.981 | Acc: 27.135% (3178/11712)\n",
      "Epoch 0 Step 366/1563 Loss: 1.980 | Acc: 27.163% (3190/11744)\n",
      "Epoch 0 Step 367/1563 Loss: 1.981 | Acc: 27.157% (3198/11776)\n",
      "Epoch 0 Step 368/1563 Loss: 1.981 | Acc: 27.134% (3204/11808)\n",
      "Epoch 0 Step 369/1563 Loss: 1.981 | Acc: 27.154% (3215/11840)\n",
      "Epoch 0 Step 370/1563 Loss: 1.980 | Acc: 27.173% (3226/11872)\n",
      "Epoch 0 Step 371/1563 Loss: 1.980 | Acc: 27.209% (3239/11904)\n",
      "Epoch 0 Step 372/1563 Loss: 1.979 | Acc: 27.187% (3245/11936)\n",
      "Epoch 0 Step 373/1563 Loss: 1.979 | Acc: 27.223% (3258/11968)\n",
      "Epoch 0 Step 374/1563 Loss: 1.979 | Acc: 27.200% (3264/12000)\n",
      "Epoch 0 Step 375/1563 Loss: 1.979 | Acc: 27.219% (3275/12032)\n",
      "Epoch 0 Step 376/1563 Loss: 1.979 | Acc: 27.263% (3289/12064)\n",
      "Epoch 0 Step 377/1563 Loss: 1.978 | Acc: 27.290% (3301/12096)\n",
      "Epoch 0 Step 378/1563 Loss: 1.978 | Acc: 27.325% (3314/12128)\n",
      "Epoch 0 Step 379/1563 Loss: 1.977 | Acc: 27.352% (3326/12160)\n",
      "Epoch 0 Step 380/1563 Loss: 1.977 | Acc: 27.346% (3334/12192)\n",
      "Epoch 0 Step 381/1563 Loss: 1.977 | Acc: 27.348% (3343/12224)\n",
      "Epoch 0 Step 382/1563 Loss: 1.977 | Acc: 27.358% (3353/12256)\n",
      "Epoch 0 Step 383/1563 Loss: 1.976 | Acc: 27.393% (3366/12288)\n",
      "Epoch 0 Step 384/1563 Loss: 1.976 | Acc: 27.411% (3377/12320)\n",
      "Epoch 0 Step 385/1563 Loss: 1.976 | Acc: 27.445% (3390/12352)\n",
      "Epoch 0 Step 386/1563 Loss: 1.976 | Acc: 27.439% (3398/12384)\n",
      "Epoch 0 Step 387/1563 Loss: 1.975 | Acc: 27.481% (3412/12416)\n",
      "Epoch 0 Step 388/1563 Loss: 1.975 | Acc: 27.506% (3424/12448)\n",
      "Epoch 0 Step 389/1563 Loss: 1.975 | Acc: 27.508% (3433/12480)\n",
      "Epoch 0 Step 390/1563 Loss: 1.974 | Acc: 27.518% (3443/12512)\n",
      "Epoch 0 Step 391/1563 Loss: 1.974 | Acc: 27.543% (3455/12544)\n",
      "Epoch 0 Step 392/1563 Loss: 1.974 | Acc: 27.545% (3464/12576)\n",
      "Epoch 0 Step 393/1563 Loss: 1.974 | Acc: 27.530% (3471/12608)\n",
      "Epoch 0 Step 394/1563 Loss: 1.974 | Acc: 27.532% (3480/12640)\n",
      "Epoch 0 Step 395/1563 Loss: 1.974 | Acc: 27.517% (3487/12672)\n",
      "Epoch 0 Step 396/1563 Loss: 1.974 | Acc: 27.519% (3496/12704)\n",
      "Epoch 0 Step 397/1563 Loss: 1.974 | Acc: 27.544% (3508/12736)\n",
      "Epoch 0 Step 398/1563 Loss: 1.974 | Acc: 27.545% (3517/12768)\n",
      "Epoch 0 Step 399/1563 Loss: 1.974 | Acc: 27.555% (3527/12800)\n",
      "Epoch 0 Step 400/1563 Loss: 1.973 | Acc: 27.548% (3535/12832)\n",
      "Epoch 0 Step 401/1563 Loss: 1.973 | Acc: 27.565% (3546/12864)\n",
      "Epoch 0 Step 402/1563 Loss: 1.972 | Acc: 27.605% (3560/12896)\n",
      "Epoch 0 Step 403/1563 Loss: 1.972 | Acc: 27.599% (3568/12928)\n",
      "Epoch 0 Step 404/1563 Loss: 1.973 | Acc: 27.600% (3577/12960)\n",
      "Epoch 0 Step 405/1563 Loss: 1.972 | Acc: 27.625% (3589/12992)\n",
      "Epoch 0 Step 406/1563 Loss: 1.971 | Acc: 27.680% (3605/13024)\n",
      "Epoch 0 Step 407/1563 Loss: 1.970 | Acc: 27.688% (3615/13056)\n",
      "Epoch 0 Step 408/1563 Loss: 1.970 | Acc: 27.697% (3625/13088)\n",
      "Epoch 0 Step 409/1563 Loss: 1.970 | Acc: 27.706% (3635/13120)\n",
      "Epoch 0 Step 410/1563 Loss: 1.970 | Acc: 27.722% (3646/13152)\n",
      "Epoch 0 Step 411/1563 Loss: 1.970 | Acc: 27.715% (3654/13184)\n",
      "Epoch 0 Step 412/1563 Loss: 1.970 | Acc: 27.709% (3662/13216)\n",
      "Epoch 0 Step 413/1563 Loss: 1.969 | Acc: 27.725% (3673/13248)\n",
      "Epoch 0 Step 414/1563 Loss: 1.969 | Acc: 27.711% (3680/13280)\n",
      "Epoch 0 Step 415/1563 Loss: 1.969 | Acc: 27.682% (3685/13312)\n",
      "Epoch 0 Step 416/1563 Loss: 1.968 | Acc: 27.675% (3693/13344)\n",
      "Epoch 0 Step 417/1563 Loss: 1.968 | Acc: 27.661% (3700/13376)\n",
      "Epoch 0 Step 418/1563 Loss: 1.969 | Acc: 27.663% (3709/13408)\n",
      "Epoch 0 Step 419/1563 Loss: 1.969 | Acc: 27.656% (3717/13440)\n",
      "Epoch 0 Step 420/1563 Loss: 1.969 | Acc: 27.665% (3727/13472)\n",
      "Epoch 0 Step 421/1563 Loss: 1.969 | Acc: 27.673% (3737/13504)\n",
      "Epoch 0 Step 422/1563 Loss: 1.968 | Acc: 27.697% (3749/13536)\n",
      "Epoch 0 Step 423/1563 Loss: 1.968 | Acc: 27.690% (3757/13568)\n",
      "Epoch 0 Step 424/1563 Loss: 1.968 | Acc: 27.699% (3767/13600)\n",
      "Epoch 0 Step 425/1563 Loss: 1.968 | Acc: 27.744% (3782/13632)\n",
      "Epoch 0 Step 426/1563 Loss: 1.967 | Acc: 27.752% (3792/13664)\n",
      "Epoch 0 Step 427/1563 Loss: 1.967 | Acc: 27.738% (3799/13696)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 428/1563 Loss: 1.967 | Acc: 27.739% (3808/13728)\n",
      "Epoch 0 Step 429/1563 Loss: 1.967 | Acc: 27.747% (3818/13760)\n",
      "Epoch 0 Step 430/1563 Loss: 1.967 | Acc: 27.748% (3827/13792)\n",
      "Epoch 0 Step 431/1563 Loss: 1.967 | Acc: 27.749% (3836/13824)\n",
      "Epoch 0 Step 432/1563 Loss: 1.966 | Acc: 27.779% (3849/13856)\n",
      "Epoch 0 Step 433/1563 Loss: 1.966 | Acc: 27.794% (3860/13888)\n",
      "Epoch 0 Step 434/1563 Loss: 1.966 | Acc: 27.816% (3872/13920)\n",
      "Epoch 0 Step 435/1563 Loss: 1.966 | Acc: 27.824% (3882/13952)\n",
      "Epoch 0 Step 436/1563 Loss: 1.966 | Acc: 27.832% (3892/13984)\n",
      "Epoch 0 Step 437/1563 Loss: 1.967 | Acc: 27.825% (3900/14016)\n",
      "Epoch 0 Step 438/1563 Loss: 1.967 | Acc: 27.833% (3910/14048)\n",
      "Epoch 0 Step 439/1563 Loss: 1.967 | Acc: 27.848% (3921/14080)\n",
      "Epoch 0 Step 440/1563 Loss: 1.967 | Acc: 27.842% (3929/14112)\n",
      "Epoch 0 Step 441/1563 Loss: 1.967 | Acc: 27.828% (3936/14144)\n",
      "Epoch 0 Step 442/1563 Loss: 1.966 | Acc: 27.857% (3949/14176)\n",
      "Epoch 0 Step 443/1563 Loss: 1.966 | Acc: 27.872% (3960/14208)\n",
      "Epoch 0 Step 444/1563 Loss: 1.967 | Acc: 27.858% (3967/14240)\n",
      "Epoch 0 Step 445/1563 Loss: 1.967 | Acc: 27.859% (3976/14272)\n",
      "Epoch 0 Step 446/1563 Loss: 1.966 | Acc: 27.859% (3985/14304)\n",
      "Epoch 0 Step 447/1563 Loss: 1.966 | Acc: 27.881% (3997/14336)\n",
      "Epoch 0 Step 448/1563 Loss: 1.966 | Acc: 27.895% (4008/14368)\n",
      "Epoch 0 Step 449/1563 Loss: 1.965 | Acc: 27.910% (4019/14400)\n",
      "Epoch 0 Step 450/1563 Loss: 1.965 | Acc: 27.924% (4030/14432)\n",
      "Epoch 0 Step 451/1563 Loss: 1.964 | Acc: 27.938% (4041/14464)\n",
      "Epoch 0 Step 452/1563 Loss: 1.964 | Acc: 27.959% (4053/14496)\n",
      "Epoch 0 Step 453/1563 Loss: 1.964 | Acc: 27.994% (4067/14528)\n",
      "Epoch 0 Step 454/1563 Loss: 1.963 | Acc: 28.015% (4079/14560)\n",
      "Epoch 0 Step 455/1563 Loss: 1.963 | Acc: 28.050% (4093/14592)\n",
      "Epoch 0 Step 456/1563 Loss: 1.962 | Acc: 28.070% (4105/14624)\n",
      "Epoch 0 Step 457/1563 Loss: 1.962 | Acc: 28.105% (4119/14656)\n",
      "Epoch 0 Step 458/1563 Loss: 1.962 | Acc: 28.105% (4128/14688)\n",
      "Epoch 0 Step 459/1563 Loss: 1.961 | Acc: 28.132% (4141/14720)\n",
      "Epoch 0 Step 460/1563 Loss: 1.961 | Acc: 28.132% (4150/14752)\n",
      "Epoch 0 Step 461/1563 Loss: 1.961 | Acc: 28.125% (4158/14784)\n",
      "Epoch 0 Step 462/1563 Loss: 1.961 | Acc: 28.118% (4166/14816)\n",
      "Epoch 0 Step 463/1563 Loss: 1.961 | Acc: 28.105% (4173/14848)\n",
      "Epoch 0 Step 464/1563 Loss: 1.961 | Acc: 28.118% (4184/14880)\n",
      "Epoch 0 Step 465/1563 Loss: 1.961 | Acc: 28.105% (4191/14912)\n",
      "Epoch 0 Step 466/1563 Loss: 1.961 | Acc: 28.118% (4202/14944)\n",
      "Epoch 0 Step 467/1563 Loss: 1.961 | Acc: 28.118% (4211/14976)\n",
      "Epoch 0 Step 468/1563 Loss: 1.961 | Acc: 28.118% (4220/15008)\n",
      "Epoch 0 Step 469/1563 Loss: 1.960 | Acc: 28.172% (4237/15040)\n",
      "Epoch 0 Step 470/1563 Loss: 1.961 | Acc: 28.165% (4245/15072)\n",
      "Epoch 0 Step 471/1563 Loss: 1.960 | Acc: 28.185% (4257/15104)\n",
      "Epoch 0 Step 472/1563 Loss: 1.959 | Acc: 28.204% (4269/15136)\n",
      "Epoch 0 Step 473/1563 Loss: 1.959 | Acc: 28.224% (4281/15168)\n",
      "Epoch 0 Step 474/1563 Loss: 1.960 | Acc: 28.224% (4290/15200)\n",
      "Epoch 0 Step 475/1563 Loss: 1.959 | Acc: 28.237% (4301/15232)\n",
      "Epoch 0 Step 476/1563 Loss: 1.959 | Acc: 28.263% (4314/15264)\n",
      "Epoch 0 Step 477/1563 Loss: 1.959 | Acc: 28.269% (4324/15296)\n",
      "Epoch 0 Step 478/1563 Loss: 1.958 | Acc: 28.295% (4337/15328)\n",
      "Epoch 0 Step 479/1563 Loss: 1.958 | Acc: 28.301% (4347/15360)\n",
      "Epoch 0 Step 480/1563 Loss: 1.958 | Acc: 28.307% (4357/15392)\n",
      "Epoch 0 Step 481/1563 Loss: 1.958 | Acc: 28.307% (4366/15424)\n",
      "Epoch 0 Step 482/1563 Loss: 1.958 | Acc: 28.326% (4378/15456)\n",
      "Epoch 0 Step 483/1563 Loss: 1.957 | Acc: 28.351% (4391/15488)\n",
      "Epoch 0 Step 484/1563 Loss: 1.957 | Acc: 28.376% (4404/15520)\n",
      "Epoch 0 Step 485/1563 Loss: 1.957 | Acc: 28.389% (4415/15552)\n",
      "Epoch 0 Step 486/1563 Loss: 1.957 | Acc: 28.388% (4424/15584)\n",
      "Epoch 0 Step 487/1563 Loss: 1.957 | Acc: 28.388% (4433/15616)\n",
      "Epoch 0 Step 488/1563 Loss: 1.957 | Acc: 28.374% (4440/15648)\n",
      "Epoch 0 Step 489/1563 Loss: 1.956 | Acc: 28.393% (4452/15680)\n",
      "Epoch 0 Step 490/1563 Loss: 1.956 | Acc: 28.392% (4461/15712)\n",
      "Epoch 0 Step 491/1563 Loss: 1.956 | Acc: 28.411% (4473/15744)\n",
      "Epoch 0 Step 492/1563 Loss: 1.955 | Acc: 28.429% (4485/15776)\n",
      "Epoch 0 Step 493/1563 Loss: 1.955 | Acc: 28.460% (4499/15808)\n",
      "Epoch 0 Step 494/1563 Loss: 1.954 | Acc: 28.472% (4510/15840)\n",
      "Epoch 0 Step 495/1563 Loss: 1.954 | Acc: 28.490% (4522/15872)\n",
      "Epoch 0 Step 496/1563 Loss: 1.954 | Acc: 28.490% (4531/15904)\n",
      "Epoch 0 Step 497/1563 Loss: 1.954 | Acc: 28.527% (4546/15936)\n",
      "Epoch 0 Step 498/1563 Loss: 1.954 | Acc: 28.545% (4558/15968)\n",
      "Epoch 0 Step 499/1563 Loss: 1.953 | Acc: 28.550% (4568/16000)\n",
      "Epoch 0 Step 500/1563 Loss: 1.953 | Acc: 28.549% (4577/16032)\n",
      "Epoch 0 Step 501/1563 Loss: 1.953 | Acc: 28.548% (4586/16064)\n",
      "Epoch 0 Step 502/1563 Loss: 1.954 | Acc: 28.535% (4593/16096)\n",
      "Epoch 0 Step 503/1563 Loss: 1.954 | Acc: 28.547% (4604/16128)\n",
      "Epoch 0 Step 504/1563 Loss: 1.954 | Acc: 28.540% (4612/16160)\n",
      "Epoch 0 Step 505/1563 Loss: 1.953 | Acc: 28.533% (4620/16192)\n",
      "Epoch 0 Step 506/1563 Loss: 1.953 | Acc: 28.526% (4628/16224)\n",
      "Epoch 0 Step 507/1563 Loss: 1.953 | Acc: 28.568% (4644/16256)\n",
      "Epoch 0 Step 508/1563 Loss: 1.952 | Acc: 28.585% (4656/16288)\n",
      "Epoch 0 Step 509/1563 Loss: 1.952 | Acc: 28.591% (4666/16320)\n",
      "Epoch 0 Step 510/1563 Loss: 1.952 | Acc: 28.596% (4676/16352)\n",
      "Epoch 0 Step 511/1563 Loss: 1.952 | Acc: 28.589% (4684/16384)\n",
      "Epoch 0 Step 512/1563 Loss: 1.952 | Acc: 28.588% (4693/16416)\n",
      "Epoch 0 Step 513/1563 Loss: 1.952 | Acc: 28.605% (4705/16448)\n",
      "Epoch 0 Step 514/1563 Loss: 1.951 | Acc: 28.641% (4720/16480)\n",
      "Epoch 0 Step 515/1563 Loss: 1.951 | Acc: 28.670% (4734/16512)\n",
      "Epoch 0 Step 516/1563 Loss: 1.951 | Acc: 28.657% (4741/16544)\n",
      "Epoch 0 Step 517/1563 Loss: 1.951 | Acc: 28.680% (4754/16576)\n",
      "Epoch 0 Step 518/1563 Loss: 1.951 | Acc: 28.691% (4765/16608)\n",
      "Epoch 0 Step 519/1563 Loss: 1.951 | Acc: 28.696% (4775/16640)\n",
      "Epoch 0 Step 520/1563 Loss: 1.951 | Acc: 28.695% (4784/16672)\n",
      "Epoch 0 Step 521/1563 Loss: 1.950 | Acc: 28.706% (4795/16704)\n",
      "Epoch 0 Step 522/1563 Loss: 1.950 | Acc: 28.740% (4810/16736)\n",
      "Epoch 0 Step 523/1563 Loss: 1.949 | Acc: 28.793% (4828/16768)\n",
      "Epoch 0 Step 524/1563 Loss: 1.949 | Acc: 28.792% (4837/16800)\n",
      "Epoch 0 Step 525/1563 Loss: 1.948 | Acc: 28.820% (4851/16832)\n",
      "Epoch 0 Step 526/1563 Loss: 1.948 | Acc: 28.831% (4862/16864)\n",
      "Epoch 0 Step 527/1563 Loss: 1.948 | Acc: 28.829% (4871/16896)\n",
      "Epoch 0 Step 528/1563 Loss: 1.947 | Acc: 28.875% (4888/16928)\n",
      "Epoch 0 Step 529/1563 Loss: 1.947 | Acc: 28.909% (4903/16960)\n",
      "Epoch 0 Step 530/1563 Loss: 1.946 | Acc: 28.955% (4920/16992)\n",
      "Epoch 0 Step 531/1563 Loss: 1.946 | Acc: 28.977% (4933/17024)\n",
      "Epoch 0 Step 532/1563 Loss: 1.946 | Acc: 28.981% (4943/17056)\n",
      "Epoch 0 Step 533/1563 Loss: 1.946 | Acc: 28.979% (4952/17088)\n",
      "Epoch 0 Step 534/1563 Loss: 1.945 | Acc: 28.978% (4961/17120)\n",
      "Epoch 0 Step 535/1563 Loss: 1.945 | Acc: 28.970% (4969/17152)\n",
      "Epoch 0 Step 536/1563 Loss: 1.945 | Acc: 28.980% (4980/17184)\n",
      "Epoch 0 Step 537/1563 Loss: 1.944 | Acc: 29.008% (4994/17216)\n",
      "Epoch 0 Step 538/1563 Loss: 1.944 | Acc: 29.006% (5003/17248)\n",
      "Epoch 0 Step 539/1563 Loss: 1.944 | Acc: 28.987% (5009/17280)\n",
      "Epoch 0 Step 540/1563 Loss: 1.944 | Acc: 28.997% (5020/17312)\n",
      "Epoch 0 Step 541/1563 Loss: 1.943 | Acc: 29.036% (5036/17344)\n",
      "Epoch 0 Step 542/1563 Loss: 1.943 | Acc: 29.052% (5048/17376)\n",
      "Epoch 0 Step 543/1563 Loss: 1.942 | Acc: 29.073% (5061/17408)\n",
      "Epoch 0 Step 544/1563 Loss: 1.942 | Acc: 29.077% (5071/17440)\n",
      "Epoch 0 Step 545/1563 Loss: 1.942 | Acc: 29.104% (5085/17472)\n",
      "Epoch 0 Step 546/1563 Loss: 1.942 | Acc: 29.125% (5098/17504)\n",
      "Epoch 0 Step 547/1563 Loss: 1.942 | Acc: 29.134% (5109/17536)\n",
      "Epoch 0 Step 548/1563 Loss: 1.941 | Acc: 29.150% (5121/17568)\n",
      "Epoch 0 Step 549/1563 Loss: 1.941 | Acc: 29.131% (5127/17600)\n",
      "Epoch 0 Step 550/1563 Loss: 1.941 | Acc: 29.135% (5137/17632)\n",
      "Epoch 0 Step 551/1563 Loss: 1.942 | Acc: 29.133% (5146/17664)\n",
      "Epoch 0 Step 552/1563 Loss: 1.942 | Acc: 29.153% (5159/17696)\n",
      "Epoch 0 Step 553/1563 Loss: 1.941 | Acc: 29.157% (5169/17728)\n",
      "Epoch 0 Step 554/1563 Loss: 1.941 | Acc: 29.178% (5182/17760)\n",
      "Epoch 0 Step 555/1563 Loss: 1.941 | Acc: 29.170% (5190/17792)\n",
      "Epoch 0 Step 556/1563 Loss: 1.941 | Acc: 29.157% (5197/17824)\n",
      "Epoch 0 Step 557/1563 Loss: 1.941 | Acc: 29.155% (5206/17856)\n",
      "Epoch 0 Step 558/1563 Loss: 1.941 | Acc: 29.148% (5214/17888)\n",
      "Epoch 0 Step 559/1563 Loss: 1.941 | Acc: 29.152% (5224/17920)\n",
      "Epoch 0 Step 560/1563 Loss: 1.941 | Acc: 29.167% (5236/17952)\n",
      "Epoch 0 Step 561/1563 Loss: 1.941 | Acc: 29.181% (5248/17984)\n",
      "Epoch 0 Step 562/1563 Loss: 1.941 | Acc: 29.157% (5253/18016)\n",
      "Epoch 0 Step 563/1563 Loss: 1.941 | Acc: 29.167% (5264/18048)\n",
      "Epoch 0 Step 564/1563 Loss: 1.941 | Acc: 29.192% (5278/18080)\n",
      "Epoch 0 Step 565/1563 Loss: 1.940 | Acc: 29.202% (5289/18112)\n",
      "Epoch 0 Step 566/1563 Loss: 1.940 | Acc: 29.222% (5302/18144)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 567/1563 Loss: 1.940 | Acc: 29.236% (5314/18176)\n",
      "Epoch 0 Step 568/1563 Loss: 1.940 | Acc: 29.256% (5327/18208)\n",
      "Epoch 0 Step 569/1563 Loss: 1.940 | Acc: 29.276% (5340/18240)\n",
      "Epoch 0 Step 570/1563 Loss: 1.940 | Acc: 29.302% (5354/18272)\n",
      "Epoch 0 Step 571/1563 Loss: 1.939 | Acc: 29.300% (5363/18304)\n",
      "Epoch 0 Step 572/1563 Loss: 1.939 | Acc: 29.303% (5373/18336)\n",
      "Epoch 0 Step 573/1563 Loss: 1.939 | Acc: 29.296% (5381/18368)\n",
      "Epoch 0 Step 574/1563 Loss: 1.939 | Acc: 29.288% (5389/18400)\n",
      "Epoch 0 Step 575/1563 Loss: 1.939 | Acc: 29.302% (5401/18432)\n",
      "Epoch 0 Step 576/1563 Loss: 1.939 | Acc: 29.289% (5408/18464)\n",
      "Epoch 0 Step 577/1563 Loss: 1.939 | Acc: 29.266% (5413/18496)\n",
      "Epoch 0 Step 578/1563 Loss: 1.939 | Acc: 29.280% (5425/18528)\n",
      "Epoch 0 Step 579/1563 Loss: 1.938 | Acc: 29.316% (5441/18560)\n",
      "Epoch 0 Step 580/1563 Loss: 1.938 | Acc: 29.319% (5451/18592)\n",
      "Epoch 0 Step 581/1563 Loss: 1.938 | Acc: 29.333% (5463/18624)\n",
      "Epoch 0 Step 582/1563 Loss: 1.937 | Acc: 29.352% (5476/18656)\n",
      "Epoch 0 Step 583/1563 Loss: 1.937 | Acc: 29.366% (5488/18688)\n",
      "Epoch 0 Step 584/1563 Loss: 1.937 | Acc: 29.370% (5498/18720)\n",
      "Epoch 0 Step 585/1563 Loss: 1.938 | Acc: 29.368% (5507/18752)\n",
      "Epoch 0 Step 586/1563 Loss: 1.938 | Acc: 29.376% (5518/18784)\n",
      "Epoch 0 Step 587/1563 Loss: 1.937 | Acc: 29.406% (5533/18816)\n",
      "Epoch 0 Step 588/1563 Loss: 1.937 | Acc: 29.398% (5541/18848)\n",
      "Epoch 0 Step 589/1563 Loss: 1.937 | Acc: 29.396% (5550/18880)\n",
      "Epoch 0 Step 590/1563 Loss: 1.937 | Acc: 29.405% (5561/18912)\n",
      "Epoch 0 Step 591/1563 Loss: 1.937 | Acc: 29.429% (5575/18944)\n",
      "Epoch 0 Step 592/1563 Loss: 1.937 | Acc: 29.432% (5585/18976)\n",
      "Epoch 0 Step 593/1563 Loss: 1.936 | Acc: 29.451% (5598/19008)\n",
      "Epoch 0 Step 594/1563 Loss: 1.937 | Acc: 29.443% (5606/19040)\n",
      "Epoch 0 Step 595/1563 Loss: 1.937 | Acc: 29.446% (5616/19072)\n",
      "Epoch 0 Step 596/1563 Loss: 1.936 | Acc: 29.460% (5628/19104)\n",
      "Epoch 0 Step 597/1563 Loss: 1.936 | Acc: 29.494% (5644/19136)\n",
      "Epoch 0 Step 598/1563 Loss: 1.936 | Acc: 29.518% (5658/19168)\n",
      "Epoch 0 Step 599/1563 Loss: 1.936 | Acc: 29.521% (5668/19200)\n",
      "Epoch 0 Step 600/1563 Loss: 1.936 | Acc: 29.529% (5679/19232)\n",
      "Epoch 0 Step 601/1563 Loss: 1.936 | Acc: 29.532% (5689/19264)\n",
      "Epoch 0 Step 602/1563 Loss: 1.936 | Acc: 29.529% (5698/19296)\n",
      "Epoch 0 Step 603/1563 Loss: 1.936 | Acc: 29.543% (5710/19328)\n",
      "Epoch 0 Step 604/1563 Loss: 1.936 | Acc: 29.535% (5718/19360)\n",
      "Epoch 0 Step 605/1563 Loss: 1.936 | Acc: 29.528% (5726/19392)\n",
      "Epoch 0 Step 606/1563 Loss: 1.936 | Acc: 29.546% (5739/19424)\n",
      "Epoch 0 Step 607/1563 Loss: 1.936 | Acc: 29.538% (5747/19456)\n",
      "Epoch 0 Step 608/1563 Loss: 1.935 | Acc: 29.567% (5762/19488)\n",
      "Epoch 0 Step 609/1563 Loss: 1.935 | Acc: 29.565% (5771/19520)\n",
      "Epoch 0 Step 610/1563 Loss: 1.935 | Acc: 29.578% (5783/19552)\n",
      "Epoch 0 Step 611/1563 Loss: 1.934 | Acc: 29.590% (5795/19584)\n",
      "Epoch 0 Step 612/1563 Loss: 1.935 | Acc: 29.568% (5800/19616)\n",
      "Epoch 0 Step 613/1563 Loss: 1.935 | Acc: 29.565% (5809/19648)\n",
      "Epoch 0 Step 614/1563 Loss: 1.935 | Acc: 29.583% (5822/19680)\n",
      "Epoch 0 Step 615/1563 Loss: 1.935 | Acc: 29.576% (5830/19712)\n",
      "Epoch 0 Step 616/1563 Loss: 1.935 | Acc: 29.594% (5843/19744)\n",
      "Epoch 0 Step 617/1563 Loss: 1.935 | Acc: 29.602% (5854/19776)\n",
      "Epoch 0 Step 618/1563 Loss: 1.934 | Acc: 29.594% (5862/19808)\n",
      "Epoch 0 Step 619/1563 Loss: 1.934 | Acc: 29.592% (5871/19840)\n",
      "Epoch 0 Step 620/1563 Loss: 1.934 | Acc: 29.594% (5881/19872)\n",
      "Epoch 0 Step 621/1563 Loss: 1.934 | Acc: 29.617% (5895/19904)\n",
      "Epoch 0 Step 622/1563 Loss: 1.935 | Acc: 29.605% (5902/19936)\n",
      "Epoch 0 Step 623/1563 Loss: 1.935 | Acc: 29.602% (5911/19968)\n",
      "Epoch 0 Step 624/1563 Loss: 1.935 | Acc: 29.605% (5921/20000)\n",
      "Epoch 0 Step 625/1563 Loss: 1.934 | Acc: 29.633% (5936/20032)\n",
      "Epoch 0 Step 626/1563 Loss: 1.934 | Acc: 29.620% (5943/20064)\n",
      "Epoch 0 Step 627/1563 Loss: 1.934 | Acc: 29.598% (5948/20096)\n",
      "Epoch 0 Step 628/1563 Loss: 1.934 | Acc: 29.576% (5953/20128)\n",
      "Epoch 0 Step 629/1563 Loss: 1.934 | Acc: 29.578% (5963/20160)\n",
      "Epoch 0 Step 630/1563 Loss: 1.933 | Acc: 29.576% (5972/20192)\n",
      "Epoch 0 Step 631/1563 Loss: 1.933 | Acc: 29.574% (5981/20224)\n",
      "Epoch 0 Step 632/1563 Loss: 1.934 | Acc: 29.571% (5990/20256)\n",
      "Epoch 0 Step 633/1563 Loss: 1.933 | Acc: 29.574% (6000/20288)\n",
      "Epoch 0 Step 634/1563 Loss: 1.933 | Acc: 29.587% (6012/20320)\n",
      "Epoch 0 Step 635/1563 Loss: 1.933 | Acc: 29.589% (6022/20352)\n",
      "Epoch 0 Step 636/1563 Loss: 1.933 | Acc: 29.597% (6033/20384)\n",
      "Epoch 0 Step 637/1563 Loss: 1.933 | Acc: 29.604% (6044/20416)\n",
      "Epoch 0 Step 638/1563 Loss: 1.933 | Acc: 29.607% (6054/20448)\n",
      "Epoch 0 Step 639/1563 Loss: 1.933 | Acc: 29.604% (6063/20480)\n",
      "Epoch 0 Step 640/1563 Loss: 1.932 | Acc: 29.622% (6076/20512)\n",
      "Epoch 0 Step 641/1563 Loss: 1.932 | Acc: 29.634% (6088/20544)\n",
      "Epoch 0 Step 642/1563 Loss: 1.932 | Acc: 29.651% (6101/20576)\n",
      "Epoch 0 Step 643/1563 Loss: 1.932 | Acc: 29.663% (6113/20608)\n",
      "Epoch 0 Step 644/1563 Loss: 1.931 | Acc: 29.661% (6122/20640)\n",
      "Epoch 0 Step 645/1563 Loss: 1.931 | Acc: 29.658% (6131/20672)\n",
      "Epoch 0 Step 646/1563 Loss: 1.931 | Acc: 29.666% (6142/20704)\n",
      "Epoch 0 Step 647/1563 Loss: 1.931 | Acc: 29.688% (6156/20736)\n",
      "Epoch 0 Step 648/1563 Loss: 1.930 | Acc: 29.719% (6172/20768)\n",
      "Epoch 0 Step 649/1563 Loss: 1.930 | Acc: 29.736% (6185/20800)\n",
      "Epoch 0 Step 650/1563 Loss: 1.930 | Acc: 29.714% (6190/20832)\n",
      "Epoch 0 Step 651/1563 Loss: 1.930 | Acc: 29.735% (6204/20864)\n",
      "Epoch 0 Step 652/1563 Loss: 1.930 | Acc: 29.747% (6216/20896)\n",
      "Epoch 0 Step 653/1563 Loss: 1.929 | Acc: 29.769% (6230/20928)\n",
      "Epoch 0 Step 654/1563 Loss: 1.929 | Acc: 29.785% (6243/20960)\n",
      "Epoch 0 Step 655/1563 Loss: 1.929 | Acc: 29.773% (6250/20992)\n",
      "Epoch 0 Step 656/1563 Loss: 1.929 | Acc: 29.795% (6264/21024)\n",
      "Epoch 0 Step 657/1563 Loss: 1.929 | Acc: 29.806% (6276/21056)\n",
      "Epoch 0 Step 658/1563 Loss: 1.928 | Acc: 29.827% (6290/21088)\n",
      "Epoch 0 Step 659/1563 Loss: 1.929 | Acc: 29.811% (6296/21120)\n",
      "Epoch 0 Step 660/1563 Loss: 1.929 | Acc: 29.822% (6308/21152)\n",
      "Epoch 0 Step 661/1563 Loss: 1.929 | Acc: 29.820% (6317/21184)\n",
      "Epoch 0 Step 662/1563 Loss: 1.928 | Acc: 29.841% (6331/21216)\n",
      "Epoch 0 Step 663/1563 Loss: 1.928 | Acc: 29.843% (6341/21248)\n",
      "Epoch 0 Step 664/1563 Loss: 1.928 | Acc: 29.864% (6355/21280)\n",
      "Epoch 0 Step 665/1563 Loss: 1.928 | Acc: 29.875% (6367/21312)\n",
      "Epoch 0 Step 666/1563 Loss: 1.927 | Acc: 29.919% (6386/21344)\n",
      "Epoch 0 Step 667/1563 Loss: 1.927 | Acc: 29.917% (6395/21376)\n",
      "Epoch 0 Step 668/1563 Loss: 1.927 | Acc: 29.914% (6404/21408)\n",
      "Epoch 0 Step 669/1563 Loss: 1.927 | Acc: 29.916% (6414/21440)\n",
      "Epoch 0 Step 670/1563 Loss: 1.927 | Acc: 29.923% (6425/21472)\n",
      "Epoch 0 Step 671/1563 Loss: 1.927 | Acc: 29.920% (6434/21504)\n",
      "Epoch 0 Step 672/1563 Loss: 1.927 | Acc: 29.899% (6439/21536)\n",
      "Epoch 0 Step 673/1563 Loss: 1.927 | Acc: 29.910% (6451/21568)\n",
      "Epoch 0 Step 674/1563 Loss: 1.927 | Acc: 29.907% (6460/21600)\n",
      "Epoch 0 Step 675/1563 Loss: 1.927 | Acc: 29.914% (6471/21632)\n",
      "Epoch 0 Step 676/1563 Loss: 1.927 | Acc: 29.925% (6483/21664)\n",
      "Epoch 0 Step 677/1563 Loss: 1.926 | Acc: 29.932% (6494/21696)\n",
      "Epoch 0 Step 678/1563 Loss: 1.926 | Acc: 29.948% (6507/21728)\n",
      "Epoch 0 Step 679/1563 Loss: 1.926 | Acc: 29.940% (6515/21760)\n",
      "Epoch 0 Step 680/1563 Loss: 1.926 | Acc: 29.956% (6528/21792)\n",
      "Epoch 0 Step 681/1563 Loss: 1.925 | Acc: 29.967% (6540/21824)\n",
      "Epoch 0 Step 682/1563 Loss: 1.925 | Acc: 29.973% (6551/21856)\n",
      "Epoch 0 Step 683/1563 Loss: 1.925 | Acc: 29.980% (6562/21888)\n",
      "Epoch 0 Step 684/1563 Loss: 1.925 | Acc: 29.982% (6572/21920)\n",
      "Epoch 0 Step 685/1563 Loss: 1.925 | Acc: 29.988% (6583/21952)\n",
      "Epoch 0 Step 686/1563 Loss: 1.925 | Acc: 29.985% (6592/21984)\n",
      "Epoch 0 Step 687/1563 Loss: 1.925 | Acc: 29.992% (6603/22016)\n",
      "Epoch 0 Step 688/1563 Loss: 1.925 | Acc: 30.003% (6615/22048)\n",
      "Epoch 0 Step 689/1563 Loss: 1.925 | Acc: 30.009% (6626/22080)\n",
      "Epoch 0 Step 690/1563 Loss: 1.924 | Acc: 30.024% (6639/22112)\n",
      "Epoch 0 Step 691/1563 Loss: 1.925 | Acc: 30.026% (6649/22144)\n",
      "Epoch 0 Step 692/1563 Loss: 1.925 | Acc: 30.023% (6658/22176)\n",
      "Epoch 0 Step 693/1563 Loss: 1.924 | Acc: 30.030% (6669/22208)\n",
      "Epoch 0 Step 694/1563 Loss: 1.924 | Acc: 30.022% (6677/22240)\n",
      "Epoch 0 Step 695/1563 Loss: 1.924 | Acc: 30.024% (6687/22272)\n",
      "Epoch 0 Step 696/1563 Loss: 1.923 | Acc: 30.030% (6698/22304)\n",
      "Epoch 0 Step 697/1563 Loss: 1.923 | Acc: 30.046% (6711/22336)\n",
      "Epoch 0 Step 698/1563 Loss: 1.923 | Acc: 30.047% (6721/22368)\n",
      "Epoch 0 Step 699/1563 Loss: 1.923 | Acc: 30.045% (6730/22400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 700/1563 Loss: 1.923 | Acc: 30.064% (6744/22432)\n",
      "Epoch 0 Step 701/1563 Loss: 1.923 | Acc: 30.066% (6754/22464)\n",
      "Epoch 0 Step 702/1563 Loss: 1.923 | Acc: 30.076% (6766/22496)\n",
      "Epoch 0 Step 703/1563 Loss: 1.923 | Acc: 30.083% (6777/22528)\n",
      "Epoch 0 Step 704/1563 Loss: 1.923 | Acc: 30.093% (6789/22560)\n",
      "Epoch 0 Step 705/1563 Loss: 1.923 | Acc: 30.081% (6796/22592)\n",
      "Epoch 0 Step 706/1563 Loss: 1.922 | Acc: 30.083% (6806/22624)\n",
      "Epoch 0 Step 707/1563 Loss: 1.922 | Acc: 30.076% (6814/22656)\n",
      "Epoch 0 Step 708/1563 Loss: 1.922 | Acc: 30.078% (6824/22688)\n",
      "Epoch 0 Step 709/1563 Loss: 1.923 | Acc: 30.066% (6831/22720)\n",
      "Epoch 0 Step 710/1563 Loss: 1.922 | Acc: 30.059% (6839/22752)\n",
      "Epoch 0 Step 711/1563 Loss: 1.922 | Acc: 30.069% (6851/22784)\n",
      "Epoch 0 Step 712/1563 Loss: 1.922 | Acc: 30.075% (6862/22816)\n",
      "Epoch 0 Step 713/1563 Loss: 1.922 | Acc: 30.077% (6872/22848)\n",
      "Epoch 0 Step 714/1563 Loss: 1.921 | Acc: 30.114% (6890/22880)\n",
      "Epoch 0 Step 715/1563 Loss: 1.921 | Acc: 30.120% (6901/22912)\n",
      "Epoch 0 Step 716/1563 Loss: 1.921 | Acc: 30.130% (6913/22944)\n",
      "Epoch 0 Step 717/1563 Loss: 1.921 | Acc: 30.127% (6922/22976)\n",
      "Epoch 0 Step 718/1563 Loss: 1.921 | Acc: 30.142% (6935/23008)\n",
      "Epoch 0 Step 719/1563 Loss: 1.921 | Acc: 30.139% (6944/23040)\n",
      "Epoch 0 Step 720/1563 Loss: 1.920 | Acc: 30.175% (6962/23072)\n",
      "Epoch 0 Step 721/1563 Loss: 1.920 | Acc: 30.185% (6974/23104)\n",
      "Epoch 0 Step 722/1563 Loss: 1.920 | Acc: 30.204% (6988/23136)\n",
      "Epoch 0 Step 723/1563 Loss: 1.920 | Acc: 30.210% (6999/23168)\n",
      "Epoch 0 Step 724/1563 Loss: 1.920 | Acc: 30.207% (7008/23200)\n",
      "Epoch 0 Step 725/1563 Loss: 1.920 | Acc: 30.200% (7016/23232)\n",
      "Epoch 0 Step 726/1563 Loss: 1.920 | Acc: 30.197% (7025/23264)\n",
      "Epoch 0 Step 727/1563 Loss: 1.920 | Acc: 30.185% (7032/23296)\n",
      "Epoch 0 Step 728/1563 Loss: 1.920 | Acc: 30.187% (7042/23328)\n",
      "Epoch 0 Step 729/1563 Loss: 1.919 | Acc: 30.205% (7056/23360)\n",
      "Epoch 0 Step 730/1563 Loss: 1.919 | Acc: 30.224% (7070/23392)\n",
      "Epoch 0 Step 731/1563 Loss: 1.919 | Acc: 30.213% (7077/23424)\n",
      "Epoch 0 Step 732/1563 Loss: 1.919 | Acc: 30.227% (7090/23456)\n",
      "Epoch 0 Step 733/1563 Loss: 1.919 | Acc: 30.228% (7100/23488)\n",
      "Epoch 0 Step 734/1563 Loss: 1.918 | Acc: 30.247% (7114/23520)\n",
      "Epoch 0 Step 735/1563 Loss: 1.918 | Acc: 30.252% (7125/23552)\n",
      "Epoch 0 Step 736/1563 Loss: 1.918 | Acc: 30.245% (7133/23584)\n",
      "Epoch 0 Step 737/1563 Loss: 1.918 | Acc: 30.246% (7143/23616)\n",
      "Epoch 0 Step 738/1563 Loss: 1.918 | Acc: 30.256% (7155/23648)\n",
      "Epoch 0 Step 739/1563 Loss: 1.918 | Acc: 30.266% (7167/23680)\n",
      "Epoch 0 Step 740/1563 Loss: 1.918 | Acc: 30.276% (7179/23712)\n",
      "Epoch 0 Step 741/1563 Loss: 1.918 | Acc: 30.269% (7187/23744)\n",
      "Epoch 0 Step 742/1563 Loss: 1.918 | Acc: 30.270% (7197/23776)\n",
      "Epoch 0 Step 743/1563 Loss: 1.917 | Acc: 30.276% (7208/23808)\n",
      "Epoch 0 Step 744/1563 Loss: 1.917 | Acc: 30.285% (7220/23840)\n",
      "Epoch 0 Step 745/1563 Loss: 1.917 | Acc: 30.287% (7230/23872)\n",
      "Epoch 0 Step 746/1563 Loss: 1.917 | Acc: 30.313% (7246/23904)\n",
      "Epoch 0 Step 747/1563 Loss: 1.917 | Acc: 30.306% (7254/23936)\n",
      "Epoch 0 Step 748/1563 Loss: 1.917 | Acc: 30.315% (7266/23968)\n",
      "Epoch 0 Step 749/1563 Loss: 1.917 | Acc: 30.317% (7276/24000)\n",
      "Epoch 0 Step 750/1563 Loss: 1.917 | Acc: 30.360% (7296/24032)\n",
      "Epoch 0 Step 751/1563 Loss: 1.917 | Acc: 30.352% (7304/24064)\n",
      "Epoch 0 Step 752/1563 Loss: 1.917 | Acc: 30.366% (7317/24096)\n",
      "Epoch 0 Step 753/1563 Loss: 1.917 | Acc: 30.367% (7327/24128)\n",
      "Epoch 0 Step 754/1563 Loss: 1.916 | Acc: 30.385% (7341/24160)\n",
      "Epoch 0 Step 755/1563 Loss: 1.916 | Acc: 30.386% (7351/24192)\n",
      "Epoch 0 Step 756/1563 Loss: 1.916 | Acc: 30.375% (7358/24224)\n",
      "Epoch 0 Step 757/1563 Loss: 1.916 | Acc: 30.388% (7371/24256)\n",
      "Epoch 0 Step 758/1563 Loss: 1.917 | Acc: 30.369% (7376/24288)\n",
      "Epoch 0 Step 759/1563 Loss: 1.917 | Acc: 30.350% (7381/24320)\n",
      "Epoch 0 Step 760/1563 Loss: 1.917 | Acc: 30.359% (7393/24352)\n",
      "Epoch 0 Step 761/1563 Loss: 1.917 | Acc: 30.364% (7404/24384)\n",
      "Epoch 0 Step 762/1563 Loss: 1.917 | Acc: 30.374% (7416/24416)\n",
      "Epoch 0 Step 763/1563 Loss: 1.917 | Acc: 30.366% (7424/24448)\n",
      "Epoch 0 Step 764/1563 Loss: 1.917 | Acc: 30.351% (7430/24480)\n",
      "Epoch 0 Step 765/1563 Loss: 1.917 | Acc: 30.348% (7439/24512)\n",
      "Epoch 0 Step 766/1563 Loss: 1.916 | Acc: 30.350% (7449/24544)\n",
      "Epoch 0 Step 767/1563 Loss: 1.917 | Acc: 30.347% (7458/24576)\n",
      "Epoch 0 Step 768/1563 Loss: 1.916 | Acc: 30.368% (7473/24608)\n",
      "Epoch 0 Step 769/1563 Loss: 1.916 | Acc: 30.381% (7486/24640)\n",
      "Epoch 0 Step 770/1563 Loss: 1.916 | Acc: 30.395% (7499/24672)\n",
      "Epoch 0 Step 771/1563 Loss: 1.916 | Acc: 30.408% (7512/24704)\n",
      "Epoch 0 Step 772/1563 Loss: 1.915 | Acc: 30.409% (7522/24736)\n",
      "Epoch 0 Step 773/1563 Loss: 1.915 | Acc: 30.426% (7536/24768)\n",
      "Epoch 0 Step 774/1563 Loss: 1.915 | Acc: 30.444% (7550/24800)\n",
      "Epoch 0 Step 775/1563 Loss: 1.915 | Acc: 30.449% (7561/24832)\n",
      "Epoch 0 Step 776/1563 Loss: 1.915 | Acc: 30.458% (7573/24864)\n",
      "Epoch 0 Step 777/1563 Loss: 1.915 | Acc: 30.467% (7585/24896)\n",
      "Epoch 0 Step 778/1563 Loss: 1.915 | Acc: 30.456% (7592/24928)\n",
      "Epoch 0 Step 779/1563 Loss: 1.915 | Acc: 30.453% (7601/24960)\n",
      "Epoch 0 Step 780/1563 Loss: 1.915 | Acc: 30.446% (7609/24992)\n",
      "Epoch 0 Step 781/1563 Loss: 1.915 | Acc: 30.459% (7622/25024)\n",
      "Epoch 0 Step 782/1563 Loss: 1.914 | Acc: 30.480% (7637/25056)\n",
      "Epoch 0 Step 783/1563 Loss: 1.914 | Acc: 30.497% (7651/25088)\n",
      "Epoch 0 Step 784/1563 Loss: 1.914 | Acc: 30.502% (7662/25120)\n",
      "Epoch 0 Step 785/1563 Loss: 1.914 | Acc: 30.499% (7671/25152)\n",
      "Epoch 0 Step 786/1563 Loss: 1.914 | Acc: 30.507% (7683/25184)\n",
      "Epoch 0 Step 787/1563 Loss: 1.914 | Acc: 30.508% (7693/25216)\n",
      "Epoch 0 Step 788/1563 Loss: 1.914 | Acc: 30.529% (7708/25248)\n",
      "Epoch 0 Step 789/1563 Loss: 1.914 | Acc: 30.526% (7717/25280)\n",
      "Epoch 0 Step 790/1563 Loss: 1.914 | Acc: 30.527% (7727/25312)\n",
      "Epoch 0 Step 791/1563 Loss: 1.914 | Acc: 30.548% (7742/25344)\n",
      "Epoch 0 Step 792/1563 Loss: 1.913 | Acc: 30.549% (7752/25376)\n",
      "Epoch 0 Step 793/1563 Loss: 1.913 | Acc: 30.538% (7759/25408)\n",
      "Epoch 0 Step 794/1563 Loss: 1.913 | Acc: 30.539% (7769/25440)\n",
      "Epoch 0 Step 795/1563 Loss: 1.913 | Acc: 30.543% (7780/25472)\n",
      "Epoch 0 Step 796/1563 Loss: 1.913 | Acc: 30.560% (7794/25504)\n",
      "Epoch 0 Step 797/1563 Loss: 1.913 | Acc: 30.569% (7806/25536)\n",
      "Epoch 0 Step 798/1563 Loss: 1.913 | Acc: 30.577% (7818/25568)\n",
      "Epoch 0 Step 799/1563 Loss: 1.913 | Acc: 30.574% (7827/25600)\n",
      "Epoch 0 Step 800/1563 Loss: 1.913 | Acc: 30.579% (7838/25632)\n",
      "Epoch 0 Step 801/1563 Loss: 1.913 | Acc: 30.591% (7851/25664)\n",
      "Epoch 0 Step 802/1563 Loss: 1.913 | Acc: 30.585% (7859/25696)\n",
      "Epoch 0 Step 803/1563 Loss: 1.913 | Acc: 30.566% (7864/25728)\n",
      "Epoch 0 Step 804/1563 Loss: 1.913 | Acc: 30.555% (7871/25760)\n",
      "Epoch 0 Step 805/1563 Loss: 1.913 | Acc: 30.568% (7884/25792)\n",
      "Epoch 0 Step 806/1563 Loss: 1.913 | Acc: 30.588% (7899/25824)\n",
      "Epoch 0 Step 807/1563 Loss: 1.913 | Acc: 30.593% (7910/25856)\n",
      "Epoch 0 Step 808/1563 Loss: 1.913 | Acc: 30.582% (7917/25888)\n",
      "Epoch 0 Step 809/1563 Loss: 1.912 | Acc: 30.594% (7930/25920)\n",
      "Epoch 0 Step 810/1563 Loss: 1.913 | Acc: 30.591% (7939/25952)\n",
      "Epoch 0 Step 811/1563 Loss: 1.913 | Acc: 30.588% (7948/25984)\n",
      "Epoch 0 Step 812/1563 Loss: 1.913 | Acc: 30.593% (7959/26016)\n",
      "Epoch 0 Step 813/1563 Loss: 1.913 | Acc: 30.597% (7970/26048)\n",
      "Epoch 0 Step 814/1563 Loss: 1.912 | Acc: 30.610% (7983/26080)\n",
      "Epoch 0 Step 815/1563 Loss: 1.912 | Acc: 30.610% (7993/26112)\n",
      "Epoch 0 Step 816/1563 Loss: 1.912 | Acc: 30.623% (8006/26144)\n",
      "Epoch 0 Step 817/1563 Loss: 1.912 | Acc: 30.631% (8018/26176)\n",
      "Epoch 0 Step 818/1563 Loss: 1.912 | Acc: 30.632% (8028/26208)\n",
      "Epoch 0 Step 819/1563 Loss: 1.912 | Acc: 30.640% (8040/26240)\n",
      "Epoch 0 Step 820/1563 Loss: 1.912 | Acc: 30.649% (8052/26272)\n",
      "Epoch 0 Step 821/1563 Loss: 1.912 | Acc: 30.649% (8062/26304)\n",
      "Epoch 0 Step 822/1563 Loss: 1.912 | Acc: 30.658% (8074/26336)\n",
      "Epoch 0 Step 823/1563 Loss: 1.912 | Acc: 30.655% (8083/26368)\n",
      "Epoch 0 Step 824/1563 Loss: 1.911 | Acc: 30.678% (8099/26400)\n",
      "Epoch 0 Step 825/1563 Loss: 1.911 | Acc: 30.679% (8109/26432)\n",
      "Epoch 0 Step 826/1563 Loss: 1.911 | Acc: 30.698% (8124/26464)\n",
      "Epoch 0 Step 827/1563 Loss: 1.911 | Acc: 30.703% (8135/26496)\n",
      "Epoch 0 Step 828/1563 Loss: 1.911 | Acc: 30.688% (8141/26528)\n",
      "Epoch 0 Step 829/1563 Loss: 1.911 | Acc: 30.681% (8149/26560)\n",
      "Epoch 0 Step 830/1563 Loss: 1.911 | Acc: 30.678% (8158/26592)\n",
      "Epoch 0 Step 831/1563 Loss: 1.911 | Acc: 30.668% (8165/26624)\n",
      "Epoch 0 Step 832/1563 Loss: 1.911 | Acc: 30.676% (8177/26656)\n",
      "Epoch 0 Step 833/1563 Loss: 1.911 | Acc: 30.673% (8186/26688)\n",
      "Epoch 0 Step 834/1563 Loss: 1.911 | Acc: 30.677% (8197/26720)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 835/1563 Loss: 1.911 | Acc: 30.693% (8211/26752)\n",
      "Epoch 0 Step 836/1563 Loss: 1.911 | Acc: 30.694% (8221/26784)\n",
      "Epoch 0 Step 837/1563 Loss: 1.910 | Acc: 30.702% (8233/26816)\n",
      "Epoch 0 Step 838/1563 Loss: 1.910 | Acc: 30.695% (8241/26848)\n",
      "Epoch 0 Step 839/1563 Loss: 1.910 | Acc: 30.696% (8251/26880)\n",
      "Epoch 0 Step 840/1563 Loss: 1.910 | Acc: 30.689% (8259/26912)\n",
      "Epoch 0 Step 841/1563 Loss: 1.910 | Acc: 30.671% (8264/26944)\n",
      "Epoch 0 Step 842/1563 Loss: 1.911 | Acc: 30.668% (8273/26976)\n",
      "Epoch 0 Step 843/1563 Loss: 1.910 | Acc: 30.680% (8286/27008)\n",
      "Epoch 0 Step 844/1563 Loss: 1.910 | Acc: 30.692% (8299/27040)\n",
      "Epoch 0 Step 845/1563 Loss: 1.910 | Acc: 30.696% (8310/27072)\n",
      "Epoch 0 Step 846/1563 Loss: 1.910 | Acc: 30.700% (8321/27104)\n",
      "Epoch 0 Step 847/1563 Loss: 1.910 | Acc: 30.697% (8330/27136)\n",
      "Epoch 0 Step 848/1563 Loss: 1.910 | Acc: 30.705% (8342/27168)\n",
      "Epoch 0 Step 849/1563 Loss: 1.910 | Acc: 30.710% (8353/27200)\n",
      "Epoch 0 Step 850/1563 Loss: 1.910 | Acc: 30.710% (8363/27232)\n",
      "Epoch 0 Step 851/1563 Loss: 1.909 | Acc: 30.737% (8380/27264)\n",
      "Epoch 0 Step 852/1563 Loss: 1.909 | Acc: 30.722% (8386/27296)\n",
      "Epoch 0 Step 853/1563 Loss: 1.909 | Acc: 30.719% (8395/27328)\n",
      "Epoch 0 Step 854/1563 Loss: 1.909 | Acc: 30.731% (8408/27360)\n",
      "Epoch 0 Step 855/1563 Loss: 1.909 | Acc: 30.717% (8414/27392)\n",
      "Epoch 0 Step 856/1563 Loss: 1.910 | Acc: 30.710% (8422/27424)\n",
      "Epoch 0 Step 857/1563 Loss: 1.909 | Acc: 30.722% (8435/27456)\n",
      "Epoch 0 Step 858/1563 Loss: 1.909 | Acc: 30.733% (8448/27488)\n",
      "Epoch 0 Step 859/1563 Loss: 1.909 | Acc: 30.738% (8459/27520)\n",
      "Epoch 0 Step 860/1563 Loss: 1.909 | Acc: 30.742% (8470/27552)\n",
      "Epoch 0 Step 861/1563 Loss: 1.908 | Acc: 30.753% (8483/27584)\n",
      "Epoch 0 Step 862/1563 Loss: 1.908 | Acc: 30.761% (8495/27616)\n",
      "Epoch 0 Step 863/1563 Loss: 1.908 | Acc: 30.765% (8506/27648)\n",
      "Epoch 0 Step 864/1563 Loss: 1.908 | Acc: 30.773% (8518/27680)\n",
      "Epoch 0 Step 865/1563 Loss: 1.907 | Acc: 30.788% (8532/27712)\n",
      "Epoch 0 Step 866/1563 Loss: 1.907 | Acc: 30.792% (8543/27744)\n",
      "Epoch 0 Step 867/1563 Loss: 1.907 | Acc: 30.800% (8555/27776)\n",
      "Epoch 0 Step 868/1563 Loss: 1.907 | Acc: 30.815% (8569/27808)\n",
      "Epoch 0 Step 869/1563 Loss: 1.907 | Acc: 30.823% (8581/27840)\n",
      "Epoch 0 Step 870/1563 Loss: 1.907 | Acc: 30.827% (8592/27872)\n",
      "Epoch 0 Step 871/1563 Loss: 1.906 | Acc: 30.841% (8606/27904)\n",
      "Epoch 0 Step 872/1563 Loss: 1.906 | Acc: 30.849% (8618/27936)\n",
      "Epoch 0 Step 873/1563 Loss: 1.906 | Acc: 30.835% (8624/27968)\n",
      "Epoch 0 Step 874/1563 Loss: 1.906 | Acc: 30.857% (8640/28000)\n",
      "Epoch 0 Step 875/1563 Loss: 1.906 | Acc: 30.872% (8654/28032)\n",
      "Epoch 0 Step 876/1563 Loss: 1.905 | Acc: 30.883% (8667/28064)\n",
      "Epoch 0 Step 877/1563 Loss: 1.905 | Acc: 30.891% (8679/28096)\n",
      "Epoch 0 Step 878/1563 Loss: 1.905 | Acc: 30.898% (8691/28128)\n",
      "Epoch 0 Step 879/1563 Loss: 1.905 | Acc: 30.902% (8702/28160)\n",
      "Epoch 0 Step 880/1563 Loss: 1.905 | Acc: 30.895% (8710/28192)\n",
      "Epoch 0 Step 881/1563 Loss: 1.905 | Acc: 30.896% (8720/28224)\n",
      "Epoch 0 Step 882/1563 Loss: 1.905 | Acc: 30.903% (8732/28256)\n",
      "Epoch 0 Step 883/1563 Loss: 1.905 | Acc: 30.896% (8740/28288)\n",
      "Epoch 0 Step 884/1563 Loss: 1.905 | Acc: 30.890% (8748/28320)\n",
      "Epoch 0 Step 885/1563 Loss: 1.905 | Acc: 30.887% (8757/28352)\n",
      "Epoch 0 Step 886/1563 Loss: 1.904 | Acc: 30.901% (8771/28384)\n",
      "Epoch 0 Step 887/1563 Loss: 1.905 | Acc: 30.898% (8780/28416)\n",
      "Epoch 0 Step 888/1563 Loss: 1.904 | Acc: 30.902% (8791/28448)\n",
      "Epoch 0 Step 889/1563 Loss: 1.904 | Acc: 30.899% (8800/28480)\n",
      "Epoch 0 Step 890/1563 Loss: 1.904 | Acc: 30.903% (8811/28512)\n",
      "Epoch 0 Step 891/1563 Loss: 1.905 | Acc: 30.903% (8821/28544)\n",
      "Epoch 0 Step 892/1563 Loss: 1.905 | Acc: 30.904% (8831/28576)\n",
      "Epoch 0 Step 893/1563 Loss: 1.905 | Acc: 30.911% (8843/28608)\n",
      "Epoch 0 Step 894/1563 Loss: 1.905 | Acc: 30.904% (8851/28640)\n",
      "Epoch 0 Step 895/1563 Loss: 1.905 | Acc: 30.905% (8861/28672)\n",
      "Epoch 0 Step 896/1563 Loss: 1.905 | Acc: 30.909% (8872/28704)\n",
      "Epoch 0 Step 897/1563 Loss: 1.905 | Acc: 30.909% (8882/28736)\n",
      "Epoch 0 Step 898/1563 Loss: 1.905 | Acc: 30.916% (8894/28768)\n",
      "Epoch 0 Step 899/1563 Loss: 1.905 | Acc: 30.934% (8909/28800)\n",
      "Epoch 0 Step 900/1563 Loss: 1.905 | Acc: 30.941% (8921/28832)\n",
      "Epoch 0 Step 901/1563 Loss: 1.904 | Acc: 30.945% (8932/28864)\n",
      "Epoch 0 Step 902/1563 Loss: 1.904 | Acc: 30.945% (8942/28896)\n",
      "Epoch 0 Step 903/1563 Loss: 1.904 | Acc: 30.939% (8950/28928)\n",
      "Epoch 0 Step 904/1563 Loss: 1.904 | Acc: 30.936% (8959/28960)\n",
      "Epoch 0 Step 905/1563 Loss: 1.904 | Acc: 30.936% (8969/28992)\n",
      "Epoch 0 Step 906/1563 Loss: 1.904 | Acc: 30.957% (8985/29024)\n",
      "Epoch 0 Step 907/1563 Loss: 1.904 | Acc: 30.964% (8997/29056)\n",
      "Epoch 0 Step 908/1563 Loss: 1.904 | Acc: 30.965% (9007/29088)\n",
      "Epoch 0 Step 909/1563 Loss: 1.904 | Acc: 30.968% (9018/29120)\n",
      "Epoch 0 Step 910/1563 Loss: 1.904 | Acc: 30.962% (9026/29152)\n",
      "Epoch 0 Step 911/1563 Loss: 1.904 | Acc: 30.948% (9032/29184)\n",
      "Epoch 0 Step 912/1563 Loss: 1.904 | Acc: 30.952% (9043/29216)\n",
      "Epoch 0 Step 913/1563 Loss: 1.904 | Acc: 30.942% (9050/29248)\n",
      "Epoch 0 Step 914/1563 Loss: 1.904 | Acc: 30.929% (9056/29280)\n",
      "Epoch 0 Step 915/1563 Loss: 1.904 | Acc: 30.929% (9066/29312)\n",
      "Epoch 0 Step 916/1563 Loss: 1.904 | Acc: 30.930% (9076/29344)\n",
      "Epoch 0 Step 917/1563 Loss: 1.904 | Acc: 30.933% (9087/29376)\n",
      "Epoch 0 Step 918/1563 Loss: 1.904 | Acc: 30.937% (9098/29408)\n",
      "Epoch 0 Step 919/1563 Loss: 1.903 | Acc: 30.924% (9104/29440)\n",
      "Epoch 0 Step 920/1563 Loss: 1.903 | Acc: 30.928% (9115/29472)\n",
      "Epoch 0 Step 921/1563 Loss: 1.903 | Acc: 30.938% (9128/29504)\n",
      "Epoch 0 Step 922/1563 Loss: 1.903 | Acc: 30.932% (9136/29536)\n",
      "Epoch 0 Step 923/1563 Loss: 1.903 | Acc: 30.935% (9147/29568)\n",
      "Epoch 0 Step 924/1563 Loss: 1.903 | Acc: 30.929% (9155/29600)\n",
      "Epoch 0 Step 925/1563 Loss: 1.903 | Acc: 30.940% (9168/29632)\n",
      "Epoch 0 Step 926/1563 Loss: 1.903 | Acc: 30.933% (9176/29664)\n",
      "Epoch 0 Step 927/1563 Loss: 1.903 | Acc: 30.937% (9187/29696)\n",
      "Epoch 0 Step 928/1563 Loss: 1.903 | Acc: 30.937% (9197/29728)\n",
      "Epoch 0 Step 929/1563 Loss: 1.902 | Acc: 30.951% (9211/29760)\n",
      "Epoch 0 Step 930/1563 Loss: 1.902 | Acc: 30.955% (9222/29792)\n",
      "Epoch 0 Step 931/1563 Loss: 1.902 | Acc: 30.972% (9237/29824)\n",
      "Epoch 0 Step 932/1563 Loss: 1.902 | Acc: 30.972% (9247/29856)\n",
      "Epoch 0 Step 933/1563 Loss: 1.902 | Acc: 30.986% (9261/29888)\n",
      "Epoch 0 Step 934/1563 Loss: 1.902 | Acc: 30.983% (9270/29920)\n",
      "Epoch 0 Step 935/1563 Loss: 1.902 | Acc: 30.973% (9277/29952)\n",
      "Epoch 0 Step 936/1563 Loss: 1.902 | Acc: 30.970% (9286/29984)\n",
      "Epoch 0 Step 937/1563 Loss: 1.902 | Acc: 30.983% (9300/30016)\n",
      "Epoch 0 Step 938/1563 Loss: 1.901 | Acc: 30.987% (9311/30048)\n",
      "Epoch 0 Step 939/1563 Loss: 1.901 | Acc: 30.994% (9323/30080)\n",
      "Epoch 0 Step 940/1563 Loss: 1.901 | Acc: 30.981% (9329/30112)\n",
      "Epoch 0 Step 941/1563 Loss: 1.901 | Acc: 30.988% (9341/30144)\n",
      "Epoch 0 Step 942/1563 Loss: 1.901 | Acc: 30.995% (9353/30176)\n",
      "Epoch 0 Step 943/1563 Loss: 1.901 | Acc: 30.992% (9362/30208)\n",
      "Epoch 0 Step 944/1563 Loss: 1.900 | Acc: 30.992% (9372/30240)\n",
      "Epoch 0 Step 945/1563 Loss: 1.900 | Acc: 31.002% (9385/30272)\n",
      "Epoch 0 Step 946/1563 Loss: 1.900 | Acc: 30.996% (9393/30304)\n",
      "Epoch 0 Step 947/1563 Loss: 1.900 | Acc: 31.009% (9407/30336)\n",
      "Epoch 0 Step 948/1563 Loss: 1.900 | Acc: 31.003% (9415/30368)\n",
      "Epoch 0 Step 949/1563 Loss: 1.900 | Acc: 31.023% (9431/30400)\n",
      "Epoch 0 Step 950/1563 Loss: 1.900 | Acc: 31.023% (9441/30432)\n",
      "Epoch 0 Step 951/1563 Loss: 1.900 | Acc: 31.030% (9453/30464)\n",
      "Epoch 0 Step 952/1563 Loss: 1.899 | Acc: 31.027% (9462/30496)\n",
      "Epoch 0 Step 953/1563 Loss: 1.899 | Acc: 31.027% (9472/30528)\n",
      "Epoch 0 Step 954/1563 Loss: 1.899 | Acc: 31.037% (9485/30560)\n",
      "Epoch 0 Step 955/1563 Loss: 1.899 | Acc: 31.044% (9497/30592)\n",
      "Epoch 0 Step 956/1563 Loss: 1.899 | Acc: 31.048% (9508/30624)\n",
      "Epoch 0 Step 957/1563 Loss: 1.899 | Acc: 31.058% (9521/30656)\n",
      "Epoch 0 Step 958/1563 Loss: 1.899 | Acc: 31.064% (9533/30688)\n",
      "Epoch 0 Step 959/1563 Loss: 1.899 | Acc: 31.064% (9543/30720)\n",
      "Epoch 0 Step 960/1563 Loss: 1.898 | Acc: 31.084% (9559/30752)\n",
      "Epoch 0 Step 961/1563 Loss: 1.898 | Acc: 31.097% (9573/30784)\n",
      "Epoch 0 Step 962/1563 Loss: 1.898 | Acc: 31.110% (9587/30816)\n",
      "Epoch 0 Step 963/1563 Loss: 1.898 | Acc: 31.114% (9598/30848)\n",
      "Epoch 0 Step 964/1563 Loss: 1.898 | Acc: 31.114% (9608/30880)\n",
      "Epoch 0 Step 965/1563 Loss: 1.897 | Acc: 31.130% (9623/30912)\n",
      "Epoch 0 Step 966/1563 Loss: 1.898 | Acc: 31.121% (9630/30944)\n",
      "Epoch 0 Step 967/1563 Loss: 1.898 | Acc: 31.124% (9641/30976)\n",
      "Epoch 0 Step 968/1563 Loss: 1.898 | Acc: 31.147% (9658/31008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 969/1563 Loss: 1.897 | Acc: 31.160% (9672/31040)\n",
      "Epoch 0 Step 970/1563 Loss: 1.897 | Acc: 31.157% (9681/31072)\n",
      "Epoch 0 Step 971/1563 Loss: 1.897 | Acc: 31.170% (9695/31104)\n",
      "Epoch 0 Step 972/1563 Loss: 1.896 | Acc: 31.189% (9711/31136)\n",
      "Epoch 0 Step 973/1563 Loss: 1.896 | Acc: 31.205% (9726/31168)\n",
      "Epoch 0 Step 974/1563 Loss: 1.896 | Acc: 31.212% (9738/31200)\n",
      "Epoch 0 Step 975/1563 Loss: 1.896 | Acc: 31.218% (9750/31232)\n",
      "Epoch 0 Step 976/1563 Loss: 1.895 | Acc: 31.224% (9762/31264)\n",
      "Epoch 0 Step 977/1563 Loss: 1.896 | Acc: 31.218% (9770/31296)\n",
      "Epoch 0 Step 978/1563 Loss: 1.895 | Acc: 31.234% (9785/31328)\n",
      "Epoch 0 Step 979/1563 Loss: 1.895 | Acc: 31.240% (9797/31360)\n",
      "Epoch 0 Step 980/1563 Loss: 1.895 | Acc: 31.253% (9811/31392)\n",
      "Epoch 0 Step 981/1563 Loss: 1.895 | Acc: 31.263% (9824/31424)\n",
      "Epoch 0 Step 982/1563 Loss: 1.895 | Acc: 31.269% (9836/31456)\n",
      "Epoch 0 Step 983/1563 Loss: 1.895 | Acc: 31.282% (9850/31488)\n",
      "Epoch 0 Step 984/1563 Loss: 1.895 | Acc: 31.279% (9859/31520)\n",
      "Epoch 0 Step 985/1563 Loss: 1.894 | Acc: 31.301% (9876/31552)\n",
      "Epoch 0 Step 986/1563 Loss: 1.894 | Acc: 31.307% (9888/31584)\n",
      "Epoch 0 Step 987/1563 Loss: 1.894 | Acc: 31.310% (9899/31616)\n",
      "Epoch 0 Step 988/1563 Loss: 1.894 | Acc: 31.316% (9911/31648)\n",
      "Epoch 0 Step 989/1563 Loss: 1.894 | Acc: 31.313% (9920/31680)\n",
      "Epoch 0 Step 990/1563 Loss: 1.894 | Acc: 31.313% (9930/31712)\n",
      "Epoch 0 Step 991/1563 Loss: 1.894 | Acc: 31.326% (9944/31744)\n",
      "Epoch 0 Step 992/1563 Loss: 1.894 | Acc: 31.316% (9951/31776)\n",
      "Epoch 0 Step 993/1563 Loss: 1.894 | Acc: 31.319% (9962/31808)\n",
      "Epoch 0 Step 994/1563 Loss: 1.894 | Acc: 31.319% (9972/31840)\n",
      "Epoch 0 Step 995/1563 Loss: 1.894 | Acc: 31.322% (9983/31872)\n",
      "Epoch 0 Step 996/1563 Loss: 1.894 | Acc: 31.331% (9996/31904)\n",
      "Epoch 0 Step 997/1563 Loss: 1.894 | Acc: 31.341% (10009/31936)\n",
      "Epoch 0 Step 998/1563 Loss: 1.893 | Acc: 31.353% (10023/31968)\n",
      "Epoch 0 Step 999/1563 Loss: 1.893 | Acc: 31.359% (10035/32000)\n",
      "Epoch 0 Step 1000/1563 Loss: 1.893 | Acc: 31.384% (10053/32032)\n",
      "Epoch 0 Step 1001/1563 Loss: 1.893 | Acc: 31.393% (10066/32064)\n",
      "Epoch 0 Step 1002/1563 Loss: 1.893 | Acc: 31.396% (10077/32096)\n",
      "Epoch 0 Step 1003/1563 Loss: 1.892 | Acc: 31.390% (10085/32128)\n",
      "Epoch 0 Step 1004/1563 Loss: 1.892 | Acc: 31.399% (10098/32160)\n",
      "Epoch 0 Step 1005/1563 Loss: 1.892 | Acc: 31.405% (10110/32192)\n",
      "Epoch 0 Step 1006/1563 Loss: 1.892 | Acc: 31.405% (10120/32224)\n",
      "Epoch 0 Step 1007/1563 Loss: 1.892 | Acc: 31.408% (10131/32256)\n",
      "Epoch 0 Step 1008/1563 Loss: 1.891 | Acc: 31.402% (10139/32288)\n",
      "Epoch 0 Step 1009/1563 Loss: 1.892 | Acc: 31.392% (10146/32320)\n",
      "Epoch 0 Step 1010/1563 Loss: 1.892 | Acc: 31.392% (10156/32352)\n",
      "Epoch 0 Step 1011/1563 Loss: 1.892 | Acc: 31.398% (10168/32384)\n",
      "Epoch 0 Step 1012/1563 Loss: 1.891 | Acc: 31.404% (10180/32416)\n",
      "Epoch 0 Step 1013/1563 Loss: 1.891 | Acc: 31.413% (10193/32448)\n",
      "Epoch 0 Step 1014/1563 Loss: 1.891 | Acc: 31.416% (10204/32480)\n",
      "Epoch 0 Step 1015/1563 Loss: 1.891 | Acc: 31.425% (10217/32512)\n",
      "Epoch 0 Step 1016/1563 Loss: 1.891 | Acc: 31.422% (10226/32544)\n",
      "Epoch 0 Step 1017/1563 Loss: 1.891 | Acc: 31.397% (10228/32576)\n",
      "Epoch 0 Step 1018/1563 Loss: 1.891 | Acc: 31.397% (10238/32608)\n",
      "Epoch 0 Step 1019/1563 Loss: 1.891 | Acc: 31.409% (10252/32640)\n",
      "Epoch 0 Step 1020/1563 Loss: 1.891 | Acc: 31.403% (10260/32672)\n",
      "Epoch 0 Step 1021/1563 Loss: 1.891 | Acc: 31.406% (10271/32704)\n",
      "Epoch 0 Step 1022/1563 Loss: 1.891 | Acc: 31.400% (10279/32736)\n",
      "Epoch 0 Step 1023/1563 Loss: 1.891 | Acc: 31.403% (10290/32768)\n",
      "Epoch 0 Step 1024/1563 Loss: 1.891 | Acc: 31.396% (10298/32800)\n",
      "Epoch 0 Step 1025/1563 Loss: 1.891 | Acc: 31.390% (10306/32832)\n",
      "Epoch 0 Step 1026/1563 Loss: 1.890 | Acc: 31.399% (10319/32864)\n",
      "Epoch 0 Step 1027/1563 Loss: 1.890 | Acc: 31.405% (10331/32896)\n",
      "Epoch 0 Step 1028/1563 Loss: 1.890 | Acc: 31.405% (10341/32928)\n",
      "Epoch 0 Step 1029/1563 Loss: 1.891 | Acc: 31.393% (10347/32960)\n",
      "Epoch 0 Step 1030/1563 Loss: 1.891 | Acc: 31.395% (10358/32992)\n",
      "Epoch 0 Step 1031/1563 Loss: 1.890 | Acc: 31.407% (10372/33024)\n",
      "Epoch 0 Step 1032/1563 Loss: 1.890 | Acc: 31.410% (10383/33056)\n",
      "Epoch 0 Step 1033/1563 Loss: 1.890 | Acc: 31.410% (10393/33088)\n",
      "Epoch 0 Step 1034/1563 Loss: 1.890 | Acc: 31.422% (10407/33120)\n",
      "Epoch 0 Step 1035/1563 Loss: 1.890 | Acc: 31.425% (10418/33152)\n",
      "Epoch 0 Step 1036/1563 Loss: 1.890 | Acc: 31.437% (10432/33184)\n",
      "Epoch 0 Step 1037/1563 Loss: 1.890 | Acc: 31.449% (10446/33216)\n",
      "Epoch 0 Step 1038/1563 Loss: 1.890 | Acc: 31.452% (10457/33248)\n",
      "Epoch 0 Step 1039/1563 Loss: 1.889 | Acc: 31.457% (10469/33280)\n",
      "Epoch 0 Step 1040/1563 Loss: 1.889 | Acc: 31.469% (10483/33312)\n",
      "Epoch 0 Step 1041/1563 Loss: 1.889 | Acc: 31.472% (10494/33344)\n",
      "Epoch 0 Step 1042/1563 Loss: 1.889 | Acc: 31.484% (10508/33376)\n",
      "Epoch 0 Step 1043/1563 Loss: 1.889 | Acc: 31.483% (10518/33408)\n",
      "Epoch 0 Step 1044/1563 Loss: 1.889 | Acc: 31.492% (10531/33440)\n",
      "Epoch 0 Step 1045/1563 Loss: 1.889 | Acc: 31.498% (10543/33472)\n",
      "Epoch 0 Step 1046/1563 Loss: 1.889 | Acc: 31.507% (10556/33504)\n",
      "Epoch 0 Step 1047/1563 Loss: 1.889 | Acc: 31.515% (10569/33536)\n",
      "Epoch 0 Step 1048/1563 Loss: 1.888 | Acc: 31.533% (10585/33568)\n",
      "Epoch 0 Step 1049/1563 Loss: 1.888 | Acc: 31.539% (10597/33600)\n",
      "Epoch 0 Step 1050/1563 Loss: 1.888 | Acc: 31.547% (10610/33632)\n",
      "Epoch 0 Step 1051/1563 Loss: 1.888 | Acc: 31.553% (10622/33664)\n",
      "Epoch 0 Step 1052/1563 Loss: 1.888 | Acc: 31.565% (10636/33696)\n",
      "Epoch 0 Step 1053/1563 Loss: 1.887 | Acc: 31.579% (10651/33728)\n",
      "Epoch 0 Step 1054/1563 Loss: 1.887 | Acc: 31.576% (10660/33760)\n",
      "Epoch 0 Step 1055/1563 Loss: 1.887 | Acc: 31.590% (10675/33792)\n",
      "Epoch 0 Step 1056/1563 Loss: 1.887 | Acc: 31.593% (10686/33824)\n",
      "Epoch 0 Step 1057/1563 Loss: 1.887 | Acc: 31.613% (10703/33856)\n",
      "Epoch 0 Step 1058/1563 Loss: 1.887 | Acc: 31.619% (10715/33888)\n",
      "Epoch 0 Step 1059/1563 Loss: 1.887 | Acc: 31.624% (10727/33920)\n",
      "Epoch 0 Step 1060/1563 Loss: 1.887 | Acc: 31.633% (10740/33952)\n",
      "Epoch 0 Step 1061/1563 Loss: 1.887 | Acc: 31.633% (10750/33984)\n",
      "Epoch 0 Step 1062/1563 Loss: 1.887 | Acc: 31.638% (10762/34016)\n",
      "Epoch 0 Step 1063/1563 Loss: 1.887 | Acc: 31.644% (10774/34048)\n",
      "Epoch 0 Step 1064/1563 Loss: 1.887 | Acc: 31.637% (10782/34080)\n",
      "Epoch 0 Step 1065/1563 Loss: 1.886 | Acc: 31.640% (10793/34112)\n",
      "Epoch 0 Step 1066/1563 Loss: 1.886 | Acc: 31.640% (10803/34144)\n",
      "Epoch 0 Step 1067/1563 Loss: 1.886 | Acc: 31.639% (10813/34176)\n",
      "Epoch 0 Step 1068/1563 Loss: 1.886 | Acc: 31.642% (10824/34208)\n",
      "Epoch 0 Step 1069/1563 Loss: 1.886 | Acc: 31.633% (10831/34240)\n",
      "Epoch 0 Step 1070/1563 Loss: 1.886 | Acc: 31.635% (10842/34272)\n",
      "Epoch 0 Step 1071/1563 Loss: 1.886 | Acc: 31.649% (10857/34304)\n",
      "Epoch 0 Step 1072/1563 Loss: 1.886 | Acc: 31.652% (10868/34336)\n",
      "Epoch 0 Step 1073/1563 Loss: 1.886 | Acc: 31.660% (10881/34368)\n",
      "Epoch 0 Step 1074/1563 Loss: 1.886 | Acc: 31.666% (10893/34400)\n",
      "Epoch 0 Step 1075/1563 Loss: 1.886 | Acc: 31.677% (10907/34432)\n",
      "Epoch 0 Step 1076/1563 Loss: 1.886 | Acc: 31.679% (10918/34464)\n",
      "Epoch 0 Step 1077/1563 Loss: 1.885 | Acc: 31.676% (10927/34496)\n",
      "Epoch 0 Step 1078/1563 Loss: 1.885 | Acc: 31.673% (10936/34528)\n",
      "Epoch 0 Step 1079/1563 Loss: 1.885 | Acc: 31.687% (10951/34560)\n",
      "Epoch 0 Step 1080/1563 Loss: 1.885 | Acc: 31.707% (10968/34592)\n",
      "Epoch 0 Step 1081/1563 Loss: 1.885 | Acc: 31.698% (10975/34624)\n",
      "Epoch 0 Step 1082/1563 Loss: 1.885 | Acc: 31.694% (10984/34656)\n",
      "Epoch 0 Step 1083/1563 Loss: 1.884 | Acc: 31.691% (10993/34688)\n",
      "Epoch 0 Step 1084/1563 Loss: 1.884 | Acc: 31.679% (10999/34720)\n",
      "Epoch 0 Step 1085/1563 Loss: 1.884 | Acc: 31.676% (11008/34752)\n",
      "Epoch 0 Step 1086/1563 Loss: 1.884 | Acc: 31.690% (11023/34784)\n",
      "Epoch 0 Step 1087/1563 Loss: 1.884 | Acc: 31.695% (11035/34816)\n",
      "Epoch 0 Step 1088/1563 Loss: 1.884 | Acc: 31.689% (11043/34848)\n",
      "Epoch 0 Step 1089/1563 Loss: 1.884 | Acc: 31.689% (11053/34880)\n",
      "Epoch 0 Step 1090/1563 Loss: 1.884 | Acc: 31.694% (11065/34912)\n",
      "Epoch 0 Step 1091/1563 Loss: 1.884 | Acc: 31.714% (11082/34944)\n",
      "Epoch 0 Step 1092/1563 Loss: 1.884 | Acc: 31.719% (11094/34976)\n",
      "Epoch 0 Step 1093/1563 Loss: 1.883 | Acc: 31.724% (11106/35008)\n",
      "Epoch 0 Step 1094/1563 Loss: 1.883 | Acc: 31.738% (11121/35040)\n",
      "Epoch 0 Step 1095/1563 Loss: 1.883 | Acc: 31.740% (11132/35072)\n",
      "Epoch 0 Step 1096/1563 Loss: 1.883 | Acc: 31.749% (11145/35104)\n",
      "Epoch 0 Step 1097/1563 Loss: 1.883 | Acc: 31.762% (11160/35136)\n",
      "Epoch 0 Step 1098/1563 Loss: 1.883 | Acc: 31.759% (11169/35168)\n",
      "Epoch 0 Step 1099/1563 Loss: 1.883 | Acc: 31.756% (11178/35200)\n",
      "Epoch 0 Step 1100/1563 Loss: 1.883 | Acc: 31.747% (11185/35232)\n",
      "Epoch 0 Step 1101/1563 Loss: 1.882 | Acc: 31.760% (11200/35264)\n",
      "Epoch 0 Step 1102/1563 Loss: 1.882 | Acc: 31.763% (11211/35296)\n",
      "Epoch 0 Step 1103/1563 Loss: 1.882 | Acc: 31.771% (11224/35328)\n",
      "Epoch 0 Step 1104/1563 Loss: 1.882 | Acc: 31.765% (11232/35360)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 1105/1563 Loss: 1.882 | Acc: 31.776% (11246/35392)\n",
      "Epoch 0 Step 1106/1563 Loss: 1.881 | Acc: 31.784% (11259/35424)\n",
      "Epoch 0 Step 1107/1563 Loss: 1.881 | Acc: 31.792% (11272/35456)\n",
      "Epoch 0 Step 1108/1563 Loss: 1.881 | Acc: 31.791% (11282/35488)\n",
      "Epoch 0 Step 1109/1563 Loss: 1.881 | Acc: 31.793% (11293/35520)\n",
      "Epoch 0 Step 1110/1563 Loss: 1.881 | Acc: 31.798% (11305/35552)\n",
      "Epoch 0 Step 1111/1563 Loss: 1.880 | Acc: 31.812% (11320/35584)\n",
      "Epoch 0 Step 1112/1563 Loss: 1.881 | Acc: 31.814% (11331/35616)\n",
      "Epoch 0 Step 1113/1563 Loss: 1.880 | Acc: 31.817% (11342/35648)\n",
      "Epoch 0 Step 1114/1563 Loss: 1.880 | Acc: 31.822% (11354/35680)\n",
      "Epoch 0 Step 1115/1563 Loss: 1.880 | Acc: 31.816% (11362/35712)\n",
      "Epoch 0 Step 1116/1563 Loss: 1.880 | Acc: 31.821% (11374/35744)\n",
      "Epoch 0 Step 1117/1563 Loss: 1.880 | Acc: 31.826% (11386/35776)\n",
      "Epoch 0 Step 1118/1563 Loss: 1.880 | Acc: 31.828% (11397/35808)\n",
      "Epoch 0 Step 1119/1563 Loss: 1.880 | Acc: 31.828% (11407/35840)\n",
      "Epoch 0 Step 1120/1563 Loss: 1.880 | Acc: 31.844% (11423/35872)\n",
      "Epoch 0 Step 1121/1563 Loss: 1.879 | Acc: 31.852% (11436/35904)\n",
      "Epoch 0 Step 1122/1563 Loss: 1.879 | Acc: 31.859% (11449/35936)\n",
      "Epoch 0 Step 1123/1563 Loss: 1.879 | Acc: 31.876% (11465/35968)\n",
      "Epoch 0 Step 1124/1563 Loss: 1.879 | Acc: 31.875% (11475/36000)\n",
      "Epoch 0 Step 1125/1563 Loss: 1.879 | Acc: 31.880% (11487/36032)\n",
      "Epoch 0 Step 1126/1563 Loss: 1.879 | Acc: 31.879% (11497/36064)\n",
      "Epoch 0 Step 1127/1563 Loss: 1.879 | Acc: 31.882% (11508/36096)\n",
      "Epoch 0 Step 1128/1563 Loss: 1.879 | Acc: 31.884% (11519/36128)\n",
      "Epoch 0 Step 1129/1563 Loss: 1.879 | Acc: 31.883% (11529/36160)\n",
      "Epoch 0 Step 1130/1563 Loss: 1.879 | Acc: 31.880% (11538/36192)\n",
      "Epoch 0 Step 1131/1563 Loss: 1.878 | Acc: 31.896% (11554/36224)\n",
      "Epoch 0 Step 1132/1563 Loss: 1.878 | Acc: 31.890% (11562/36256)\n",
      "Epoch 0 Step 1133/1563 Loss: 1.878 | Acc: 31.898% (11575/36288)\n",
      "Epoch 0 Step 1134/1563 Loss: 1.878 | Acc: 31.903% (11587/36320)\n",
      "Epoch 0 Step 1135/1563 Loss: 1.878 | Acc: 31.907% (11599/36352)\n",
      "Epoch 0 Step 1136/1563 Loss: 1.878 | Acc: 31.910% (11610/36384)\n",
      "Epoch 0 Step 1137/1563 Loss: 1.878 | Acc: 31.912% (11621/36416)\n",
      "Epoch 0 Step 1138/1563 Loss: 1.877 | Acc: 31.914% (11632/36448)\n",
      "Epoch 0 Step 1139/1563 Loss: 1.877 | Acc: 31.905% (11639/36480)\n",
      "Epoch 0 Step 1140/1563 Loss: 1.877 | Acc: 31.907% (11650/36512)\n",
      "Epoch 0 Step 1141/1563 Loss: 1.877 | Acc: 31.915% (11663/36544)\n",
      "Epoch 0 Step 1142/1563 Loss: 1.877 | Acc: 31.909% (11671/36576)\n",
      "Epoch 0 Step 1143/1563 Loss: 1.877 | Acc: 31.911% (11682/36608)\n",
      "Epoch 0 Step 1144/1563 Loss: 1.877 | Acc: 31.921% (11696/36640)\n",
      "Epoch 0 Step 1145/1563 Loss: 1.877 | Acc: 31.921% (11706/36672)\n",
      "Epoch 0 Step 1146/1563 Loss: 1.877 | Acc: 31.926% (11718/36704)\n",
      "Epoch 0 Step 1147/1563 Loss: 1.877 | Acc: 31.928% (11729/36736)\n",
      "Epoch 0 Step 1148/1563 Loss: 1.876 | Acc: 31.927% (11739/36768)\n",
      "Epoch 0 Step 1149/1563 Loss: 1.876 | Acc: 31.932% (11751/36800)\n",
      "Epoch 0 Step 1150/1563 Loss: 1.876 | Acc: 31.934% (11762/36832)\n",
      "Epoch 0 Step 1151/1563 Loss: 1.876 | Acc: 31.950% (11778/36864)\n",
      "Epoch 0 Step 1152/1563 Loss: 1.876 | Acc: 31.947% (11787/36896)\n",
      "Epoch 0 Step 1153/1563 Loss: 1.876 | Acc: 31.949% (11798/36928)\n",
      "Epoch 0 Step 1154/1563 Loss: 1.877 | Acc: 31.943% (11806/36960)\n",
      "Epoch 0 Step 1155/1563 Loss: 1.877 | Acc: 31.937% (11814/36992)\n",
      "Epoch 0 Step 1156/1563 Loss: 1.876 | Acc: 31.958% (11832/37024)\n",
      "Epoch 0 Step 1157/1563 Loss: 1.876 | Acc: 31.957% (11842/37056)\n",
      "Epoch 0 Step 1158/1563 Loss: 1.876 | Acc: 31.946% (11848/37088)\n",
      "Epoch 0 Step 1159/1563 Loss: 1.876 | Acc: 31.950% (11860/37120)\n",
      "Epoch 0 Step 1160/1563 Loss: 1.876 | Acc: 31.955% (11872/37152)\n",
      "Epoch 0 Step 1161/1563 Loss: 1.876 | Acc: 31.965% (11886/37184)\n",
      "Epoch 0 Step 1162/1563 Loss: 1.876 | Acc: 31.962% (11895/37216)\n",
      "Epoch 0 Step 1163/1563 Loss: 1.876 | Acc: 31.964% (11906/37248)\n",
      "Epoch 0 Step 1164/1563 Loss: 1.876 | Acc: 31.977% (11921/37280)\n",
      "Epoch 0 Step 1165/1563 Loss: 1.876 | Acc: 31.990% (11936/37312)\n",
      "Epoch 0 Step 1166/1563 Loss: 1.876 | Acc: 31.986% (11945/37344)\n",
      "Epoch 0 Step 1167/1563 Loss: 1.875 | Acc: 32.013% (11965/37376)\n",
      "Epoch 0 Step 1168/1563 Loss: 1.875 | Acc: 32.028% (11981/37408)\n",
      "Epoch 0 Step 1169/1563 Loss: 1.875 | Acc: 32.046% (11998/37440)\n",
      "Epoch 0 Step 1170/1563 Loss: 1.875 | Acc: 32.037% (12005/37472)\n",
      "Epoch 0 Step 1171/1563 Loss: 1.875 | Acc: 32.045% (12018/37504)\n",
      "Epoch 0 Step 1172/1563 Loss: 1.875 | Acc: 32.049% (12030/37536)\n",
      "Epoch 0 Step 1173/1563 Loss: 1.875 | Acc: 32.041% (12037/37568)\n",
      "Epoch 0 Step 1174/1563 Loss: 1.874 | Acc: 32.037% (12046/37600)\n",
      "Epoch 0 Step 1175/1563 Loss: 1.874 | Acc: 32.039% (12057/37632)\n",
      "Epoch 0 Step 1176/1563 Loss: 1.874 | Acc: 32.041% (12068/37664)\n",
      "Epoch 0 Step 1177/1563 Loss: 1.874 | Acc: 32.051% (12082/37696)\n",
      "Epoch 0 Step 1178/1563 Loss: 1.874 | Acc: 32.056% (12094/37728)\n",
      "Epoch 0 Step 1179/1563 Loss: 1.874 | Acc: 32.063% (12107/37760)\n",
      "Epoch 0 Step 1180/1563 Loss: 1.874 | Acc: 32.065% (12118/37792)\n",
      "Epoch 0 Step 1181/1563 Loss: 1.874 | Acc: 32.080% (12134/37824)\n",
      "Epoch 0 Step 1182/1563 Loss: 1.874 | Acc: 32.079% (12144/37856)\n",
      "Epoch 0 Step 1183/1563 Loss: 1.874 | Acc: 32.092% (12159/37888)\n",
      "Epoch 0 Step 1184/1563 Loss: 1.874 | Acc: 32.094% (12170/37920)\n",
      "Epoch 0 Step 1185/1563 Loss: 1.873 | Acc: 32.098% (12182/37952)\n",
      "Epoch 0 Step 1186/1563 Loss: 1.873 | Acc: 32.106% (12195/37984)\n",
      "Epoch 0 Step 1187/1563 Loss: 1.873 | Acc: 32.110% (12207/38016)\n",
      "Epoch 0 Step 1188/1563 Loss: 1.873 | Acc: 32.115% (12219/38048)\n",
      "Epoch 0 Step 1189/1563 Loss: 1.873 | Acc: 32.124% (12233/38080)\n",
      "Epoch 0 Step 1190/1563 Loss: 1.873 | Acc: 32.116% (12240/38112)\n",
      "Epoch 0 Step 1191/1563 Loss: 1.873 | Acc: 32.120% (12252/38144)\n",
      "Epoch 0 Step 1192/1563 Loss: 1.873 | Acc: 32.122% (12263/38176)\n",
      "Epoch 0 Step 1193/1563 Loss: 1.873 | Acc: 32.119% (12272/38208)\n",
      "Epoch 0 Step 1194/1563 Loss: 1.872 | Acc: 32.123% (12284/38240)\n",
      "Epoch 0 Step 1195/1563 Loss: 1.872 | Acc: 32.125% (12295/38272)\n",
      "Epoch 0 Step 1196/1563 Loss: 1.872 | Acc: 32.127% (12306/38304)\n",
      "Epoch 0 Step 1197/1563 Loss: 1.872 | Acc: 32.119% (12313/38336)\n",
      "Epoch 0 Step 1198/1563 Loss: 1.872 | Acc: 32.128% (12327/38368)\n",
      "Epoch 0 Step 1199/1563 Loss: 1.872 | Acc: 32.135% (12340/38400)\n",
      "Epoch 0 Step 1200/1563 Loss: 1.872 | Acc: 32.124% (12346/38432)\n",
      "Epoch 0 Step 1201/1563 Loss: 1.872 | Acc: 32.129% (12358/38464)\n",
      "Epoch 0 Step 1202/1563 Loss: 1.872 | Acc: 32.125% (12367/38496)\n",
      "Epoch 0 Step 1203/1563 Loss: 1.872 | Acc: 32.122% (12376/38528)\n",
      "Epoch 0 Step 1204/1563 Loss: 1.872 | Acc: 32.124% (12387/38560)\n",
      "Epoch 0 Step 1205/1563 Loss: 1.872 | Acc: 32.134% (12401/38592)\n",
      "Epoch 0 Step 1206/1563 Loss: 1.871 | Acc: 32.148% (12417/38624)\n",
      "Epoch 0 Step 1207/1563 Loss: 1.871 | Acc: 32.142% (12425/38656)\n",
      "Epoch 0 Step 1208/1563 Loss: 1.871 | Acc: 32.155% (12440/38688)\n",
      "Epoch 0 Step 1209/1563 Loss: 1.871 | Acc: 32.159% (12452/38720)\n",
      "Epoch 0 Step 1210/1563 Loss: 1.871 | Acc: 32.148% (12458/38752)\n",
      "Epoch 0 Step 1211/1563 Loss: 1.871 | Acc: 32.142% (12466/38784)\n",
      "Epoch 0 Step 1212/1563 Loss: 1.871 | Acc: 32.152% (12480/38816)\n",
      "Epoch 0 Step 1213/1563 Loss: 1.871 | Acc: 32.151% (12490/38848)\n",
      "Epoch 0 Step 1214/1563 Loss: 1.871 | Acc: 32.160% (12504/38880)\n",
      "Epoch 0 Step 1215/1563 Loss: 1.871 | Acc: 32.157% (12513/38912)\n",
      "Epoch 0 Step 1216/1563 Loss: 1.871 | Acc: 32.159% (12524/38944)\n",
      "Epoch 0 Step 1217/1563 Loss: 1.871 | Acc: 32.169% (12538/38976)\n",
      "Epoch 0 Step 1218/1563 Loss: 1.871 | Acc: 32.168% (12548/39008)\n",
      "Epoch 0 Step 1219/1563 Loss: 1.870 | Acc: 32.180% (12563/39040)\n",
      "Epoch 0 Step 1220/1563 Loss: 1.870 | Acc: 32.179% (12573/39072)\n",
      "Epoch 0 Step 1221/1563 Loss: 1.870 | Acc: 32.181% (12584/39104)\n",
      "Epoch 0 Step 1222/1563 Loss: 1.870 | Acc: 32.190% (12598/39136)\n",
      "Epoch 0 Step 1223/1563 Loss: 1.870 | Acc: 32.197% (12611/39168)\n",
      "Epoch 0 Step 1224/1563 Loss: 1.870 | Acc: 32.202% (12623/39200)\n",
      "Epoch 0 Step 1225/1563 Loss: 1.870 | Acc: 32.201% (12633/39232)\n",
      "Epoch 0 Step 1226/1563 Loss: 1.869 | Acc: 32.208% (12646/39264)\n",
      "Epoch 0 Step 1227/1563 Loss: 1.869 | Acc: 32.202% (12654/39296)\n",
      "Epoch 0 Step 1228/1563 Loss: 1.869 | Acc: 32.201% (12664/39328)\n",
      "Epoch 0 Step 1229/1563 Loss: 1.869 | Acc: 32.198% (12673/39360)\n",
      "Epoch 0 Step 1230/1563 Loss: 1.869 | Acc: 32.197% (12683/39392)\n",
      "Epoch 0 Step 1231/1563 Loss: 1.869 | Acc: 32.206% (12697/39424)\n",
      "Epoch 0 Step 1232/1563 Loss: 1.869 | Acc: 32.221% (12713/39456)\n",
      "Epoch 0 Step 1233/1563 Loss: 1.869 | Acc: 32.235% (12729/39488)\n",
      "Epoch 0 Step 1234/1563 Loss: 1.868 | Acc: 32.239% (12741/39520)\n",
      "Epoch 0 Step 1235/1563 Loss: 1.868 | Acc: 32.256% (12758/39552)\n",
      "Epoch 0 Step 1236/1563 Loss: 1.868 | Acc: 32.268% (12773/39584)\n",
      "Epoch 0 Step 1237/1563 Loss: 1.868 | Acc: 32.272% (12785/39616)\n",
      "Epoch 0 Step 1238/1563 Loss: 1.868 | Acc: 32.277% (12797/39648)\n",
      "Epoch 0 Step 1239/1563 Loss: 1.867 | Acc: 32.291% (12813/39680)\n",
      "Epoch 0 Step 1240/1563 Loss: 1.867 | Acc: 32.293% (12824/39712)\n",
      "Epoch 0 Step 1241/1563 Loss: 1.867 | Acc: 32.297% (12836/39744)\n",
      "Epoch 0 Step 1242/1563 Loss: 1.867 | Acc: 32.288% (12843/39776)\n",
      "Epoch 0 Step 1243/1563 Loss: 1.868 | Acc: 32.287% (12853/39808)\n",
      "Epoch 0 Step 1244/1563 Loss: 1.867 | Acc: 32.284% (12862/39840)\n",
      "Epoch 0 Step 1245/1563 Loss: 1.867 | Acc: 32.296% (12877/39872)\n",
      "Epoch 0 Step 1246/1563 Loss: 1.867 | Acc: 32.298% (12888/39904)\n",
      "Epoch 0 Step 1247/1563 Loss: 1.867 | Acc: 32.289% (12895/39936)\n",
      "Epoch 0 Step 1248/1563 Loss: 1.867 | Acc: 32.291% (12906/39968)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 1249/1563 Loss: 1.867 | Acc: 32.290% (12916/40000)\n",
      "Epoch 0 Step 1250/1563 Loss: 1.867 | Acc: 32.297% (12929/40032)\n",
      "Epoch 0 Step 1251/1563 Loss: 1.867 | Acc: 32.298% (12940/40064)\n",
      "Epoch 0 Step 1252/1563 Loss: 1.867 | Acc: 32.307% (12954/40096)\n",
      "Epoch 0 Step 1253/1563 Loss: 1.867 | Acc: 32.302% (12962/40128)\n",
      "Epoch 0 Step 1254/1563 Loss: 1.867 | Acc: 32.301% (12972/40160)\n",
      "Epoch 0 Step 1255/1563 Loss: 1.867 | Acc: 32.305% (12984/40192)\n",
      "Epoch 0 Step 1256/1563 Loss: 1.867 | Acc: 32.319% (13000/40224)\n",
      "Epoch 0 Step 1257/1563 Loss: 1.866 | Acc: 32.328% (13014/40256)\n",
      "Epoch 0 Step 1258/1563 Loss: 1.866 | Acc: 32.335% (13027/40288)\n",
      "Epoch 0 Step 1259/1563 Loss: 1.866 | Acc: 32.331% (13036/40320)\n",
      "Epoch 0 Step 1260/1563 Loss: 1.866 | Acc: 32.328% (13045/40352)\n",
      "Epoch 0 Step 1261/1563 Loss: 1.866 | Acc: 32.342% (13061/40384)\n",
      "Epoch 0 Step 1262/1563 Loss: 1.866 | Acc: 32.344% (13072/40416)\n",
      "Epoch 0 Step 1263/1563 Loss: 1.866 | Acc: 32.350% (13085/40448)\n",
      "Epoch 0 Step 1264/1563 Loss: 1.866 | Acc: 32.357% (13098/40480)\n",
      "Epoch 0 Step 1265/1563 Loss: 1.866 | Acc: 32.361% (13110/40512)\n",
      "Epoch 0 Step 1266/1563 Loss: 1.865 | Acc: 32.372% (13125/40544)\n",
      "Epoch 0 Step 1267/1563 Loss: 1.865 | Acc: 32.364% (13132/40576)\n",
      "Epoch 0 Step 1268/1563 Loss: 1.865 | Acc: 32.361% (13141/40608)\n",
      "Epoch 0 Step 1269/1563 Loss: 1.865 | Acc: 32.367% (13154/40640)\n",
      "Epoch 0 Step 1270/1563 Loss: 1.865 | Acc: 32.374% (13167/40672)\n",
      "Epoch 0 Step 1271/1563 Loss: 1.865 | Acc: 32.373% (13177/40704)\n",
      "Epoch 0 Step 1272/1563 Loss: 1.865 | Acc: 32.374% (13188/40736)\n",
      "Epoch 0 Step 1273/1563 Loss: 1.865 | Acc: 32.373% (13198/40768)\n",
      "Epoch 0 Step 1274/1563 Loss: 1.865 | Acc: 32.375% (13209/40800)\n",
      "Epoch 0 Step 1275/1563 Loss: 1.864 | Acc: 32.381% (13222/40832)\n",
      "Epoch 0 Step 1276/1563 Loss: 1.864 | Acc: 32.388% (13235/40864)\n",
      "Epoch 0 Step 1277/1563 Loss: 1.864 | Acc: 32.392% (13247/40896)\n",
      "Epoch 0 Step 1278/1563 Loss: 1.864 | Acc: 32.391% (13257/40928)\n",
      "Epoch 0 Step 1279/1563 Loss: 1.864 | Acc: 32.397% (13270/40960)\n",
      "Epoch 0 Step 1280/1563 Loss: 1.864 | Acc: 32.399% (13281/40992)\n",
      "Epoch 0 Step 1281/1563 Loss: 1.863 | Acc: 32.408% (13295/41024)\n",
      "Epoch 0 Step 1282/1563 Loss: 1.863 | Acc: 32.417% (13309/41056)\n",
      "Epoch 0 Step 1283/1563 Loss: 1.863 | Acc: 32.423% (13322/41088)\n",
      "Epoch 0 Step 1284/1563 Loss: 1.863 | Acc: 32.432% (13336/41120)\n",
      "Epoch 0 Step 1285/1563 Loss: 1.863 | Acc: 32.441% (13350/41152)\n",
      "Epoch 0 Step 1286/1563 Loss: 1.863 | Acc: 32.440% (13360/41184)\n",
      "Epoch 0 Step 1287/1563 Loss: 1.863 | Acc: 32.446% (13373/41216)\n",
      "Epoch 0 Step 1288/1563 Loss: 1.863 | Acc: 32.452% (13386/41248)\n",
      "Epoch 0 Step 1289/1563 Loss: 1.863 | Acc: 32.449% (13395/41280)\n",
      "Epoch 0 Step 1290/1563 Loss: 1.863 | Acc: 32.451% (13406/41312)\n",
      "Epoch 0 Step 1291/1563 Loss: 1.863 | Acc: 32.452% (13417/41344)\n",
      "Epoch 0 Step 1292/1563 Loss: 1.863 | Acc: 32.451% (13427/41376)\n",
      "Epoch 0 Step 1293/1563 Loss: 1.863 | Acc: 32.441% (13433/41408)\n",
      "Epoch 0 Step 1294/1563 Loss: 1.863 | Acc: 32.444% (13445/41440)\n",
      "Epoch 0 Step 1295/1563 Loss: 1.863 | Acc: 32.446% (13456/41472)\n",
      "Epoch 0 Step 1296/1563 Loss: 1.862 | Acc: 32.450% (13468/41504)\n",
      "Epoch 0 Step 1297/1563 Loss: 1.862 | Acc: 32.449% (13478/41536)\n",
      "Epoch 0 Step 1298/1563 Loss: 1.862 | Acc: 32.441% (13485/41568)\n",
      "Epoch 0 Step 1299/1563 Loss: 1.863 | Acc: 32.435% (13493/41600)\n",
      "Epoch 0 Step 1300/1563 Loss: 1.862 | Acc: 32.444% (13507/41632)\n",
      "Epoch 0 Step 1301/1563 Loss: 1.862 | Acc: 32.445% (13518/41664)\n",
      "Epoch 0 Step 1302/1563 Loss: 1.862 | Acc: 32.447% (13529/41696)\n",
      "Epoch 0 Step 1303/1563 Loss: 1.862 | Acc: 32.443% (13538/41728)\n",
      "Epoch 0 Step 1304/1563 Loss: 1.862 | Acc: 32.450% (13551/41760)\n",
      "Epoch 0 Step 1305/1563 Loss: 1.863 | Acc: 32.446% (13560/41792)\n",
      "Epoch 0 Step 1306/1563 Loss: 1.863 | Acc: 32.450% (13572/41824)\n",
      "Epoch 0 Step 1307/1563 Loss: 1.862 | Acc: 32.464% (13588/41856)\n",
      "Epoch 0 Step 1308/1563 Loss: 1.862 | Acc: 32.470% (13601/41888)\n",
      "Epoch 0 Step 1309/1563 Loss: 1.862 | Acc: 32.471% (13612/41920)\n",
      "Epoch 0 Step 1310/1563 Loss: 1.862 | Acc: 32.485% (13628/41952)\n",
      "Epoch 0 Step 1311/1563 Loss: 1.861 | Acc: 32.491% (13641/41984)\n",
      "Epoch 0 Step 1312/1563 Loss: 1.861 | Acc: 32.502% (13656/42016)\n",
      "Epoch 0 Step 1313/1563 Loss: 1.861 | Acc: 32.499% (13665/42048)\n",
      "Epoch 0 Step 1314/1563 Loss: 1.861 | Acc: 32.500% (13676/42080)\n",
      "Epoch 0 Step 1315/1563 Loss: 1.861 | Acc: 32.499% (13686/42112)\n",
      "Epoch 0 Step 1316/1563 Loss: 1.861 | Acc: 32.510% (13701/42144)\n",
      "Epoch 0 Step 1317/1563 Loss: 1.861 | Acc: 32.521% (13716/42176)\n",
      "Epoch 0 Step 1318/1563 Loss: 1.861 | Acc: 32.520% (13726/42208)\n",
      "Epoch 0 Step 1319/1563 Loss: 1.861 | Acc: 32.524% (13738/42240)\n",
      "Epoch 0 Step 1320/1563 Loss: 1.861 | Acc: 32.520% (13747/42272)\n",
      "Epoch 0 Step 1321/1563 Loss: 1.860 | Acc: 32.526% (13760/42304)\n",
      "Epoch 0 Step 1322/1563 Loss: 1.860 | Acc: 32.535% (13774/42336)\n",
      "Epoch 0 Step 1323/1563 Loss: 1.860 | Acc: 32.536% (13785/42368)\n",
      "Epoch 0 Step 1324/1563 Loss: 1.860 | Acc: 32.545% (13799/42400)\n",
      "Epoch 0 Step 1325/1563 Loss: 1.860 | Acc: 32.563% (13817/42432)\n",
      "Epoch 0 Step 1326/1563 Loss: 1.860 | Acc: 32.564% (13828/42464)\n",
      "Epoch 0 Step 1327/1563 Loss: 1.860 | Acc: 32.572% (13842/42496)\n",
      "Epoch 0 Step 1328/1563 Loss: 1.860 | Acc: 32.562% (13848/42528)\n",
      "Epoch 0 Step 1329/1563 Loss: 1.860 | Acc: 32.568% (13861/42560)\n",
      "Epoch 0 Step 1330/1563 Loss: 1.860 | Acc: 32.572% (13873/42592)\n",
      "Epoch 0 Step 1331/1563 Loss: 1.860 | Acc: 32.576% (13885/42624)\n",
      "Epoch 0 Step 1332/1563 Loss: 1.859 | Acc: 32.572% (13894/42656)\n",
      "Epoch 0 Step 1333/1563 Loss: 1.859 | Acc: 32.581% (13908/42688)\n",
      "Epoch 0 Step 1334/1563 Loss: 1.859 | Acc: 32.577% (13917/42720)\n",
      "Epoch 0 Step 1335/1563 Loss: 1.859 | Acc: 32.572% (13925/42752)\n",
      "Epoch 0 Step 1336/1563 Loss: 1.859 | Acc: 32.568% (13934/42784)\n",
      "Epoch 0 Step 1337/1563 Loss: 1.859 | Acc: 32.570% (13945/42816)\n",
      "Epoch 0 Step 1338/1563 Loss: 1.859 | Acc: 32.566% (13954/42848)\n",
      "Epoch 0 Step 1339/1563 Loss: 1.859 | Acc: 32.579% (13970/42880)\n",
      "Epoch 0 Step 1340/1563 Loss: 1.859 | Acc: 32.576% (13979/42912)\n",
      "Epoch 0 Step 1341/1563 Loss: 1.859 | Acc: 32.575% (13989/42944)\n",
      "Epoch 0 Step 1342/1563 Loss: 1.859 | Acc: 32.581% (14002/42976)\n",
      "Epoch 0 Step 1343/1563 Loss: 1.859 | Acc: 32.580% (14012/43008)\n",
      "Epoch 0 Step 1344/1563 Loss: 1.858 | Acc: 32.581% (14023/43040)\n",
      "Epoch 0 Step 1345/1563 Loss: 1.858 | Acc: 32.580% (14033/43072)\n",
      "Epoch 0 Step 1346/1563 Loss: 1.858 | Acc: 32.582% (14044/43104)\n",
      "Epoch 0 Step 1347/1563 Loss: 1.858 | Acc: 32.585% (14056/43136)\n",
      "Epoch 0 Step 1348/1563 Loss: 1.858 | Acc: 32.594% (14070/43168)\n",
      "Epoch 0 Step 1349/1563 Loss: 1.858 | Acc: 32.597% (14082/43200)\n",
      "Epoch 0 Step 1350/1563 Loss: 1.858 | Acc: 32.610% (14098/43232)\n",
      "Epoch 0 Step 1351/1563 Loss: 1.858 | Acc: 32.607% (14107/43264)\n",
      "Epoch 0 Step 1352/1563 Loss: 1.858 | Acc: 32.608% (14118/43296)\n",
      "Epoch 0 Step 1353/1563 Loss: 1.857 | Acc: 32.619% (14133/43328)\n",
      "Epoch 0 Step 1354/1563 Loss: 1.857 | Acc: 32.618% (14143/43360)\n",
      "Epoch 0 Step 1355/1563 Loss: 1.857 | Acc: 32.619% (14154/43392)\n",
      "Epoch 0 Step 1356/1563 Loss: 1.857 | Acc: 32.627% (14168/43424)\n",
      "Epoch 0 Step 1357/1563 Loss: 1.857 | Acc: 32.631% (14180/43456)\n",
      "Epoch 0 Step 1358/1563 Loss: 1.857 | Acc: 32.639% (14194/43488)\n",
      "Epoch 0 Step 1359/1563 Loss: 1.857 | Acc: 32.636% (14203/43520)\n",
      "Epoch 0 Step 1360/1563 Loss: 1.857 | Acc: 32.646% (14218/43552)\n",
      "Epoch 0 Step 1361/1563 Loss: 1.856 | Acc: 32.654% (14232/43584)\n",
      "Epoch 0 Step 1362/1563 Loss: 1.856 | Acc: 32.658% (14244/43616)\n",
      "Epoch 0 Step 1363/1563 Loss: 1.856 | Acc: 32.666% (14258/43648)\n",
      "Epoch 0 Step 1364/1563 Loss: 1.856 | Acc: 32.656% (14264/43680)\n",
      "Epoch 0 Step 1365/1563 Loss: 1.856 | Acc: 32.662% (14277/43712)\n",
      "Epoch 0 Step 1366/1563 Loss: 1.856 | Acc: 32.660% (14287/43744)\n",
      "Epoch 0 Step 1367/1563 Loss: 1.856 | Acc: 32.669% (14301/43776)\n",
      "Epoch 0 Step 1368/1563 Loss: 1.856 | Acc: 32.672% (14313/43808)\n",
      "Epoch 0 Step 1369/1563 Loss: 1.856 | Acc: 32.678% (14326/43840)\n",
      "Epoch 0 Step 1370/1563 Loss: 1.855 | Acc: 32.688% (14341/43872)\n",
      "Epoch 0 Step 1371/1563 Loss: 1.855 | Acc: 32.694% (14354/43904)\n",
      "Epoch 0 Step 1372/1563 Loss: 1.855 | Acc: 32.698% (14366/43936)\n",
      "Epoch 0 Step 1373/1563 Loss: 1.855 | Acc: 32.703% (14379/43968)\n",
      "Epoch 0 Step 1374/1563 Loss: 1.855 | Acc: 32.720% (14397/44000)\n",
      "Epoch 0 Step 1375/1563 Loss: 1.854 | Acc: 32.728% (14411/44032)\n",
      "Epoch 0 Step 1376/1563 Loss: 1.854 | Acc: 32.730% (14422/44064)\n",
      "Epoch 0 Step 1377/1563 Loss: 1.854 | Acc: 32.744% (14439/44096)\n",
      "Epoch 0 Step 1378/1563 Loss: 1.854 | Acc: 32.757% (14455/44128)\n",
      "Epoch 0 Step 1379/1563 Loss: 1.854 | Acc: 32.756% (14465/44160)\n",
      "Epoch 0 Step 1380/1563 Loss: 1.854 | Acc: 32.748% (14472/44192)\n",
      "Epoch 0 Step 1381/1563 Loss: 1.853 | Acc: 32.742% (14480/44224)\n",
      "Epoch 0 Step 1382/1563 Loss: 1.853 | Acc: 32.762% (14499/44256)\n",
      "Epoch 0 Step 1383/1563 Loss: 1.853 | Acc: 32.767% (14512/44288)\n",
      "Epoch 0 Step 1384/1563 Loss: 1.853 | Acc: 32.771% (14524/44320)\n",
      "Epoch 0 Step 1385/1563 Loss: 1.853 | Acc: 32.783% (14540/44352)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 1386/1563 Loss: 1.852 | Acc: 32.789% (14553/44384)\n",
      "Epoch 0 Step 1387/1563 Loss: 1.852 | Acc: 32.788% (14563/44416)\n",
      "Epoch 0 Step 1388/1563 Loss: 1.852 | Acc: 32.796% (14577/44448)\n",
      "Epoch 0 Step 1389/1563 Loss: 1.852 | Acc: 32.786% (14583/44480)\n",
      "Epoch 0 Step 1390/1563 Loss: 1.852 | Acc: 32.789% (14595/44512)\n",
      "Epoch 0 Step 1391/1563 Loss: 1.852 | Acc: 32.799% (14610/44544)\n",
      "Epoch 0 Step 1392/1563 Loss: 1.852 | Acc: 32.814% (14627/44576)\n",
      "Epoch 0 Step 1393/1563 Loss: 1.852 | Acc: 32.817% (14639/44608)\n",
      "Epoch 0 Step 1394/1563 Loss: 1.851 | Acc: 32.834% (14657/44640)\n",
      "Epoch 0 Step 1395/1563 Loss: 1.851 | Acc: 32.839% (14670/44672)\n",
      "Epoch 0 Step 1396/1563 Loss: 1.851 | Acc: 32.847% (14684/44704)\n",
      "Epoch 0 Step 1397/1563 Loss: 1.851 | Acc: 32.848% (14695/44736)\n",
      "Epoch 0 Step 1398/1563 Loss: 1.851 | Acc: 32.840% (14702/44768)\n",
      "Epoch 0 Step 1399/1563 Loss: 1.851 | Acc: 32.842% (14713/44800)\n",
      "Epoch 0 Step 1400/1563 Loss: 1.851 | Acc: 32.838% (14722/44832)\n",
      "Epoch 0 Step 1401/1563 Loss: 1.851 | Acc: 32.848% (14737/44864)\n",
      "Epoch 0 Step 1402/1563 Loss: 1.850 | Acc: 32.854% (14750/44896)\n",
      "Epoch 0 Step 1403/1563 Loss: 1.850 | Acc: 32.855% (14761/44928)\n",
      "Epoch 0 Step 1404/1563 Loss: 1.850 | Acc: 32.851% (14770/44960)\n",
      "Epoch 0 Step 1405/1563 Loss: 1.850 | Acc: 32.859% (14784/44992)\n",
      "Epoch 0 Step 1406/1563 Loss: 1.850 | Acc: 32.858% (14794/45024)\n",
      "Epoch 0 Step 1407/1563 Loss: 1.850 | Acc: 32.868% (14809/45056)\n",
      "Epoch 0 Step 1408/1563 Loss: 1.850 | Acc: 32.871% (14821/45088)\n",
      "Epoch 0 Step 1409/1563 Loss: 1.850 | Acc: 32.872% (14832/45120)\n",
      "Epoch 0 Step 1410/1563 Loss: 1.850 | Acc: 32.882% (14847/45152)\n",
      "Epoch 0 Step 1411/1563 Loss: 1.850 | Acc: 32.892% (14862/45184)\n",
      "Epoch 0 Step 1412/1563 Loss: 1.850 | Acc: 32.893% (14873/45216)\n",
      "Epoch 0 Step 1413/1563 Loss: 1.849 | Acc: 32.888% (14881/45248)\n",
      "Epoch 0 Step 1414/1563 Loss: 1.849 | Acc: 32.889% (14892/45280)\n",
      "Epoch 0 Step 1415/1563 Loss: 1.849 | Acc: 32.888% (14902/45312)\n",
      "Epoch 0 Step 1416/1563 Loss: 1.849 | Acc: 32.878% (14908/45344)\n",
      "Epoch 0 Step 1417/1563 Loss: 1.849 | Acc: 32.887% (14923/45376)\n",
      "Epoch 0 Step 1418/1563 Loss: 1.849 | Acc: 32.880% (14930/45408)\n",
      "Epoch 0 Step 1419/1563 Loss: 1.849 | Acc: 32.885% (14943/45440)\n",
      "Epoch 0 Step 1420/1563 Loss: 1.849 | Acc: 32.888% (14955/45472)\n",
      "Epoch 0 Step 1421/1563 Loss: 1.849 | Acc: 32.889% (14966/45504)\n",
      "Epoch 0 Step 1422/1563 Loss: 1.849 | Acc: 32.910% (14986/45536)\n",
      "Epoch 0 Step 1423/1563 Loss: 1.848 | Acc: 32.927% (15004/45568)\n",
      "Epoch 0 Step 1424/1563 Loss: 1.848 | Acc: 32.930% (15016/45600)\n",
      "Epoch 0 Step 1425/1563 Loss: 1.848 | Acc: 32.929% (15026/45632)\n",
      "Epoch 0 Step 1426/1563 Loss: 1.848 | Acc: 32.936% (15040/45664)\n",
      "Epoch 0 Step 1427/1563 Loss: 1.848 | Acc: 32.942% (15053/45696)\n",
      "Epoch 0 Step 1428/1563 Loss: 1.848 | Acc: 32.951% (15068/45728)\n",
      "Epoch 0 Step 1429/1563 Loss: 1.847 | Acc: 32.952% (15079/45760)\n",
      "Epoch 0 Step 1430/1563 Loss: 1.847 | Acc: 32.956% (15091/45792)\n",
      "Epoch 0 Step 1431/1563 Loss: 1.847 | Acc: 32.959% (15103/45824)\n",
      "Epoch 0 Step 1432/1563 Loss: 1.847 | Acc: 32.962% (15115/45856)\n",
      "Epoch 0 Step 1433/1563 Loss: 1.847 | Acc: 32.967% (15128/45888)\n",
      "Epoch 0 Step 1434/1563 Loss: 1.847 | Acc: 32.979% (15144/45920)\n",
      "Epoch 0 Step 1435/1563 Loss: 1.847 | Acc: 32.984% (15157/45952)\n",
      "Epoch 0 Step 1436/1563 Loss: 1.847 | Acc: 32.996% (15173/45984)\n",
      "Epoch 0 Step 1437/1563 Loss: 1.847 | Acc: 32.995% (15183/46016)\n",
      "Epoch 0 Step 1438/1563 Loss: 1.846 | Acc: 33.000% (15196/46048)\n",
      "Epoch 0 Step 1439/1563 Loss: 1.846 | Acc: 32.999% (15206/46080)\n",
      "Epoch 0 Step 1440/1563 Loss: 1.846 | Acc: 33.004% (15219/46112)\n",
      "Epoch 0 Step 1441/1563 Loss: 1.846 | Acc: 32.999% (15227/46144)\n",
      "Epoch 0 Step 1442/1563 Loss: 1.846 | Acc: 33.000% (15238/46176)\n",
      "Epoch 0 Step 1443/1563 Loss: 1.846 | Acc: 33.005% (15251/46208)\n",
      "Epoch 0 Step 1444/1563 Loss: 1.846 | Acc: 33.017% (15267/46240)\n",
      "Epoch 0 Step 1445/1563 Loss: 1.846 | Acc: 33.026% (15282/46272)\n",
      "Epoch 0 Step 1446/1563 Loss: 1.846 | Acc: 33.036% (15297/46304)\n",
      "Epoch 0 Step 1447/1563 Loss: 1.846 | Acc: 33.037% (15308/46336)\n",
      "Epoch 0 Step 1448/1563 Loss: 1.846 | Acc: 33.044% (15322/46368)\n",
      "Epoch 0 Step 1449/1563 Loss: 1.845 | Acc: 33.047% (15334/46400)\n",
      "Epoch 0 Step 1450/1563 Loss: 1.845 | Acc: 33.053% (15347/46432)\n",
      "Epoch 0 Step 1451/1563 Loss: 1.845 | Acc: 33.060% (15361/46464)\n",
      "Epoch 0 Step 1452/1563 Loss: 1.845 | Acc: 33.067% (15375/46496)\n",
      "Epoch 0 Step 1453/1563 Loss: 1.845 | Acc: 33.066% (15385/46528)\n",
      "Epoch 0 Step 1454/1563 Loss: 1.845 | Acc: 33.067% (15396/46560)\n",
      "Epoch 0 Step 1455/1563 Loss: 1.845 | Acc: 33.070% (15408/46592)\n",
      "Epoch 0 Step 1456/1563 Loss: 1.845 | Acc: 33.067% (15417/46624)\n",
      "Epoch 0 Step 1457/1563 Loss: 1.845 | Acc: 33.068% (15428/46656)\n",
      "Epoch 0 Step 1458/1563 Loss: 1.845 | Acc: 33.081% (15445/46688)\n",
      "Epoch 0 Step 1459/1563 Loss: 1.845 | Acc: 33.080% (15455/46720)\n",
      "Epoch 0 Step 1460/1563 Loss: 1.845 | Acc: 33.075% (15463/46752)\n",
      "Epoch 0 Step 1461/1563 Loss: 1.845 | Acc: 33.080% (15476/46784)\n",
      "Epoch 0 Step 1462/1563 Loss: 1.845 | Acc: 33.081% (15487/46816)\n",
      "Epoch 0 Step 1463/1563 Loss: 1.844 | Acc: 33.079% (15497/46848)\n",
      "Epoch 0 Step 1464/1563 Loss: 1.844 | Acc: 33.084% (15510/46880)\n",
      "Epoch 0 Step 1465/1563 Loss: 1.844 | Acc: 33.081% (15519/46912)\n",
      "Epoch 0 Step 1466/1563 Loss: 1.844 | Acc: 33.093% (15535/46944)\n",
      "Epoch 0 Step 1467/1563 Loss: 1.844 | Acc: 33.091% (15545/46976)\n",
      "Epoch 0 Step 1468/1563 Loss: 1.844 | Acc: 33.096% (15558/47008)\n",
      "Epoch 0 Step 1469/1563 Loss: 1.844 | Acc: 33.102% (15571/47040)\n",
      "Epoch 0 Step 1470/1563 Loss: 1.844 | Acc: 33.107% (15584/47072)\n",
      "Epoch 0 Step 1471/1563 Loss: 1.843 | Acc: 33.116% (15599/47104)\n",
      "Epoch 0 Step 1472/1563 Loss: 1.843 | Acc: 33.117% (15610/47136)\n",
      "Epoch 0 Step 1473/1563 Loss: 1.843 | Acc: 33.114% (15619/47168)\n",
      "Epoch 0 Step 1474/1563 Loss: 1.843 | Acc: 33.112% (15629/47200)\n",
      "Epoch 0 Step 1475/1563 Loss: 1.843 | Acc: 33.113% (15640/47232)\n",
      "Epoch 0 Step 1476/1563 Loss: 1.843 | Acc: 33.116% (15652/47264)\n",
      "Epoch 0 Step 1477/1563 Loss: 1.843 | Acc: 33.119% (15664/47296)\n",
      "Epoch 0 Step 1478/1563 Loss: 1.843 | Acc: 33.120% (15675/47328)\n",
      "Epoch 0 Step 1479/1563 Loss: 1.843 | Acc: 33.127% (15689/47360)\n",
      "Epoch 0 Step 1480/1563 Loss: 1.843 | Acc: 33.130% (15701/47392)\n",
      "Epoch 0 Step 1481/1563 Loss: 1.843 | Acc: 33.129% (15711/47424)\n",
      "Epoch 0 Step 1482/1563 Loss: 1.843 | Acc: 33.121% (15718/47456)\n",
      "Epoch 0 Step 1483/1563 Loss: 1.843 | Acc: 33.126% (15731/47488)\n",
      "Epoch 0 Step 1484/1563 Loss: 1.843 | Acc: 33.133% (15745/47520)\n",
      "Epoch 0 Step 1485/1563 Loss: 1.842 | Acc: 33.143% (15760/47552)\n",
      "Epoch 0 Step 1486/1563 Loss: 1.842 | Acc: 33.150% (15774/47584)\n",
      "Epoch 0 Step 1487/1563 Loss: 1.842 | Acc: 33.165% (15792/47616)\n",
      "Epoch 0 Step 1488/1563 Loss: 1.842 | Acc: 33.164% (15802/47648)\n",
      "Epoch 0 Step 1489/1563 Loss: 1.842 | Acc: 33.165% (15813/47680)\n",
      "Epoch 0 Step 1490/1563 Loss: 1.842 | Acc: 33.174% (15828/47712)\n",
      "Epoch 0 Step 1491/1563 Loss: 1.841 | Acc: 33.166% (15835/47744)\n",
      "Epoch 0 Step 1492/1563 Loss: 1.841 | Acc: 33.174% (15849/47776)\n",
      "Epoch 0 Step 1493/1563 Loss: 1.841 | Acc: 33.183% (15864/47808)\n",
      "Epoch 0 Step 1494/1563 Loss: 1.841 | Acc: 33.186% (15876/47840)\n",
      "Epoch 0 Step 1495/1563 Loss: 1.841 | Acc: 33.195% (15891/47872)\n",
      "Epoch 0 Step 1496/1563 Loss: 1.841 | Acc: 33.193% (15901/47904)\n",
      "Epoch 0 Step 1497/1563 Loss: 1.841 | Acc: 33.207% (15918/47936)\n",
      "Epoch 0 Step 1498/1563 Loss: 1.841 | Acc: 33.210% (15930/47968)\n",
      "Epoch 0 Step 1499/1563 Loss: 1.841 | Acc: 33.212% (15942/48000)\n",
      "Epoch 0 Step 1500/1563 Loss: 1.841 | Acc: 33.215% (15954/48032)\n",
      "Epoch 0 Step 1501/1563 Loss: 1.840 | Acc: 33.218% (15966/48064)\n",
      "Epoch 0 Step 1502/1563 Loss: 1.840 | Acc: 33.211% (15973/48096)\n",
      "Epoch 0 Step 1503/1563 Loss: 1.840 | Acc: 33.222% (15989/48128)\n",
      "Epoch 0 Step 1504/1563 Loss: 1.840 | Acc: 33.237% (16007/48160)\n",
      "Epoch 0 Step 1505/1563 Loss: 1.840 | Acc: 33.248% (16023/48192)\n",
      "Epoch 0 Step 1506/1563 Loss: 1.839 | Acc: 33.255% (16037/48224)\n",
      "Epoch 0 Step 1507/1563 Loss: 1.839 | Acc: 33.256% (16048/48256)\n",
      "Epoch 0 Step 1508/1563 Loss: 1.840 | Acc: 33.257% (16059/48288)\n",
      "Epoch 0 Step 1509/1563 Loss: 1.840 | Acc: 33.260% (16071/48320)\n",
      "Epoch 0 Step 1510/1563 Loss: 1.839 | Acc: 33.264% (16084/48352)\n",
      "Epoch 0 Step 1511/1563 Loss: 1.839 | Acc: 33.269% (16097/48384)\n",
      "Epoch 0 Step 1512/1563 Loss: 1.840 | Acc: 33.258% (16102/48416)\n",
      "Epoch 0 Step 1513/1563 Loss: 1.839 | Acc: 33.265% (16116/48448)\n",
      "Epoch 0 Step 1514/1563 Loss: 1.839 | Acc: 33.274% (16131/48480)\n",
      "Epoch 0 Step 1515/1563 Loss: 1.839 | Acc: 33.278% (16144/48512)\n",
      "Epoch 0 Step 1516/1563 Loss: 1.839 | Acc: 33.277% (16154/48544)\n",
      "Epoch 0 Step 1517/1563 Loss: 1.839 | Acc: 33.276% (16164/48576)\n",
      "Epoch 0 Step 1518/1563 Loss: 1.839 | Acc: 33.283% (16178/48608)\n",
      "Epoch 0 Step 1519/1563 Loss: 1.839 | Acc: 33.281% (16188/48640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 1520/1563 Loss: 1.838 | Acc: 33.290% (16203/48672)\n",
      "Epoch 0 Step 1521/1563 Loss: 1.838 | Acc: 33.299% (16218/48704)\n",
      "Epoch 0 Step 1522/1563 Loss: 1.838 | Acc: 33.312% (16235/48736)\n",
      "Epoch 0 Step 1523/1563 Loss: 1.838 | Acc: 33.325% (16252/48768)\n",
      "Epoch 0 Step 1524/1563 Loss: 1.838 | Acc: 33.332% (16266/48800)\n",
      "Epoch 0 Step 1525/1563 Loss: 1.838 | Acc: 33.339% (16280/48832)\n",
      "Epoch 0 Step 1526/1563 Loss: 1.838 | Acc: 33.342% (16292/48864)\n",
      "Epoch 0 Step 1527/1563 Loss: 1.838 | Acc: 33.350% (16307/48896)\n",
      "Epoch 0 Step 1528/1563 Loss: 1.838 | Acc: 33.357% (16321/48928)\n",
      "Epoch 0 Step 1529/1563 Loss: 1.838 | Acc: 33.354% (16330/48960)\n",
      "Epoch 0 Step 1530/1563 Loss: 1.838 | Acc: 33.359% (16343/48992)\n",
      "Epoch 0 Step 1531/1563 Loss: 1.837 | Acc: 33.363% (16356/49024)\n",
      "Epoch 0 Step 1532/1563 Loss: 1.837 | Acc: 33.374% (16372/49056)\n",
      "Epoch 0 Step 1533/1563 Loss: 1.837 | Acc: 33.363% (16377/49088)\n",
      "Epoch 0 Step 1534/1563 Loss: 1.837 | Acc: 33.361% (16387/49120)\n",
      "Epoch 0 Step 1535/1563 Loss: 1.837 | Acc: 33.370% (16402/49152)\n",
      "Epoch 0 Step 1536/1563 Loss: 1.837 | Acc: 33.369% (16412/49184)\n",
      "Epoch 0 Step 1537/1563 Loss: 1.837 | Acc: 33.373% (16425/49216)\n",
      "Epoch 0 Step 1538/1563 Loss: 1.837 | Acc: 33.376% (16437/49248)\n",
      "Epoch 0 Step 1539/1563 Loss: 1.837 | Acc: 33.385% (16452/49280)\n",
      "Epoch 0 Step 1540/1563 Loss: 1.837 | Acc: 33.385% (16463/49312)\n",
      "Epoch 0 Step 1541/1563 Loss: 1.837 | Acc: 33.388% (16475/49344)\n",
      "Epoch 0 Step 1542/1563 Loss: 1.837 | Acc: 33.385% (16484/49376)\n",
      "Epoch 0 Step 1543/1563 Loss: 1.837 | Acc: 33.379% (16492/49408)\n",
      "Epoch 0 Step 1544/1563 Loss: 1.837 | Acc: 33.376% (16501/49440)\n",
      "Epoch 0 Step 1545/1563 Loss: 1.837 | Acc: 33.383% (16515/49472)\n",
      "Epoch 0 Step 1546/1563 Loss: 1.837 | Acc: 33.379% (16524/49504)\n",
      "Epoch 0 Step 1547/1563 Loss: 1.837 | Acc: 33.378% (16534/49536)\n",
      "Epoch 0 Step 1548/1563 Loss: 1.836 | Acc: 33.382% (16547/49568)\n",
      "Epoch 0 Step 1549/1563 Loss: 1.836 | Acc: 33.379% (16556/49600)\n",
      "Epoch 0 Step 1550/1563 Loss: 1.836 | Acc: 33.380% (16567/49632)\n",
      "Epoch 0 Step 1551/1563 Loss: 1.836 | Acc: 33.376% (16576/49664)\n",
      "Epoch 0 Step 1552/1563 Loss: 1.836 | Acc: 33.373% (16585/49696)\n",
      "Epoch 0 Step 1553/1563 Loss: 1.836 | Acc: 33.380% (16599/49728)\n",
      "Epoch 0 Step 1554/1563 Loss: 1.836 | Acc: 33.380% (16610/49760)\n",
      "Epoch 0 Step 1555/1563 Loss: 1.836 | Acc: 33.385% (16623/49792)\n",
      "Epoch 0 Step 1556/1563 Loss: 1.836 | Acc: 33.382% (16632/49824)\n",
      "Epoch 0 Step 1557/1563 Loss: 1.836 | Acc: 33.394% (16649/49856)\n",
      "Epoch 0 Step 1558/1563 Loss: 1.836 | Acc: 33.395% (16660/49888)\n",
      "Epoch 0 Step 1559/1563 Loss: 1.835 | Acc: 33.401% (16674/49920)\n",
      "Epoch 0 Step 1560/1563 Loss: 1.835 | Acc: 33.404% (16686/49952)\n",
      "Epoch 0 Step 1561/1563 Loss: 1.835 | Acc: 33.405% (16697/49984)\n",
      "Epoch 0 Step 1562/1563 Loss: 1.835 | Acc: 33.402% (16701/50000)\n",
      "Epoch 0 Step 0/313 Test Loss: 1.353 | Test Acc: 43.750% (14/32)\n",
      "Epoch 0 Step 1/313 Test Loss: 1.509 | Test Acc: 42.188% (27/64)\n",
      "Epoch 0 Step 2/313 Test Loss: 1.553 | Test Acc: 40.625% (39/96)\n",
      "Epoch 0 Step 3/313 Test Loss: 1.512 | Test Acc: 42.969% (55/128)\n",
      "Epoch 0 Step 4/313 Test Loss: 1.560 | Test Acc: 40.625% (65/160)\n",
      "Epoch 0 Step 5/313 Test Loss: 1.571 | Test Acc: 40.625% (78/192)\n",
      "Epoch 0 Step 6/313 Test Loss: 1.644 | Test Acc: 39.286% (88/224)\n",
      "Epoch 0 Step 7/313 Test Loss: 1.648 | Test Acc: 38.281% (98/256)\n",
      "Epoch 0 Step 8/313 Test Loss: 1.662 | Test Acc: 37.153% (107/288)\n",
      "Epoch 0 Step 9/313 Test Loss: 1.621 | Test Acc: 38.750% (124/320)\n",
      "Epoch 0 Step 10/313 Test Loss: 1.624 | Test Acc: 39.205% (138/352)\n",
      "Epoch 0 Step 11/313 Test Loss: 1.642 | Test Acc: 39.062% (150/384)\n",
      "Epoch 0 Step 12/313 Test Loss: 1.634 | Test Acc: 39.183% (163/416)\n",
      "Epoch 0 Step 13/313 Test Loss: 1.651 | Test Acc: 38.170% (171/448)\n",
      "Epoch 0 Step 14/313 Test Loss: 1.657 | Test Acc: 38.333% (184/480)\n",
      "Epoch 0 Step 15/313 Test Loss: 1.646 | Test Acc: 38.477% (197/512)\n",
      "Epoch 0 Step 16/313 Test Loss: 1.636 | Test Acc: 39.154% (213/544)\n",
      "Epoch 0 Step 17/313 Test Loss: 1.628 | Test Acc: 39.236% (226/576)\n",
      "Epoch 0 Step 18/313 Test Loss: 1.627 | Test Acc: 39.309% (239/608)\n",
      "Epoch 0 Step 19/313 Test Loss: 1.605 | Test Acc: 40.000% (256/640)\n",
      "Epoch 0 Step 20/313 Test Loss: 1.604 | Test Acc: 40.179% (270/672)\n",
      "Epoch 0 Step 21/313 Test Loss: 1.620 | Test Acc: 39.773% (280/704)\n",
      "Epoch 0 Step 22/313 Test Loss: 1.622 | Test Acc: 39.810% (293/736)\n",
      "Epoch 0 Step 23/313 Test Loss: 1.625 | Test Acc: 39.844% (306/768)\n",
      "Epoch 0 Step 24/313 Test Loss: 1.629 | Test Acc: 39.625% (317/800)\n",
      "Epoch 0 Step 25/313 Test Loss: 1.630 | Test Acc: 39.663% (330/832)\n",
      "Epoch 0 Step 26/313 Test Loss: 1.627 | Test Acc: 39.931% (345/864)\n",
      "Epoch 0 Step 27/313 Test Loss: 1.619 | Test Acc: 40.402% (362/896)\n",
      "Epoch 0 Step 28/313 Test Loss: 1.620 | Test Acc: 40.625% (377/928)\n",
      "Epoch 0 Step 29/313 Test Loss: 1.608 | Test Acc: 41.354% (397/960)\n",
      "Epoch 0 Step 30/313 Test Loss: 1.603 | Test Acc: 41.431% (411/992)\n",
      "Epoch 0 Step 31/313 Test Loss: 1.599 | Test Acc: 41.797% (428/1024)\n",
      "Epoch 0 Step 32/313 Test Loss: 1.603 | Test Acc: 41.856% (442/1056)\n",
      "Epoch 0 Step 33/313 Test Loss: 1.597 | Test Acc: 42.188% (459/1088)\n",
      "Epoch 0 Step 34/313 Test Loss: 1.587 | Test Acc: 42.768% (479/1120)\n",
      "Epoch 0 Step 35/313 Test Loss: 1.591 | Test Acc: 42.448% (489/1152)\n",
      "Epoch 0 Step 36/313 Test Loss: 1.588 | Test Acc: 42.314% (501/1184)\n",
      "Epoch 0 Step 37/313 Test Loss: 1.588 | Test Acc: 42.599% (518/1216)\n",
      "Epoch 0 Step 38/313 Test Loss: 1.595 | Test Acc: 42.628% (532/1248)\n",
      "Epoch 0 Step 39/313 Test Loss: 1.596 | Test Acc: 42.422% (543/1280)\n",
      "Epoch 0 Step 40/313 Test Loss: 1.596 | Test Acc: 42.378% (556/1312)\n",
      "Epoch 0 Step 41/313 Test Loss: 1.600 | Test Acc: 42.113% (566/1344)\n",
      "Epoch 0 Step 42/313 Test Loss: 1.594 | Test Acc: 42.369% (583/1376)\n",
      "Epoch 0 Step 43/313 Test Loss: 1.600 | Test Acc: 42.116% (593/1408)\n",
      "Epoch 0 Step 44/313 Test Loss: 1.601 | Test Acc: 42.014% (605/1440)\n",
      "Epoch 0 Step 45/313 Test Loss: 1.599 | Test Acc: 42.052% (619/1472)\n",
      "Epoch 0 Step 46/313 Test Loss: 1.597 | Test Acc: 42.221% (635/1504)\n",
      "Epoch 0 Step 47/313 Test Loss: 1.596 | Test Acc: 42.122% (647/1536)\n",
      "Epoch 0 Step 48/313 Test Loss: 1.594 | Test Acc: 42.092% (660/1568)\n",
      "Epoch 0 Step 49/313 Test Loss: 1.599 | Test Acc: 41.875% (670/1600)\n",
      "Epoch 0 Step 50/313 Test Loss: 1.605 | Test Acc: 41.728% (681/1632)\n",
      "Epoch 0 Step 51/313 Test Loss: 1.601 | Test Acc: 42.007% (699/1664)\n",
      "Epoch 0 Step 52/313 Test Loss: 1.599 | Test Acc: 42.158% (715/1696)\n",
      "Epoch 0 Step 53/313 Test Loss: 1.601 | Test Acc: 42.072% (727/1728)\n",
      "Epoch 0 Step 54/313 Test Loss: 1.603 | Test Acc: 41.989% (739/1760)\n",
      "Epoch 0 Step 55/313 Test Loss: 1.599 | Test Acc: 42.020% (753/1792)\n",
      "Epoch 0 Step 56/313 Test Loss: 1.601 | Test Acc: 41.831% (763/1824)\n",
      "Epoch 0 Step 57/313 Test Loss: 1.603 | Test Acc: 42.026% (780/1856)\n",
      "Epoch 0 Step 58/313 Test Loss: 1.603 | Test Acc: 42.055% (794/1888)\n",
      "Epoch 0 Step 59/313 Test Loss: 1.606 | Test Acc: 41.771% (802/1920)\n",
      "Epoch 0 Step 60/313 Test Loss: 1.605 | Test Acc: 41.752% (815/1952)\n",
      "Epoch 0 Step 61/313 Test Loss: 1.602 | Test Acc: 41.885% (831/1984)\n",
      "Epoch 0 Step 62/313 Test Loss: 1.605 | Test Acc: 41.766% (842/2016)\n",
      "Epoch 0 Step 63/313 Test Loss: 1.603 | Test Acc: 41.895% (858/2048)\n",
      "Epoch 0 Step 64/313 Test Loss: 1.601 | Test Acc: 41.731% (868/2080)\n",
      "Epoch 0 Step 65/313 Test Loss: 1.598 | Test Acc: 42.045% (888/2112)\n",
      "Epoch 0 Step 66/313 Test Loss: 1.596 | Test Acc: 42.024% (901/2144)\n",
      "Epoch 0 Step 67/313 Test Loss: 1.600 | Test Acc: 42.050% (915/2176)\n",
      "Epoch 0 Step 68/313 Test Loss: 1.600 | Test Acc: 42.120% (930/2208)\n",
      "Epoch 0 Step 69/313 Test Loss: 1.599 | Test Acc: 42.054% (942/2240)\n",
      "Epoch 0 Step 70/313 Test Loss: 1.598 | Test Acc: 42.165% (958/2272)\n",
      "Epoch 0 Step 71/313 Test Loss: 1.598 | Test Acc: 42.144% (971/2304)\n",
      "Epoch 0 Step 72/313 Test Loss: 1.601 | Test Acc: 42.080% (983/2336)\n",
      "Epoch 0 Step 73/313 Test Loss: 1.601 | Test Acc: 42.061% (996/2368)\n",
      "Epoch 0 Step 74/313 Test Loss: 1.600 | Test Acc: 42.083% (1010/2400)\n",
      "Epoch 0 Step 75/313 Test Loss: 1.600 | Test Acc: 41.982% (1021/2432)\n",
      "Epoch 0 Step 76/313 Test Loss: 1.599 | Test Acc: 42.086% (1037/2464)\n",
      "Epoch 0 Step 77/313 Test Loss: 1.597 | Test Acc: 42.228% (1054/2496)\n",
      "Epoch 0 Step 78/313 Test Loss: 1.602 | Test Acc: 42.049% (1063/2528)\n",
      "Epoch 0 Step 79/313 Test Loss: 1.604 | Test Acc: 41.914% (1073/2560)\n",
      "Epoch 0 Step 80/313 Test Loss: 1.604 | Test Acc: 41.744% (1082/2592)\n",
      "Epoch 0 Step 81/313 Test Loss: 1.603 | Test Acc: 41.806% (1097/2624)\n",
      "Epoch 0 Step 82/313 Test Loss: 1.605 | Test Acc: 41.755% (1109/2656)\n",
      "Epoch 0 Step 83/313 Test Loss: 1.604 | Test Acc: 41.890% (1126/2688)\n",
      "Epoch 0 Step 84/313 Test Loss: 1.603 | Test Acc: 41.985% (1142/2720)\n",
      "Epoch 0 Step 85/313 Test Loss: 1.606 | Test Acc: 41.788% (1150/2752)\n",
      "Epoch 0 Step 86/313 Test Loss: 1.606 | Test Acc: 41.703% (1161/2784)\n",
      "Epoch 0 Step 87/313 Test Loss: 1.606 | Test Acc: 41.584% (1171/2816)\n",
      "Epoch 0 Step 88/313 Test Loss: 1.608 | Test Acc: 41.538% (1183/2848)\n",
      "Epoch 0 Step 89/313 Test Loss: 1.607 | Test Acc: 41.562% (1197/2880)\n",
      "Epoch 0 Step 90/313 Test Loss: 1.609 | Test Acc: 41.346% (1204/2912)\n",
      "Epoch 0 Step 91/313 Test Loss: 1.607 | Test Acc: 41.372% (1218/2944)\n",
      "Epoch 0 Step 92/313 Test Loss: 1.606 | Test Acc: 41.431% (1233/2976)\n",
      "Epoch 0 Step 93/313 Test Loss: 1.606 | Test Acc: 41.423% (1246/3008)\n",
      "Epoch 0 Step 94/313 Test Loss: 1.605 | Test Acc: 41.480% (1261/3040)\n",
      "Epoch 0 Step 95/313 Test Loss: 1.605 | Test Acc: 41.439% (1273/3072)\n",
      "Epoch 0 Step 96/313 Test Loss: 1.603 | Test Acc: 41.495% (1288/3104)\n",
      "Epoch 0 Step 97/313 Test Loss: 1.605 | Test Acc: 41.422% (1299/3136)\n",
      "Epoch 0 Step 98/313 Test Loss: 1.605 | Test Acc: 41.477% (1314/3168)\n",
      "Epoch 0 Step 99/313 Test Loss: 1.605 | Test Acc: 41.594% (1331/3200)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 100/313 Test Loss: 1.609 | Test Acc: 41.522% (1342/3232)\n",
      "Epoch 0 Step 101/313 Test Loss: 1.608 | Test Acc: 41.605% (1358/3264)\n",
      "Epoch 0 Step 102/313 Test Loss: 1.606 | Test Acc: 41.717% (1375/3296)\n",
      "Epoch 0 Step 103/313 Test Loss: 1.607 | Test Acc: 41.647% (1386/3328)\n",
      "Epoch 0 Step 104/313 Test Loss: 1.607 | Test Acc: 41.756% (1403/3360)\n",
      "Epoch 0 Step 105/313 Test Loss: 1.605 | Test Acc: 41.804% (1418/3392)\n",
      "Epoch 0 Step 106/313 Test Loss: 1.608 | Test Acc: 41.647% (1426/3424)\n",
      "Epoch 0 Step 107/313 Test Loss: 1.608 | Test Acc: 41.753% (1443/3456)\n",
      "Epoch 0 Step 108/313 Test Loss: 1.607 | Test Acc: 41.800% (1458/3488)\n",
      "Epoch 0 Step 109/313 Test Loss: 1.608 | Test Acc: 41.733% (1469/3520)\n",
      "Epoch 0 Step 110/313 Test Loss: 1.608 | Test Acc: 41.723% (1482/3552)\n",
      "Epoch 0 Step 111/313 Test Loss: 1.606 | Test Acc: 41.741% (1496/3584)\n",
      "Epoch 0 Step 112/313 Test Loss: 1.607 | Test Acc: 41.704% (1508/3616)\n",
      "Epoch 0 Step 113/313 Test Loss: 1.606 | Test Acc: 41.721% (1522/3648)\n",
      "Epoch 0 Step 114/313 Test Loss: 1.604 | Test Acc: 41.793% (1538/3680)\n",
      "Epoch 0 Step 115/313 Test Loss: 1.604 | Test Acc: 41.837% (1553/3712)\n",
      "Epoch 0 Step 116/313 Test Loss: 1.603 | Test Acc: 41.827% (1566/3744)\n",
      "Epoch 0 Step 117/313 Test Loss: 1.603 | Test Acc: 41.870% (1581/3776)\n",
      "Epoch 0 Step 118/313 Test Loss: 1.603 | Test Acc: 41.964% (1598/3808)\n",
      "Epoch 0 Step 119/313 Test Loss: 1.600 | Test Acc: 42.057% (1615/3840)\n",
      "Epoch 0 Step 120/313 Test Loss: 1.599 | Test Acc: 42.045% (1628/3872)\n",
      "Epoch 0 Step 121/313 Test Loss: 1.597 | Test Acc: 42.162% (1646/3904)\n",
      "Epoch 0 Step 122/313 Test Loss: 1.598 | Test Acc: 42.149% (1659/3936)\n",
      "Epoch 0 Step 123/313 Test Loss: 1.597 | Test Acc: 42.137% (1672/3968)\n",
      "Epoch 0 Step 124/313 Test Loss: 1.601 | Test Acc: 42.050% (1682/4000)\n",
      "Epoch 0 Step 125/313 Test Loss: 1.600 | Test Acc: 42.063% (1696/4032)\n",
      "Epoch 0 Step 126/313 Test Loss: 1.602 | Test Acc: 42.003% (1707/4064)\n",
      "Epoch 0 Step 127/313 Test Loss: 1.602 | Test Acc: 41.968% (1719/4096)\n",
      "Epoch 0 Step 128/313 Test Loss: 1.604 | Test Acc: 41.982% (1733/4128)\n",
      "Epoch 0 Step 129/313 Test Loss: 1.603 | Test Acc: 42.043% (1749/4160)\n",
      "Epoch 0 Step 130/313 Test Loss: 1.602 | Test Acc: 42.104% (1765/4192)\n",
      "Epoch 0 Step 131/313 Test Loss: 1.601 | Test Acc: 42.116% (1779/4224)\n",
      "Epoch 0 Step 132/313 Test Loss: 1.601 | Test Acc: 42.152% (1794/4256)\n",
      "Epoch 0 Step 133/313 Test Loss: 1.600 | Test Acc: 42.188% (1809/4288)\n",
      "Epoch 0 Step 134/313 Test Loss: 1.600 | Test Acc: 42.245% (1825/4320)\n",
      "Epoch 0 Step 135/313 Test Loss: 1.599 | Test Acc: 42.371% (1844/4352)\n",
      "Epoch 0 Step 136/313 Test Loss: 1.598 | Test Acc: 42.359% (1857/4384)\n",
      "Epoch 0 Step 137/313 Test Loss: 1.597 | Test Acc: 42.414% (1873/4416)\n",
      "Epoch 0 Step 138/313 Test Loss: 1.596 | Test Acc: 42.446% (1888/4448)\n",
      "Epoch 0 Step 139/313 Test Loss: 1.596 | Test Acc: 42.411% (1900/4480)\n",
      "Epoch 0 Step 140/313 Test Loss: 1.595 | Test Acc: 42.442% (1915/4512)\n",
      "Epoch 0 Step 141/313 Test Loss: 1.596 | Test Acc: 42.342% (1924/4544)\n",
      "Epoch 0 Step 142/313 Test Loss: 1.596 | Test Acc: 42.330% (1937/4576)\n",
      "Epoch 0 Step 143/313 Test Loss: 1.598 | Test Acc: 42.253% (1947/4608)\n",
      "Epoch 0 Step 144/313 Test Loss: 1.599 | Test Acc: 42.263% (1961/4640)\n",
      "Epoch 0 Step 145/313 Test Loss: 1.598 | Test Acc: 42.273% (1975/4672)\n",
      "Epoch 0 Step 146/313 Test Loss: 1.597 | Test Acc: 42.219% (1986/4704)\n",
      "Epoch 0 Step 147/313 Test Loss: 1.597 | Test Acc: 42.188% (1998/4736)\n",
      "Epoch 0 Step 148/313 Test Loss: 1.597 | Test Acc: 42.282% (2016/4768)\n",
      "Epoch 0 Step 149/313 Test Loss: 1.597 | Test Acc: 42.333% (2032/4800)\n",
      "Epoch 0 Step 150/313 Test Loss: 1.597 | Test Acc: 42.322% (2045/4832)\n",
      "Epoch 0 Step 151/313 Test Loss: 1.596 | Test Acc: 42.414% (2063/4864)\n",
      "Epoch 0 Step 152/313 Test Loss: 1.595 | Test Acc: 42.443% (2078/4896)\n",
      "Epoch 0 Step 153/313 Test Loss: 1.594 | Test Acc: 42.492% (2094/4928)\n",
      "Epoch 0 Step 154/313 Test Loss: 1.593 | Test Acc: 42.520% (2109/4960)\n",
      "Epoch 0 Step 155/313 Test Loss: 1.594 | Test Acc: 42.568% (2125/4992)\n",
      "Epoch 0 Step 156/313 Test Loss: 1.594 | Test Acc: 42.596% (2140/5024)\n",
      "Epoch 0 Step 157/313 Test Loss: 1.594 | Test Acc: 42.524% (2150/5056)\n",
      "Epoch 0 Step 158/313 Test Loss: 1.594 | Test Acc: 42.472% (2161/5088)\n",
      "Epoch 0 Step 159/313 Test Loss: 1.595 | Test Acc: 42.500% (2176/5120)\n",
      "Epoch 0 Step 160/313 Test Loss: 1.594 | Test Acc: 42.605% (2195/5152)\n",
      "Epoch 0 Step 161/313 Test Loss: 1.594 | Test Acc: 42.670% (2212/5184)\n",
      "Epoch 0 Step 162/313 Test Loss: 1.595 | Test Acc: 42.657% (2225/5216)\n",
      "Epoch 0 Step 163/313 Test Loss: 1.594 | Test Acc: 42.645% (2238/5248)\n",
      "Epoch 0 Step 164/313 Test Loss: 1.594 | Test Acc: 42.633% (2251/5280)\n",
      "Epoch 0 Step 165/313 Test Loss: 1.593 | Test Acc: 42.658% (2266/5312)\n",
      "Epoch 0 Step 166/313 Test Loss: 1.595 | Test Acc: 42.609% (2277/5344)\n",
      "Epoch 0 Step 167/313 Test Loss: 1.595 | Test Acc: 42.671% (2294/5376)\n",
      "Epoch 0 Step 168/313 Test Loss: 1.596 | Test Acc: 42.678% (2308/5408)\n",
      "Epoch 0 Step 169/313 Test Loss: 1.595 | Test Acc: 42.684% (2322/5440)\n",
      "Epoch 0 Step 170/313 Test Loss: 1.595 | Test Acc: 42.727% (2338/5472)\n",
      "Epoch 0 Step 171/313 Test Loss: 1.594 | Test Acc: 42.751% (2353/5504)\n",
      "Epoch 0 Step 172/313 Test Loss: 1.595 | Test Acc: 42.738% (2366/5536)\n",
      "Epoch 0 Step 173/313 Test Loss: 1.595 | Test Acc: 42.708% (2378/5568)\n",
      "Epoch 0 Step 174/313 Test Loss: 1.595 | Test Acc: 42.732% (2393/5600)\n",
      "Epoch 0 Step 175/313 Test Loss: 1.597 | Test Acc: 42.702% (2405/5632)\n",
      "Epoch 0 Step 176/313 Test Loss: 1.598 | Test Acc: 42.620% (2414/5664)\n",
      "Epoch 0 Step 177/313 Test Loss: 1.597 | Test Acc: 42.732% (2434/5696)\n",
      "Epoch 0 Step 178/313 Test Loss: 1.595 | Test Acc: 42.807% (2452/5728)\n",
      "Epoch 0 Step 179/313 Test Loss: 1.595 | Test Acc: 42.726% (2461/5760)\n",
      "Epoch 0 Step 180/313 Test Loss: 1.594 | Test Acc: 42.783% (2478/5792)\n",
      "Epoch 0 Step 181/313 Test Loss: 1.594 | Test Acc: 42.720% (2488/5824)\n",
      "Epoch 0 Step 182/313 Test Loss: 1.595 | Test Acc: 42.657% (2498/5856)\n",
      "Epoch 0 Step 183/313 Test Loss: 1.595 | Test Acc: 42.612% (2509/5888)\n",
      "Epoch 0 Step 184/313 Test Loss: 1.596 | Test Acc: 42.568% (2520/5920)\n",
      "Epoch 0 Step 185/313 Test Loss: 1.597 | Test Acc: 42.507% (2530/5952)\n",
      "Epoch 0 Step 186/313 Test Loss: 1.597 | Test Acc: 42.530% (2545/5984)\n",
      "Epoch 0 Step 187/313 Test Loss: 1.597 | Test Acc: 42.503% (2557/6016)\n",
      "Epoch 0 Step 188/313 Test Loss: 1.596 | Test Acc: 42.460% (2568/6048)\n",
      "Epoch 0 Step 189/313 Test Loss: 1.597 | Test Acc: 42.385% (2577/6080)\n",
      "Epoch 0 Step 190/313 Test Loss: 1.596 | Test Acc: 42.376% (2590/6112)\n",
      "Epoch 0 Step 191/313 Test Loss: 1.597 | Test Acc: 42.415% (2606/6144)\n",
      "Epoch 0 Step 192/313 Test Loss: 1.597 | Test Acc: 42.374% (2617/6176)\n",
      "Epoch 0 Step 193/313 Test Loss: 1.596 | Test Acc: 42.349% (2629/6208)\n",
      "Epoch 0 Step 194/313 Test Loss: 1.598 | Test Acc: 42.276% (2638/6240)\n",
      "Epoch 0 Step 195/313 Test Loss: 1.599 | Test Acc: 42.172% (2645/6272)\n",
      "Epoch 0 Step 196/313 Test Loss: 1.599 | Test Acc: 42.132% (2656/6304)\n",
      "Epoch 0 Step 197/313 Test Loss: 1.599 | Test Acc: 42.172% (2672/6336)\n",
      "Epoch 0 Step 198/313 Test Loss: 1.597 | Test Acc: 42.242% (2690/6368)\n",
      "Epoch 0 Step 199/313 Test Loss: 1.597 | Test Acc: 42.250% (2704/6400)\n",
      "Epoch 0 Step 200/313 Test Loss: 1.598 | Test Acc: 42.242% (2717/6432)\n",
      "Epoch 0 Step 201/313 Test Loss: 1.598 | Test Acc: 42.188% (2727/6464)\n",
      "Epoch 0 Step 202/313 Test Loss: 1.598 | Test Acc: 42.211% (2742/6496)\n",
      "Epoch 0 Step 203/313 Test Loss: 1.598 | Test Acc: 42.218% (2756/6528)\n",
      "Epoch 0 Step 204/313 Test Loss: 1.600 | Test Acc: 42.226% (2770/6560)\n",
      "Epoch 0 Step 205/313 Test Loss: 1.601 | Test Acc: 42.157% (2779/6592)\n",
      "Epoch 0 Step 206/313 Test Loss: 1.601 | Test Acc: 42.165% (2793/6624)\n",
      "Epoch 0 Step 207/313 Test Loss: 1.600 | Test Acc: 42.142% (2805/6656)\n",
      "Epoch 0 Step 208/313 Test Loss: 1.600 | Test Acc: 42.135% (2818/6688)\n",
      "Epoch 0 Step 209/313 Test Loss: 1.600 | Test Acc: 42.113% (2830/6720)\n",
      "Epoch 0 Step 210/313 Test Loss: 1.600 | Test Acc: 42.150% (2846/6752)\n",
      "Epoch 0 Step 211/313 Test Loss: 1.600 | Test Acc: 42.114% (2857/6784)\n",
      "Epoch 0 Step 212/313 Test Loss: 1.598 | Test Acc: 42.210% (2877/6816)\n",
      "Epoch 0 Step 213/313 Test Loss: 1.598 | Test Acc: 42.246% (2893/6848)\n",
      "Epoch 0 Step 214/313 Test Loss: 1.599 | Test Acc: 42.151% (2900/6880)\n",
      "Epoch 0 Step 215/313 Test Loss: 1.598 | Test Acc: 42.159% (2914/6912)\n",
      "Epoch 0 Step 216/313 Test Loss: 1.599 | Test Acc: 42.151% (2927/6944)\n",
      "Epoch 0 Step 217/313 Test Loss: 1.600 | Test Acc: 42.159% (2941/6976)\n",
      "Epoch 0 Step 218/313 Test Loss: 1.600 | Test Acc: 42.109% (2951/7008)\n",
      "Epoch 0 Step 219/313 Test Loss: 1.600 | Test Acc: 42.116% (2965/7040)\n",
      "Epoch 0 Step 220/313 Test Loss: 1.602 | Test Acc: 42.067% (2975/7072)\n",
      "Epoch 0 Step 221/313 Test Loss: 1.602 | Test Acc: 42.089% (2990/7104)\n",
      "Epoch 0 Step 222/313 Test Loss: 1.602 | Test Acc: 42.096% (3004/7136)\n",
      "Epoch 0 Step 223/313 Test Loss: 1.601 | Test Acc: 42.132% (3020/7168)\n",
      "Epoch 0 Step 224/313 Test Loss: 1.602 | Test Acc: 42.097% (3031/7200)\n",
      "Epoch 0 Step 225/313 Test Loss: 1.602 | Test Acc: 42.063% (3042/7232)\n",
      "Epoch 0 Step 226/313 Test Loss: 1.603 | Test Acc: 42.002% (3051/7264)\n",
      "Epoch 0 Step 227/313 Test Loss: 1.602 | Test Acc: 41.968% (3062/7296)\n",
      "Epoch 0 Step 228/313 Test Loss: 1.602 | Test Acc: 41.949% (3074/7328)\n",
      "Epoch 0 Step 229/313 Test Loss: 1.601 | Test Acc: 41.997% (3091/7360)\n",
      "Epoch 0 Step 230/313 Test Loss: 1.600 | Test Acc: 42.005% (3105/7392)\n",
      "Epoch 0 Step 231/313 Test Loss: 1.601 | Test Acc: 41.959% (3115/7424)\n",
      "Epoch 0 Step 232/313 Test Loss: 1.601 | Test Acc: 41.939% (3127/7456)\n",
      "Epoch 0 Step 233/313 Test Loss: 1.599 | Test Acc: 42.054% (3149/7488)\n",
      "Epoch 0 Step 234/313 Test Loss: 1.599 | Test Acc: 42.048% (3162/7520)\n",
      "Epoch 0 Step 235/313 Test Loss: 1.598 | Test Acc: 42.055% (3176/7552)\n",
      "Epoch 0 Step 236/313 Test Loss: 1.599 | Test Acc: 42.023% (3187/7584)\n",
      "Epoch 0 Step 237/313 Test Loss: 1.600 | Test Acc: 41.964% (3196/7616)\n",
      "Epoch 0 Step 238/313 Test Loss: 1.601 | Test Acc: 41.959% (3209/7648)\n",
      "Epoch 0 Step 239/313 Test Loss: 1.600 | Test Acc: 41.966% (3223/7680)\n",
      "Epoch 0 Step 240/313 Test Loss: 1.599 | Test Acc: 42.051% (3243/7712)\n",
      "Epoch 0 Step 241/313 Test Loss: 1.599 | Test Acc: 42.033% (3255/7744)\n",
      "Epoch 0 Step 242/313 Test Loss: 1.598 | Test Acc: 42.078% (3272/7776)\n",
      "Epoch 0 Step 243/313 Test Loss: 1.598 | Test Acc: 42.072% (3285/7808)\n",
      "Epoch 0 Step 244/313 Test Loss: 1.598 | Test Acc: 42.041% (3296/7840)\n",
      "Epoch 0 Step 245/313 Test Loss: 1.598 | Test Acc: 42.099% (3314/7872)\n",
      "Epoch 0 Step 246/313 Test Loss: 1.598 | Test Acc: 42.131% (3330/7904)\n",
      "Epoch 0 Step 247/313 Test Loss: 1.599 | Test Acc: 42.036% (3336/7936)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 248/313 Test Loss: 1.600 | Test Acc: 41.993% (3346/7968)\n",
      "Epoch 0 Step 249/313 Test Loss: 1.600 | Test Acc: 42.013% (3361/8000)\n",
      "Epoch 0 Step 250/313 Test Loss: 1.599 | Test Acc: 42.019% (3375/8032)\n",
      "Epoch 0 Step 251/313 Test Loss: 1.599 | Test Acc: 42.039% (3390/8064)\n",
      "Epoch 0 Step 252/313 Test Loss: 1.600 | Test Acc: 42.033% (3403/8096)\n",
      "Epoch 0 Step 253/313 Test Loss: 1.600 | Test Acc: 41.978% (3412/8128)\n",
      "Epoch 0 Step 254/313 Test Loss: 1.600 | Test Acc: 41.961% (3424/8160)\n",
      "Epoch 0 Step 255/313 Test Loss: 1.600 | Test Acc: 42.004% (3441/8192)\n",
      "Epoch 0 Step 256/313 Test Loss: 1.600 | Test Acc: 41.963% (3451/8224)\n",
      "Epoch 0 Step 257/313 Test Loss: 1.600 | Test Acc: 41.957% (3464/8256)\n",
      "Epoch 0 Step 258/313 Test Loss: 1.600 | Test Acc: 41.976% (3479/8288)\n",
      "Epoch 0 Step 259/313 Test Loss: 1.601 | Test Acc: 41.911% (3487/8320)\n",
      "Epoch 0 Step 260/313 Test Loss: 1.602 | Test Acc: 41.858% (3496/8352)\n",
      "Epoch 0 Step 261/313 Test Loss: 1.601 | Test Acc: 41.865% (3510/8384)\n",
      "Epoch 0 Step 262/313 Test Loss: 1.601 | Test Acc: 41.861% (3523/8416)\n",
      "Epoch 0 Step 263/313 Test Loss: 1.601 | Test Acc: 41.809% (3532/8448)\n",
      "Epoch 0 Step 264/313 Test Loss: 1.602 | Test Acc: 41.781% (3543/8480)\n",
      "Epoch 0 Step 265/313 Test Loss: 1.602 | Test Acc: 41.753% (3554/8512)\n",
      "Epoch 0 Step 266/313 Test Loss: 1.603 | Test Acc: 41.749% (3567/8544)\n",
      "Epoch 0 Step 267/313 Test Loss: 1.603 | Test Acc: 41.733% (3579/8576)\n",
      "Epoch 0 Step 268/313 Test Loss: 1.603 | Test Acc: 41.729% (3592/8608)\n",
      "Epoch 0 Step 269/313 Test Loss: 1.603 | Test Acc: 41.736% (3606/8640)\n",
      "Epoch 0 Step 270/313 Test Loss: 1.603 | Test Acc: 41.732% (3619/8672)\n",
      "Epoch 0 Step 271/313 Test Loss: 1.603 | Test Acc: 41.716% (3631/8704)\n",
      "Epoch 0 Step 272/313 Test Loss: 1.602 | Test Acc: 41.701% (3643/8736)\n",
      "Epoch 0 Step 273/313 Test Loss: 1.602 | Test Acc: 41.731% (3659/8768)\n",
      "Epoch 0 Step 274/313 Test Loss: 1.602 | Test Acc: 41.750% (3674/8800)\n",
      "Epoch 0 Step 275/313 Test Loss: 1.602 | Test Acc: 41.769% (3689/8832)\n",
      "Epoch 0 Step 276/313 Test Loss: 1.603 | Test Acc: 41.764% (3702/8864)\n",
      "Epoch 0 Step 277/313 Test Loss: 1.602 | Test Acc: 41.817% (3720/8896)\n",
      "Epoch 0 Step 278/313 Test Loss: 1.600 | Test Acc: 41.924% (3743/8928)\n",
      "Epoch 0 Step 279/313 Test Loss: 1.601 | Test Acc: 41.886% (3753/8960)\n",
      "Epoch 0 Step 280/313 Test Loss: 1.601 | Test Acc: 41.882% (3766/8992)\n",
      "Epoch 0 Step 281/313 Test Loss: 1.601 | Test Acc: 41.910% (3782/9024)\n",
      "Epoch 0 Step 282/313 Test Loss: 1.601 | Test Acc: 41.884% (3793/9056)\n",
      "Epoch 0 Step 283/313 Test Loss: 1.602 | Test Acc: 41.846% (3803/9088)\n",
      "Epoch 0 Step 284/313 Test Loss: 1.601 | Test Acc: 41.842% (3816/9120)\n",
      "Epoch 0 Step 285/313 Test Loss: 1.602 | Test Acc: 41.838% (3829/9152)\n",
      "Epoch 0 Step 286/313 Test Loss: 1.601 | Test Acc: 41.855% (3844/9184)\n",
      "Epoch 0 Step 287/313 Test Loss: 1.600 | Test Acc: 41.938% (3865/9216)\n",
      "Epoch 0 Step 288/313 Test Loss: 1.600 | Test Acc: 41.998% (3884/9248)\n",
      "Epoch 0 Step 289/313 Test Loss: 1.599 | Test Acc: 42.026% (3900/9280)\n",
      "Epoch 0 Step 290/313 Test Loss: 1.600 | Test Acc: 41.967% (3908/9312)\n",
      "Epoch 0 Step 291/313 Test Loss: 1.600 | Test Acc: 41.973% (3922/9344)\n",
      "Epoch 0 Step 292/313 Test Loss: 1.600 | Test Acc: 41.969% (3935/9376)\n",
      "Epoch 0 Step 293/313 Test Loss: 1.600 | Test Acc: 41.986% (3950/9408)\n",
      "Epoch 0 Step 294/313 Test Loss: 1.601 | Test Acc: 41.992% (3964/9440)\n",
      "Epoch 0 Step 295/313 Test Loss: 1.601 | Test Acc: 41.997% (3978/9472)\n",
      "Epoch 0 Step 296/313 Test Loss: 1.600 | Test Acc: 42.056% (3997/9504)\n",
      "Epoch 0 Step 297/313 Test Loss: 1.600 | Test Acc: 42.062% (4011/9536)\n",
      "Epoch 0 Step 298/313 Test Loss: 1.600 | Test Acc: 42.078% (4026/9568)\n",
      "Epoch 0 Step 299/313 Test Loss: 1.599 | Test Acc: 42.104% (4042/9600)\n",
      "Epoch 0 Step 300/313 Test Loss: 1.599 | Test Acc: 42.120% (4057/9632)\n",
      "Epoch 0 Step 301/313 Test Loss: 1.599 | Test Acc: 42.156% (4074/9664)\n",
      "Epoch 0 Step 302/313 Test Loss: 1.599 | Test Acc: 42.182% (4090/9696)\n",
      "Epoch 0 Step 303/313 Test Loss: 1.599 | Test Acc: 42.198% (4105/9728)\n",
      "Epoch 0 Step 304/313 Test Loss: 1.599 | Test Acc: 42.172% (4116/9760)\n",
      "Epoch 0 Step 305/313 Test Loss: 1.599 | Test Acc: 42.198% (4132/9792)\n",
      "Epoch 0 Step 306/313 Test Loss: 1.599 | Test Acc: 42.213% (4147/9824)\n",
      "Epoch 0 Step 307/313 Test Loss: 1.599 | Test Acc: 42.218% (4161/9856)\n",
      "Epoch 0 Step 308/313 Test Loss: 1.599 | Test Acc: 42.203% (4173/9888)\n",
      "Epoch 0 Step 309/313 Test Loss: 1.599 | Test Acc: 42.188% (4185/9920)\n",
      "Epoch 0 Step 310/313 Test Loss: 1.600 | Test Acc: 42.162% (4196/9952)\n",
      "Epoch 0 Step 311/313 Test Loss: 1.600 | Test Acc: 42.177% (4211/9984)\n",
      "Epoch 0 Step 312/313 Test Loss: 1.600 | Test Acc: 42.160% (4216/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      "Epoch 1 Step 0/1563 Loss: 1.783 | Acc: 40.625% (13/32)\n",
      "Epoch 1 Step 1/1563 Loss: 1.788 | Acc: 42.188% (27/64)\n",
      "Epoch 1 Step 2/1563 Loss: 1.785 | Acc: 37.500% (36/96)\n",
      "Epoch 1 Step 3/1563 Loss: 1.746 | Acc: 39.062% (50/128)\n",
      "Epoch 1 Step 4/1563 Loss: 1.769 | Acc: 39.375% (63/160)\n",
      "Epoch 1 Step 5/1563 Loss: 1.789 | Acc: 37.500% (72/192)\n",
      "Epoch 1 Step 6/1563 Loss: 1.794 | Acc: 36.607% (82/224)\n",
      "Epoch 1 Step 7/1563 Loss: 1.767 | Acc: 36.719% (94/256)\n",
      "Epoch 1 Step 8/1563 Loss: 1.754 | Acc: 36.458% (105/288)\n",
      "Epoch 1 Step 9/1563 Loss: 1.713 | Acc: 38.125% (122/320)\n",
      "Epoch 1 Step 10/1563 Loss: 1.717 | Acc: 37.500% (132/352)\n",
      "Epoch 1 Step 11/1563 Loss: 1.705 | Acc: 37.760% (145/384)\n",
      "Epoch 1 Step 12/1563 Loss: 1.709 | Acc: 37.740% (157/416)\n",
      "Epoch 1 Step 13/1563 Loss: 1.714 | Acc: 38.393% (172/448)\n",
      "Epoch 1 Step 14/1563 Loss: 1.729 | Acc: 37.292% (179/480)\n",
      "Epoch 1 Step 15/1563 Loss: 1.733 | Acc: 37.305% (191/512)\n",
      "Epoch 1 Step 16/1563 Loss: 1.735 | Acc: 37.132% (202/544)\n",
      "Epoch 1 Step 17/1563 Loss: 1.727 | Acc: 37.153% (214/576)\n",
      "Epoch 1 Step 18/1563 Loss: 1.730 | Acc: 37.336% (227/608)\n",
      "Epoch 1 Step 19/1563 Loss: 1.715 | Acc: 37.812% (242/640)\n",
      "Epoch 1 Step 20/1563 Loss: 1.713 | Acc: 37.500% (252/672)\n",
      "Epoch 1 Step 21/1563 Loss: 1.716 | Acc: 36.932% (260/704)\n",
      "Epoch 1 Step 22/1563 Loss: 1.711 | Acc: 36.957% (272/736)\n",
      "Epoch 1 Step 23/1563 Loss: 1.715 | Acc: 36.849% (283/768)\n",
      "Epoch 1 Step 24/1563 Loss: 1.709 | Acc: 37.375% (299/800)\n",
      "Epoch 1 Step 25/1563 Loss: 1.711 | Acc: 37.380% (311/832)\n",
      "Epoch 1 Step 26/1563 Loss: 1.706 | Acc: 38.079% (329/864)\n",
      "Epoch 1 Step 27/1563 Loss: 1.699 | Acc: 38.504% (345/896)\n",
      "Epoch 1 Step 28/1563 Loss: 1.696 | Acc: 39.009% (362/928)\n",
      "Epoch 1 Step 29/1563 Loss: 1.701 | Acc: 38.854% (373/960)\n",
      "Epoch 1 Step 30/1563 Loss: 1.700 | Acc: 38.911% (386/992)\n",
      "Epoch 1 Step 31/1563 Loss: 1.699 | Acc: 38.672% (396/1024)\n",
      "Epoch 1 Step 32/1563 Loss: 1.695 | Acc: 38.636% (408/1056)\n",
      "Epoch 1 Step 33/1563 Loss: 1.691 | Acc: 38.879% (423/1088)\n",
      "Epoch 1 Step 34/1563 Loss: 1.690 | Acc: 39.196% (439/1120)\n",
      "Epoch 1 Step 35/1563 Loss: 1.695 | Acc: 38.889% (448/1152)\n",
      "Epoch 1 Step 36/1563 Loss: 1.697 | Acc: 38.767% (459/1184)\n",
      "Epoch 1 Step 37/1563 Loss: 1.696 | Acc: 38.816% (472/1216)\n",
      "Epoch 1 Step 38/1563 Loss: 1.695 | Acc: 38.942% (486/1248)\n",
      "Epoch 1 Step 39/1563 Loss: 1.699 | Acc: 38.906% (498/1280)\n",
      "Epoch 1 Step 40/1563 Loss: 1.700 | Acc: 38.796% (509/1312)\n",
      "Epoch 1 Step 41/1563 Loss: 1.702 | Acc: 38.839% (522/1344)\n",
      "Epoch 1 Step 42/1563 Loss: 1.704 | Acc: 38.808% (534/1376)\n",
      "Epoch 1 Step 43/1563 Loss: 1.705 | Acc: 38.707% (545/1408)\n",
      "Epoch 1 Step 44/1563 Loss: 1.705 | Acc: 38.542% (555/1440)\n",
      "Epoch 1 Step 45/1563 Loss: 1.703 | Acc: 38.587% (568/1472)\n",
      "Epoch 1 Step 46/1563 Loss: 1.704 | Acc: 38.364% (577/1504)\n",
      "Epoch 1 Step 47/1563 Loss: 1.699 | Acc: 38.346% (589/1536)\n",
      "Epoch 1 Step 48/1563 Loss: 1.698 | Acc: 38.457% (603/1568)\n",
      "Epoch 1 Step 49/1563 Loss: 1.696 | Acc: 38.562% (617/1600)\n",
      "Epoch 1 Step 50/1563 Loss: 1.697 | Acc: 38.358% (626/1632)\n",
      "Epoch 1 Step 51/1563 Loss: 1.696 | Acc: 38.281% (637/1664)\n",
      "Epoch 1 Step 52/1563 Loss: 1.698 | Acc: 38.267% (649/1696)\n",
      "Epoch 1 Step 53/1563 Loss: 1.700 | Acc: 38.079% (658/1728)\n",
      "Epoch 1 Step 54/1563 Loss: 1.697 | Acc: 38.239% (673/1760)\n",
      "Epoch 1 Step 55/1563 Loss: 1.696 | Acc: 38.114% (683/1792)\n",
      "Epoch 1 Step 56/1563 Loss: 1.693 | Acc: 38.158% (696/1824)\n",
      "Epoch 1 Step 57/1563 Loss: 1.691 | Acc: 38.147% (708/1856)\n",
      "Epoch 1 Step 58/1563 Loss: 1.693 | Acc: 38.030% (718/1888)\n",
      "Epoch 1 Step 59/1563 Loss: 1.691 | Acc: 38.229% (734/1920)\n",
      "Epoch 1 Step 60/1563 Loss: 1.691 | Acc: 38.166% (745/1952)\n",
      "Epoch 1 Step 61/1563 Loss: 1.694 | Acc: 38.155% (757/1984)\n",
      "Epoch 1 Step 62/1563 Loss: 1.694 | Acc: 38.095% (768/2016)\n",
      "Epoch 1 Step 63/1563 Loss: 1.695 | Acc: 38.086% (780/2048)\n",
      "Epoch 1 Step 64/1563 Loss: 1.692 | Acc: 38.173% (794/2080)\n",
      "Epoch 1 Step 65/1563 Loss: 1.691 | Acc: 38.210% (807/2112)\n",
      "Epoch 1 Step 66/1563 Loss: 1.696 | Acc: 38.106% (817/2144)\n",
      "Epoch 1 Step 67/1563 Loss: 1.698 | Acc: 37.960% (826/2176)\n",
      "Epoch 1 Step 68/1563 Loss: 1.700 | Acc: 37.772% (834/2208)\n",
      "Epoch 1 Step 69/1563 Loss: 1.699 | Acc: 37.768% (846/2240)\n",
      "Epoch 1 Step 70/1563 Loss: 1.697 | Acc: 37.764% (858/2272)\n",
      "Epoch 1 Step 71/1563 Loss: 1.700 | Acc: 37.804% (871/2304)\n",
      "Epoch 1 Step 72/1563 Loss: 1.695 | Acc: 38.185% (892/2336)\n",
      "Epoch 1 Step 73/1563 Loss: 1.695 | Acc: 38.133% (903/2368)\n",
      "Epoch 1 Step 74/1563 Loss: 1.692 | Acc: 38.208% (917/2400)\n",
      "Epoch 1 Step 75/1563 Loss: 1.691 | Acc: 38.281% (931/2432)\n",
      "Epoch 1 Step 76/1563 Loss: 1.689 | Acc: 38.312% (944/2464)\n",
      "Epoch 1 Step 77/1563 Loss: 1.690 | Acc: 38.301% (956/2496)\n",
      "Epoch 1 Step 78/1563 Loss: 1.690 | Acc: 38.489% (973/2528)\n",
      "Epoch 1 Step 79/1563 Loss: 1.691 | Acc: 38.320% (981/2560)\n",
      "Epoch 1 Step 80/1563 Loss: 1.689 | Acc: 38.310% (993/2592)\n",
      "Epoch 1 Step 81/1563 Loss: 1.686 | Acc: 38.377% (1007/2624)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 82/1563 Loss: 1.688 | Acc: 38.404% (1020/2656)\n",
      "Epoch 1 Step 83/1563 Loss: 1.688 | Acc: 38.393% (1032/2688)\n",
      "Epoch 1 Step 84/1563 Loss: 1.683 | Acc: 38.676% (1052/2720)\n",
      "Epoch 1 Step 85/1563 Loss: 1.684 | Acc: 38.626% (1063/2752)\n",
      "Epoch 1 Step 86/1563 Loss: 1.682 | Acc: 38.757% (1079/2784)\n",
      "Epoch 1 Step 87/1563 Loss: 1.682 | Acc: 38.743% (1091/2816)\n",
      "Epoch 1 Step 88/1563 Loss: 1.682 | Acc: 38.799% (1105/2848)\n",
      "Epoch 1 Step 89/1563 Loss: 1.682 | Acc: 38.819% (1118/2880)\n",
      "Epoch 1 Step 90/1563 Loss: 1.681 | Acc: 38.736% (1128/2912)\n",
      "Epoch 1 Step 91/1563 Loss: 1.679 | Acc: 38.859% (1144/2944)\n",
      "Epoch 1 Step 92/1563 Loss: 1.677 | Acc: 38.844% (1156/2976)\n",
      "Epoch 1 Step 93/1563 Loss: 1.679 | Acc: 38.797% (1167/3008)\n",
      "Epoch 1 Step 94/1563 Loss: 1.678 | Acc: 38.651% (1175/3040)\n",
      "Epoch 1 Step 95/1563 Loss: 1.681 | Acc: 38.509% (1183/3072)\n",
      "Epoch 1 Step 96/1563 Loss: 1.680 | Acc: 38.660% (1200/3104)\n",
      "Epoch 1 Step 97/1563 Loss: 1.681 | Acc: 38.680% (1213/3136)\n",
      "Epoch 1 Step 98/1563 Loss: 1.679 | Acc: 38.668% (1225/3168)\n",
      "Epoch 1 Step 99/1563 Loss: 1.678 | Acc: 38.625% (1236/3200)\n",
      "Epoch 1 Step 100/1563 Loss: 1.678 | Acc: 38.738% (1252/3232)\n",
      "Epoch 1 Step 101/1563 Loss: 1.678 | Acc: 38.664% (1262/3264)\n",
      "Epoch 1 Step 102/1563 Loss: 1.676 | Acc: 38.714% (1276/3296)\n",
      "Epoch 1 Step 103/1563 Loss: 1.678 | Acc: 38.552% (1283/3328)\n",
      "Epoch 1 Step 104/1563 Loss: 1.680 | Acc: 38.512% (1294/3360)\n",
      "Epoch 1 Step 105/1563 Loss: 1.679 | Acc: 38.532% (1307/3392)\n",
      "Epoch 1 Step 106/1563 Loss: 1.680 | Acc: 38.435% (1316/3424)\n",
      "Epoch 1 Step 107/1563 Loss: 1.679 | Acc: 38.513% (1331/3456)\n",
      "Epoch 1 Step 108/1563 Loss: 1.678 | Acc: 38.475% (1342/3488)\n",
      "Epoch 1 Step 109/1563 Loss: 1.679 | Acc: 38.466% (1354/3520)\n",
      "Epoch 1 Step 110/1563 Loss: 1.679 | Acc: 38.485% (1367/3552)\n",
      "Epoch 1 Step 111/1563 Loss: 1.679 | Acc: 38.421% (1377/3584)\n",
      "Epoch 1 Step 112/1563 Loss: 1.678 | Acc: 38.496% (1392/3616)\n",
      "Epoch 1 Step 113/1563 Loss: 1.679 | Acc: 38.514% (1405/3648)\n",
      "Epoch 1 Step 114/1563 Loss: 1.678 | Acc: 38.533% (1418/3680)\n",
      "Epoch 1 Step 115/1563 Loss: 1.678 | Acc: 38.551% (1431/3712)\n",
      "Epoch 1 Step 116/1563 Loss: 1.677 | Acc: 38.568% (1444/3744)\n",
      "Epoch 1 Step 117/1563 Loss: 1.675 | Acc: 38.639% (1459/3776)\n",
      "Epoch 1 Step 118/1563 Loss: 1.675 | Acc: 38.577% (1469/3808)\n",
      "Epoch 1 Step 119/1563 Loss: 1.676 | Acc: 38.542% (1480/3840)\n",
      "Epoch 1 Step 120/1563 Loss: 1.677 | Acc: 38.481% (1490/3872)\n",
      "Epoch 1 Step 121/1563 Loss: 1.674 | Acc: 38.653% (1509/3904)\n",
      "Epoch 1 Step 122/1563 Loss: 1.675 | Acc: 38.643% (1521/3936)\n",
      "Epoch 1 Step 123/1563 Loss: 1.675 | Acc: 38.609% (1532/3968)\n",
      "Epoch 1 Step 124/1563 Loss: 1.674 | Acc: 38.450% (1538/4000)\n",
      "Epoch 1 Step 125/1563 Loss: 1.674 | Acc: 38.418% (1549/4032)\n",
      "Epoch 1 Step 126/1563 Loss: 1.674 | Acc: 38.410% (1561/4064)\n",
      "Epoch 1 Step 127/1563 Loss: 1.675 | Acc: 38.379% (1572/4096)\n",
      "Epoch 1 Step 128/1563 Loss: 1.676 | Acc: 38.372% (1584/4128)\n",
      "Epoch 1 Step 129/1563 Loss: 1.674 | Acc: 38.389% (1597/4160)\n",
      "Epoch 1 Step 130/1563 Loss: 1.675 | Acc: 38.383% (1609/4192)\n",
      "Epoch 1 Step 131/1563 Loss: 1.673 | Acc: 38.471% (1625/4224)\n",
      "Epoch 1 Step 132/1563 Loss: 1.674 | Acc: 38.557% (1641/4256)\n",
      "Epoch 1 Step 133/1563 Loss: 1.674 | Acc: 38.526% (1652/4288)\n",
      "Epoch 1 Step 134/1563 Loss: 1.675 | Acc: 38.472% (1662/4320)\n",
      "Epoch 1 Step 135/1563 Loss: 1.675 | Acc: 38.442% (1673/4352)\n",
      "Epoch 1 Step 136/1563 Loss: 1.674 | Acc: 38.526% (1689/4384)\n",
      "Epoch 1 Step 137/1563 Loss: 1.674 | Acc: 38.564% (1703/4416)\n",
      "Epoch 1 Step 138/1563 Loss: 1.675 | Acc: 38.489% (1712/4448)\n",
      "Epoch 1 Step 139/1563 Loss: 1.675 | Acc: 38.460% (1723/4480)\n",
      "Epoch 1 Step 140/1563 Loss: 1.675 | Acc: 38.453% (1735/4512)\n",
      "Epoch 1 Step 141/1563 Loss: 1.676 | Acc: 38.424% (1746/4544)\n",
      "Epoch 1 Step 142/1563 Loss: 1.676 | Acc: 38.418% (1758/4576)\n",
      "Epoch 1 Step 143/1563 Loss: 1.675 | Acc: 38.542% (1776/4608)\n",
      "Epoch 1 Step 144/1563 Loss: 1.676 | Acc: 38.427% (1783/4640)\n",
      "Epoch 1 Step 145/1563 Loss: 1.677 | Acc: 38.378% (1793/4672)\n",
      "Epoch 1 Step 146/1563 Loss: 1.675 | Acc: 38.393% (1806/4704)\n",
      "Epoch 1 Step 147/1563 Loss: 1.677 | Acc: 38.345% (1816/4736)\n",
      "Epoch 1 Step 148/1563 Loss: 1.677 | Acc: 38.339% (1828/4768)\n",
      "Epoch 1 Step 149/1563 Loss: 1.677 | Acc: 38.375% (1842/4800)\n",
      "Epoch 1 Step 150/1563 Loss: 1.677 | Acc: 38.349% (1853/4832)\n",
      "Epoch 1 Step 151/1563 Loss: 1.677 | Acc: 38.261% (1861/4864)\n",
      "Epoch 1 Step 152/1563 Loss: 1.677 | Acc: 38.297% (1875/4896)\n",
      "Epoch 1 Step 153/1563 Loss: 1.676 | Acc: 38.373% (1891/4928)\n",
      "Epoch 1 Step 154/1563 Loss: 1.678 | Acc: 38.286% (1899/4960)\n",
      "Epoch 1 Step 155/1563 Loss: 1.677 | Acc: 38.321% (1913/4992)\n",
      "Epoch 1 Step 156/1563 Loss: 1.677 | Acc: 38.296% (1924/5024)\n",
      "Epoch 1 Step 157/1563 Loss: 1.677 | Acc: 38.271% (1935/5056)\n",
      "Epoch 1 Step 158/1563 Loss: 1.680 | Acc: 38.188% (1943/5088)\n",
      "Epoch 1 Step 159/1563 Loss: 1.680 | Acc: 38.164% (1954/5120)\n",
      "Epoch 1 Step 160/1563 Loss: 1.678 | Acc: 38.199% (1968/5152)\n",
      "Epoch 1 Step 161/1563 Loss: 1.681 | Acc: 38.117% (1976/5184)\n",
      "Epoch 1 Step 162/1563 Loss: 1.681 | Acc: 38.152% (1990/5216)\n",
      "Epoch 1 Step 163/1563 Loss: 1.682 | Acc: 38.129% (2001/5248)\n",
      "Epoch 1 Step 164/1563 Loss: 1.683 | Acc: 38.144% (2014/5280)\n",
      "Epoch 1 Step 165/1563 Loss: 1.683 | Acc: 38.197% (2029/5312)\n",
      "Epoch 1 Step 166/1563 Loss: 1.683 | Acc: 38.230% (2043/5344)\n",
      "Epoch 1 Step 167/1563 Loss: 1.683 | Acc: 38.151% (2051/5376)\n",
      "Epoch 1 Step 168/1563 Loss: 1.683 | Acc: 38.129% (2062/5408)\n",
      "Epoch 1 Step 169/1563 Loss: 1.682 | Acc: 38.162% (2076/5440)\n",
      "Epoch 1 Step 170/1563 Loss: 1.680 | Acc: 38.231% (2092/5472)\n",
      "Epoch 1 Step 171/1563 Loss: 1.680 | Acc: 38.263% (2106/5504)\n",
      "Epoch 1 Step 172/1563 Loss: 1.680 | Acc: 38.259% (2118/5536)\n",
      "Epoch 1 Step 173/1563 Loss: 1.679 | Acc: 38.290% (2132/5568)\n",
      "Epoch 1 Step 174/1563 Loss: 1.679 | Acc: 38.286% (2144/5600)\n",
      "Epoch 1 Step 175/1563 Loss: 1.678 | Acc: 38.317% (2158/5632)\n",
      "Epoch 1 Step 176/1563 Loss: 1.677 | Acc: 38.347% (2172/5664)\n",
      "Epoch 1 Step 177/1563 Loss: 1.680 | Acc: 38.290% (2181/5696)\n",
      "Epoch 1 Step 178/1563 Loss: 1.679 | Acc: 38.338% (2196/5728)\n",
      "Epoch 1 Step 179/1563 Loss: 1.678 | Acc: 38.351% (2209/5760)\n",
      "Epoch 1 Step 180/1563 Loss: 1.677 | Acc: 38.415% (2225/5792)\n",
      "Epoch 1 Step 181/1563 Loss: 1.679 | Acc: 38.359% (2234/5824)\n",
      "Epoch 1 Step 182/1563 Loss: 1.680 | Acc: 38.303% (2243/5856)\n",
      "Epoch 1 Step 183/1563 Loss: 1.680 | Acc: 38.298% (2255/5888)\n",
      "Epoch 1 Step 184/1563 Loss: 1.681 | Acc: 38.277% (2266/5920)\n",
      "Epoch 1 Step 185/1563 Loss: 1.682 | Acc: 38.189% (2273/5952)\n",
      "Epoch 1 Step 186/1563 Loss: 1.681 | Acc: 38.202% (2286/5984)\n",
      "Epoch 1 Step 187/1563 Loss: 1.682 | Acc: 38.182% (2297/6016)\n",
      "Epoch 1 Step 188/1563 Loss: 1.681 | Acc: 38.244% (2313/6048)\n",
      "Epoch 1 Step 189/1563 Loss: 1.681 | Acc: 38.289% (2328/6080)\n",
      "Epoch 1 Step 190/1563 Loss: 1.681 | Acc: 38.334% (2343/6112)\n",
      "Epoch 1 Step 191/1563 Loss: 1.680 | Acc: 38.346% (2356/6144)\n",
      "Epoch 1 Step 192/1563 Loss: 1.680 | Acc: 38.342% (2368/6176)\n",
      "Epoch 1 Step 193/1563 Loss: 1.680 | Acc: 38.322% (2379/6208)\n",
      "Epoch 1 Step 194/1563 Loss: 1.680 | Acc: 38.349% (2393/6240)\n",
      "Epoch 1 Step 195/1563 Loss: 1.680 | Acc: 38.313% (2403/6272)\n",
      "Epoch 1 Step 196/1563 Loss: 1.680 | Acc: 38.341% (2417/6304)\n",
      "Epoch 1 Step 197/1563 Loss: 1.679 | Acc: 38.368% (2431/6336)\n",
      "Epoch 1 Step 198/1563 Loss: 1.682 | Acc: 38.285% (2438/6368)\n",
      "Epoch 1 Step 199/1563 Loss: 1.681 | Acc: 38.250% (2448/6400)\n",
      "Epoch 1 Step 200/1563 Loss: 1.681 | Acc: 38.231% (2459/6432)\n",
      "Epoch 1 Step 201/1563 Loss: 1.681 | Acc: 38.181% (2468/6464)\n",
      "Epoch 1 Step 202/1563 Loss: 1.680 | Acc: 38.254% (2485/6496)\n",
      "Epoch 1 Step 203/1563 Loss: 1.681 | Acc: 38.251% (2497/6528)\n",
      "Epoch 1 Step 204/1563 Loss: 1.680 | Acc: 38.277% (2511/6560)\n",
      "Epoch 1 Step 205/1563 Loss: 1.680 | Acc: 38.334% (2527/6592)\n",
      "Epoch 1 Step 206/1563 Loss: 1.680 | Acc: 38.330% (2539/6624)\n",
      "Epoch 1 Step 207/1563 Loss: 1.680 | Acc: 38.311% (2550/6656)\n",
      "Epoch 1 Step 208/1563 Loss: 1.681 | Acc: 38.337% (2564/6688)\n",
      "Epoch 1 Step 209/1563 Loss: 1.681 | Acc: 38.333% (2576/6720)\n",
      "Epoch 1 Step 210/1563 Loss: 1.681 | Acc: 38.344% (2589/6752)\n",
      "Epoch 1 Step 211/1563 Loss: 1.680 | Acc: 38.340% (2601/6784)\n",
      "Epoch 1 Step 212/1563 Loss: 1.679 | Acc: 38.351% (2614/6816)\n",
      "Epoch 1 Step 213/1563 Loss: 1.678 | Acc: 38.435% (2632/6848)\n",
      "Epoch 1 Step 214/1563 Loss: 1.678 | Acc: 38.372% (2640/6880)\n",
      "Epoch 1 Step 215/1563 Loss: 1.677 | Acc: 38.469% (2659/6912)\n",
      "Epoch 1 Step 216/1563 Loss: 1.677 | Acc: 38.537% (2676/6944)\n",
      "Epoch 1 Step 217/1563 Loss: 1.677 | Acc: 38.460% (2683/6976)\n",
      "Epoch 1 Step 218/1563 Loss: 1.677 | Acc: 38.456% (2695/7008)\n",
      "Epoch 1 Step 219/1563 Loss: 1.676 | Acc: 38.494% (2710/7040)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 220/1563 Loss: 1.676 | Acc: 38.490% (2722/7072)\n",
      "Epoch 1 Step 221/1563 Loss: 1.676 | Acc: 38.499% (2735/7104)\n",
      "Epoch 1 Step 222/1563 Loss: 1.676 | Acc: 38.481% (2746/7136)\n",
      "Epoch 1 Step 223/1563 Loss: 1.676 | Acc: 38.504% (2760/7168)\n",
      "Epoch 1 Step 224/1563 Loss: 1.675 | Acc: 38.556% (2776/7200)\n",
      "Epoch 1 Step 225/1563 Loss: 1.675 | Acc: 38.606% (2792/7232)\n",
      "Epoch 1 Step 226/1563 Loss: 1.675 | Acc: 38.588% (2803/7264)\n",
      "Epoch 1 Step 227/1563 Loss: 1.674 | Acc: 38.638% (2819/7296)\n",
      "Epoch 1 Step 228/1563 Loss: 1.674 | Acc: 38.646% (2832/7328)\n",
      "Epoch 1 Step 229/1563 Loss: 1.674 | Acc: 38.682% (2847/7360)\n",
      "Epoch 1 Step 230/1563 Loss: 1.673 | Acc: 38.745% (2864/7392)\n",
      "Epoch 1 Step 231/1563 Loss: 1.672 | Acc: 38.739% (2876/7424)\n",
      "Epoch 1 Step 232/1563 Loss: 1.673 | Acc: 38.694% (2885/7456)\n",
      "Epoch 1 Step 233/1563 Loss: 1.671 | Acc: 38.769% (2903/7488)\n",
      "Epoch 1 Step 234/1563 Loss: 1.670 | Acc: 38.803% (2918/7520)\n",
      "Epoch 1 Step 235/1563 Loss: 1.670 | Acc: 38.811% (2931/7552)\n",
      "Epoch 1 Step 236/1563 Loss: 1.670 | Acc: 38.805% (2943/7584)\n",
      "Epoch 1 Step 237/1563 Loss: 1.670 | Acc: 38.839% (2958/7616)\n",
      "Epoch 1 Step 238/1563 Loss: 1.670 | Acc: 38.821% (2969/7648)\n",
      "Epoch 1 Step 239/1563 Loss: 1.669 | Acc: 38.828% (2982/7680)\n",
      "Epoch 1 Step 240/1563 Loss: 1.669 | Acc: 38.823% (2994/7712)\n",
      "Epoch 1 Step 241/1563 Loss: 1.670 | Acc: 38.791% (3004/7744)\n",
      "Epoch 1 Step 242/1563 Loss: 1.672 | Acc: 38.747% (3013/7776)\n",
      "Epoch 1 Step 243/1563 Loss: 1.672 | Acc: 38.717% (3023/7808)\n",
      "Epoch 1 Step 244/1563 Loss: 1.670 | Acc: 38.788% (3041/7840)\n",
      "Epoch 1 Step 245/1563 Loss: 1.671 | Acc: 38.758% (3051/7872)\n",
      "Epoch 1 Step 246/1563 Loss: 1.671 | Acc: 38.841% (3070/7904)\n",
      "Epoch 1 Step 247/1563 Loss: 1.670 | Acc: 38.886% (3086/7936)\n",
      "Epoch 1 Step 248/1563 Loss: 1.671 | Acc: 38.855% (3096/7968)\n",
      "Epoch 1 Step 249/1563 Loss: 1.671 | Acc: 38.850% (3108/8000)\n",
      "Epoch 1 Step 250/1563 Loss: 1.670 | Acc: 38.882% (3123/8032)\n",
      "Epoch 1 Step 251/1563 Loss: 1.670 | Acc: 38.914% (3138/8064)\n",
      "Epoch 1 Step 252/1563 Loss: 1.669 | Acc: 38.933% (3152/8096)\n",
      "Epoch 1 Step 253/1563 Loss: 1.670 | Acc: 38.952% (3166/8128)\n",
      "Epoch 1 Step 254/1563 Loss: 1.669 | Acc: 39.032% (3185/8160)\n",
      "Epoch 1 Step 255/1563 Loss: 1.669 | Acc: 39.075% (3201/8192)\n",
      "Epoch 1 Step 256/1563 Loss: 1.670 | Acc: 39.056% (3212/8224)\n",
      "Epoch 1 Step 257/1563 Loss: 1.669 | Acc: 39.050% (3224/8256)\n",
      "Epoch 1 Step 258/1563 Loss: 1.670 | Acc: 39.069% (3238/8288)\n",
      "Epoch 1 Step 259/1563 Loss: 1.669 | Acc: 39.099% (3253/8320)\n",
      "Epoch 1 Step 260/1563 Loss: 1.669 | Acc: 39.080% (3264/8352)\n",
      "Epoch 1 Step 261/1563 Loss: 1.670 | Acc: 39.098% (3278/8384)\n",
      "Epoch 1 Step 262/1563 Loss: 1.670 | Acc: 39.116% (3292/8416)\n",
      "Epoch 1 Step 263/1563 Loss: 1.670 | Acc: 39.062% (3300/8448)\n",
      "Epoch 1 Step 264/1563 Loss: 1.672 | Acc: 39.057% (3312/8480)\n",
      "Epoch 1 Step 265/1563 Loss: 1.671 | Acc: 39.098% (3328/8512)\n",
      "Epoch 1 Step 266/1563 Loss: 1.670 | Acc: 39.057% (3337/8544)\n",
      "Epoch 1 Step 267/1563 Loss: 1.671 | Acc: 39.004% (3345/8576)\n",
      "Epoch 1 Step 268/1563 Loss: 1.671 | Acc: 39.057% (3362/8608)\n",
      "Epoch 1 Step 269/1563 Loss: 1.671 | Acc: 39.074% (3376/8640)\n",
      "Epoch 1 Step 270/1563 Loss: 1.670 | Acc: 39.126% (3393/8672)\n",
      "Epoch 1 Step 271/1563 Loss: 1.671 | Acc: 39.108% (3404/8704)\n",
      "Epoch 1 Step 272/1563 Loss: 1.672 | Acc: 39.080% (3414/8736)\n",
      "Epoch 1 Step 273/1563 Loss: 1.671 | Acc: 39.074% (3426/8768)\n",
      "Epoch 1 Step 274/1563 Loss: 1.672 | Acc: 39.023% (3434/8800)\n",
      "Epoch 1 Step 275/1563 Loss: 1.673 | Acc: 39.029% (3447/8832)\n",
      "Epoch 1 Step 276/1563 Loss: 1.673 | Acc: 39.046% (3461/8864)\n",
      "Epoch 1 Step 277/1563 Loss: 1.674 | Acc: 39.040% (3473/8896)\n",
      "Epoch 1 Step 278/1563 Loss: 1.673 | Acc: 39.091% (3490/8928)\n",
      "Epoch 1 Step 279/1563 Loss: 1.674 | Acc: 39.085% (3502/8960)\n",
      "Epoch 1 Step 280/1563 Loss: 1.674 | Acc: 39.057% (3512/8992)\n",
      "Epoch 1 Step 281/1563 Loss: 1.674 | Acc: 39.040% (3523/9024)\n",
      "Epoch 1 Step 282/1563 Loss: 1.674 | Acc: 39.057% (3537/9056)\n",
      "Epoch 1 Step 283/1563 Loss: 1.674 | Acc: 39.051% (3549/9088)\n",
      "Epoch 1 Step 284/1563 Loss: 1.674 | Acc: 39.079% (3564/9120)\n",
      "Epoch 1 Step 285/1563 Loss: 1.674 | Acc: 39.106% (3579/9152)\n",
      "Epoch 1 Step 286/1563 Loss: 1.674 | Acc: 39.079% (3589/9184)\n",
      "Epoch 1 Step 287/1563 Loss: 1.673 | Acc: 39.106% (3604/9216)\n",
      "Epoch 1 Step 288/1563 Loss: 1.674 | Acc: 39.090% (3615/9248)\n",
      "Epoch 1 Step 289/1563 Loss: 1.673 | Acc: 39.138% (3632/9280)\n",
      "Epoch 1 Step 290/1563 Loss: 1.673 | Acc: 39.143% (3645/9312)\n",
      "Epoch 1 Step 291/1563 Loss: 1.673 | Acc: 39.127% (3656/9344)\n",
      "Epoch 1 Step 292/1563 Loss: 1.673 | Acc: 39.132% (3669/9376)\n",
      "Epoch 1 Step 293/1563 Loss: 1.672 | Acc: 39.148% (3683/9408)\n",
      "Epoch 1 Step 294/1563 Loss: 1.672 | Acc: 39.131% (3694/9440)\n",
      "Epoch 1 Step 295/1563 Loss: 1.673 | Acc: 39.094% (3703/9472)\n",
      "Epoch 1 Step 296/1563 Loss: 1.672 | Acc: 39.131% (3719/9504)\n",
      "Epoch 1 Step 297/1563 Loss: 1.673 | Acc: 39.157% (3734/9536)\n",
      "Epoch 1 Step 298/1563 Loss: 1.672 | Acc: 39.183% (3749/9568)\n",
      "Epoch 1 Step 299/1563 Loss: 1.672 | Acc: 39.156% (3759/9600)\n",
      "Epoch 1 Step 300/1563 Loss: 1.672 | Acc: 39.109% (3767/9632)\n",
      "Epoch 1 Step 301/1563 Loss: 1.672 | Acc: 39.135% (3782/9664)\n",
      "Epoch 1 Step 302/1563 Loss: 1.672 | Acc: 39.160% (3797/9696)\n",
      "Epoch 1 Step 303/1563 Loss: 1.671 | Acc: 39.145% (3808/9728)\n",
      "Epoch 1 Step 304/1563 Loss: 1.671 | Acc: 39.170% (3823/9760)\n",
      "Epoch 1 Step 305/1563 Loss: 1.671 | Acc: 39.165% (3835/9792)\n",
      "Epoch 1 Step 306/1563 Loss: 1.670 | Acc: 39.220% (3853/9824)\n",
      "Epoch 1 Step 307/1563 Loss: 1.670 | Acc: 39.255% (3869/9856)\n",
      "Epoch 1 Step 308/1563 Loss: 1.670 | Acc: 39.270% (3883/9888)\n",
      "Epoch 1 Step 309/1563 Loss: 1.670 | Acc: 39.304% (3899/9920)\n",
      "Epoch 1 Step 310/1563 Loss: 1.670 | Acc: 39.299% (3911/9952)\n",
      "Epoch 1 Step 311/1563 Loss: 1.669 | Acc: 39.303% (3924/9984)\n",
      "Epoch 1 Step 312/1563 Loss: 1.669 | Acc: 39.277% (3934/10016)\n",
      "Epoch 1 Step 313/1563 Loss: 1.669 | Acc: 39.301% (3949/10048)\n",
      "Epoch 1 Step 314/1563 Loss: 1.668 | Acc: 39.345% (3966/10080)\n",
      "Epoch 1 Step 315/1563 Loss: 1.668 | Acc: 39.300% (3974/10112)\n",
      "Epoch 1 Step 316/1563 Loss: 1.668 | Acc: 39.304% (3987/10144)\n",
      "Epoch 1 Step 317/1563 Loss: 1.669 | Acc: 39.289% (3998/10176)\n",
      "Epoch 1 Step 318/1563 Loss: 1.669 | Acc: 39.283% (4010/10208)\n",
      "Epoch 1 Step 319/1563 Loss: 1.668 | Acc: 39.316% (4026/10240)\n",
      "Epoch 1 Step 320/1563 Loss: 1.668 | Acc: 39.311% (4038/10272)\n",
      "Epoch 1 Step 321/1563 Loss: 1.668 | Acc: 39.295% (4049/10304)\n",
      "Epoch 1 Step 322/1563 Loss: 1.668 | Acc: 39.290% (4061/10336)\n",
      "Epoch 1 Step 323/1563 Loss: 1.669 | Acc: 39.284% (4073/10368)\n",
      "Epoch 1 Step 324/1563 Loss: 1.668 | Acc: 39.288% (4086/10400)\n",
      "Epoch 1 Step 325/1563 Loss: 1.669 | Acc: 39.302% (4100/10432)\n",
      "Epoch 1 Step 326/1563 Loss: 1.669 | Acc: 39.306% (4113/10464)\n",
      "Epoch 1 Step 327/1563 Loss: 1.669 | Acc: 39.310% (4126/10496)\n",
      "Epoch 1 Step 328/1563 Loss: 1.669 | Acc: 39.276% (4135/10528)\n",
      "Epoch 1 Step 329/1563 Loss: 1.669 | Acc: 39.271% (4147/10560)\n",
      "Epoch 1 Step 330/1563 Loss: 1.670 | Acc: 39.275% (4160/10592)\n",
      "Epoch 1 Step 331/1563 Loss: 1.670 | Acc: 39.298% (4175/10624)\n",
      "Epoch 1 Step 332/1563 Loss: 1.669 | Acc: 39.283% (4186/10656)\n",
      "Epoch 1 Step 333/1563 Loss: 1.669 | Acc: 39.259% (4196/10688)\n",
      "Epoch 1 Step 334/1563 Loss: 1.670 | Acc: 39.254% (4208/10720)\n",
      "Epoch 1 Step 335/1563 Loss: 1.670 | Acc: 39.230% (4218/10752)\n",
      "Epoch 1 Step 336/1563 Loss: 1.670 | Acc: 39.225% (4230/10784)\n",
      "Epoch 1 Step 337/1563 Loss: 1.670 | Acc: 39.284% (4249/10816)\n",
      "Epoch 1 Step 338/1563 Loss: 1.670 | Acc: 39.307% (4264/10848)\n",
      "Epoch 1 Step 339/1563 Loss: 1.670 | Acc: 39.311% (4277/10880)\n",
      "Epoch 1 Step 340/1563 Loss: 1.671 | Acc: 39.278% (4286/10912)\n",
      "Epoch 1 Step 341/1563 Loss: 1.670 | Acc: 39.291% (4300/10944)\n",
      "Epoch 1 Step 342/1563 Loss: 1.671 | Acc: 39.295% (4313/10976)\n",
      "Epoch 1 Step 343/1563 Loss: 1.670 | Acc: 39.326% (4329/11008)\n",
      "Epoch 1 Step 344/1563 Loss: 1.670 | Acc: 39.321% (4341/11040)\n",
      "Epoch 1 Step 345/1563 Loss: 1.670 | Acc: 39.315% (4353/11072)\n",
      "Epoch 1 Step 346/1563 Loss: 1.670 | Acc: 39.328% (4367/11104)\n",
      "Epoch 1 Step 347/1563 Loss: 1.669 | Acc: 39.341% (4381/11136)\n",
      "Epoch 1 Step 348/1563 Loss: 1.669 | Acc: 39.354% (4395/11168)\n",
      "Epoch 1 Step 349/1563 Loss: 1.669 | Acc: 39.357% (4408/11200)\n",
      "Epoch 1 Step 350/1563 Loss: 1.668 | Acc: 39.396% (4425/11232)\n",
      "Epoch 1 Step 351/1563 Loss: 1.668 | Acc: 39.373% (4435/11264)\n",
      "Epoch 1 Step 352/1563 Loss: 1.667 | Acc: 39.368% (4447/11296)\n",
      "Epoch 1 Step 353/1563 Loss: 1.667 | Acc: 39.389% (4462/11328)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 354/1563 Loss: 1.668 | Acc: 39.349% (4470/11360)\n",
      "Epoch 1 Step 355/1563 Loss: 1.668 | Acc: 39.379% (4486/11392)\n",
      "Epoch 1 Step 356/1563 Loss: 1.668 | Acc: 39.382% (4499/11424)\n",
      "Epoch 1 Step 357/1563 Loss: 1.667 | Acc: 39.438% (4518/11456)\n",
      "Epoch 1 Step 358/1563 Loss: 1.667 | Acc: 39.450% (4532/11488)\n",
      "Epoch 1 Step 359/1563 Loss: 1.667 | Acc: 39.453% (4545/11520)\n",
      "Epoch 1 Step 360/1563 Loss: 1.667 | Acc: 39.456% (4558/11552)\n",
      "Epoch 1 Step 361/1563 Loss: 1.667 | Acc: 39.477% (4573/11584)\n",
      "Epoch 1 Step 362/1563 Loss: 1.666 | Acc: 39.471% (4585/11616)\n",
      "Epoch 1 Step 363/1563 Loss: 1.667 | Acc: 39.440% (4594/11648)\n",
      "Epoch 1 Step 364/1563 Loss: 1.667 | Acc: 39.461% (4609/11680)\n",
      "Epoch 1 Step 365/1563 Loss: 1.668 | Acc: 39.447% (4620/11712)\n",
      "Epoch 1 Step 366/1563 Loss: 1.668 | Acc: 39.450% (4633/11744)\n",
      "Epoch 1 Step 367/1563 Loss: 1.668 | Acc: 39.496% (4651/11776)\n",
      "Epoch 1 Step 368/1563 Loss: 1.668 | Acc: 39.516% (4666/11808)\n",
      "Epoch 1 Step 369/1563 Loss: 1.667 | Acc: 39.544% (4682/11840)\n",
      "Epoch 1 Step 370/1563 Loss: 1.667 | Acc: 39.547% (4695/11872)\n",
      "Epoch 1 Step 371/1563 Loss: 1.667 | Acc: 39.508% (4703/11904)\n",
      "Epoch 1 Step 372/1563 Loss: 1.668 | Acc: 39.511% (4716/11936)\n",
      "Epoch 1 Step 373/1563 Loss: 1.667 | Acc: 39.530% (4731/11968)\n",
      "Epoch 1 Step 374/1563 Loss: 1.668 | Acc: 39.508% (4741/12000)\n",
      "Epoch 1 Step 375/1563 Loss: 1.668 | Acc: 39.528% (4756/12032)\n",
      "Epoch 1 Step 376/1563 Loss: 1.668 | Acc: 39.564% (4773/12064)\n",
      "Epoch 1 Step 377/1563 Loss: 1.668 | Acc: 39.542% (4783/12096)\n",
      "Epoch 1 Step 378/1563 Loss: 1.668 | Acc: 39.545% (4796/12128)\n",
      "Epoch 1 Step 379/1563 Loss: 1.668 | Acc: 39.539% (4808/12160)\n",
      "Epoch 1 Step 380/1563 Loss: 1.668 | Acc: 39.559% (4823/12192)\n",
      "Epoch 1 Step 381/1563 Loss: 1.667 | Acc: 39.586% (4839/12224)\n",
      "Epoch 1 Step 382/1563 Loss: 1.667 | Acc: 39.605% (4854/12256)\n",
      "Epoch 1 Step 383/1563 Loss: 1.666 | Acc: 39.632% (4870/12288)\n",
      "Epoch 1 Step 384/1563 Loss: 1.665 | Acc: 39.667% (4887/12320)\n",
      "Epoch 1 Step 385/1563 Loss: 1.665 | Acc: 39.686% (4902/12352)\n",
      "Epoch 1 Step 386/1563 Loss: 1.666 | Acc: 39.656% (4911/12384)\n",
      "Epoch 1 Step 387/1563 Loss: 1.665 | Acc: 39.667% (4925/12416)\n",
      "Epoch 1 Step 388/1563 Loss: 1.666 | Acc: 39.637% (4934/12448)\n",
      "Epoch 1 Step 389/1563 Loss: 1.666 | Acc: 39.639% (4947/12480)\n",
      "Epoch 1 Step 390/1563 Loss: 1.665 | Acc: 39.690% (4966/12512)\n",
      "Epoch 1 Step 391/1563 Loss: 1.665 | Acc: 39.652% (4974/12544)\n",
      "Epoch 1 Step 392/1563 Loss: 1.665 | Acc: 39.655% (4987/12576)\n",
      "Epoch 1 Step 393/1563 Loss: 1.665 | Acc: 39.665% (5001/12608)\n",
      "Epoch 1 Step 394/1563 Loss: 1.666 | Acc: 39.660% (5013/12640)\n",
      "Epoch 1 Step 395/1563 Loss: 1.665 | Acc: 39.670% (5027/12672)\n",
      "Epoch 1 Step 396/1563 Loss: 1.666 | Acc: 39.633% (5035/12704)\n",
      "Epoch 1 Step 397/1563 Loss: 1.666 | Acc: 39.636% (5048/12736)\n",
      "Epoch 1 Step 398/1563 Loss: 1.666 | Acc: 39.662% (5064/12768)\n",
      "Epoch 1 Step 399/1563 Loss: 1.666 | Acc: 39.664% (5077/12800)\n",
      "Epoch 1 Step 400/1563 Loss: 1.665 | Acc: 39.674% (5091/12832)\n",
      "Epoch 1 Step 401/1563 Loss: 1.665 | Acc: 39.692% (5106/12864)\n",
      "Epoch 1 Step 402/1563 Loss: 1.664 | Acc: 39.718% (5122/12896)\n",
      "Epoch 1 Step 403/1563 Loss: 1.663 | Acc: 39.735% (5137/12928)\n",
      "Epoch 1 Step 404/1563 Loss: 1.663 | Acc: 39.745% (5151/12960)\n",
      "Epoch 1 Step 405/1563 Loss: 1.663 | Acc: 39.763% (5166/12992)\n",
      "Epoch 1 Step 406/1563 Loss: 1.663 | Acc: 39.765% (5179/13024)\n",
      "Epoch 1 Step 407/1563 Loss: 1.663 | Acc: 39.744% (5189/13056)\n",
      "Epoch 1 Step 408/1563 Loss: 1.663 | Acc: 39.785% (5207/13088)\n",
      "Epoch 1 Step 409/1563 Loss: 1.663 | Acc: 39.764% (5217/13120)\n",
      "Epoch 1 Step 410/1563 Loss: 1.663 | Acc: 39.751% (5228/13152)\n",
      "Epoch 1 Step 411/1563 Loss: 1.663 | Acc: 39.738% (5239/13184)\n",
      "Epoch 1 Step 412/1563 Loss: 1.663 | Acc: 39.740% (5252/13216)\n",
      "Epoch 1 Step 413/1563 Loss: 1.663 | Acc: 39.749% (5266/13248)\n",
      "Epoch 1 Step 414/1563 Loss: 1.663 | Acc: 39.774% (5282/13280)\n",
      "Epoch 1 Step 415/1563 Loss: 1.663 | Acc: 39.769% (5294/13312)\n",
      "Epoch 1 Step 416/1563 Loss: 1.663 | Acc: 39.786% (5309/13344)\n",
      "Epoch 1 Step 417/1563 Loss: 1.663 | Acc: 39.780% (5321/13376)\n",
      "Epoch 1 Step 418/1563 Loss: 1.663 | Acc: 39.760% (5331/13408)\n",
      "Epoch 1 Step 419/1563 Loss: 1.663 | Acc: 39.740% (5341/13440)\n",
      "Epoch 1 Step 420/1563 Loss: 1.663 | Acc: 39.719% (5351/13472)\n",
      "Epoch 1 Step 421/1563 Loss: 1.663 | Acc: 39.722% (5364/13504)\n",
      "Epoch 1 Step 422/1563 Loss: 1.663 | Acc: 39.709% (5375/13536)\n",
      "Epoch 1 Step 423/1563 Loss: 1.662 | Acc: 39.696% (5386/13568)\n",
      "Epoch 1 Step 424/1563 Loss: 1.662 | Acc: 39.669% (5395/13600)\n",
      "Epoch 1 Step 425/1563 Loss: 1.661 | Acc: 39.679% (5409/13632)\n",
      "Epoch 1 Step 426/1563 Loss: 1.661 | Acc: 39.674% (5421/13664)\n",
      "Epoch 1 Step 427/1563 Loss: 1.660 | Acc: 39.705% (5438/13696)\n",
      "Epoch 1 Step 428/1563 Loss: 1.660 | Acc: 39.707% (5451/13728)\n",
      "Epoch 1 Step 429/1563 Loss: 1.661 | Acc: 39.702% (5463/13760)\n",
      "Epoch 1 Step 430/1563 Loss: 1.660 | Acc: 39.711% (5477/13792)\n",
      "Epoch 1 Step 431/1563 Loss: 1.661 | Acc: 39.699% (5488/13824)\n",
      "Epoch 1 Step 432/1563 Loss: 1.661 | Acc: 39.694% (5500/13856)\n",
      "Epoch 1 Step 433/1563 Loss: 1.661 | Acc: 39.689% (5512/13888)\n",
      "Epoch 1 Step 434/1563 Loss: 1.662 | Acc: 39.698% (5526/13920)\n",
      "Epoch 1 Step 435/1563 Loss: 1.661 | Acc: 39.708% (5540/13952)\n",
      "Epoch 1 Step 436/1563 Loss: 1.661 | Acc: 39.695% (5551/13984)\n",
      "Epoch 1 Step 437/1563 Loss: 1.661 | Acc: 39.683% (5562/14016)\n",
      "Epoch 1 Step 438/1563 Loss: 1.661 | Acc: 39.678% (5574/14048)\n",
      "Epoch 1 Step 439/1563 Loss: 1.660 | Acc: 39.709% (5591/14080)\n",
      "Epoch 1 Step 440/1563 Loss: 1.660 | Acc: 39.711% (5604/14112)\n",
      "Epoch 1 Step 441/1563 Loss: 1.661 | Acc: 39.692% (5614/14144)\n",
      "Epoch 1 Step 442/1563 Loss: 1.661 | Acc: 39.694% (5627/14176)\n",
      "Epoch 1 Step 443/1563 Loss: 1.662 | Acc: 39.661% (5635/14208)\n",
      "Epoch 1 Step 444/1563 Loss: 1.662 | Acc: 39.670% (5649/14240)\n",
      "Epoch 1 Step 445/1563 Loss: 1.662 | Acc: 39.679% (5663/14272)\n",
      "Epoch 1 Step 446/1563 Loss: 1.662 | Acc: 39.695% (5678/14304)\n",
      "Epoch 1 Step 447/1563 Loss: 1.662 | Acc: 39.697% (5691/14336)\n",
      "Epoch 1 Step 448/1563 Loss: 1.662 | Acc: 39.685% (5702/14368)\n",
      "Epoch 1 Step 449/1563 Loss: 1.662 | Acc: 39.688% (5715/14400)\n",
      "Epoch 1 Step 450/1563 Loss: 1.662 | Acc: 39.676% (5726/14432)\n",
      "Epoch 1 Step 451/1563 Loss: 1.662 | Acc: 39.650% (5735/14464)\n",
      "Epoch 1 Step 452/1563 Loss: 1.663 | Acc: 39.639% (5746/14496)\n",
      "Epoch 1 Step 453/1563 Loss: 1.662 | Acc: 39.654% (5761/14528)\n",
      "Epoch 1 Step 454/1563 Loss: 1.662 | Acc: 39.643% (5772/14560)\n",
      "Epoch 1 Step 455/1563 Loss: 1.662 | Acc: 39.638% (5784/14592)\n",
      "Epoch 1 Step 456/1563 Loss: 1.662 | Acc: 39.640% (5797/14624)\n",
      "Epoch 1 Step 457/1563 Loss: 1.662 | Acc: 39.663% (5813/14656)\n",
      "Epoch 1 Step 458/1563 Loss: 1.662 | Acc: 39.658% (5825/14688)\n",
      "Epoch 1 Step 459/1563 Loss: 1.662 | Acc: 39.667% (5839/14720)\n",
      "Epoch 1 Step 460/1563 Loss: 1.662 | Acc: 39.656% (5850/14752)\n",
      "Epoch 1 Step 461/1563 Loss: 1.662 | Acc: 39.665% (5864/14784)\n",
      "Epoch 1 Step 462/1563 Loss: 1.662 | Acc: 39.640% (5873/14816)\n",
      "Epoch 1 Step 463/1563 Loss: 1.662 | Acc: 39.635% (5885/14848)\n",
      "Epoch 1 Step 464/1563 Loss: 1.662 | Acc: 39.597% (5892/14880)\n",
      "Epoch 1 Step 465/1563 Loss: 1.663 | Acc: 39.579% (5902/14912)\n",
      "Epoch 1 Step 466/1563 Loss: 1.664 | Acc: 39.561% (5912/14944)\n",
      "Epoch 1 Step 467/1563 Loss: 1.663 | Acc: 39.537% (5921/14976)\n",
      "Epoch 1 Step 468/1563 Loss: 1.663 | Acc: 39.572% (5939/15008)\n",
      "Epoch 1 Step 469/1563 Loss: 1.663 | Acc: 39.581% (5953/15040)\n",
      "Epoch 1 Step 470/1563 Loss: 1.663 | Acc: 39.597% (5968/15072)\n",
      "Epoch 1 Step 471/1563 Loss: 1.664 | Acc: 39.586% (5979/15104)\n",
      "Epoch 1 Step 472/1563 Loss: 1.663 | Acc: 39.581% (5991/15136)\n",
      "Epoch 1 Step 473/1563 Loss: 1.663 | Acc: 39.570% (6002/15168)\n",
      "Epoch 1 Step 474/1563 Loss: 1.663 | Acc: 39.592% (6018/15200)\n",
      "Epoch 1 Step 475/1563 Loss: 1.664 | Acc: 39.581% (6029/15232)\n",
      "Epoch 1 Step 476/1563 Loss: 1.664 | Acc: 39.577% (6041/15264)\n",
      "Epoch 1 Step 477/1563 Loss: 1.664 | Acc: 39.579% (6054/15296)\n",
      "Epoch 1 Step 478/1563 Loss: 1.663 | Acc: 39.601% (6070/15328)\n",
      "Epoch 1 Step 479/1563 Loss: 1.663 | Acc: 39.583% (6080/15360)\n",
      "Epoch 1 Step 480/1563 Loss: 1.664 | Acc: 39.560% (6089/15392)\n",
      "Epoch 1 Step 481/1563 Loss: 1.664 | Acc: 39.575% (6104/15424)\n",
      "Epoch 1 Step 482/1563 Loss: 1.664 | Acc: 39.603% (6121/15456)\n",
      "Epoch 1 Step 483/1563 Loss: 1.663 | Acc: 39.598% (6133/15488)\n",
      "Epoch 1 Step 484/1563 Loss: 1.663 | Acc: 39.607% (6147/15520)\n",
      "Epoch 1 Step 485/1563 Loss: 1.664 | Acc: 39.590% (6157/15552)\n",
      "Epoch 1 Step 486/1563 Loss: 1.663 | Acc: 39.624% (6175/15584)\n",
      "Epoch 1 Step 487/1563 Loss: 1.664 | Acc: 39.600% (6184/15616)\n",
      "Epoch 1 Step 488/1563 Loss: 1.664 | Acc: 39.603% (6197/15648)\n",
      "Epoch 1 Step 489/1563 Loss: 1.664 | Acc: 39.598% (6209/15680)\n",
      "Epoch 1 Step 490/1563 Loss: 1.664 | Acc: 39.600% (6222/15712)\n",
      "Epoch 1 Step 491/1563 Loss: 1.665 | Acc: 39.571% (6230/15744)\n",
      "Epoch 1 Step 492/1563 Loss: 1.664 | Acc: 39.592% (6246/15776)\n",
      "Epoch 1 Step 493/1563 Loss: 1.665 | Acc: 39.581% (6257/15808)\n",
      "Epoch 1 Step 494/1563 Loss: 1.665 | Acc: 39.590% (6271/15840)\n",
      "Epoch 1 Step 495/1563 Loss: 1.665 | Acc: 39.585% (6283/15872)\n",
      "Epoch 1 Step 496/1563 Loss: 1.665 | Acc: 39.588% (6296/15904)\n",
      "Epoch 1 Step 497/1563 Loss: 1.664 | Acc: 39.590% (6309/15936)\n",
      "Epoch 1 Step 498/1563 Loss: 1.664 | Acc: 39.598% (6323/15968)\n",
      "Epoch 1 Step 499/1563 Loss: 1.664 | Acc: 39.581% (6333/16000)\n",
      "Epoch 1 Step 500/1563 Loss: 1.664 | Acc: 39.571% (6344/16032)\n",
      "Epoch 1 Step 501/1563 Loss: 1.664 | Acc: 39.561% (6355/16064)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 502/1563 Loss: 1.664 | Acc: 39.563% (6368/16096)\n",
      "Epoch 1 Step 503/1563 Loss: 1.664 | Acc: 39.559% (6380/16128)\n",
      "Epoch 1 Step 504/1563 Loss: 1.664 | Acc: 39.548% (6391/16160)\n",
      "Epoch 1 Step 505/1563 Loss: 1.664 | Acc: 39.526% (6400/16192)\n",
      "Epoch 1 Step 506/1563 Loss: 1.665 | Acc: 39.497% (6408/16224)\n",
      "Epoch 1 Step 507/1563 Loss: 1.664 | Acc: 39.518% (6424/16256)\n",
      "Epoch 1 Step 508/1563 Loss: 1.664 | Acc: 39.538% (6440/16288)\n",
      "Epoch 1 Step 509/1563 Loss: 1.664 | Acc: 39.534% (6452/16320)\n",
      "Epoch 1 Step 510/1563 Loss: 1.664 | Acc: 39.518% (6462/16352)\n",
      "Epoch 1 Step 511/1563 Loss: 1.664 | Acc: 39.526% (6476/16384)\n",
      "Epoch 1 Step 512/1563 Loss: 1.664 | Acc: 39.559% (6494/16416)\n",
      "Epoch 1 Step 513/1563 Loss: 1.664 | Acc: 39.549% (6505/16448)\n",
      "Epoch 1 Step 514/1563 Loss: 1.664 | Acc: 39.533% (6515/16480)\n",
      "Epoch 1 Step 515/1563 Loss: 1.664 | Acc: 39.517% (6525/16512)\n",
      "Epoch 1 Step 516/1563 Loss: 1.664 | Acc: 39.519% (6538/16544)\n",
      "Epoch 1 Step 517/1563 Loss: 1.665 | Acc: 39.485% (6545/16576)\n",
      "Epoch 1 Step 518/1563 Loss: 1.665 | Acc: 39.475% (6556/16608)\n",
      "Epoch 1 Step 519/1563 Loss: 1.665 | Acc: 39.471% (6568/16640)\n",
      "Epoch 1 Step 520/1563 Loss: 1.665 | Acc: 39.449% (6577/16672)\n",
      "Epoch 1 Step 521/1563 Loss: 1.665 | Acc: 39.458% (6591/16704)\n",
      "Epoch 1 Step 522/1563 Loss: 1.665 | Acc: 39.472% (6606/16736)\n",
      "Epoch 1 Step 523/1563 Loss: 1.665 | Acc: 39.474% (6619/16768)\n",
      "Epoch 1 Step 524/1563 Loss: 1.665 | Acc: 39.458% (6629/16800)\n",
      "Epoch 1 Step 525/1563 Loss: 1.665 | Acc: 39.478% (6645/16832)\n",
      "Epoch 1 Step 526/1563 Loss: 1.665 | Acc: 39.486% (6659/16864)\n",
      "Epoch 1 Step 527/1563 Loss: 1.665 | Acc: 39.500% (6674/16896)\n",
      "Epoch 1 Step 528/1563 Loss: 1.664 | Acc: 39.509% (6688/16928)\n",
      "Epoch 1 Step 529/1563 Loss: 1.664 | Acc: 39.511% (6701/16960)\n",
      "Epoch 1 Step 530/1563 Loss: 1.664 | Acc: 39.519% (6715/16992)\n",
      "Epoch 1 Step 531/1563 Loss: 1.663 | Acc: 39.532% (6730/17024)\n",
      "Epoch 1 Step 532/1563 Loss: 1.663 | Acc: 39.558% (6747/17056)\n",
      "Epoch 1 Step 533/1563 Loss: 1.663 | Acc: 39.548% (6758/17088)\n",
      "Epoch 1 Step 534/1563 Loss: 1.663 | Acc: 39.562% (6773/17120)\n",
      "Epoch 1 Step 535/1563 Loss: 1.663 | Acc: 39.570% (6787/17152)\n",
      "Epoch 1 Step 536/1563 Loss: 1.663 | Acc: 39.572% (6800/17184)\n",
      "Epoch 1 Step 537/1563 Loss: 1.664 | Acc: 39.556% (6810/17216)\n",
      "Epoch 1 Step 538/1563 Loss: 1.664 | Acc: 39.535% (6819/17248)\n",
      "Epoch 1 Step 539/1563 Loss: 1.664 | Acc: 39.514% (6828/17280)\n",
      "Epoch 1 Step 540/1563 Loss: 1.664 | Acc: 39.504% (6839/17312)\n",
      "Epoch 1 Step 541/1563 Loss: 1.663 | Acc: 39.518% (6854/17344)\n",
      "Epoch 1 Step 542/1563 Loss: 1.664 | Acc: 39.503% (6864/17376)\n",
      "Epoch 1 Step 543/1563 Loss: 1.664 | Acc: 39.505% (6877/17408)\n",
      "Epoch 1 Step 544/1563 Loss: 1.664 | Acc: 39.495% (6888/17440)\n",
      "Epoch 1 Step 545/1563 Loss: 1.664 | Acc: 39.463% (6895/17472)\n",
      "Epoch 1 Step 546/1563 Loss: 1.664 | Acc: 39.465% (6908/17504)\n",
      "Epoch 1 Step 547/1563 Loss: 1.664 | Acc: 39.462% (6920/17536)\n",
      "Epoch 1 Step 548/1563 Loss: 1.664 | Acc: 39.430% (6927/17568)\n",
      "Epoch 1 Step 549/1563 Loss: 1.664 | Acc: 39.455% (6944/17600)\n",
      "Epoch 1 Step 550/1563 Loss: 1.664 | Acc: 39.485% (6962/17632)\n",
      "Epoch 1 Step 551/1563 Loss: 1.663 | Acc: 39.498% (6977/17664)\n",
      "Epoch 1 Step 552/1563 Loss: 1.663 | Acc: 39.512% (6992/17696)\n",
      "Epoch 1 Step 553/1563 Loss: 1.663 | Acc: 39.514% (7005/17728)\n",
      "Epoch 1 Step 554/1563 Loss: 1.663 | Acc: 39.538% (7022/17760)\n",
      "Epoch 1 Step 555/1563 Loss: 1.662 | Acc: 39.551% (7037/17792)\n",
      "Epoch 1 Step 556/1563 Loss: 1.662 | Acc: 39.542% (7048/17824)\n",
      "Epoch 1 Step 557/1563 Loss: 1.662 | Acc: 39.505% (7054/17856)\n",
      "Epoch 1 Step 558/1563 Loss: 1.662 | Acc: 39.507% (7067/17888)\n",
      "Epoch 1 Step 559/1563 Loss: 1.662 | Acc: 39.481% (7075/17920)\n",
      "Epoch 1 Step 560/1563 Loss: 1.662 | Acc: 39.472% (7086/17952)\n",
      "Epoch 1 Step 561/1563 Loss: 1.662 | Acc: 39.463% (7097/17984)\n",
      "Epoch 1 Step 562/1563 Loss: 1.662 | Acc: 39.476% (7112/18016)\n",
      "Epoch 1 Step 563/1563 Loss: 1.662 | Acc: 39.484% (7126/18048)\n",
      "Epoch 1 Step 564/1563 Loss: 1.662 | Acc: 39.480% (7138/18080)\n",
      "Epoch 1 Step 565/1563 Loss: 1.662 | Acc: 39.499% (7154/18112)\n",
      "Epoch 1 Step 566/1563 Loss: 1.662 | Acc: 39.495% (7166/18144)\n",
      "Epoch 1 Step 567/1563 Loss: 1.662 | Acc: 39.503% (7180/18176)\n",
      "Epoch 1 Step 568/1563 Loss: 1.662 | Acc: 39.499% (7192/18208)\n",
      "Epoch 1 Step 569/1563 Loss: 1.662 | Acc: 39.507% (7206/18240)\n",
      "Epoch 1 Step 570/1563 Loss: 1.662 | Acc: 39.514% (7220/18272)\n",
      "Epoch 1 Step 571/1563 Loss: 1.662 | Acc: 39.500% (7230/18304)\n",
      "Epoch 1 Step 572/1563 Loss: 1.662 | Acc: 39.518% (7246/18336)\n",
      "Epoch 1 Step 573/1563 Loss: 1.662 | Acc: 39.536% (7262/18368)\n",
      "Epoch 1 Step 574/1563 Loss: 1.661 | Acc: 39.565% (7280/18400)\n",
      "Epoch 1 Step 575/1563 Loss: 1.661 | Acc: 39.583% (7296/18432)\n",
      "Epoch 1 Step 576/1563 Loss: 1.661 | Acc: 39.580% (7308/18464)\n",
      "Epoch 1 Step 577/1563 Loss: 1.661 | Acc: 39.576% (7320/18496)\n",
      "Epoch 1 Step 578/1563 Loss: 1.660 | Acc: 39.573% (7332/18528)\n",
      "Epoch 1 Step 579/1563 Loss: 1.660 | Acc: 39.547% (7340/18560)\n",
      "Epoch 1 Step 580/1563 Loss: 1.661 | Acc: 39.533% (7350/18592)\n",
      "Epoch 1 Step 581/1563 Loss: 1.661 | Acc: 39.535% (7363/18624)\n",
      "Epoch 1 Step 582/1563 Loss: 1.660 | Acc: 39.574% (7383/18656)\n",
      "Epoch 1 Step 583/1563 Loss: 1.660 | Acc: 39.587% (7398/18688)\n",
      "Epoch 1 Step 584/1563 Loss: 1.660 | Acc: 39.599% (7413/18720)\n",
      "Epoch 1 Step 585/1563 Loss: 1.659 | Acc: 39.612% (7428/18752)\n",
      "Epoch 1 Step 586/1563 Loss: 1.660 | Acc: 39.608% (7440/18784)\n",
      "Epoch 1 Step 587/1563 Loss: 1.660 | Acc: 39.615% (7454/18816)\n",
      "Epoch 1 Step 588/1563 Loss: 1.659 | Acc: 39.633% (7470/18848)\n",
      "Epoch 1 Step 589/1563 Loss: 1.660 | Acc: 39.645% (7485/18880)\n",
      "Epoch 1 Step 590/1563 Loss: 1.659 | Acc: 39.657% (7500/18912)\n",
      "Epoch 1 Step 591/1563 Loss: 1.659 | Acc: 39.648% (7511/18944)\n",
      "Epoch 1 Step 592/1563 Loss: 1.659 | Acc: 39.687% (7531/18976)\n",
      "Epoch 1 Step 593/1563 Loss: 1.659 | Acc: 39.673% (7541/19008)\n",
      "Epoch 1 Step 594/1563 Loss: 1.660 | Acc: 39.648% (7549/19040)\n",
      "Epoch 1 Step 595/1563 Loss: 1.659 | Acc: 39.665% (7565/19072)\n",
      "Epoch 1 Step 596/1563 Loss: 1.659 | Acc: 39.678% (7580/19104)\n",
      "Epoch 1 Step 597/1563 Loss: 1.660 | Acc: 39.695% (7596/19136)\n",
      "Epoch 1 Step 598/1563 Loss: 1.660 | Acc: 39.696% (7609/19168)\n",
      "Epoch 1 Step 599/1563 Loss: 1.660 | Acc: 39.693% (7621/19200)\n",
      "Epoch 1 Step 600/1563 Loss: 1.660 | Acc: 39.699% (7635/19232)\n",
      "Epoch 1 Step 601/1563 Loss: 1.660 | Acc: 39.701% (7648/19264)\n",
      "Epoch 1 Step 602/1563 Loss: 1.660 | Acc: 39.692% (7659/19296)\n",
      "Epoch 1 Step 603/1563 Loss: 1.660 | Acc: 39.714% (7676/19328)\n",
      "Epoch 1 Step 604/1563 Loss: 1.660 | Acc: 39.711% (7688/19360)\n",
      "Epoch 1 Step 605/1563 Loss: 1.660 | Acc: 39.728% (7704/19392)\n",
      "Epoch 1 Step 606/1563 Loss: 1.660 | Acc: 39.734% (7718/19424)\n",
      "Epoch 1 Step 607/1563 Loss: 1.660 | Acc: 39.715% (7727/19456)\n",
      "Epoch 1 Step 608/1563 Loss: 1.660 | Acc: 39.722% (7741/19488)\n",
      "Epoch 1 Step 609/1563 Loss: 1.660 | Acc: 39.728% (7755/19520)\n",
      "Epoch 1 Step 610/1563 Loss: 1.659 | Acc: 39.756% (7773/19552)\n",
      "Epoch 1 Step 611/1563 Loss: 1.660 | Acc: 39.721% (7779/19584)\n",
      "Epoch 1 Step 612/1563 Loss: 1.659 | Acc: 39.753% (7798/19616)\n",
      "Epoch 1 Step 613/1563 Loss: 1.660 | Acc: 39.739% (7808/19648)\n",
      "Epoch 1 Step 614/1563 Loss: 1.660 | Acc: 39.741% (7821/19680)\n",
      "Epoch 1 Step 615/1563 Loss: 1.660 | Acc: 39.747% (7835/19712)\n",
      "Epoch 1 Step 616/1563 Loss: 1.660 | Acc: 39.739% (7846/19744)\n",
      "Epoch 1 Step 617/1563 Loss: 1.660 | Acc: 39.720% (7855/19776)\n",
      "Epoch 1 Step 618/1563 Loss: 1.660 | Acc: 39.721% (7868/19808)\n",
      "Epoch 1 Step 619/1563 Loss: 1.660 | Acc: 39.733% (7883/19840)\n",
      "Epoch 1 Step 620/1563 Loss: 1.659 | Acc: 39.719% (7893/19872)\n",
      "Epoch 1 Step 621/1563 Loss: 1.660 | Acc: 39.685% (7899/19904)\n",
      "Epoch 1 Step 622/1563 Loss: 1.660 | Acc: 39.697% (7914/19936)\n",
      "Epoch 1 Step 623/1563 Loss: 1.660 | Acc: 39.724% (7932/19968)\n",
      "Epoch 1 Step 624/1563 Loss: 1.660 | Acc: 39.735% (7947/20000)\n",
      "Epoch 1 Step 625/1563 Loss: 1.659 | Acc: 39.726% (7958/20032)\n",
      "Epoch 1 Step 626/1563 Loss: 1.659 | Acc: 39.728% (7971/20064)\n",
      "Epoch 1 Step 627/1563 Loss: 1.659 | Acc: 39.724% (7983/20096)\n",
      "Epoch 1 Step 628/1563 Loss: 1.658 | Acc: 39.706% (7992/20128)\n",
      "Epoch 1 Step 629/1563 Loss: 1.658 | Acc: 39.712% (8006/20160)\n",
      "Epoch 1 Step 630/1563 Loss: 1.658 | Acc: 39.714% (8019/20192)\n",
      "Epoch 1 Step 631/1563 Loss: 1.658 | Acc: 39.690% (8027/20224)\n",
      "Epoch 1 Step 632/1563 Loss: 1.657 | Acc: 39.702% (8042/20256)\n",
      "Epoch 1 Step 633/1563 Loss: 1.657 | Acc: 39.723% (8059/20288)\n",
      "Epoch 1 Step 634/1563 Loss: 1.657 | Acc: 39.729% (8073/20320)\n",
      "Epoch 1 Step 635/1563 Loss: 1.657 | Acc: 39.721% (8084/20352)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 636/1563 Loss: 1.657 | Acc: 39.722% (8097/20384)\n",
      "Epoch 1 Step 637/1563 Loss: 1.656 | Acc: 39.748% (8115/20416)\n",
      "Epoch 1 Step 638/1563 Loss: 1.656 | Acc: 39.759% (8130/20448)\n",
      "Epoch 1 Step 639/1563 Loss: 1.656 | Acc: 39.761% (8143/20480)\n",
      "Epoch 1 Step 640/1563 Loss: 1.656 | Acc: 39.772% (8158/20512)\n",
      "Epoch 1 Step 641/1563 Loss: 1.656 | Acc: 39.773% (8171/20544)\n",
      "Epoch 1 Step 642/1563 Loss: 1.656 | Acc: 39.770% (8183/20576)\n",
      "Epoch 1 Step 643/1563 Loss: 1.656 | Acc: 39.771% (8196/20608)\n",
      "Epoch 1 Step 644/1563 Loss: 1.656 | Acc: 39.753% (8205/20640)\n",
      "Epoch 1 Step 645/1563 Loss: 1.656 | Acc: 39.749% (8217/20672)\n",
      "Epoch 1 Step 646/1563 Loss: 1.656 | Acc: 39.741% (8228/20704)\n",
      "Epoch 1 Step 647/1563 Loss: 1.656 | Acc: 39.752% (8243/20736)\n",
      "Epoch 1 Step 648/1563 Loss: 1.655 | Acc: 39.753% (8256/20768)\n",
      "Epoch 1 Step 649/1563 Loss: 1.655 | Acc: 39.774% (8273/20800)\n",
      "Epoch 1 Step 650/1563 Loss: 1.655 | Acc: 39.775% (8286/20832)\n",
      "Epoch 1 Step 651/1563 Loss: 1.655 | Acc: 39.786% (8301/20864)\n",
      "Epoch 1 Step 652/1563 Loss: 1.655 | Acc: 39.788% (8314/20896)\n",
      "Epoch 1 Step 653/1563 Loss: 1.655 | Acc: 39.794% (8328/20928)\n",
      "Epoch 1 Step 654/1563 Loss: 1.655 | Acc: 39.804% (8343/20960)\n",
      "Epoch 1 Step 655/1563 Loss: 1.655 | Acc: 39.806% (8356/20992)\n",
      "Epoch 1 Step 656/1563 Loss: 1.654 | Acc: 39.802% (8368/21024)\n",
      "Epoch 1 Step 657/1563 Loss: 1.655 | Acc: 39.789% (8378/21056)\n",
      "Epoch 1 Step 658/1563 Loss: 1.655 | Acc: 39.771% (8387/21088)\n",
      "Epoch 1 Step 659/1563 Loss: 1.655 | Acc: 39.777% (8401/21120)\n",
      "Epoch 1 Step 660/1563 Loss: 1.655 | Acc: 39.765% (8411/21152)\n",
      "Epoch 1 Step 661/1563 Loss: 1.655 | Acc: 39.775% (8426/21184)\n",
      "Epoch 1 Step 662/1563 Loss: 1.654 | Acc: 39.781% (8440/21216)\n",
      "Epoch 1 Step 663/1563 Loss: 1.654 | Acc: 39.792% (8455/21248)\n",
      "Epoch 1 Step 664/1563 Loss: 1.654 | Acc: 39.793% (8468/21280)\n",
      "Epoch 1 Step 665/1563 Loss: 1.654 | Acc: 39.804% (8483/21312)\n",
      "Epoch 1 Step 666/1563 Loss: 1.654 | Acc: 39.814% (8498/21344)\n",
      "Epoch 1 Step 667/1563 Loss: 1.654 | Acc: 39.797% (8507/21376)\n",
      "Epoch 1 Step 668/1563 Loss: 1.654 | Acc: 39.789% (8518/21408)\n",
      "Epoch 1 Step 669/1563 Loss: 1.654 | Acc: 39.771% (8527/21440)\n",
      "Epoch 1 Step 670/1563 Loss: 1.654 | Acc: 39.782% (8542/21472)\n",
      "Epoch 1 Step 671/1563 Loss: 1.654 | Acc: 39.769% (8552/21504)\n",
      "Epoch 1 Step 672/1563 Loss: 1.654 | Acc: 39.780% (8567/21536)\n",
      "Epoch 1 Step 673/1563 Loss: 1.655 | Acc: 39.781% (8580/21568)\n",
      "Epoch 1 Step 674/1563 Loss: 1.655 | Acc: 39.778% (8592/21600)\n",
      "Epoch 1 Step 675/1563 Loss: 1.655 | Acc: 39.765% (8602/21632)\n",
      "Epoch 1 Step 676/1563 Loss: 1.655 | Acc: 39.794% (8621/21664)\n",
      "Epoch 1 Step 677/1563 Loss: 1.655 | Acc: 39.795% (8634/21696)\n",
      "Epoch 1 Step 678/1563 Loss: 1.655 | Acc: 39.797% (8647/21728)\n",
      "Epoch 1 Step 679/1563 Loss: 1.655 | Acc: 39.793% (8659/21760)\n",
      "Epoch 1 Step 680/1563 Loss: 1.655 | Acc: 39.781% (8669/21792)\n",
      "Epoch 1 Step 681/1563 Loss: 1.655 | Acc: 39.777% (8681/21824)\n",
      "Epoch 1 Step 682/1563 Loss: 1.655 | Acc: 39.797% (8698/21856)\n",
      "Epoch 1 Step 683/1563 Loss: 1.654 | Acc: 39.807% (8713/21888)\n",
      "Epoch 1 Step 684/1563 Loss: 1.654 | Acc: 39.822% (8729/21920)\n",
      "Epoch 1 Step 685/1563 Loss: 1.654 | Acc: 39.828% (8743/21952)\n",
      "Epoch 1 Step 686/1563 Loss: 1.654 | Acc: 39.824% (8755/21984)\n",
      "Epoch 1 Step 687/1563 Loss: 1.654 | Acc: 39.821% (8767/22016)\n",
      "Epoch 1 Step 688/1563 Loss: 1.654 | Acc: 39.845% (8785/22048)\n",
      "Epoch 1 Step 689/1563 Loss: 1.654 | Acc: 39.841% (8797/22080)\n",
      "Epoch 1 Step 690/1563 Loss: 1.654 | Acc: 39.847% (8811/22112)\n",
      "Epoch 1 Step 691/1563 Loss: 1.654 | Acc: 39.826% (8819/22144)\n",
      "Epoch 1 Step 692/1563 Loss: 1.654 | Acc: 39.827% (8832/22176)\n",
      "Epoch 1 Step 693/1563 Loss: 1.654 | Acc: 39.832% (8846/22208)\n",
      "Epoch 1 Step 694/1563 Loss: 1.653 | Acc: 39.838% (8860/22240)\n",
      "Epoch 1 Step 695/1563 Loss: 1.653 | Acc: 39.839% (8873/22272)\n",
      "Epoch 1 Step 696/1563 Loss: 1.653 | Acc: 39.849% (8888/22304)\n",
      "Epoch 1 Step 697/1563 Loss: 1.653 | Acc: 39.855% (8902/22336)\n",
      "Epoch 1 Step 698/1563 Loss: 1.653 | Acc: 39.852% (8914/22368)\n",
      "Epoch 1 Step 699/1563 Loss: 1.653 | Acc: 39.871% (8931/22400)\n",
      "Epoch 1 Step 700/1563 Loss: 1.653 | Acc: 39.881% (8946/22432)\n",
      "Epoch 1 Step 701/1563 Loss: 1.653 | Acc: 39.882% (8959/22464)\n",
      "Epoch 1 Step 702/1563 Loss: 1.652 | Acc: 39.905% (8977/22496)\n",
      "Epoch 1 Step 703/1563 Loss: 1.652 | Acc: 39.906% (8990/22528)\n",
      "Epoch 1 Step 704/1563 Loss: 1.652 | Acc: 39.911% (9004/22560)\n",
      "Epoch 1 Step 705/1563 Loss: 1.652 | Acc: 39.917% (9018/22592)\n",
      "Epoch 1 Step 706/1563 Loss: 1.652 | Acc: 39.931% (9034/22624)\n",
      "Epoch 1 Step 707/1563 Loss: 1.652 | Acc: 39.928% (9046/22656)\n",
      "Epoch 1 Step 708/1563 Loss: 1.652 | Acc: 39.915% (9056/22688)\n",
      "Epoch 1 Step 709/1563 Loss: 1.652 | Acc: 39.912% (9068/22720)\n",
      "Epoch 1 Step 710/1563 Loss: 1.652 | Acc: 39.931% (9085/22752)\n",
      "Epoch 1 Step 711/1563 Loss: 1.652 | Acc: 39.932% (9098/22784)\n",
      "Epoch 1 Step 712/1563 Loss: 1.652 | Acc: 39.937% (9112/22816)\n",
      "Epoch 1 Step 713/1563 Loss: 1.652 | Acc: 39.942% (9126/22848)\n",
      "Epoch 1 Step 714/1563 Loss: 1.652 | Acc: 39.930% (9136/22880)\n",
      "Epoch 1 Step 715/1563 Loss: 1.651 | Acc: 39.966% (9157/22912)\n",
      "Epoch 1 Step 716/1563 Loss: 1.651 | Acc: 39.984% (9174/22944)\n",
      "Epoch 1 Step 717/1563 Loss: 1.651 | Acc: 39.976% (9185/22976)\n",
      "Epoch 1 Step 718/1563 Loss: 1.651 | Acc: 39.977% (9198/23008)\n",
      "Epoch 1 Step 719/1563 Loss: 1.651 | Acc: 39.991% (9214/23040)\n",
      "Epoch 1 Step 720/1563 Loss: 1.651 | Acc: 40.010% (9231/23072)\n",
      "Epoch 1 Step 721/1563 Loss: 1.651 | Acc: 40.019% (9246/23104)\n",
      "Epoch 1 Step 722/1563 Loss: 1.651 | Acc: 40.020% (9259/23136)\n",
      "Epoch 1 Step 723/1563 Loss: 1.651 | Acc: 40.021% (9272/23168)\n",
      "Epoch 1 Step 724/1563 Loss: 1.650 | Acc: 40.034% (9288/23200)\n",
      "Epoch 1 Step 725/1563 Loss: 1.650 | Acc: 40.022% (9298/23232)\n",
      "Epoch 1 Step 726/1563 Loss: 1.651 | Acc: 40.015% (9309/23264)\n",
      "Epoch 1 Step 727/1563 Loss: 1.651 | Acc: 40.011% (9321/23296)\n",
      "Epoch 1 Step 728/1563 Loss: 1.650 | Acc: 40.025% (9337/23328)\n",
      "Epoch 1 Step 729/1563 Loss: 1.651 | Acc: 40.013% (9347/23360)\n",
      "Epoch 1 Step 730/1563 Loss: 1.651 | Acc: 40.014% (9360/23392)\n",
      "Epoch 1 Step 731/1563 Loss: 1.651 | Acc: 40.036% (9378/23424)\n",
      "Epoch 1 Step 732/1563 Loss: 1.651 | Acc: 40.054% (9395/23456)\n",
      "Epoch 1 Step 733/1563 Loss: 1.651 | Acc: 40.054% (9408/23488)\n",
      "Epoch 1 Step 734/1563 Loss: 1.651 | Acc: 40.030% (9415/23520)\n",
      "Epoch 1 Step 735/1563 Loss: 1.651 | Acc: 40.031% (9428/23552)\n",
      "Epoch 1 Step 736/1563 Loss: 1.651 | Acc: 40.040% (9443/23584)\n",
      "Epoch 1 Step 737/1563 Loss: 1.650 | Acc: 40.024% (9452/23616)\n",
      "Epoch 1 Step 738/1563 Loss: 1.650 | Acc: 40.041% (9469/23648)\n",
      "Epoch 1 Step 739/1563 Loss: 1.651 | Acc: 40.030% (9479/23680)\n",
      "Epoch 1 Step 740/1563 Loss: 1.651 | Acc: 40.022% (9490/23712)\n",
      "Epoch 1 Step 741/1563 Loss: 1.651 | Acc: 40.023% (9503/23744)\n",
      "Epoch 1 Step 742/1563 Loss: 1.651 | Acc: 40.011% (9513/23776)\n",
      "Epoch 1 Step 743/1563 Loss: 1.651 | Acc: 40.008% (9525/23808)\n",
      "Epoch 1 Step 744/1563 Loss: 1.650 | Acc: 40.021% (9541/23840)\n",
      "Epoch 1 Step 745/1563 Loss: 1.650 | Acc: 40.030% (9556/23872)\n",
      "Epoch 1 Step 746/1563 Loss: 1.651 | Acc: 40.006% (9563/23904)\n",
      "Epoch 1 Step 747/1563 Loss: 1.651 | Acc: 40.011% (9577/23936)\n",
      "Epoch 1 Step 748/1563 Loss: 1.650 | Acc: 40.028% (9594/23968)\n",
      "Epoch 1 Step 749/1563 Loss: 1.650 | Acc: 40.046% (9611/24000)\n",
      "Epoch 1 Step 750/1563 Loss: 1.650 | Acc: 40.042% (9623/24032)\n",
      "Epoch 1 Step 751/1563 Loss: 1.650 | Acc: 40.047% (9637/24064)\n",
      "Epoch 1 Step 752/1563 Loss: 1.650 | Acc: 40.061% (9653/24096)\n",
      "Epoch 1 Step 753/1563 Loss: 1.650 | Acc: 40.065% (9667/24128)\n",
      "Epoch 1 Step 754/1563 Loss: 1.649 | Acc: 40.079% (9683/24160)\n",
      "Epoch 1 Step 755/1563 Loss: 1.649 | Acc: 40.063% (9692/24192)\n",
      "Epoch 1 Step 756/1563 Loss: 1.649 | Acc: 40.068% (9706/24224)\n",
      "Epoch 1 Step 757/1563 Loss: 1.650 | Acc: 40.064% (9718/24256)\n",
      "Epoch 1 Step 758/1563 Loss: 1.650 | Acc: 40.061% (9730/24288)\n",
      "Epoch 1 Step 759/1563 Loss: 1.649 | Acc: 40.066% (9744/24320)\n",
      "Epoch 1 Step 760/1563 Loss: 1.649 | Acc: 40.058% (9755/24352)\n",
      "Epoch 1 Step 761/1563 Loss: 1.650 | Acc: 40.059% (9768/24384)\n",
      "Epoch 1 Step 762/1563 Loss: 1.650 | Acc: 40.048% (9778/24416)\n",
      "Epoch 1 Step 763/1563 Loss: 1.650 | Acc: 40.044% (9790/24448)\n",
      "Epoch 1 Step 764/1563 Loss: 1.650 | Acc: 40.045% (9803/24480)\n",
      "Epoch 1 Step 765/1563 Loss: 1.649 | Acc: 40.054% (9818/24512)\n",
      "Epoch 1 Step 766/1563 Loss: 1.649 | Acc: 40.071% (9835/24544)\n",
      "Epoch 1 Step 767/1563 Loss: 1.649 | Acc: 40.068% (9847/24576)\n",
      "Epoch 1 Step 768/1563 Loss: 1.649 | Acc: 40.080% (9863/24608)\n",
      "Epoch 1 Step 769/1563 Loss: 1.649 | Acc: 40.081% (9876/24640)\n",
      "Epoch 1 Step 770/1563 Loss: 1.649 | Acc: 40.082% (9889/24672)\n",
      "Epoch 1 Step 771/1563 Loss: 1.649 | Acc: 40.091% (9904/24704)\n",
      "Epoch 1 Step 772/1563 Loss: 1.649 | Acc: 40.075% (9913/24736)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 773/1563 Loss: 1.649 | Acc: 40.072% (9925/24768)\n",
      "Epoch 1 Step 774/1563 Loss: 1.649 | Acc: 40.069% (9937/24800)\n",
      "Epoch 1 Step 775/1563 Loss: 1.649 | Acc: 40.065% (9949/24832)\n",
      "Epoch 1 Step 776/1563 Loss: 1.649 | Acc: 40.062% (9961/24864)\n",
      "Epoch 1 Step 777/1563 Loss: 1.649 | Acc: 40.055% (9972/24896)\n",
      "Epoch 1 Step 778/1563 Loss: 1.650 | Acc: 40.047% (9983/24928)\n",
      "Epoch 1 Step 779/1563 Loss: 1.649 | Acc: 40.064% (10000/24960)\n",
      "Epoch 1 Step 780/1563 Loss: 1.649 | Acc: 40.089% (10019/24992)\n",
      "Epoch 1 Step 781/1563 Loss: 1.649 | Acc: 40.098% (10034/25024)\n",
      "Epoch 1 Step 782/1563 Loss: 1.649 | Acc: 40.114% (10051/25056)\n",
      "Epoch 1 Step 783/1563 Loss: 1.649 | Acc: 40.119% (10065/25088)\n",
      "Epoch 1 Step 784/1563 Loss: 1.649 | Acc: 40.143% (10084/25120)\n",
      "Epoch 1 Step 785/1563 Loss: 1.649 | Acc: 40.148% (10098/25152)\n",
      "Epoch 1 Step 786/1563 Loss: 1.649 | Acc: 40.145% (10110/25184)\n",
      "Epoch 1 Step 787/1563 Loss: 1.649 | Acc: 40.153% (10125/25216)\n",
      "Epoch 1 Step 788/1563 Loss: 1.649 | Acc: 40.146% (10136/25248)\n",
      "Epoch 1 Step 789/1563 Loss: 1.649 | Acc: 40.134% (10146/25280)\n",
      "Epoch 1 Step 790/1563 Loss: 1.649 | Acc: 40.147% (10162/25312)\n",
      "Epoch 1 Step 791/1563 Loss: 1.649 | Acc: 40.159% (10178/25344)\n",
      "Epoch 1 Step 792/1563 Loss: 1.649 | Acc: 40.168% (10193/25376)\n",
      "Epoch 1 Step 793/1563 Loss: 1.649 | Acc: 40.157% (10203/25408)\n",
      "Epoch 1 Step 794/1563 Loss: 1.649 | Acc: 40.173% (10220/25440)\n",
      "Epoch 1 Step 795/1563 Loss: 1.649 | Acc: 40.170% (10232/25472)\n",
      "Epoch 1 Step 796/1563 Loss: 1.649 | Acc: 40.170% (10245/25504)\n",
      "Epoch 1 Step 797/1563 Loss: 1.649 | Acc: 40.167% (10257/25536)\n",
      "Epoch 1 Step 798/1563 Loss: 1.649 | Acc: 40.167% (10270/25568)\n",
      "Epoch 1 Step 799/1563 Loss: 1.649 | Acc: 40.176% (10285/25600)\n",
      "Epoch 1 Step 800/1563 Loss: 1.648 | Acc: 40.180% (10299/25632)\n",
      "Epoch 1 Step 801/1563 Loss: 1.648 | Acc: 40.181% (10312/25664)\n",
      "Epoch 1 Step 802/1563 Loss: 1.648 | Acc: 40.181% (10325/25696)\n",
      "Epoch 1 Step 803/1563 Loss: 1.648 | Acc: 40.170% (10335/25728)\n",
      "Epoch 1 Step 804/1563 Loss: 1.648 | Acc: 40.179% (10350/25760)\n",
      "Epoch 1 Step 805/1563 Loss: 1.648 | Acc: 40.179% (10363/25792)\n",
      "Epoch 1 Step 806/1563 Loss: 1.649 | Acc: 40.172% (10374/25824)\n",
      "Epoch 1 Step 807/1563 Loss: 1.648 | Acc: 40.196% (10393/25856)\n",
      "Epoch 1 Step 808/1563 Loss: 1.648 | Acc: 40.196% (10406/25888)\n",
      "Epoch 1 Step 809/1563 Loss: 1.648 | Acc: 40.204% (10421/25920)\n",
      "Epoch 1 Step 810/1563 Loss: 1.648 | Acc: 40.213% (10436/25952)\n",
      "Epoch 1 Step 811/1563 Loss: 1.649 | Acc: 40.217% (10450/25984)\n",
      "Epoch 1 Step 812/1563 Loss: 1.648 | Acc: 40.221% (10464/26016)\n",
      "Epoch 1 Step 813/1563 Loss: 1.648 | Acc: 40.233% (10480/26048)\n",
      "Epoch 1 Step 814/1563 Loss: 1.648 | Acc: 40.219% (10489/26080)\n",
      "Epoch 1 Step 815/1563 Loss: 1.648 | Acc: 40.231% (10505/26112)\n",
      "Epoch 1 Step 816/1563 Loss: 1.648 | Acc: 40.231% (10518/26144)\n",
      "Epoch 1 Step 817/1563 Loss: 1.648 | Acc: 40.247% (10535/26176)\n",
      "Epoch 1 Step 818/1563 Loss: 1.648 | Acc: 40.270% (10554/26208)\n",
      "Epoch 1 Step 819/1563 Loss: 1.648 | Acc: 40.282% (10570/26240)\n",
      "Epoch 1 Step 820/1563 Loss: 1.647 | Acc: 40.294% (10586/26272)\n",
      "Epoch 1 Step 821/1563 Loss: 1.647 | Acc: 40.298% (10600/26304)\n",
      "Epoch 1 Step 822/1563 Loss: 1.647 | Acc: 40.302% (10614/26336)\n",
      "Epoch 1 Step 823/1563 Loss: 1.647 | Acc: 40.295% (10625/26368)\n",
      "Epoch 1 Step 824/1563 Loss: 1.648 | Acc: 40.277% (10633/26400)\n",
      "Epoch 1 Step 825/1563 Loss: 1.647 | Acc: 40.288% (10649/26432)\n",
      "Epoch 1 Step 826/1563 Loss: 1.647 | Acc: 40.277% (10659/26464)\n",
      "Epoch 1 Step 827/1563 Loss: 1.647 | Acc: 40.282% (10673/26496)\n",
      "Epoch 1 Step 828/1563 Loss: 1.647 | Acc: 40.282% (10686/26528)\n",
      "Epoch 1 Step 829/1563 Loss: 1.647 | Acc: 40.279% (10698/26560)\n",
      "Epoch 1 Step 830/1563 Loss: 1.647 | Acc: 40.287% (10713/26592)\n",
      "Epoch 1 Step 831/1563 Loss: 1.647 | Acc: 40.276% (10723/26624)\n",
      "Epoch 1 Step 832/1563 Loss: 1.647 | Acc: 40.269% (10734/26656)\n",
      "Epoch 1 Step 833/1563 Loss: 1.647 | Acc: 40.269% (10747/26688)\n",
      "Epoch 1 Step 834/1563 Loss: 1.647 | Acc: 40.258% (10757/26720)\n",
      "Epoch 1 Step 835/1563 Loss: 1.647 | Acc: 40.270% (10773/26752)\n",
      "Epoch 1 Step 836/1563 Loss: 1.647 | Acc: 40.263% (10784/26784)\n",
      "Epoch 1 Step 837/1563 Loss: 1.647 | Acc: 40.278% (10801/26816)\n",
      "Epoch 1 Step 838/1563 Loss: 1.647 | Acc: 40.275% (10813/26848)\n",
      "Epoch 1 Step 839/1563 Loss: 1.647 | Acc: 40.275% (10826/26880)\n",
      "Epoch 1 Step 840/1563 Loss: 1.647 | Acc: 40.287% (10842/26912)\n",
      "Epoch 1 Step 841/1563 Loss: 1.647 | Acc: 40.276% (10852/26944)\n",
      "Epoch 1 Step 842/1563 Loss: 1.647 | Acc: 40.277% (10865/26976)\n",
      "Epoch 1 Step 843/1563 Loss: 1.647 | Acc: 40.288% (10881/27008)\n",
      "Epoch 1 Step 844/1563 Loss: 1.647 | Acc: 40.296% (10896/27040)\n",
      "Epoch 1 Step 845/1563 Loss: 1.647 | Acc: 40.281% (10905/27072)\n",
      "Epoch 1 Step 846/1563 Loss: 1.647 | Acc: 40.282% (10918/27104)\n",
      "Epoch 1 Step 847/1563 Loss: 1.647 | Acc: 40.286% (10932/27136)\n",
      "Epoch 1 Step 848/1563 Loss: 1.647 | Acc: 40.305% (10950/27168)\n",
      "Epoch 1 Step 849/1563 Loss: 1.647 | Acc: 40.298% (10961/27200)\n",
      "Epoch 1 Step 850/1563 Loss: 1.647 | Acc: 40.302% (10975/27232)\n",
      "Epoch 1 Step 851/1563 Loss: 1.647 | Acc: 40.302% (10988/27264)\n",
      "Epoch 1 Step 852/1563 Loss: 1.647 | Acc: 40.295% (10999/27296)\n",
      "Epoch 1 Step 853/1563 Loss: 1.648 | Acc: 40.281% (11008/27328)\n",
      "Epoch 1 Step 854/1563 Loss: 1.648 | Acc: 40.285% (11022/27360)\n",
      "Epoch 1 Step 855/1563 Loss: 1.648 | Acc: 40.282% (11034/27392)\n",
      "Epoch 1 Step 856/1563 Loss: 1.648 | Acc: 40.268% (11043/27424)\n",
      "Epoch 1 Step 857/1563 Loss: 1.648 | Acc: 40.275% (11058/27456)\n",
      "Epoch 1 Step 858/1563 Loss: 1.648 | Acc: 40.276% (11071/27488)\n",
      "Epoch 1 Step 859/1563 Loss: 1.648 | Acc: 40.283% (11086/27520)\n",
      "Epoch 1 Step 860/1563 Loss: 1.648 | Acc: 40.287% (11100/27552)\n",
      "Epoch 1 Step 861/1563 Loss: 1.648 | Acc: 40.295% (11115/27584)\n",
      "Epoch 1 Step 862/1563 Loss: 1.647 | Acc: 40.303% (11130/27616)\n",
      "Epoch 1 Step 863/1563 Loss: 1.648 | Acc: 40.299% (11142/27648)\n",
      "Epoch 1 Step 864/1563 Loss: 1.647 | Acc: 40.307% (11157/27680)\n",
      "Epoch 1 Step 865/1563 Loss: 1.647 | Acc: 40.304% (11169/27712)\n",
      "Epoch 1 Step 866/1563 Loss: 1.647 | Acc: 40.297% (11180/27744)\n",
      "Epoch 1 Step 867/1563 Loss: 1.647 | Acc: 40.308% (11196/27776)\n",
      "Epoch 1 Step 868/1563 Loss: 1.647 | Acc: 40.319% (11212/27808)\n",
      "Epoch 1 Step 869/1563 Loss: 1.647 | Acc: 40.316% (11224/27840)\n",
      "Epoch 1 Step 870/1563 Loss: 1.647 | Acc: 40.334% (11242/27872)\n",
      "Epoch 1 Step 871/1563 Loss: 1.647 | Acc: 40.349% (11259/27904)\n",
      "Epoch 1 Step 872/1563 Loss: 1.646 | Acc: 40.346% (11271/27936)\n",
      "Epoch 1 Step 873/1563 Loss: 1.647 | Acc: 40.332% (11280/27968)\n",
      "Epoch 1 Step 874/1563 Loss: 1.646 | Acc: 40.332% (11293/28000)\n",
      "Epoch 1 Step 875/1563 Loss: 1.646 | Acc: 40.332% (11306/28032)\n",
      "Epoch 1 Step 876/1563 Loss: 1.646 | Acc: 40.329% (11318/28064)\n",
      "Epoch 1 Step 877/1563 Loss: 1.646 | Acc: 40.322% (11329/28096)\n",
      "Epoch 1 Step 878/1563 Loss: 1.646 | Acc: 40.326% (11343/28128)\n",
      "Epoch 1 Step 879/1563 Loss: 1.646 | Acc: 40.341% (11360/28160)\n",
      "Epoch 1 Step 880/1563 Loss: 1.646 | Acc: 40.352% (11376/28192)\n",
      "Epoch 1 Step 881/1563 Loss: 1.646 | Acc: 40.338% (11385/28224)\n",
      "Epoch 1 Step 882/1563 Loss: 1.647 | Acc: 40.335% (11397/28256)\n",
      "Epoch 1 Step 883/1563 Loss: 1.647 | Acc: 40.332% (11409/28288)\n",
      "Epoch 1 Step 884/1563 Loss: 1.646 | Acc: 40.335% (11423/28320)\n",
      "Epoch 1 Step 885/1563 Loss: 1.646 | Acc: 40.343% (11438/28352)\n",
      "Epoch 1 Step 886/1563 Loss: 1.646 | Acc: 40.347% (11452/28384)\n",
      "Epoch 1 Step 887/1563 Loss: 1.646 | Acc: 40.343% (11464/28416)\n",
      "Epoch 1 Step 888/1563 Loss: 1.646 | Acc: 40.354% (11480/28448)\n",
      "Epoch 1 Step 889/1563 Loss: 1.646 | Acc: 40.355% (11493/28480)\n",
      "Epoch 1 Step 890/1563 Loss: 1.646 | Acc: 40.348% (11504/28512)\n",
      "Epoch 1 Step 891/1563 Loss: 1.647 | Acc: 40.338% (11514/28544)\n",
      "Epoch 1 Step 892/1563 Loss: 1.647 | Acc: 40.345% (11529/28576)\n",
      "Epoch 1 Step 893/1563 Loss: 1.647 | Acc: 40.331% (11538/28608)\n",
      "Epoch 1 Step 894/1563 Loss: 1.647 | Acc: 40.353% (11557/28640)\n",
      "Epoch 1 Step 895/1563 Loss: 1.646 | Acc: 40.370% (11575/28672)\n",
      "Epoch 1 Step 896/1563 Loss: 1.647 | Acc: 40.360% (11585/28704)\n",
      "Epoch 1 Step 897/1563 Loss: 1.646 | Acc: 40.374% (11602/28736)\n",
      "Epoch 1 Step 898/1563 Loss: 1.646 | Acc: 40.378% (11616/28768)\n",
      "Epoch 1 Step 899/1563 Loss: 1.646 | Acc: 40.372% (11627/28800)\n",
      "Epoch 1 Step 900/1563 Loss: 1.646 | Acc: 40.372% (11640/28832)\n",
      "Epoch 1 Step 901/1563 Loss: 1.646 | Acc: 40.355% (11648/28864)\n",
      "Epoch 1 Step 902/1563 Loss: 1.647 | Acc: 40.362% (11663/28896)\n",
      "Epoch 1 Step 903/1563 Loss: 1.647 | Acc: 40.366% (11677/28928)\n",
      "Epoch 1 Step 904/1563 Loss: 1.647 | Acc: 40.373% (11692/28960)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 905/1563 Loss: 1.646 | Acc: 40.359% (11701/28992)\n",
      "Epoch 1 Step 906/1563 Loss: 1.647 | Acc: 40.353% (11712/29024)\n",
      "Epoch 1 Step 907/1563 Loss: 1.646 | Acc: 40.350% (11724/29056)\n",
      "Epoch 1 Step 908/1563 Loss: 1.646 | Acc: 40.350% (11737/29088)\n",
      "Epoch 1 Step 909/1563 Loss: 1.646 | Acc: 40.337% (11746/29120)\n",
      "Epoch 1 Step 910/1563 Loss: 1.646 | Acc: 40.337% (11759/29152)\n",
      "Epoch 1 Step 911/1563 Loss: 1.646 | Acc: 40.334% (11771/29184)\n",
      "Epoch 1 Step 912/1563 Loss: 1.646 | Acc: 40.327% (11782/29216)\n",
      "Epoch 1 Step 913/1563 Loss: 1.646 | Acc: 40.351% (11802/29248)\n",
      "Epoch 1 Step 914/1563 Loss: 1.646 | Acc: 40.345% (11813/29280)\n",
      "Epoch 1 Step 915/1563 Loss: 1.646 | Acc: 40.349% (11827/29312)\n",
      "Epoch 1 Step 916/1563 Loss: 1.646 | Acc: 40.349% (11840/29344)\n",
      "Epoch 1 Step 917/1563 Loss: 1.647 | Acc: 40.346% (11852/29376)\n",
      "Epoch 1 Step 918/1563 Loss: 1.646 | Acc: 40.356% (11868/29408)\n",
      "Epoch 1 Step 919/1563 Loss: 1.646 | Acc: 40.367% (11884/29440)\n",
      "Epoch 1 Step 920/1563 Loss: 1.646 | Acc: 40.374% (11899/29472)\n",
      "Epoch 1 Step 921/1563 Loss: 1.646 | Acc: 40.367% (11910/29504)\n",
      "Epoch 1 Step 922/1563 Loss: 1.647 | Acc: 40.358% (11920/29536)\n",
      "Epoch 1 Step 923/1563 Loss: 1.647 | Acc: 40.354% (11932/29568)\n",
      "Epoch 1 Step 924/1563 Loss: 1.647 | Acc: 40.334% (11939/29600)\n",
      "Epoch 1 Step 925/1563 Loss: 1.647 | Acc: 40.335% (11952/29632)\n",
      "Epoch 1 Step 926/1563 Loss: 1.647 | Acc: 40.328% (11963/29664)\n",
      "Epoch 1 Step 927/1563 Loss: 1.647 | Acc: 40.342% (11980/29696)\n",
      "Epoch 1 Step 928/1563 Loss: 1.647 | Acc: 40.346% (11994/29728)\n",
      "Epoch 1 Step 929/1563 Loss: 1.647 | Acc: 40.356% (12010/29760)\n",
      "Epoch 1 Step 930/1563 Loss: 1.647 | Acc: 40.363% (12025/29792)\n",
      "Epoch 1 Step 931/1563 Loss: 1.647 | Acc: 40.363% (12038/29824)\n",
      "Epoch 1 Step 932/1563 Loss: 1.647 | Acc: 40.360% (12050/29856)\n",
      "Epoch 1 Step 933/1563 Loss: 1.647 | Acc: 40.357% (12062/29888)\n",
      "Epoch 1 Step 934/1563 Loss: 1.647 | Acc: 40.354% (12074/29920)\n",
      "Epoch 1 Step 935/1563 Loss: 1.647 | Acc: 40.341% (12083/29952)\n",
      "Epoch 1 Step 936/1563 Loss: 1.647 | Acc: 40.332% (12093/29984)\n",
      "Epoch 1 Step 937/1563 Loss: 1.647 | Acc: 40.355% (12113/30016)\n",
      "Epoch 1 Step 938/1563 Loss: 1.647 | Acc: 40.349% (12124/30048)\n",
      "Epoch 1 Step 939/1563 Loss: 1.647 | Acc: 40.349% (12137/30080)\n",
      "Epoch 1 Step 940/1563 Loss: 1.647 | Acc: 40.346% (12149/30112)\n",
      "Epoch 1 Step 941/1563 Loss: 1.647 | Acc: 40.340% (12160/30144)\n",
      "Epoch 1 Step 942/1563 Loss: 1.647 | Acc: 40.343% (12174/30176)\n",
      "Epoch 1 Step 943/1563 Loss: 1.647 | Acc: 40.330% (12183/30208)\n",
      "Epoch 1 Step 944/1563 Loss: 1.647 | Acc: 40.331% (12196/30240)\n",
      "Epoch 1 Step 945/1563 Loss: 1.647 | Acc: 40.331% (12209/30272)\n",
      "Epoch 1 Step 946/1563 Loss: 1.647 | Acc: 40.328% (12221/30304)\n",
      "Epoch 1 Step 947/1563 Loss: 1.647 | Acc: 40.332% (12235/30336)\n",
      "Epoch 1 Step 948/1563 Loss: 1.647 | Acc: 40.345% (12252/30368)\n",
      "Epoch 1 Step 949/1563 Loss: 1.647 | Acc: 40.349% (12266/30400)\n",
      "Epoch 1 Step 950/1563 Loss: 1.647 | Acc: 40.339% (12276/30432)\n",
      "Epoch 1 Step 951/1563 Loss: 1.647 | Acc: 40.320% (12283/30464)\n",
      "Epoch 1 Step 952/1563 Loss: 1.647 | Acc: 40.327% (12298/30496)\n",
      "Epoch 1 Step 953/1563 Loss: 1.646 | Acc: 40.337% (12314/30528)\n",
      "Epoch 1 Step 954/1563 Loss: 1.646 | Acc: 40.344% (12329/30560)\n",
      "Epoch 1 Step 955/1563 Loss: 1.646 | Acc: 40.350% (12344/30592)\n",
      "Epoch 1 Step 956/1563 Loss: 1.646 | Acc: 40.344% (12355/30624)\n",
      "Epoch 1 Step 957/1563 Loss: 1.646 | Acc: 40.335% (12365/30656)\n",
      "Epoch 1 Step 958/1563 Loss: 1.646 | Acc: 40.338% (12379/30688)\n",
      "Epoch 1 Step 959/1563 Loss: 1.646 | Acc: 40.348% (12395/30720)\n",
      "Epoch 1 Step 960/1563 Loss: 1.646 | Acc: 40.342% (12406/30752)\n",
      "Epoch 1 Step 961/1563 Loss: 1.646 | Acc: 40.339% (12418/30784)\n",
      "Epoch 1 Step 962/1563 Loss: 1.646 | Acc: 40.343% (12432/30816)\n",
      "Epoch 1 Step 963/1563 Loss: 1.646 | Acc: 40.346% (12446/30848)\n",
      "Epoch 1 Step 964/1563 Loss: 1.646 | Acc: 40.343% (12458/30880)\n",
      "Epoch 1 Step 965/1563 Loss: 1.646 | Acc: 40.347% (12472/30912)\n",
      "Epoch 1 Step 966/1563 Loss: 1.646 | Acc: 40.341% (12483/30944)\n",
      "Epoch 1 Step 967/1563 Loss: 1.646 | Acc: 40.344% (12497/30976)\n",
      "Epoch 1 Step 968/1563 Loss: 1.646 | Acc: 40.344% (12510/31008)\n",
      "Epoch 1 Step 969/1563 Loss: 1.646 | Acc: 40.354% (12526/31040)\n",
      "Epoch 1 Step 970/1563 Loss: 1.646 | Acc: 40.351% (12538/31072)\n",
      "Epoch 1 Step 971/1563 Loss: 1.646 | Acc: 40.352% (12551/31104)\n",
      "Epoch 1 Step 972/1563 Loss: 1.646 | Acc: 40.358% (12566/31136)\n",
      "Epoch 1 Step 973/1563 Loss: 1.646 | Acc: 40.352% (12577/31168)\n",
      "Epoch 1 Step 974/1563 Loss: 1.646 | Acc: 40.356% (12591/31200)\n",
      "Epoch 1 Step 975/1563 Loss: 1.646 | Acc: 40.356% (12604/31232)\n",
      "Epoch 1 Step 976/1563 Loss: 1.646 | Acc: 40.366% (12620/31264)\n",
      "Epoch 1 Step 977/1563 Loss: 1.646 | Acc: 40.363% (12632/31296)\n",
      "Epoch 1 Step 978/1563 Loss: 1.646 | Acc: 40.354% (12642/31328)\n",
      "Epoch 1 Step 979/1563 Loss: 1.646 | Acc: 40.370% (12660/31360)\n",
      "Epoch 1 Step 980/1563 Loss: 1.646 | Acc: 40.377% (12675/31392)\n",
      "Epoch 1 Step 981/1563 Loss: 1.645 | Acc: 40.390% (12692/31424)\n",
      "Epoch 1 Step 982/1563 Loss: 1.645 | Acc: 40.393% (12706/31456)\n",
      "Epoch 1 Step 983/1563 Loss: 1.645 | Acc: 40.419% (12727/31488)\n",
      "Epoch 1 Step 984/1563 Loss: 1.645 | Acc: 40.419% (12740/31520)\n",
      "Epoch 1 Step 985/1563 Loss: 1.645 | Acc: 40.416% (12752/31552)\n",
      "Epoch 1 Step 986/1563 Loss: 1.645 | Acc: 40.426% (12768/31584)\n",
      "Epoch 1 Step 987/1563 Loss: 1.645 | Acc: 40.416% (12778/31616)\n",
      "Epoch 1 Step 988/1563 Loss: 1.644 | Acc: 40.432% (12796/31648)\n",
      "Epoch 1 Step 989/1563 Loss: 1.644 | Acc: 40.448% (12814/31680)\n",
      "Epoch 1 Step 990/1563 Loss: 1.644 | Acc: 40.452% (12828/31712)\n",
      "Epoch 1 Step 991/1563 Loss: 1.644 | Acc: 40.449% (12840/31744)\n",
      "Epoch 1 Step 992/1563 Loss: 1.644 | Acc: 40.452% (12854/31776)\n",
      "Epoch 1 Step 993/1563 Loss: 1.644 | Acc: 40.458% (12869/31808)\n",
      "Epoch 1 Step 994/1563 Loss: 1.644 | Acc: 40.459% (12882/31840)\n",
      "Epoch 1 Step 995/1563 Loss: 1.644 | Acc: 40.462% (12896/31872)\n",
      "Epoch 1 Step 996/1563 Loss: 1.644 | Acc: 40.453% (12906/31904)\n",
      "Epoch 1 Step 997/1563 Loss: 1.644 | Acc: 40.443% (12916/31936)\n",
      "Epoch 1 Step 998/1563 Loss: 1.644 | Acc: 40.440% (12928/31968)\n",
      "Epoch 1 Step 999/1563 Loss: 1.644 | Acc: 40.444% (12942/32000)\n",
      "Epoch 1 Step 1000/1563 Loss: 1.644 | Acc: 40.438% (12953/32032)\n",
      "Epoch 1 Step 1001/1563 Loss: 1.644 | Acc: 40.432% (12964/32064)\n",
      "Epoch 1 Step 1002/1563 Loss: 1.644 | Acc: 40.435% (12978/32096)\n",
      "Epoch 1 Step 1003/1563 Loss: 1.644 | Acc: 40.441% (12993/32128)\n",
      "Epoch 1 Step 1004/1563 Loss: 1.644 | Acc: 40.442% (13006/32160)\n",
      "Epoch 1 Step 1005/1563 Loss: 1.644 | Acc: 40.432% (13016/32192)\n",
      "Epoch 1 Step 1006/1563 Loss: 1.644 | Acc: 40.436% (13030/32224)\n",
      "Epoch 1 Step 1007/1563 Loss: 1.644 | Acc: 40.430% (13041/32256)\n",
      "Epoch 1 Step 1008/1563 Loss: 1.644 | Acc: 40.427% (13053/32288)\n",
      "Epoch 1 Step 1009/1563 Loss: 1.644 | Acc: 40.430% (13067/32320)\n",
      "Epoch 1 Step 1010/1563 Loss: 1.644 | Acc: 40.455% (13088/32352)\n",
      "Epoch 1 Step 1011/1563 Loss: 1.644 | Acc: 40.446% (13098/32384)\n",
      "Epoch 1 Step 1012/1563 Loss: 1.643 | Acc: 40.449% (13112/32416)\n",
      "Epoch 1 Step 1013/1563 Loss: 1.643 | Acc: 40.446% (13124/32448)\n",
      "Epoch 1 Step 1014/1563 Loss: 1.643 | Acc: 40.443% (13136/32480)\n",
      "Epoch 1 Step 1015/1563 Loss: 1.643 | Acc: 40.440% (13148/32512)\n",
      "Epoch 1 Step 1016/1563 Loss: 1.643 | Acc: 40.468% (13170/32544)\n",
      "Epoch 1 Step 1017/1563 Loss: 1.643 | Acc: 40.487% (13189/32576)\n",
      "Epoch 1 Step 1018/1563 Loss: 1.643 | Acc: 40.496% (13205/32608)\n",
      "Epoch 1 Step 1019/1563 Loss: 1.643 | Acc: 40.496% (13218/32640)\n",
      "Epoch 1 Step 1020/1563 Loss: 1.643 | Acc: 40.503% (13233/32672)\n",
      "Epoch 1 Step 1021/1563 Loss: 1.643 | Acc: 40.509% (13248/32704)\n",
      "Epoch 1 Step 1022/1563 Loss: 1.643 | Acc: 40.497% (13257/32736)\n",
      "Epoch 1 Step 1023/1563 Loss: 1.643 | Acc: 40.503% (13272/32768)\n",
      "Epoch 1 Step 1024/1563 Loss: 1.643 | Acc: 40.500% (13284/32800)\n",
      "Epoch 1 Step 1025/1563 Loss: 1.642 | Acc: 40.506% (13299/32832)\n",
      "Epoch 1 Step 1026/1563 Loss: 1.642 | Acc: 40.494% (13308/32864)\n",
      "Epoch 1 Step 1027/1563 Loss: 1.642 | Acc: 40.509% (13326/32896)\n",
      "Epoch 1 Step 1028/1563 Loss: 1.642 | Acc: 40.513% (13340/32928)\n",
      "Epoch 1 Step 1029/1563 Loss: 1.642 | Acc: 40.510% (13352/32960)\n",
      "Epoch 1 Step 1030/1563 Loss: 1.642 | Acc: 40.516% (13367/32992)\n",
      "Epoch 1 Step 1031/1563 Loss: 1.642 | Acc: 40.522% (13382/33024)\n",
      "Epoch 1 Step 1032/1563 Loss: 1.642 | Acc: 40.513% (13392/33056)\n",
      "Epoch 1 Step 1033/1563 Loss: 1.643 | Acc: 40.507% (13403/33088)\n",
      "Epoch 1 Step 1034/1563 Loss: 1.643 | Acc: 40.492% (13411/33120)\n",
      "Epoch 1 Step 1035/1563 Loss: 1.643 | Acc: 40.489% (13423/33152)\n",
      "Epoch 1 Step 1036/1563 Loss: 1.643 | Acc: 40.492% (13437/33184)\n",
      "Epoch 1 Step 1037/1563 Loss: 1.643 | Acc: 40.490% (13449/33216)\n",
      "Epoch 1 Step 1038/1563 Loss: 1.642 | Acc: 40.496% (13464/33248)\n",
      "Epoch 1 Step 1039/1563 Loss: 1.642 | Acc: 40.514% (13483/33280)\n",
      "Epoch 1 Step 1040/1563 Loss: 1.642 | Acc: 40.496% (13490/33312)\n",
      "Epoch 1 Step 1041/1563 Loss: 1.642 | Acc: 40.490% (13501/33344)\n",
      "Epoch 1 Step 1042/1563 Loss: 1.642 | Acc: 40.493% (13515/33376)\n",
      "Epoch 1 Step 1043/1563 Loss: 1.642 | Acc: 40.487% (13526/33408)\n",
      "Epoch 1 Step 1044/1563 Loss: 1.642 | Acc: 40.496% (13542/33440)\n",
      "Epoch 1 Step 1045/1563 Loss: 1.642 | Acc: 40.508% (13559/33472)\n",
      "Epoch 1 Step 1046/1563 Loss: 1.642 | Acc: 40.506% (13571/33504)\n",
      "Epoch 1 Step 1047/1563 Loss: 1.642 | Acc: 40.494% (13580/33536)\n",
      "Epoch 1 Step 1048/1563 Loss: 1.642 | Acc: 40.488% (13591/33568)\n",
      "Epoch 1 Step 1049/1563 Loss: 1.642 | Acc: 40.497% (13607/33600)\n",
      "Epoch 1 Step 1050/1563 Loss: 1.642 | Acc: 40.491% (13618/33632)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1051/1563 Loss: 1.642 | Acc: 40.494% (13632/33664)\n",
      "Epoch 1 Step 1052/1563 Loss: 1.642 | Acc: 40.500% (13647/33696)\n",
      "Epoch 1 Step 1053/1563 Loss: 1.642 | Acc: 40.503% (13661/33728)\n",
      "Epoch 1 Step 1054/1563 Loss: 1.642 | Acc: 40.501% (13673/33760)\n",
      "Epoch 1 Step 1055/1563 Loss: 1.642 | Acc: 40.513% (13690/33792)\n",
      "Epoch 1 Step 1056/1563 Loss: 1.642 | Acc: 40.513% (13703/33824)\n",
      "Epoch 1 Step 1057/1563 Loss: 1.642 | Acc: 40.501% (13712/33856)\n",
      "Epoch 1 Step 1058/1563 Loss: 1.642 | Acc: 40.495% (13723/33888)\n",
      "Epoch 1 Step 1059/1563 Loss: 1.642 | Acc: 40.489% (13734/33920)\n",
      "Epoch 1 Step 1060/1563 Loss: 1.642 | Acc: 40.487% (13746/33952)\n",
      "Epoch 1 Step 1061/1563 Loss: 1.642 | Acc: 40.498% (13763/33984)\n",
      "Epoch 1 Step 1062/1563 Loss: 1.641 | Acc: 40.507% (13779/34016)\n",
      "Epoch 1 Step 1063/1563 Loss: 1.641 | Acc: 40.513% (13794/34048)\n",
      "Epoch 1 Step 1064/1563 Loss: 1.641 | Acc: 40.511% (13806/34080)\n",
      "Epoch 1 Step 1065/1563 Loss: 1.641 | Acc: 40.505% (13817/34112)\n",
      "Epoch 1 Step 1066/1563 Loss: 1.641 | Acc: 40.499% (13828/34144)\n",
      "Epoch 1 Step 1067/1563 Loss: 1.641 | Acc: 40.505% (13843/34176)\n",
      "Epoch 1 Step 1068/1563 Loss: 1.641 | Acc: 40.493% (13852/34208)\n",
      "Epoch 1 Step 1069/1563 Loss: 1.641 | Acc: 40.499% (13867/34240)\n",
      "Epoch 1 Step 1070/1563 Loss: 1.641 | Acc: 40.500% (13880/34272)\n",
      "Epoch 1 Step 1071/1563 Loss: 1.641 | Acc: 40.497% (13892/34304)\n",
      "Epoch 1 Step 1072/1563 Loss: 1.641 | Acc: 40.500% (13906/34336)\n",
      "Epoch 1 Step 1073/1563 Loss: 1.641 | Acc: 40.509% (13922/34368)\n",
      "Epoch 1 Step 1074/1563 Loss: 1.641 | Acc: 40.497% (13931/34400)\n",
      "Epoch 1 Step 1075/1563 Loss: 1.642 | Acc: 40.494% (13943/34432)\n",
      "Epoch 1 Step 1076/1563 Loss: 1.641 | Acc: 40.503% (13959/34464)\n",
      "Epoch 1 Step 1077/1563 Loss: 1.642 | Acc: 40.497% (13970/34496)\n",
      "Epoch 1 Step 1078/1563 Loss: 1.642 | Acc: 40.492% (13981/34528)\n",
      "Epoch 1 Step 1079/1563 Loss: 1.641 | Acc: 40.509% (14000/34560)\n",
      "Epoch 1 Step 1080/1563 Loss: 1.641 | Acc: 40.518% (14016/34592)\n",
      "Epoch 1 Step 1081/1563 Loss: 1.641 | Acc: 40.515% (14028/34624)\n",
      "Epoch 1 Step 1082/1563 Loss: 1.641 | Acc: 40.510% (14039/34656)\n",
      "Epoch 1 Step 1083/1563 Loss: 1.641 | Acc: 40.521% (14056/34688)\n",
      "Epoch 1 Step 1084/1563 Loss: 1.641 | Acc: 40.521% (14069/34720)\n",
      "Epoch 1 Step 1085/1563 Loss: 1.641 | Acc: 40.513% (14079/34752)\n",
      "Epoch 1 Step 1086/1563 Loss: 1.641 | Acc: 40.522% (14095/34784)\n",
      "Epoch 1 Step 1087/1563 Loss: 1.640 | Acc: 40.522% (14108/34816)\n",
      "Epoch 1 Step 1088/1563 Loss: 1.641 | Acc: 40.516% (14119/34848)\n",
      "Epoch 1 Step 1089/1563 Loss: 1.641 | Acc: 40.510% (14130/34880)\n",
      "Epoch 1 Step 1090/1563 Loss: 1.641 | Acc: 40.499% (14139/34912)\n",
      "Epoch 1 Step 1091/1563 Loss: 1.641 | Acc: 40.505% (14154/34944)\n",
      "Epoch 1 Step 1092/1563 Loss: 1.641 | Acc: 40.511% (14169/34976)\n",
      "Epoch 1 Step 1093/1563 Loss: 1.641 | Acc: 40.511% (14182/35008)\n",
      "Epoch 1 Step 1094/1563 Loss: 1.641 | Acc: 40.511% (14195/35040)\n",
      "Epoch 1 Step 1095/1563 Loss: 1.641 | Acc: 40.514% (14209/35072)\n",
      "Epoch 1 Step 1096/1563 Loss: 1.641 | Acc: 40.528% (14227/35104)\n",
      "Epoch 1 Step 1097/1563 Loss: 1.640 | Acc: 40.531% (14241/35136)\n",
      "Epoch 1 Step 1098/1563 Loss: 1.640 | Acc: 40.528% (14253/35168)\n",
      "Epoch 1 Step 1099/1563 Loss: 1.640 | Acc: 40.526% (14265/35200)\n",
      "Epoch 1 Step 1100/1563 Loss: 1.640 | Acc: 40.534% (14281/35232)\n",
      "Epoch 1 Step 1101/1563 Loss: 1.640 | Acc: 40.534% (14294/35264)\n",
      "Epoch 1 Step 1102/1563 Loss: 1.640 | Acc: 40.543% (14310/35296)\n",
      "Epoch 1 Step 1103/1563 Loss: 1.640 | Acc: 40.546% (14324/35328)\n",
      "Epoch 1 Step 1104/1563 Loss: 1.640 | Acc: 40.546% (14337/35360)\n",
      "Epoch 1 Step 1105/1563 Loss: 1.640 | Acc: 40.552% (14352/35392)\n",
      "Epoch 1 Step 1106/1563 Loss: 1.640 | Acc: 40.543% (14362/35424)\n",
      "Epoch 1 Step 1107/1563 Loss: 1.640 | Acc: 40.546% (14376/35456)\n",
      "Epoch 1 Step 1108/1563 Loss: 1.639 | Acc: 40.546% (14389/35488)\n",
      "Epoch 1 Step 1109/1563 Loss: 1.639 | Acc: 40.552% (14404/35520)\n",
      "Epoch 1 Step 1110/1563 Loss: 1.639 | Acc: 40.549% (14416/35552)\n",
      "Epoch 1 Step 1111/1563 Loss: 1.639 | Acc: 40.549% (14429/35584)\n",
      "Epoch 1 Step 1112/1563 Loss: 1.639 | Acc: 40.558% (14445/35616)\n",
      "Epoch 1 Step 1113/1563 Loss: 1.639 | Acc: 40.572% (14463/35648)\n",
      "Epoch 1 Step 1114/1563 Loss: 1.638 | Acc: 40.572% (14476/35680)\n",
      "Epoch 1 Step 1115/1563 Loss: 1.638 | Acc: 40.577% (14491/35712)\n",
      "Epoch 1 Step 1116/1563 Loss: 1.638 | Acc: 40.577% (14504/35744)\n",
      "Epoch 1 Step 1117/1563 Loss: 1.638 | Acc: 40.577% (14517/35776)\n",
      "Epoch 1 Step 1118/1563 Loss: 1.638 | Acc: 40.580% (14531/35808)\n",
      "Epoch 1 Step 1119/1563 Loss: 1.638 | Acc: 40.589% (14547/35840)\n",
      "Epoch 1 Step 1120/1563 Loss: 1.638 | Acc: 40.586% (14559/35872)\n",
      "Epoch 1 Step 1121/1563 Loss: 1.638 | Acc: 40.592% (14574/35904)\n",
      "Epoch 1 Step 1122/1563 Loss: 1.637 | Acc: 40.592% (14587/35936)\n",
      "Epoch 1 Step 1123/1563 Loss: 1.638 | Acc: 40.589% (14599/35968)\n",
      "Epoch 1 Step 1124/1563 Loss: 1.637 | Acc: 40.597% (14615/36000)\n",
      "Epoch 1 Step 1125/1563 Loss: 1.638 | Acc: 40.600% (14629/36032)\n",
      "Epoch 1 Step 1126/1563 Loss: 1.638 | Acc: 40.589% (14638/36064)\n",
      "Epoch 1 Step 1127/1563 Loss: 1.638 | Acc: 40.595% (14653/36096)\n",
      "Epoch 1 Step 1128/1563 Loss: 1.638 | Acc: 40.595% (14666/36128)\n",
      "Epoch 1 Step 1129/1563 Loss: 1.638 | Acc: 40.597% (14680/36160)\n",
      "Epoch 1 Step 1130/1563 Loss: 1.638 | Acc: 40.603% (14695/36192)\n",
      "Epoch 1 Step 1131/1563 Loss: 1.638 | Acc: 40.592% (14704/36224)\n",
      "Epoch 1 Step 1132/1563 Loss: 1.638 | Acc: 40.586% (14715/36256)\n",
      "Epoch 1 Step 1133/1563 Loss: 1.638 | Acc: 40.581% (14726/36288)\n",
      "Epoch 1 Step 1134/1563 Loss: 1.638 | Acc: 40.586% (14741/36320)\n",
      "Epoch 1 Step 1135/1563 Loss: 1.638 | Acc: 40.586% (14754/36352)\n",
      "Epoch 1 Step 1136/1563 Loss: 1.638 | Acc: 40.603% (14773/36384)\n",
      "Epoch 1 Step 1137/1563 Loss: 1.638 | Acc: 40.603% (14786/36416)\n",
      "Epoch 1 Step 1138/1563 Loss: 1.638 | Acc: 40.606% (14800/36448)\n",
      "Epoch 1 Step 1139/1563 Loss: 1.638 | Acc: 40.603% (14812/36480)\n",
      "Epoch 1 Step 1140/1563 Loss: 1.638 | Acc: 40.611% (14828/36512)\n",
      "Epoch 1 Step 1141/1563 Loss: 1.638 | Acc: 40.603% (14838/36544)\n",
      "Epoch 1 Step 1142/1563 Loss: 1.638 | Acc: 40.600% (14850/36576)\n",
      "Epoch 1 Step 1143/1563 Loss: 1.638 | Acc: 40.606% (14865/36608)\n",
      "Epoch 1 Step 1144/1563 Loss: 1.638 | Acc: 40.609% (14879/36640)\n",
      "Epoch 1 Step 1145/1563 Loss: 1.638 | Acc: 40.606% (14891/36672)\n",
      "Epoch 1 Step 1146/1563 Loss: 1.637 | Acc: 40.617% (14908/36704)\n",
      "Epoch 1 Step 1147/1563 Loss: 1.637 | Acc: 40.625% (14924/36736)\n",
      "Epoch 1 Step 1148/1563 Loss: 1.637 | Acc: 40.639% (14942/36768)\n",
      "Epoch 1 Step 1149/1563 Loss: 1.637 | Acc: 40.649% (14959/36800)\n",
      "Epoch 1 Step 1150/1563 Loss: 1.637 | Acc: 40.644% (14970/36832)\n",
      "Epoch 1 Step 1151/1563 Loss: 1.637 | Acc: 40.649% (14985/36864)\n",
      "Epoch 1 Step 1152/1563 Loss: 1.637 | Acc: 40.647% (14997/36896)\n",
      "Epoch 1 Step 1153/1563 Loss: 1.637 | Acc: 40.644% (15009/36928)\n",
      "Epoch 1 Step 1154/1563 Loss: 1.638 | Acc: 40.633% (15018/36960)\n",
      "Epoch 1 Step 1155/1563 Loss: 1.638 | Acc: 40.620% (15026/36992)\n",
      "Epoch 1 Step 1156/1563 Loss: 1.638 | Acc: 40.617% (15038/37024)\n",
      "Epoch 1 Step 1157/1563 Loss: 1.637 | Acc: 40.620% (15052/37056)\n",
      "Epoch 1 Step 1158/1563 Loss: 1.637 | Acc: 40.617% (15064/37088)\n",
      "Epoch 1 Step 1159/1563 Loss: 1.637 | Acc: 40.622% (15079/37120)\n",
      "Epoch 1 Step 1160/1563 Loss: 1.637 | Acc: 40.620% (15091/37152)\n",
      "Epoch 1 Step 1161/1563 Loss: 1.638 | Acc: 40.601% (15097/37184)\n",
      "Epoch 1 Step 1162/1563 Loss: 1.638 | Acc: 40.601% (15110/37216)\n",
      "Epoch 1 Step 1163/1563 Loss: 1.637 | Acc: 40.606% (15125/37248)\n",
      "Epoch 1 Step 1164/1563 Loss: 1.637 | Acc: 40.625% (15145/37280)\n",
      "Epoch 1 Step 1165/1563 Loss: 1.637 | Acc: 40.617% (15155/37312)\n",
      "Epoch 1 Step 1166/1563 Loss: 1.637 | Acc: 40.628% (15172/37344)\n",
      "Epoch 1 Step 1167/1563 Loss: 1.637 | Acc: 40.625% (15184/37376)\n",
      "Epoch 1 Step 1168/1563 Loss: 1.637 | Acc: 40.638% (15202/37408)\n",
      "Epoch 1 Step 1169/1563 Loss: 1.637 | Acc: 40.638% (15215/37440)\n",
      "Epoch 1 Step 1170/1563 Loss: 1.637 | Acc: 40.633% (15226/37472)\n",
      "Epoch 1 Step 1171/1563 Loss: 1.637 | Acc: 40.614% (15232/37504)\n",
      "Epoch 1 Step 1172/1563 Loss: 1.637 | Acc: 40.617% (15246/37536)\n",
      "Epoch 1 Step 1173/1563 Loss: 1.637 | Acc: 40.620% (15260/37568)\n",
      "Epoch 1 Step 1174/1563 Loss: 1.637 | Acc: 40.630% (15277/37600)\n",
      "Epoch 1 Step 1175/1563 Loss: 1.637 | Acc: 40.628% (15289/37632)\n",
      "Epoch 1 Step 1176/1563 Loss: 1.637 | Acc: 40.636% (15305/37664)\n",
      "Epoch 1 Step 1177/1563 Loss: 1.637 | Acc: 40.633% (15317/37696)\n",
      "Epoch 1 Step 1178/1563 Loss: 1.637 | Acc: 40.630% (15329/37728)\n",
      "Epoch 1 Step 1179/1563 Loss: 1.637 | Acc: 40.625% (15340/37760)\n",
      "Epoch 1 Step 1180/1563 Loss: 1.637 | Acc: 40.622% (15352/37792)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1181/1563 Loss: 1.637 | Acc: 40.628% (15367/37824)\n",
      "Epoch 1 Step 1182/1563 Loss: 1.637 | Acc: 40.628% (15380/37856)\n",
      "Epoch 1 Step 1183/1563 Loss: 1.637 | Acc: 40.630% (15394/37888)\n",
      "Epoch 1 Step 1184/1563 Loss: 1.636 | Acc: 40.638% (15410/37920)\n",
      "Epoch 1 Step 1185/1563 Loss: 1.636 | Acc: 40.638% (15423/37952)\n",
      "Epoch 1 Step 1186/1563 Loss: 1.636 | Acc: 40.641% (15437/37984)\n",
      "Epoch 1 Step 1187/1563 Loss: 1.636 | Acc: 40.633% (15447/38016)\n",
      "Epoch 1 Step 1188/1563 Loss: 1.637 | Acc: 40.625% (15457/38048)\n",
      "Epoch 1 Step 1189/1563 Loss: 1.637 | Acc: 40.625% (15470/38080)\n",
      "Epoch 1 Step 1190/1563 Loss: 1.637 | Acc: 40.630% (15485/38112)\n",
      "Epoch 1 Step 1191/1563 Loss: 1.636 | Acc: 40.641% (15502/38144)\n",
      "Epoch 1 Step 1192/1563 Loss: 1.637 | Acc: 40.638% (15514/38176)\n",
      "Epoch 1 Step 1193/1563 Loss: 1.637 | Acc: 40.630% (15524/38208)\n",
      "Epoch 1 Step 1194/1563 Loss: 1.637 | Acc: 40.635% (15539/38240)\n",
      "Epoch 1 Step 1195/1563 Loss: 1.637 | Acc: 40.625% (15548/38272)\n",
      "Epoch 1 Step 1196/1563 Loss: 1.637 | Acc: 40.622% (15560/38304)\n",
      "Epoch 1 Step 1197/1563 Loss: 1.637 | Acc: 40.622% (15573/38336)\n",
      "Epoch 1 Step 1198/1563 Loss: 1.637 | Acc: 40.630% (15589/38368)\n",
      "Epoch 1 Step 1199/1563 Loss: 1.636 | Acc: 40.643% (15607/38400)\n",
      "Epoch 1 Step 1200/1563 Loss: 1.636 | Acc: 40.635% (15617/38432)\n",
      "Epoch 1 Step 1201/1563 Loss: 1.637 | Acc: 40.638% (15631/38464)\n",
      "Epoch 1 Step 1202/1563 Loss: 1.636 | Acc: 40.659% (15652/38496)\n",
      "Epoch 1 Step 1203/1563 Loss: 1.636 | Acc: 40.664% (15667/38528)\n",
      "Epoch 1 Step 1204/1563 Loss: 1.636 | Acc: 40.669% (15682/38560)\n",
      "Epoch 1 Step 1205/1563 Loss: 1.636 | Acc: 40.672% (15696/38592)\n",
      "Epoch 1 Step 1206/1563 Loss: 1.636 | Acc: 40.672% (15709/38624)\n",
      "Epoch 1 Step 1207/1563 Loss: 1.637 | Acc: 40.659% (15717/38656)\n",
      "Epoch 1 Step 1208/1563 Loss: 1.636 | Acc: 40.672% (15735/38688)\n",
      "Epoch 1 Step 1209/1563 Loss: 1.637 | Acc: 40.669% (15747/38720)\n",
      "Epoch 1 Step 1210/1563 Loss: 1.637 | Acc: 40.666% (15759/38752)\n",
      "Epoch 1 Step 1211/1563 Loss: 1.637 | Acc: 40.674% (15775/38784)\n",
      "Epoch 1 Step 1212/1563 Loss: 1.637 | Acc: 40.674% (15788/38816)\n",
      "Epoch 1 Step 1213/1563 Loss: 1.637 | Acc: 40.671% (15800/38848)\n",
      "Epoch 1 Step 1214/1563 Loss: 1.637 | Acc: 40.671% (15813/38880)\n",
      "Epoch 1 Step 1215/1563 Loss: 1.637 | Acc: 40.682% (15830/38912)\n",
      "Epoch 1 Step 1216/1563 Loss: 1.637 | Acc: 40.674% (15840/38944)\n",
      "Epoch 1 Step 1217/1563 Loss: 1.637 | Acc: 40.674% (15853/38976)\n",
      "Epoch 1 Step 1218/1563 Loss: 1.637 | Acc: 40.671% (15865/39008)\n",
      "Epoch 1 Step 1219/1563 Loss: 1.637 | Acc: 40.674% (15879/39040)\n",
      "Epoch 1 Step 1220/1563 Loss: 1.637 | Acc: 40.671% (15891/39072)\n",
      "Epoch 1 Step 1221/1563 Loss: 1.636 | Acc: 40.674% (15905/39104)\n",
      "Epoch 1 Step 1222/1563 Loss: 1.637 | Acc: 40.676% (15919/39136)\n",
      "Epoch 1 Step 1223/1563 Loss: 1.636 | Acc: 40.679% (15933/39168)\n",
      "Epoch 1 Step 1224/1563 Loss: 1.636 | Acc: 40.679% (15946/39200)\n",
      "Epoch 1 Step 1225/1563 Loss: 1.636 | Acc: 40.684% (15961/39232)\n",
      "Epoch 1 Step 1226/1563 Loss: 1.636 | Acc: 40.689% (15976/39264)\n",
      "Epoch 1 Step 1227/1563 Loss: 1.636 | Acc: 40.706% (15996/39296)\n",
      "Epoch 1 Step 1228/1563 Loss: 1.636 | Acc: 40.706% (16009/39328)\n",
      "Epoch 1 Step 1229/1563 Loss: 1.636 | Acc: 40.706% (16022/39360)\n",
      "Epoch 1 Step 1230/1563 Loss: 1.636 | Acc: 40.724% (16042/39392)\n",
      "Epoch 1 Step 1231/1563 Loss: 1.636 | Acc: 40.726% (16056/39424)\n",
      "Epoch 1 Step 1232/1563 Loss: 1.636 | Acc: 40.719% (16066/39456)\n",
      "Epoch 1 Step 1233/1563 Loss: 1.636 | Acc: 40.711% (16076/39488)\n",
      "Epoch 1 Step 1234/1563 Loss: 1.636 | Acc: 40.716% (16091/39520)\n",
      "Epoch 1 Step 1235/1563 Loss: 1.636 | Acc: 40.713% (16103/39552)\n",
      "Epoch 1 Step 1236/1563 Loss: 1.636 | Acc: 40.716% (16117/39584)\n",
      "Epoch 1 Step 1237/1563 Loss: 1.636 | Acc: 40.713% (16129/39616)\n",
      "Epoch 1 Step 1238/1563 Loss: 1.636 | Acc: 40.728% (16148/39648)\n",
      "Epoch 1 Step 1239/1563 Loss: 1.636 | Acc: 40.733% (16163/39680)\n",
      "Epoch 1 Step 1240/1563 Loss: 1.636 | Acc: 40.726% (16173/39712)\n",
      "Epoch 1 Step 1241/1563 Loss: 1.636 | Acc: 40.731% (16188/39744)\n",
      "Epoch 1 Step 1242/1563 Loss: 1.635 | Acc: 40.741% (16205/39776)\n",
      "Epoch 1 Step 1243/1563 Loss: 1.635 | Acc: 40.736% (16216/39808)\n",
      "Epoch 1 Step 1244/1563 Loss: 1.635 | Acc: 40.725% (16225/39840)\n",
      "Epoch 1 Step 1245/1563 Loss: 1.636 | Acc: 40.725% (16238/39872)\n",
      "Epoch 1 Step 1246/1563 Loss: 1.635 | Acc: 40.725% (16251/39904)\n",
      "Epoch 1 Step 1247/1563 Loss: 1.635 | Acc: 40.723% (16263/39936)\n",
      "Epoch 1 Step 1248/1563 Loss: 1.635 | Acc: 40.740% (16283/39968)\n",
      "Epoch 1 Step 1249/1563 Loss: 1.635 | Acc: 40.742% (16297/40000)\n",
      "Epoch 1 Step 1250/1563 Loss: 1.635 | Acc: 40.745% (16311/40032)\n",
      "Epoch 1 Step 1251/1563 Loss: 1.635 | Acc: 40.745% (16324/40064)\n",
      "Epoch 1 Step 1252/1563 Loss: 1.635 | Acc: 40.742% (16336/40096)\n",
      "Epoch 1 Step 1253/1563 Loss: 1.635 | Acc: 40.740% (16348/40128)\n",
      "Epoch 1 Step 1254/1563 Loss: 1.635 | Acc: 40.740% (16361/40160)\n",
      "Epoch 1 Step 1255/1563 Loss: 1.635 | Acc: 40.749% (16378/40192)\n",
      "Epoch 1 Step 1256/1563 Loss: 1.635 | Acc: 40.744% (16389/40224)\n",
      "Epoch 1 Step 1257/1563 Loss: 1.635 | Acc: 40.739% (16400/40256)\n",
      "Epoch 1 Step 1258/1563 Loss: 1.635 | Acc: 40.742% (16414/40288)\n",
      "Epoch 1 Step 1259/1563 Loss: 1.635 | Acc: 40.744% (16428/40320)\n",
      "Epoch 1 Step 1260/1563 Loss: 1.635 | Acc: 40.734% (16437/40352)\n",
      "Epoch 1 Step 1261/1563 Loss: 1.635 | Acc: 40.731% (16449/40384)\n",
      "Epoch 1 Step 1262/1563 Loss: 1.635 | Acc: 40.719% (16457/40416)\n",
      "Epoch 1 Step 1263/1563 Loss: 1.635 | Acc: 40.707% (16465/40448)\n",
      "Epoch 1 Step 1264/1563 Loss: 1.635 | Acc: 40.707% (16478/40480)\n",
      "Epoch 1 Step 1265/1563 Loss: 1.635 | Acc: 40.706% (16491/40512)\n",
      "Epoch 1 Step 1266/1563 Loss: 1.636 | Acc: 40.706% (16504/40544)\n",
      "Epoch 1 Step 1267/1563 Loss: 1.636 | Acc: 40.704% (16516/40576)\n",
      "Epoch 1 Step 1268/1563 Loss: 1.636 | Acc: 40.711% (16532/40608)\n",
      "Epoch 1 Step 1269/1563 Loss: 1.636 | Acc: 40.704% (16542/40640)\n",
      "Epoch 1 Step 1270/1563 Loss: 1.636 | Acc: 40.706% (16556/40672)\n",
      "Epoch 1 Step 1271/1563 Loss: 1.635 | Acc: 40.709% (16570/40704)\n",
      "Epoch 1 Step 1272/1563 Loss: 1.635 | Acc: 40.701% (16580/40736)\n",
      "Epoch 1 Step 1273/1563 Loss: 1.636 | Acc: 40.696% (16591/40768)\n",
      "Epoch 1 Step 1274/1563 Loss: 1.635 | Acc: 40.708% (16609/40800)\n",
      "Epoch 1 Step 1275/1563 Loss: 1.635 | Acc: 40.721% (16627/40832)\n",
      "Epoch 1 Step 1276/1563 Loss: 1.635 | Acc: 40.718% (16639/40864)\n",
      "Epoch 1 Step 1277/1563 Loss: 1.635 | Acc: 40.718% (16652/40896)\n",
      "Epoch 1 Step 1278/1563 Loss: 1.635 | Acc: 40.715% (16664/40928)\n",
      "Epoch 1 Step 1279/1563 Loss: 1.635 | Acc: 40.710% (16675/40960)\n",
      "Epoch 1 Step 1280/1563 Loss: 1.635 | Acc: 40.710% (16688/40992)\n",
      "Epoch 1 Step 1281/1563 Loss: 1.635 | Acc: 40.713% (16702/41024)\n",
      "Epoch 1 Step 1282/1563 Loss: 1.635 | Acc: 40.715% (16716/41056)\n",
      "Epoch 1 Step 1283/1563 Loss: 1.635 | Acc: 40.715% (16729/41088)\n",
      "Epoch 1 Step 1284/1563 Loss: 1.635 | Acc: 40.722% (16745/41120)\n",
      "Epoch 1 Step 1285/1563 Loss: 1.635 | Acc: 40.720% (16757/41152)\n",
      "Epoch 1 Step 1286/1563 Loss: 1.635 | Acc: 40.708% (16765/41184)\n",
      "Epoch 1 Step 1287/1563 Loss: 1.635 | Acc: 40.712% (16780/41216)\n",
      "Epoch 1 Step 1288/1563 Loss: 1.635 | Acc: 40.720% (16796/41248)\n",
      "Epoch 1 Step 1289/1563 Loss: 1.635 | Acc: 40.732% (16814/41280)\n",
      "Epoch 1 Step 1290/1563 Loss: 1.635 | Acc: 40.722% (16823/41312)\n",
      "Epoch 1 Step 1291/1563 Loss: 1.635 | Acc: 40.727% (16838/41344)\n",
      "Epoch 1 Step 1292/1563 Loss: 1.635 | Acc: 40.717% (16847/41376)\n",
      "Epoch 1 Step 1293/1563 Loss: 1.635 | Acc: 40.724% (16863/41408)\n",
      "Epoch 1 Step 1294/1563 Loss: 1.635 | Acc: 40.734% (16880/41440)\n",
      "Epoch 1 Step 1295/1563 Loss: 1.635 | Acc: 40.738% (16895/41472)\n",
      "Epoch 1 Step 1296/1563 Loss: 1.635 | Acc: 40.731% (16905/41504)\n",
      "Epoch 1 Step 1297/1563 Loss: 1.634 | Acc: 40.738% (16921/41536)\n",
      "Epoch 1 Step 1298/1563 Loss: 1.635 | Acc: 40.726% (16929/41568)\n",
      "Epoch 1 Step 1299/1563 Loss: 1.635 | Acc: 40.728% (16943/41600)\n",
      "Epoch 1 Step 1300/1563 Loss: 1.634 | Acc: 40.748% (16964/41632)\n",
      "Epoch 1 Step 1301/1563 Loss: 1.634 | Acc: 40.759% (16982/41664)\n",
      "Epoch 1 Step 1302/1563 Loss: 1.634 | Acc: 40.767% (16998/41696)\n",
      "Epoch 1 Step 1303/1563 Loss: 1.634 | Acc: 40.774% (17014/41728)\n",
      "Epoch 1 Step 1304/1563 Loss: 1.634 | Acc: 40.773% (17027/41760)\n",
      "Epoch 1 Step 1305/1563 Loss: 1.634 | Acc: 40.766% (17037/41792)\n",
      "Epoch 1 Step 1306/1563 Loss: 1.634 | Acc: 40.766% (17050/41824)\n",
      "Epoch 1 Step 1307/1563 Loss: 1.634 | Acc: 40.768% (17064/41856)\n",
      "Epoch 1 Step 1308/1563 Loss: 1.634 | Acc: 40.771% (17078/41888)\n",
      "Epoch 1 Step 1309/1563 Loss: 1.634 | Acc: 40.771% (17091/41920)\n",
      "Epoch 1 Step 1310/1563 Loss: 1.634 | Acc: 40.773% (17105/41952)\n",
      "Epoch 1 Step 1311/1563 Loss: 1.634 | Acc: 40.775% (17119/41984)\n",
      "Epoch 1 Step 1312/1563 Loss: 1.633 | Acc: 40.777% (17133/42016)\n",
      "Epoch 1 Step 1313/1563 Loss: 1.634 | Acc: 40.770% (17143/42048)\n",
      "Epoch 1 Step 1314/1563 Loss: 1.634 | Acc: 40.768% (17155/42080)\n",
      "Epoch 1 Step 1315/1563 Loss: 1.634 | Acc: 40.756% (17163/42112)\n",
      "Epoch 1 Step 1316/1563 Loss: 1.634 | Acc: 40.753% (17175/42144)\n",
      "Epoch 1 Step 1317/1563 Loss: 1.634 | Acc: 40.758% (17190/42176)\n",
      "Epoch 1 Step 1318/1563 Loss: 1.634 | Acc: 40.767% (17207/42208)\n",
      "Epoch 1 Step 1319/1563 Loss: 1.634 | Acc: 40.762% (17218/42240)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1320/1563 Loss: 1.634 | Acc: 40.769% (17234/42272)\n",
      "Epoch 1 Step 1321/1563 Loss: 1.633 | Acc: 40.776% (17250/42304)\n",
      "Epoch 1 Step 1322/1563 Loss: 1.633 | Acc: 40.779% (17264/42336)\n",
      "Epoch 1 Step 1323/1563 Loss: 1.633 | Acc: 40.776% (17276/42368)\n",
      "Epoch 1 Step 1324/1563 Loss: 1.633 | Acc: 40.781% (17291/42400)\n",
      "Epoch 1 Step 1325/1563 Loss: 1.633 | Acc: 40.783% (17305/42432)\n",
      "Epoch 1 Step 1326/1563 Loss: 1.633 | Acc: 40.787% (17320/42464)\n",
      "Epoch 1 Step 1327/1563 Loss: 1.633 | Acc: 40.780% (17330/42496)\n",
      "Epoch 1 Step 1328/1563 Loss: 1.633 | Acc: 40.775% (17341/42528)\n",
      "Epoch 1 Step 1329/1563 Loss: 1.633 | Acc: 40.785% (17358/42560)\n",
      "Epoch 1 Step 1330/1563 Loss: 1.633 | Acc: 40.785% (17371/42592)\n",
      "Epoch 1 Step 1331/1563 Loss: 1.633 | Acc: 40.777% (17381/42624)\n",
      "Epoch 1 Step 1332/1563 Loss: 1.633 | Acc: 40.780% (17395/42656)\n",
      "Epoch 1 Step 1333/1563 Loss: 1.633 | Acc: 40.780% (17408/42688)\n",
      "Epoch 1 Step 1334/1563 Loss: 1.633 | Acc: 40.791% (17426/42720)\n",
      "Epoch 1 Step 1335/1563 Loss: 1.633 | Acc: 40.784% (17436/42752)\n",
      "Epoch 1 Step 1336/1563 Loss: 1.633 | Acc: 40.782% (17448/42784)\n",
      "Epoch 1 Step 1337/1563 Loss: 1.633 | Acc: 40.781% (17461/42816)\n",
      "Epoch 1 Step 1338/1563 Loss: 1.632 | Acc: 40.795% (17480/42848)\n",
      "Epoch 1 Step 1339/1563 Loss: 1.633 | Acc: 40.788% (17490/42880)\n",
      "Epoch 1 Step 1340/1563 Loss: 1.633 | Acc: 40.786% (17502/42912)\n",
      "Epoch 1 Step 1341/1563 Loss: 1.633 | Acc: 40.786% (17515/42944)\n",
      "Epoch 1 Step 1342/1563 Loss: 1.633 | Acc: 40.793% (17531/42976)\n",
      "Epoch 1 Step 1343/1563 Loss: 1.633 | Acc: 40.788% (17542/43008)\n",
      "Epoch 1 Step 1344/1563 Loss: 1.633 | Acc: 40.788% (17555/43040)\n",
      "Epoch 1 Step 1345/1563 Loss: 1.632 | Acc: 40.797% (17572/43072)\n",
      "Epoch 1 Step 1346/1563 Loss: 1.632 | Acc: 40.794% (17584/43104)\n",
      "Epoch 1 Step 1347/1563 Loss: 1.632 | Acc: 40.790% (17595/43136)\n",
      "Epoch 1 Step 1348/1563 Loss: 1.632 | Acc: 40.792% (17609/43168)\n",
      "Epoch 1 Step 1349/1563 Loss: 1.632 | Acc: 40.785% (17619/43200)\n",
      "Epoch 1 Step 1350/1563 Loss: 1.632 | Acc: 40.792% (17635/43232)\n",
      "Epoch 1 Step 1351/1563 Loss: 1.632 | Acc: 40.784% (17645/43264)\n",
      "Epoch 1 Step 1352/1563 Loss: 1.632 | Acc: 40.780% (17656/43296)\n",
      "Epoch 1 Step 1353/1563 Loss: 1.632 | Acc: 40.780% (17669/43328)\n",
      "Epoch 1 Step 1354/1563 Loss: 1.632 | Acc: 40.784% (17684/43360)\n",
      "Epoch 1 Step 1355/1563 Loss: 1.632 | Acc: 40.782% (17696/43392)\n",
      "Epoch 1 Step 1356/1563 Loss: 1.632 | Acc: 40.784% (17710/43424)\n",
      "Epoch 1 Step 1357/1563 Loss: 1.632 | Acc: 40.775% (17719/43456)\n",
      "Epoch 1 Step 1358/1563 Loss: 1.632 | Acc: 40.770% (17730/43488)\n",
      "Epoch 1 Step 1359/1563 Loss: 1.632 | Acc: 40.770% (17743/43520)\n",
      "Epoch 1 Step 1360/1563 Loss: 1.632 | Acc: 40.770% (17756/43552)\n",
      "Epoch 1 Step 1361/1563 Loss: 1.632 | Acc: 40.772% (17770/43584)\n",
      "Epoch 1 Step 1362/1563 Loss: 1.632 | Acc: 40.783% (17788/43616)\n",
      "Epoch 1 Step 1363/1563 Loss: 1.632 | Acc: 40.785% (17802/43648)\n",
      "Epoch 1 Step 1364/1563 Loss: 1.631 | Acc: 40.799% (17821/43680)\n",
      "Epoch 1 Step 1365/1563 Loss: 1.632 | Acc: 40.806% (17837/43712)\n",
      "Epoch 1 Step 1366/1563 Loss: 1.632 | Acc: 40.803% (17849/43744)\n",
      "Epoch 1 Step 1367/1563 Loss: 1.631 | Acc: 40.812% (17866/43776)\n",
      "Epoch 1 Step 1368/1563 Loss: 1.631 | Acc: 40.817% (17881/43808)\n",
      "Epoch 1 Step 1369/1563 Loss: 1.632 | Acc: 40.812% (17892/43840)\n",
      "Epoch 1 Step 1370/1563 Loss: 1.632 | Acc: 40.807% (17903/43872)\n",
      "Epoch 1 Step 1371/1563 Loss: 1.632 | Acc: 40.814% (17919/43904)\n",
      "Epoch 1 Step 1372/1563 Loss: 1.631 | Acc: 40.818% (17934/43936)\n",
      "Epoch 1 Step 1373/1563 Loss: 1.631 | Acc: 40.825% (17950/43968)\n",
      "Epoch 1 Step 1374/1563 Loss: 1.631 | Acc: 40.825% (17963/44000)\n",
      "Epoch 1 Step 1375/1563 Loss: 1.631 | Acc: 40.827% (17977/44032)\n",
      "Epoch 1 Step 1376/1563 Loss: 1.631 | Acc: 40.832% (17992/44064)\n",
      "Epoch 1 Step 1377/1563 Loss: 1.632 | Acc: 40.822% (18001/44096)\n",
      "Epoch 1 Step 1378/1563 Loss: 1.631 | Acc: 40.820% (18013/44128)\n",
      "Epoch 1 Step 1379/1563 Loss: 1.631 | Acc: 40.833% (18032/44160)\n",
      "Epoch 1 Step 1380/1563 Loss: 1.631 | Acc: 40.835% (18046/44192)\n",
      "Epoch 1 Step 1381/1563 Loss: 1.631 | Acc: 40.826% (18055/44224)\n",
      "Epoch 1 Step 1382/1563 Loss: 1.631 | Acc: 40.824% (18067/44256)\n",
      "Epoch 1 Step 1383/1563 Loss: 1.631 | Acc: 40.812% (18075/44288)\n",
      "Epoch 1 Step 1384/1563 Loss: 1.631 | Acc: 40.812% (18088/44320)\n",
      "Epoch 1 Step 1385/1563 Loss: 1.631 | Acc: 40.812% (18101/44352)\n",
      "Epoch 1 Step 1386/1563 Loss: 1.631 | Acc: 40.821% (18118/44384)\n",
      "Epoch 1 Step 1387/1563 Loss: 1.631 | Acc: 40.823% (18132/44416)\n",
      "Epoch 1 Step 1388/1563 Loss: 1.631 | Acc: 40.823% (18145/44448)\n",
      "Epoch 1 Step 1389/1563 Loss: 1.631 | Acc: 40.827% (18160/44480)\n",
      "Epoch 1 Step 1390/1563 Loss: 1.631 | Acc: 40.832% (18175/44512)\n",
      "Epoch 1 Step 1391/1563 Loss: 1.631 | Acc: 40.829% (18187/44544)\n",
      "Epoch 1 Step 1392/1563 Loss: 1.631 | Acc: 40.822% (18197/44576)\n",
      "Epoch 1 Step 1393/1563 Loss: 1.630 | Acc: 40.825% (18211/44608)\n",
      "Epoch 1 Step 1394/1563 Loss: 1.630 | Acc: 40.824% (18224/44640)\n",
      "Epoch 1 Step 1395/1563 Loss: 1.630 | Acc: 40.831% (18240/44672)\n",
      "Epoch 1 Step 1396/1563 Loss: 1.630 | Acc: 40.826% (18251/44704)\n",
      "Epoch 1 Step 1397/1563 Loss: 1.630 | Acc: 40.819% (18261/44736)\n",
      "Epoch 1 Step 1398/1563 Loss: 1.631 | Acc: 40.822% (18275/44768)\n",
      "Epoch 1 Step 1399/1563 Loss: 1.631 | Acc: 40.821% (18288/44800)\n",
      "Epoch 1 Step 1400/1563 Loss: 1.631 | Acc: 40.828% (18304/44832)\n",
      "Epoch 1 Step 1401/1563 Loss: 1.631 | Acc: 40.821% (18314/44864)\n",
      "Epoch 1 Step 1402/1563 Loss: 1.631 | Acc: 40.823% (18328/44896)\n",
      "Epoch 1 Step 1403/1563 Loss: 1.631 | Acc: 40.830% (18344/44928)\n",
      "Epoch 1 Step 1404/1563 Loss: 1.631 | Acc: 40.827% (18356/44960)\n",
      "Epoch 1 Step 1405/1563 Loss: 1.631 | Acc: 40.825% (18368/44992)\n",
      "Epoch 1 Step 1406/1563 Loss: 1.630 | Acc: 40.832% (18384/45024)\n",
      "Epoch 1 Step 1407/1563 Loss: 1.630 | Acc: 40.825% (18394/45056)\n",
      "Epoch 1 Step 1408/1563 Loss: 1.631 | Acc: 40.811% (18401/45088)\n",
      "Epoch 1 Step 1409/1563 Loss: 1.631 | Acc: 40.813% (18415/45120)\n",
      "Epoch 1 Step 1410/1563 Loss: 1.631 | Acc: 40.820% (18431/45152)\n",
      "Epoch 1 Step 1411/1563 Loss: 1.631 | Acc: 40.824% (18446/45184)\n",
      "Epoch 1 Step 1412/1563 Loss: 1.630 | Acc: 40.835% (18464/45216)\n",
      "Epoch 1 Step 1413/1563 Loss: 1.630 | Acc: 40.844% (18481/45248)\n",
      "Epoch 1 Step 1414/1563 Loss: 1.630 | Acc: 40.844% (18494/45280)\n",
      "Epoch 1 Step 1415/1563 Loss: 1.631 | Acc: 40.839% (18505/45312)\n",
      "Epoch 1 Step 1416/1563 Loss: 1.631 | Acc: 40.837% (18517/45344)\n",
      "Epoch 1 Step 1417/1563 Loss: 1.631 | Acc: 40.848% (18535/45376)\n",
      "Epoch 1 Step 1418/1563 Loss: 1.630 | Acc: 40.845% (18547/45408)\n",
      "Epoch 1 Step 1419/1563 Loss: 1.630 | Acc: 40.854% (18564/45440)\n",
      "Epoch 1 Step 1420/1563 Loss: 1.630 | Acc: 40.849% (18575/45472)\n",
      "Epoch 1 Step 1421/1563 Loss: 1.630 | Acc: 40.856% (18591/45504)\n",
      "Epoch 1 Step 1422/1563 Loss: 1.630 | Acc: 40.862% (18607/45536)\n",
      "Epoch 1 Step 1423/1563 Loss: 1.630 | Acc: 40.877% (18627/45568)\n",
      "Epoch 1 Step 1424/1563 Loss: 1.630 | Acc: 40.888% (18645/45600)\n",
      "Epoch 1 Step 1425/1563 Loss: 1.630 | Acc: 40.890% (18659/45632)\n",
      "Epoch 1 Step 1426/1563 Loss: 1.630 | Acc: 40.890% (18672/45664)\n",
      "Epoch 1 Step 1427/1563 Loss: 1.630 | Acc: 40.888% (18684/45696)\n",
      "Epoch 1 Step 1428/1563 Loss: 1.630 | Acc: 40.885% (18696/45728)\n",
      "Epoch 1 Step 1429/1563 Loss: 1.630 | Acc: 40.889% (18711/45760)\n",
      "Epoch 1 Step 1430/1563 Loss: 1.630 | Acc: 40.874% (18717/45792)\n",
      "Epoch 1 Step 1431/1563 Loss: 1.630 | Acc: 40.869% (18728/45824)\n",
      "Epoch 1 Step 1432/1563 Loss: 1.630 | Acc: 40.878% (18745/45856)\n",
      "Epoch 1 Step 1433/1563 Loss: 1.630 | Acc: 40.880% (18759/45888)\n",
      "Epoch 1 Step 1434/1563 Loss: 1.630 | Acc: 40.875% (18770/45920)\n",
      "Epoch 1 Step 1435/1563 Loss: 1.630 | Acc: 40.882% (18786/45952)\n",
      "Epoch 1 Step 1436/1563 Loss: 1.630 | Acc: 40.884% (18800/45984)\n",
      "Epoch 1 Step 1437/1563 Loss: 1.630 | Acc: 40.886% (18814/46016)\n",
      "Epoch 1 Step 1438/1563 Loss: 1.630 | Acc: 40.896% (18832/46048)\n",
      "Epoch 1 Step 1439/1563 Loss: 1.630 | Acc: 40.907% (18850/46080)\n",
      "Epoch 1 Step 1440/1563 Loss: 1.630 | Acc: 40.903% (18861/46112)\n",
      "Epoch 1 Step 1441/1563 Loss: 1.630 | Acc: 40.907% (18876/46144)\n",
      "Epoch 1 Step 1442/1563 Loss: 1.630 | Acc: 40.913% (18892/46176)\n",
      "Epoch 1 Step 1443/1563 Loss: 1.630 | Acc: 40.915% (18906/46208)\n",
      "Epoch 1 Step 1444/1563 Loss: 1.630 | Acc: 40.917% (18920/46240)\n",
      "Epoch 1 Step 1445/1563 Loss: 1.629 | Acc: 40.928% (18938/46272)\n",
      "Epoch 1 Step 1446/1563 Loss: 1.629 | Acc: 40.932% (18953/46304)\n",
      "Epoch 1 Step 1447/1563 Loss: 1.629 | Acc: 40.936% (18968/46336)\n",
      "Epoch 1 Step 1448/1563 Loss: 1.629 | Acc: 40.931% (18979/46368)\n",
      "Epoch 1 Step 1449/1563 Loss: 1.629 | Acc: 40.927% (18990/46400)\n",
      "Epoch 1 Step 1450/1563 Loss: 1.629 | Acc: 40.924% (19002/46432)\n",
      "Epoch 1 Step 1451/1563 Loss: 1.629 | Acc: 40.922% (19014/46464)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 1452/1563 Loss: 1.629 | Acc: 40.922% (19027/46496)\n",
      "Epoch 1 Step 1453/1563 Loss: 1.629 | Acc: 40.922% (19040/46528)\n",
      "Epoch 1 Step 1454/1563 Loss: 1.629 | Acc: 40.926% (19055/46560)\n",
      "Epoch 1 Step 1455/1563 Loss: 1.629 | Acc: 40.923% (19067/46592)\n",
      "Epoch 1 Step 1456/1563 Loss: 1.629 | Acc: 40.917% (19077/46624)\n",
      "Epoch 1 Step 1457/1563 Loss: 1.629 | Acc: 40.916% (19090/46656)\n",
      "Epoch 1 Step 1458/1563 Loss: 1.629 | Acc: 40.925% (19107/46688)\n",
      "Epoch 1 Step 1459/1563 Loss: 1.629 | Acc: 40.929% (19122/46720)\n",
      "Epoch 1 Step 1460/1563 Loss: 1.629 | Acc: 40.922% (19132/46752)\n",
      "Epoch 1 Step 1461/1563 Loss: 1.629 | Acc: 40.914% (19141/46784)\n",
      "Epoch 1 Step 1462/1563 Loss: 1.629 | Acc: 40.911% (19153/46816)\n",
      "Epoch 1 Step 1463/1563 Loss: 1.629 | Acc: 40.907% (19164/46848)\n",
      "Epoch 1 Step 1464/1563 Loss: 1.629 | Acc: 40.900% (19174/46880)\n",
      "Epoch 1 Step 1465/1563 Loss: 1.629 | Acc: 40.906% (19190/46912)\n",
      "Epoch 1 Step 1466/1563 Loss: 1.629 | Acc: 40.904% (19202/46944)\n",
      "Epoch 1 Step 1467/1563 Loss: 1.629 | Acc: 40.915% (19220/46976)\n",
      "Epoch 1 Step 1468/1563 Loss: 1.629 | Acc: 40.912% (19232/47008)\n",
      "Epoch 1 Step 1469/1563 Loss: 1.629 | Acc: 40.914% (19246/47040)\n",
      "Epoch 1 Step 1470/1563 Loss: 1.629 | Acc: 40.918% (19261/47072)\n",
      "Epoch 1 Step 1471/1563 Loss: 1.629 | Acc: 40.920% (19275/47104)\n",
      "Epoch 1 Step 1472/1563 Loss: 1.629 | Acc: 40.916% (19286/47136)\n",
      "Epoch 1 Step 1473/1563 Loss: 1.629 | Acc: 40.920% (19301/47168)\n",
      "Epoch 1 Step 1474/1563 Loss: 1.629 | Acc: 40.922% (19315/47200)\n",
      "Epoch 1 Step 1475/1563 Loss: 1.629 | Acc: 40.932% (19333/47232)\n",
      "Epoch 1 Step 1476/1563 Loss: 1.629 | Acc: 40.947% (19353/47264)\n",
      "Epoch 1 Step 1477/1563 Loss: 1.629 | Acc: 40.944% (19365/47296)\n",
      "Epoch 1 Step 1478/1563 Loss: 1.629 | Acc: 40.946% (19379/47328)\n",
      "Epoch 1 Step 1479/1563 Loss: 1.629 | Acc: 40.952% (19395/47360)\n",
      "Epoch 1 Step 1480/1563 Loss: 1.629 | Acc: 40.948% (19406/47392)\n",
      "Epoch 1 Step 1481/1563 Loss: 1.629 | Acc: 40.946% (19418/47424)\n",
      "Epoch 1 Step 1482/1563 Loss: 1.628 | Acc: 40.958% (19437/47456)\n",
      "Epoch 1 Step 1483/1563 Loss: 1.629 | Acc: 40.951% (19447/47488)\n",
      "Epoch 1 Step 1484/1563 Loss: 1.628 | Acc: 40.953% (19461/47520)\n",
      "Epoch 1 Step 1485/1563 Loss: 1.628 | Acc: 40.959% (19477/47552)\n",
      "Epoch 1 Step 1486/1563 Loss: 1.628 | Acc: 40.961% (19491/47584)\n",
      "Epoch 1 Step 1487/1563 Loss: 1.628 | Acc: 40.972% (19509/47616)\n",
      "Epoch 1 Step 1488/1563 Loss: 1.628 | Acc: 40.988% (19530/47648)\n",
      "Epoch 1 Step 1489/1563 Loss: 1.627 | Acc: 41.003% (19550/47680)\n",
      "Epoch 1 Step 1490/1563 Loss: 1.627 | Acc: 41.011% (19567/47712)\n",
      "Epoch 1 Step 1491/1563 Loss: 1.627 | Acc: 41.015% (19582/47744)\n",
      "Epoch 1 Step 1492/1563 Loss: 1.627 | Acc: 41.021% (19598/47776)\n",
      "Epoch 1 Step 1493/1563 Loss: 1.627 | Acc: 41.018% (19610/47808)\n",
      "Epoch 1 Step 1494/1563 Loss: 1.627 | Acc: 41.020% (19624/47840)\n",
      "Epoch 1 Step 1495/1563 Loss: 1.627 | Acc: 41.028% (19641/47872)\n",
      "Epoch 1 Step 1496/1563 Loss: 1.627 | Acc: 41.032% (19656/47904)\n",
      "Epoch 1 Step 1497/1563 Loss: 1.627 | Acc: 41.057% (19681/47936)\n",
      "Epoch 1 Step 1498/1563 Loss: 1.627 | Acc: 41.057% (19694/47968)\n",
      "Epoch 1 Step 1499/1563 Loss: 1.627 | Acc: 41.054% (19706/48000)\n",
      "Epoch 1 Step 1500/1563 Loss: 1.627 | Acc: 41.054% (19719/48032)\n",
      "Epoch 1 Step 1501/1563 Loss: 1.627 | Acc: 41.060% (19735/48064)\n",
      "Epoch 1 Step 1502/1563 Loss: 1.626 | Acc: 41.076% (19756/48096)\n",
      "Epoch 1 Step 1503/1563 Loss: 1.627 | Acc: 41.072% (19767/48128)\n",
      "Epoch 1 Step 1504/1563 Loss: 1.626 | Acc: 41.071% (19780/48160)\n",
      "Epoch 1 Step 1505/1563 Loss: 1.626 | Acc: 41.071% (19793/48192)\n",
      "Epoch 1 Step 1506/1563 Loss: 1.626 | Acc: 41.079% (19810/48224)\n",
      "Epoch 1 Step 1507/1563 Loss: 1.626 | Acc: 41.077% (19822/48256)\n",
      "Epoch 1 Step 1508/1563 Loss: 1.626 | Acc: 41.072% (19833/48288)\n",
      "Epoch 1 Step 1509/1563 Loss: 1.626 | Acc: 41.080% (19850/48320)\n",
      "Epoch 1 Step 1510/1563 Loss: 1.626 | Acc: 41.078% (19862/48352)\n",
      "Epoch 1 Step 1511/1563 Loss: 1.626 | Acc: 41.071% (19872/48384)\n",
      "Epoch 1 Step 1512/1563 Loss: 1.626 | Acc: 41.069% (19884/48416)\n",
      "Epoch 1 Step 1513/1563 Loss: 1.626 | Acc: 41.071% (19898/48448)\n",
      "Epoch 1 Step 1514/1563 Loss: 1.626 | Acc: 41.071% (19911/48480)\n",
      "Epoch 1 Step 1515/1563 Loss: 1.626 | Acc: 41.062% (19920/48512)\n",
      "Epoch 1 Step 1516/1563 Loss: 1.626 | Acc: 41.058% (19931/48544)\n",
      "Epoch 1 Step 1517/1563 Loss: 1.626 | Acc: 41.066% (19948/48576)\n",
      "Epoch 1 Step 1518/1563 Loss: 1.626 | Acc: 41.063% (19960/48608)\n",
      "Epoch 1 Step 1519/1563 Loss: 1.626 | Acc: 41.063% (19973/48640)\n",
      "Epoch 1 Step 1520/1563 Loss: 1.626 | Acc: 41.075% (19992/48672)\n",
      "Epoch 1 Step 1521/1563 Loss: 1.626 | Acc: 41.089% (20012/48704)\n",
      "Epoch 1 Step 1522/1563 Loss: 1.626 | Acc: 41.093% (20027/48736)\n",
      "Epoch 1 Step 1523/1563 Loss: 1.626 | Acc: 41.084% (20036/48768)\n",
      "Epoch 1 Step 1524/1563 Loss: 1.626 | Acc: 41.080% (20047/48800)\n",
      "Epoch 1 Step 1525/1563 Loss: 1.626 | Acc: 41.082% (20061/48832)\n",
      "Epoch 1 Step 1526/1563 Loss: 1.625 | Acc: 41.088% (20077/48864)\n",
      "Epoch 1 Step 1527/1563 Loss: 1.625 | Acc: 41.083% (20088/48896)\n",
      "Epoch 1 Step 1528/1563 Loss: 1.625 | Acc: 41.089% (20104/48928)\n",
      "Epoch 1 Step 1529/1563 Loss: 1.625 | Acc: 41.089% (20117/48960)\n",
      "Epoch 1 Step 1530/1563 Loss: 1.625 | Acc: 41.088% (20130/48992)\n",
      "Epoch 1 Step 1531/1563 Loss: 1.625 | Acc: 41.082% (20140/49024)\n",
      "Epoch 1 Step 1532/1563 Loss: 1.625 | Acc: 41.084% (20154/49056)\n",
      "Epoch 1 Step 1533/1563 Loss: 1.625 | Acc: 41.079% (20165/49088)\n",
      "Epoch 1 Step 1534/1563 Loss: 1.625 | Acc: 41.083% (20180/49120)\n",
      "Epoch 1 Step 1535/1563 Loss: 1.625 | Acc: 41.089% (20196/49152)\n",
      "Epoch 1 Step 1536/1563 Loss: 1.625 | Acc: 41.089% (20209/49184)\n",
      "Epoch 1 Step 1537/1563 Loss: 1.625 | Acc: 41.098% (20227/49216)\n",
      "Epoch 1 Step 1538/1563 Loss: 1.625 | Acc: 41.090% (20236/49248)\n",
      "Epoch 1 Step 1539/1563 Loss: 1.625 | Acc: 41.092% (20250/49280)\n",
      "Epoch 1 Step 1540/1563 Loss: 1.625 | Acc: 41.093% (20264/49312)\n",
      "Epoch 1 Step 1541/1563 Loss: 1.625 | Acc: 41.099% (20280/49344)\n",
      "Epoch 1 Step 1542/1563 Loss: 1.625 | Acc: 41.091% (20289/49376)\n",
      "Epoch 1 Step 1543/1563 Loss: 1.625 | Acc: 41.088% (20301/49408)\n",
      "Epoch 1 Step 1544/1563 Loss: 1.625 | Acc: 41.092% (20316/49440)\n",
      "Epoch 1 Step 1545/1563 Loss: 1.624 | Acc: 41.096% (20331/49472)\n",
      "Epoch 1 Step 1546/1563 Loss: 1.624 | Acc: 41.098% (20345/49504)\n",
      "Epoch 1 Step 1547/1563 Loss: 1.624 | Acc: 41.093% (20356/49536)\n",
      "Epoch 1 Step 1548/1563 Loss: 1.624 | Acc: 41.103% (20374/49568)\n",
      "Epoch 1 Step 1549/1563 Loss: 1.624 | Acc: 41.113% (20392/49600)\n",
      "Epoch 1 Step 1550/1563 Loss: 1.624 | Acc: 41.121% (20409/49632)\n",
      "Epoch 1 Step 1551/1563 Loss: 1.624 | Acc: 41.116% (20420/49664)\n",
      "Epoch 1 Step 1552/1563 Loss: 1.624 | Acc: 41.118% (20434/49696)\n",
      "Epoch 1 Step 1553/1563 Loss: 1.624 | Acc: 41.122% (20449/49728)\n",
      "Epoch 1 Step 1554/1563 Loss: 1.624 | Acc: 41.113% (20458/49760)\n",
      "Epoch 1 Step 1555/1563 Loss: 1.624 | Acc: 41.111% (20470/49792)\n",
      "Epoch 1 Step 1556/1563 Loss: 1.624 | Acc: 41.109% (20482/49824)\n",
      "Epoch 1 Step 1557/1563 Loss: 1.625 | Acc: 41.106% (20494/49856)\n",
      "Epoch 1 Step 1558/1563 Loss: 1.624 | Acc: 41.106% (20507/49888)\n",
      "Epoch 1 Step 1559/1563 Loss: 1.624 | Acc: 41.114% (20524/49920)\n",
      "Epoch 1 Step 1560/1563 Loss: 1.624 | Acc: 41.111% (20536/49952)\n",
      "Epoch 1 Step 1561/1563 Loss: 1.624 | Acc: 41.111% (20549/49984)\n",
      "Epoch 1 Step 1562/1563 Loss: 1.624 | Acc: 41.114% (20557/50000)\n",
      "Epoch 1 Step 0/313 Test Loss: 1.398 | Test Acc: 40.625% (13/32)\n",
      "Epoch 1 Step 1/313 Test Loss: 1.540 | Test Acc: 37.500% (24/64)\n",
      "Epoch 1 Step 2/313 Test Loss: 1.561 | Test Acc: 40.625% (39/96)\n",
      "Epoch 1 Step 3/313 Test Loss: 1.496 | Test Acc: 43.750% (56/128)\n",
      "Epoch 1 Step 4/313 Test Loss: 1.501 | Test Acc: 42.500% (68/160)\n",
      "Epoch 1 Step 5/313 Test Loss: 1.505 | Test Acc: 42.188% (81/192)\n",
      "Epoch 1 Step 6/313 Test Loss: 1.553 | Test Acc: 41.071% (92/224)\n",
      "Epoch 1 Step 7/313 Test Loss: 1.562 | Test Acc: 41.016% (105/256)\n",
      "Epoch 1 Step 8/313 Test Loss: 1.564 | Test Acc: 41.319% (119/288)\n",
      "Epoch 1 Step 9/313 Test Loss: 1.540 | Test Acc: 41.875% (134/320)\n",
      "Epoch 1 Step 10/313 Test Loss: 1.535 | Test Acc: 41.761% (147/352)\n",
      "Epoch 1 Step 11/313 Test Loss: 1.563 | Test Acc: 41.146% (158/384)\n",
      "Epoch 1 Step 12/313 Test Loss: 1.552 | Test Acc: 41.346% (172/416)\n",
      "Epoch 1 Step 13/313 Test Loss: 1.576 | Test Acc: 40.848% (183/448)\n",
      "Epoch 1 Step 14/313 Test Loss: 1.579 | Test Acc: 40.208% (193/480)\n",
      "Epoch 1 Step 15/313 Test Loss: 1.570 | Test Acc: 40.625% (208/512)\n",
      "Epoch 1 Step 16/313 Test Loss: 1.565 | Test Acc: 40.441% (220/544)\n",
      "Epoch 1 Step 17/313 Test Loss: 1.560 | Test Acc: 41.146% (237/576)\n",
      "Epoch 1 Step 18/313 Test Loss: 1.555 | Test Acc: 41.612% (253/608)\n",
      "Epoch 1 Step 19/313 Test Loss: 1.535 | Test Acc: 42.656% (273/640)\n",
      "Epoch 1 Step 20/313 Test Loss: 1.526 | Test Acc: 43.006% (289/672)\n",
      "Epoch 1 Step 21/313 Test Loss: 1.541 | Test Acc: 41.903% (295/704)\n",
      "Epoch 1 Step 22/313 Test Loss: 1.535 | Test Acc: 42.391% (312/736)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 23/313 Test Loss: 1.536 | Test Acc: 42.578% (327/768)\n",
      "Epoch 1 Step 24/313 Test Loss: 1.536 | Test Acc: 42.500% (340/800)\n",
      "Epoch 1 Step 25/313 Test Loss: 1.535 | Test Acc: 42.909% (357/832)\n",
      "Epoch 1 Step 26/313 Test Loss: 1.535 | Test Acc: 43.287% (374/864)\n",
      "Epoch 1 Step 27/313 Test Loss: 1.524 | Test Acc: 43.862% (393/896)\n",
      "Epoch 1 Step 28/313 Test Loss: 1.522 | Test Acc: 44.073% (409/928)\n",
      "Epoch 1 Step 29/313 Test Loss: 1.510 | Test Acc: 44.583% (428/960)\n",
      "Epoch 1 Step 30/313 Test Loss: 1.503 | Test Acc: 44.859% (445/992)\n",
      "Epoch 1 Step 31/313 Test Loss: 1.489 | Test Acc: 45.703% (468/1024)\n",
      "Epoch 1 Step 32/313 Test Loss: 1.498 | Test Acc: 45.644% (482/1056)\n",
      "Epoch 1 Step 33/313 Test Loss: 1.494 | Test Acc: 45.864% (499/1088)\n",
      "Epoch 1 Step 34/313 Test Loss: 1.486 | Test Acc: 46.429% (520/1120)\n",
      "Epoch 1 Step 35/313 Test Loss: 1.488 | Test Acc: 46.181% (532/1152)\n",
      "Epoch 1 Step 36/313 Test Loss: 1.487 | Test Acc: 46.199% (547/1184)\n",
      "Epoch 1 Step 37/313 Test Loss: 1.488 | Test Acc: 46.382% (564/1216)\n",
      "Epoch 1 Step 38/313 Test Loss: 1.495 | Test Acc: 46.154% (576/1248)\n",
      "Epoch 1 Step 39/313 Test Loss: 1.498 | Test Acc: 46.094% (590/1280)\n",
      "Epoch 1 Step 40/313 Test Loss: 1.503 | Test Acc: 45.503% (597/1312)\n",
      "Epoch 1 Step 41/313 Test Loss: 1.506 | Test Acc: 45.387% (610/1344)\n",
      "Epoch 1 Step 42/313 Test Loss: 1.498 | Test Acc: 45.494% (626/1376)\n",
      "Epoch 1 Step 43/313 Test Loss: 1.507 | Test Acc: 45.099% (635/1408)\n",
      "Epoch 1 Step 44/313 Test Loss: 1.506 | Test Acc: 45.139% (650/1440)\n",
      "Epoch 1 Step 45/313 Test Loss: 1.502 | Test Acc: 45.380% (668/1472)\n",
      "Epoch 1 Step 46/313 Test Loss: 1.499 | Test Acc: 45.678% (687/1504)\n",
      "Epoch 1 Step 47/313 Test Loss: 1.500 | Test Acc: 45.833% (704/1536)\n",
      "Epoch 1 Step 48/313 Test Loss: 1.498 | Test Acc: 45.727% (717/1568)\n",
      "Epoch 1 Step 49/313 Test Loss: 1.502 | Test Acc: 45.500% (728/1600)\n",
      "Epoch 1 Step 50/313 Test Loss: 1.509 | Test Acc: 45.221% (738/1632)\n",
      "Epoch 1 Step 51/313 Test Loss: 1.507 | Test Acc: 45.433% (756/1664)\n",
      "Epoch 1 Step 52/313 Test Loss: 1.503 | Test Acc: 45.755% (776/1696)\n",
      "Epoch 1 Step 53/313 Test Loss: 1.508 | Test Acc: 45.660% (789/1728)\n",
      "Epoch 1 Step 54/313 Test Loss: 1.510 | Test Acc: 45.398% (799/1760)\n",
      "Epoch 1 Step 55/313 Test Loss: 1.508 | Test Acc: 45.480% (815/1792)\n",
      "Epoch 1 Step 56/313 Test Loss: 1.510 | Test Acc: 45.395% (828/1824)\n",
      "Epoch 1 Step 57/313 Test Loss: 1.513 | Test Acc: 45.474% (844/1856)\n",
      "Epoch 1 Step 58/313 Test Loss: 1.513 | Test Acc: 45.551% (860/1888)\n",
      "Epoch 1 Step 59/313 Test Loss: 1.517 | Test Acc: 45.312% (870/1920)\n",
      "Epoch 1 Step 60/313 Test Loss: 1.519 | Test Acc: 45.184% (882/1952)\n",
      "Epoch 1 Step 61/313 Test Loss: 1.520 | Test Acc: 45.363% (900/1984)\n",
      "Epoch 1 Step 62/313 Test Loss: 1.521 | Test Acc: 45.387% (915/2016)\n",
      "Epoch 1 Step 63/313 Test Loss: 1.520 | Test Acc: 45.410% (930/2048)\n",
      "Epoch 1 Step 64/313 Test Loss: 1.519 | Test Acc: 45.288% (942/2080)\n",
      "Epoch 1 Step 65/313 Test Loss: 1.513 | Test Acc: 45.549% (962/2112)\n",
      "Epoch 1 Step 66/313 Test Loss: 1.512 | Test Acc: 45.616% (978/2144)\n",
      "Epoch 1 Step 67/313 Test Loss: 1.516 | Test Acc: 45.450% (989/2176)\n",
      "Epoch 1 Step 68/313 Test Loss: 1.517 | Test Acc: 45.516% (1005/2208)\n",
      "Epoch 1 Step 69/313 Test Loss: 1.517 | Test Acc: 45.580% (1021/2240)\n",
      "Epoch 1 Step 70/313 Test Loss: 1.517 | Test Acc: 45.599% (1036/2272)\n",
      "Epoch 1 Step 71/313 Test Loss: 1.516 | Test Acc: 45.616% (1051/2304)\n",
      "Epoch 1 Step 72/313 Test Loss: 1.517 | Test Acc: 45.719% (1068/2336)\n",
      "Epoch 1 Step 73/313 Test Loss: 1.517 | Test Acc: 45.650% (1081/2368)\n",
      "Epoch 1 Step 74/313 Test Loss: 1.518 | Test Acc: 45.792% (1099/2400)\n",
      "Epoch 1 Step 75/313 Test Loss: 1.519 | Test Acc: 45.683% (1111/2432)\n",
      "Epoch 1 Step 76/313 Test Loss: 1.518 | Test Acc: 45.779% (1128/2464)\n",
      "Epoch 1 Step 77/313 Test Loss: 1.517 | Test Acc: 45.793% (1143/2496)\n",
      "Epoch 1 Step 78/313 Test Loss: 1.520 | Test Acc: 45.767% (1157/2528)\n",
      "Epoch 1 Step 79/313 Test Loss: 1.522 | Test Acc: 45.664% (1169/2560)\n",
      "Epoch 1 Step 80/313 Test Loss: 1.523 | Test Acc: 45.602% (1182/2592)\n",
      "Epoch 1 Step 81/313 Test Loss: 1.522 | Test Acc: 45.579% (1196/2624)\n",
      "Epoch 1 Step 82/313 Test Loss: 1.524 | Test Acc: 45.633% (1212/2656)\n",
      "Epoch 1 Step 83/313 Test Loss: 1.522 | Test Acc: 45.796% (1231/2688)\n",
      "Epoch 1 Step 84/313 Test Loss: 1.521 | Test Acc: 45.846% (1247/2720)\n",
      "Epoch 1 Step 85/313 Test Loss: 1.521 | Test Acc: 45.894% (1263/2752)\n",
      "Epoch 1 Step 86/313 Test Loss: 1.525 | Test Acc: 45.690% (1272/2784)\n",
      "Epoch 1 Step 87/313 Test Loss: 1.526 | Test Acc: 45.597% (1284/2816)\n",
      "Epoch 1 Step 88/313 Test Loss: 1.526 | Test Acc: 45.541% (1297/2848)\n",
      "Epoch 1 Step 89/313 Test Loss: 1.524 | Test Acc: 45.521% (1311/2880)\n",
      "Epoch 1 Step 90/313 Test Loss: 1.527 | Test Acc: 45.330% (1320/2912)\n",
      "Epoch 1 Step 91/313 Test Loss: 1.523 | Test Acc: 45.448% (1338/2944)\n",
      "Epoch 1 Step 92/313 Test Loss: 1.523 | Test Acc: 45.397% (1351/2976)\n",
      "Epoch 1 Step 93/313 Test Loss: 1.522 | Test Acc: 45.445% (1367/3008)\n",
      "Epoch 1 Step 94/313 Test Loss: 1.523 | Test Acc: 45.461% (1382/3040)\n",
      "Epoch 1 Step 95/313 Test Loss: 1.522 | Test Acc: 45.475% (1397/3072)\n",
      "Epoch 1 Step 96/313 Test Loss: 1.520 | Test Acc: 45.554% (1414/3104)\n",
      "Epoch 1 Step 97/313 Test Loss: 1.522 | Test Acc: 45.376% (1423/3136)\n",
      "Epoch 1 Step 98/313 Test Loss: 1.524 | Test Acc: 45.360% (1437/3168)\n",
      "Epoch 1 Step 99/313 Test Loss: 1.524 | Test Acc: 45.406% (1453/3200)\n",
      "Epoch 1 Step 100/313 Test Loss: 1.527 | Test Acc: 45.235% (1462/3232)\n",
      "Epoch 1 Step 101/313 Test Loss: 1.525 | Test Acc: 45.251% (1477/3264)\n",
      "Epoch 1 Step 102/313 Test Loss: 1.524 | Test Acc: 45.358% (1495/3296)\n",
      "Epoch 1 Step 103/313 Test Loss: 1.525 | Test Acc: 45.343% (1509/3328)\n",
      "Epoch 1 Step 104/313 Test Loss: 1.525 | Test Acc: 45.357% (1524/3360)\n",
      "Epoch 1 Step 105/313 Test Loss: 1.522 | Test Acc: 45.401% (1540/3392)\n",
      "Epoch 1 Step 106/313 Test Loss: 1.523 | Test Acc: 45.327% (1552/3424)\n",
      "Epoch 1 Step 107/313 Test Loss: 1.525 | Test Acc: 45.255% (1564/3456)\n",
      "Epoch 1 Step 108/313 Test Loss: 1.523 | Test Acc: 45.413% (1584/3488)\n",
      "Epoch 1 Step 109/313 Test Loss: 1.523 | Test Acc: 45.369% (1597/3520)\n",
      "Epoch 1 Step 110/313 Test Loss: 1.521 | Test Acc: 45.524% (1617/3552)\n",
      "Epoch 1 Step 111/313 Test Loss: 1.521 | Test Acc: 45.564% (1633/3584)\n",
      "Epoch 1 Step 112/313 Test Loss: 1.521 | Test Acc: 45.631% (1650/3616)\n",
      "Epoch 1 Step 113/313 Test Loss: 1.520 | Test Acc: 45.641% (1665/3648)\n",
      "Epoch 1 Step 114/313 Test Loss: 1.520 | Test Acc: 45.598% (1678/3680)\n",
      "Epoch 1 Step 115/313 Test Loss: 1.519 | Test Acc: 45.582% (1692/3712)\n",
      "Epoch 1 Step 116/313 Test Loss: 1.519 | Test Acc: 45.593% (1707/3744)\n",
      "Epoch 1 Step 117/313 Test Loss: 1.520 | Test Acc: 45.551% (1720/3776)\n",
      "Epoch 1 Step 118/313 Test Loss: 1.520 | Test Acc: 45.641% (1738/3808)\n",
      "Epoch 1 Step 119/313 Test Loss: 1.516 | Test Acc: 45.781% (1758/3840)\n",
      "Epoch 1 Step 120/313 Test Loss: 1.514 | Test Acc: 45.816% (1774/3872)\n",
      "Epoch 1 Step 121/313 Test Loss: 1.514 | Test Acc: 45.825% (1789/3904)\n",
      "Epoch 1 Step 122/313 Test Loss: 1.515 | Test Acc: 45.808% (1803/3936)\n",
      "Epoch 1 Step 123/313 Test Loss: 1.514 | Test Acc: 45.766% (1816/3968)\n",
      "Epoch 1 Step 124/313 Test Loss: 1.516 | Test Acc: 45.775% (1831/4000)\n",
      "Epoch 1 Step 125/313 Test Loss: 1.515 | Test Acc: 45.734% (1844/4032)\n",
      "Epoch 1 Step 126/313 Test Loss: 1.519 | Test Acc: 45.669% (1856/4064)\n",
      "Epoch 1 Step 127/313 Test Loss: 1.517 | Test Acc: 45.776% (1875/4096)\n",
      "Epoch 1 Step 128/313 Test Loss: 1.519 | Test Acc: 45.712% (1887/4128)\n",
      "Epoch 1 Step 129/313 Test Loss: 1.518 | Test Acc: 45.817% (1906/4160)\n",
      "Epoch 1 Step 130/313 Test Loss: 1.517 | Test Acc: 45.825% (1921/4192)\n",
      "Epoch 1 Step 131/313 Test Loss: 1.516 | Test Acc: 45.810% (1935/4224)\n",
      "Epoch 1 Step 132/313 Test Loss: 1.516 | Test Acc: 45.818% (1950/4256)\n",
      "Epoch 1 Step 133/313 Test Loss: 1.516 | Test Acc: 45.896% (1968/4288)\n",
      "Epoch 1 Step 134/313 Test Loss: 1.516 | Test Acc: 45.880% (1982/4320)\n",
      "Epoch 1 Step 135/313 Test Loss: 1.514 | Test Acc: 45.910% (1998/4352)\n",
      "Epoch 1 Step 136/313 Test Loss: 1.513 | Test Acc: 45.963% (2015/4384)\n",
      "Epoch 1 Step 137/313 Test Loss: 1.514 | Test Acc: 45.992% (2031/4416)\n",
      "Epoch 1 Step 138/313 Test Loss: 1.512 | Test Acc: 45.976% (2045/4448)\n",
      "Epoch 1 Step 139/313 Test Loss: 1.512 | Test Acc: 45.915% (2057/4480)\n",
      "Epoch 1 Step 140/313 Test Loss: 1.511 | Test Acc: 45.878% (2070/4512)\n",
      "Epoch 1 Step 141/313 Test Loss: 1.511 | Test Acc: 45.863% (2084/4544)\n",
      "Epoch 1 Step 142/313 Test Loss: 1.513 | Test Acc: 45.739% (2093/4576)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 143/313 Test Loss: 1.513 | Test Acc: 45.660% (2104/4608)\n",
      "Epoch 1 Step 144/313 Test Loss: 1.512 | Test Acc: 45.690% (2120/4640)\n",
      "Epoch 1 Step 145/313 Test Loss: 1.511 | Test Acc: 45.805% (2140/4672)\n",
      "Epoch 1 Step 146/313 Test Loss: 1.511 | Test Acc: 45.727% (2151/4704)\n",
      "Epoch 1 Step 147/313 Test Loss: 1.511 | Test Acc: 45.735% (2166/4736)\n",
      "Epoch 1 Step 148/313 Test Loss: 1.512 | Test Acc: 45.701% (2179/4768)\n",
      "Epoch 1 Step 149/313 Test Loss: 1.513 | Test Acc: 45.708% (2194/4800)\n",
      "Epoch 1 Step 150/313 Test Loss: 1.513 | Test Acc: 45.633% (2205/4832)\n",
      "Epoch 1 Step 151/313 Test Loss: 1.512 | Test Acc: 45.683% (2222/4864)\n",
      "Epoch 1 Step 152/313 Test Loss: 1.511 | Test Acc: 45.690% (2237/4896)\n",
      "Epoch 1 Step 153/313 Test Loss: 1.511 | Test Acc: 45.678% (2251/4928)\n",
      "Epoch 1 Step 154/313 Test Loss: 1.511 | Test Acc: 45.665% (2265/4960)\n",
      "Epoch 1 Step 155/313 Test Loss: 1.510 | Test Acc: 45.653% (2279/4992)\n",
      "Epoch 1 Step 156/313 Test Loss: 1.509 | Test Acc: 45.721% (2297/5024)\n",
      "Epoch 1 Step 157/313 Test Loss: 1.510 | Test Acc: 45.649% (2308/5056)\n",
      "Epoch 1 Step 158/313 Test Loss: 1.511 | Test Acc: 45.558% (2318/5088)\n",
      "Epoch 1 Step 159/313 Test Loss: 1.512 | Test Acc: 45.547% (2332/5120)\n",
      "Epoch 1 Step 160/313 Test Loss: 1.512 | Test Acc: 45.633% (2351/5152)\n",
      "Epoch 1 Step 161/313 Test Loss: 1.511 | Test Acc: 45.640% (2366/5184)\n",
      "Epoch 1 Step 162/313 Test Loss: 1.511 | Test Acc: 45.629% (2380/5216)\n",
      "Epoch 1 Step 163/313 Test Loss: 1.510 | Test Acc: 45.655% (2396/5248)\n",
      "Epoch 1 Step 164/313 Test Loss: 1.510 | Test Acc: 45.644% (2410/5280)\n",
      "Epoch 1 Step 165/313 Test Loss: 1.510 | Test Acc: 45.614% (2423/5312)\n",
      "Epoch 1 Step 166/313 Test Loss: 1.511 | Test Acc: 45.584% (2436/5344)\n",
      "Epoch 1 Step 167/313 Test Loss: 1.512 | Test Acc: 45.554% (2449/5376)\n",
      "Epoch 1 Step 168/313 Test Loss: 1.513 | Test Acc: 45.507% (2461/5408)\n",
      "Epoch 1 Step 169/313 Test Loss: 1.513 | Test Acc: 45.515% (2476/5440)\n",
      "Epoch 1 Step 170/313 Test Loss: 1.513 | Test Acc: 45.523% (2491/5472)\n",
      "Epoch 1 Step 171/313 Test Loss: 1.513 | Test Acc: 45.494% (2504/5504)\n",
      "Epoch 1 Step 172/313 Test Loss: 1.515 | Test Acc: 45.502% (2519/5536)\n",
      "Epoch 1 Step 173/313 Test Loss: 1.516 | Test Acc: 45.402% (2528/5568)\n",
      "Epoch 1 Step 174/313 Test Loss: 1.516 | Test Acc: 45.357% (2540/5600)\n",
      "Epoch 1 Step 175/313 Test Loss: 1.517 | Test Acc: 45.348% (2554/5632)\n",
      "Epoch 1 Step 176/313 Test Loss: 1.520 | Test Acc: 45.251% (2563/5664)\n",
      "Epoch 1 Step 177/313 Test Loss: 1.518 | Test Acc: 45.348% (2583/5696)\n",
      "Epoch 1 Step 178/313 Test Loss: 1.517 | Test Acc: 45.374% (2599/5728)\n",
      "Epoch 1 Step 179/313 Test Loss: 1.518 | Test Acc: 45.330% (2611/5760)\n",
      "Epoch 1 Step 180/313 Test Loss: 1.516 | Test Acc: 45.390% (2629/5792)\n",
      "Epoch 1 Step 181/313 Test Loss: 1.517 | Test Acc: 45.381% (2643/5824)\n",
      "Epoch 1 Step 182/313 Test Loss: 1.518 | Test Acc: 45.287% (2652/5856)\n",
      "Epoch 1 Step 183/313 Test Loss: 1.518 | Test Acc: 45.245% (2664/5888)\n",
      "Epoch 1 Step 184/313 Test Loss: 1.520 | Test Acc: 45.203% (2676/5920)\n",
      "Epoch 1 Step 185/313 Test Loss: 1.519 | Test Acc: 45.161% (2688/5952)\n",
      "Epoch 1 Step 186/313 Test Loss: 1.520 | Test Acc: 45.154% (2702/5984)\n",
      "Epoch 1 Step 187/313 Test Loss: 1.520 | Test Acc: 45.096% (2713/6016)\n",
      "Epoch 1 Step 188/313 Test Loss: 1.519 | Test Acc: 45.122% (2729/6048)\n",
      "Epoch 1 Step 189/313 Test Loss: 1.518 | Test Acc: 45.148% (2745/6080)\n",
      "Epoch 1 Step 190/313 Test Loss: 1.517 | Test Acc: 45.255% (2766/6112)\n",
      "Epoch 1 Step 191/313 Test Loss: 1.516 | Test Acc: 45.264% (2781/6144)\n",
      "Epoch 1 Step 192/313 Test Loss: 1.517 | Test Acc: 45.223% (2793/6176)\n",
      "Epoch 1 Step 193/313 Test Loss: 1.516 | Test Acc: 45.280% (2811/6208)\n",
      "Epoch 1 Step 194/313 Test Loss: 1.517 | Test Acc: 45.272% (2825/6240)\n",
      "Epoch 1 Step 195/313 Test Loss: 1.518 | Test Acc: 45.233% (2837/6272)\n",
      "Epoch 1 Step 196/313 Test Loss: 1.519 | Test Acc: 45.257% (2853/6304)\n",
      "Epoch 1 Step 197/313 Test Loss: 1.519 | Test Acc: 45.297% (2870/6336)\n",
      "Epoch 1 Step 198/313 Test Loss: 1.517 | Test Acc: 45.367% (2889/6368)\n",
      "Epoch 1 Step 199/313 Test Loss: 1.517 | Test Acc: 45.312% (2900/6400)\n",
      "Epoch 1 Step 200/313 Test Loss: 1.517 | Test Acc: 45.305% (2914/6432)\n",
      "Epoch 1 Step 201/313 Test Loss: 1.517 | Test Acc: 45.312% (2929/6464)\n",
      "Epoch 1 Step 202/313 Test Loss: 1.517 | Test Acc: 45.336% (2945/6496)\n",
      "Epoch 1 Step 203/313 Test Loss: 1.517 | Test Acc: 45.358% (2961/6528)\n",
      "Epoch 1 Step 204/313 Test Loss: 1.519 | Test Acc: 45.290% (2971/6560)\n",
      "Epoch 1 Step 205/313 Test Loss: 1.521 | Test Acc: 45.191% (2979/6592)\n",
      "Epoch 1 Step 206/313 Test Loss: 1.521 | Test Acc: 45.199% (2994/6624)\n",
      "Epoch 1 Step 207/313 Test Loss: 1.520 | Test Acc: 45.207% (3009/6656)\n",
      "Epoch 1 Step 208/313 Test Loss: 1.520 | Test Acc: 45.215% (3024/6688)\n",
      "Epoch 1 Step 209/313 Test Loss: 1.519 | Test Acc: 45.283% (3043/6720)\n",
      "Epoch 1 Step 210/313 Test Loss: 1.518 | Test Acc: 45.335% (3061/6752)\n",
      "Epoch 1 Step 211/313 Test Loss: 1.518 | Test Acc: 45.342% (3076/6784)\n",
      "Epoch 1 Step 212/313 Test Loss: 1.517 | Test Acc: 45.423% (3096/6816)\n",
      "Epoch 1 Step 213/313 Test Loss: 1.516 | Test Acc: 45.488% (3115/6848)\n",
      "Epoch 1 Step 214/313 Test Loss: 1.518 | Test Acc: 45.422% (3125/6880)\n",
      "Epoch 1 Step 215/313 Test Loss: 1.519 | Test Acc: 45.457% (3142/6912)\n",
      "Epoch 1 Step 216/313 Test Loss: 1.519 | Test Acc: 45.435% (3155/6944)\n",
      "Epoch 1 Step 217/313 Test Loss: 1.521 | Test Acc: 45.384% (3166/6976)\n",
      "Epoch 1 Step 218/313 Test Loss: 1.521 | Test Acc: 45.348% (3178/7008)\n",
      "Epoch 1 Step 219/313 Test Loss: 1.521 | Test Acc: 45.398% (3196/7040)\n",
      "Epoch 1 Step 220/313 Test Loss: 1.521 | Test Acc: 45.390% (3210/7072)\n",
      "Epoch 1 Step 221/313 Test Loss: 1.522 | Test Acc: 45.397% (3225/7104)\n",
      "Epoch 1 Step 222/313 Test Loss: 1.523 | Test Acc: 45.390% (3239/7136)\n",
      "Epoch 1 Step 223/313 Test Loss: 1.522 | Test Acc: 45.396% (3254/7168)\n",
      "Epoch 1 Step 224/313 Test Loss: 1.523 | Test Acc: 45.389% (3268/7200)\n",
      "Epoch 1 Step 225/313 Test Loss: 1.523 | Test Acc: 45.465% (3288/7232)\n",
      "Epoch 1 Step 226/313 Test Loss: 1.524 | Test Acc: 45.402% (3298/7264)\n",
      "Epoch 1 Step 227/313 Test Loss: 1.524 | Test Acc: 45.340% (3308/7296)\n",
      "Epoch 1 Step 228/313 Test Loss: 1.523 | Test Acc: 45.374% (3325/7328)\n",
      "Epoch 1 Step 229/313 Test Loss: 1.523 | Test Acc: 45.367% (3339/7360)\n",
      "Epoch 1 Step 230/313 Test Loss: 1.523 | Test Acc: 45.360% (3353/7392)\n",
      "Epoch 1 Step 231/313 Test Loss: 1.524 | Test Acc: 45.353% (3367/7424)\n",
      "Epoch 1 Step 232/313 Test Loss: 1.523 | Test Acc: 45.373% (3383/7456)\n",
      "Epoch 1 Step 233/313 Test Loss: 1.521 | Test Acc: 45.459% (3404/7488)\n",
      "Epoch 1 Step 234/313 Test Loss: 1.521 | Test Acc: 45.465% (3419/7520)\n",
      "Epoch 1 Step 235/313 Test Loss: 1.521 | Test Acc: 45.471% (3434/7552)\n",
      "Epoch 1 Step 236/313 Test Loss: 1.522 | Test Acc: 45.451% (3447/7584)\n",
      "Epoch 1 Step 237/313 Test Loss: 1.522 | Test Acc: 45.404% (3458/7616)\n",
      "Epoch 1 Step 238/313 Test Loss: 1.522 | Test Acc: 45.424% (3474/7648)\n",
      "Epoch 1 Step 239/313 Test Loss: 1.522 | Test Acc: 45.404% (3487/7680)\n",
      "Epoch 1 Step 240/313 Test Loss: 1.520 | Test Acc: 45.475% (3507/7712)\n",
      "Epoch 1 Step 241/313 Test Loss: 1.521 | Test Acc: 45.467% (3521/7744)\n",
      "Epoch 1 Step 242/313 Test Loss: 1.521 | Test Acc: 45.460% (3535/7776)\n",
      "Epoch 1 Step 243/313 Test Loss: 1.520 | Test Acc: 45.453% (3549/7808)\n",
      "Epoch 1 Step 244/313 Test Loss: 1.520 | Test Acc: 45.395% (3559/7840)\n",
      "Epoch 1 Step 245/313 Test Loss: 1.520 | Test Acc: 45.376% (3572/7872)\n",
      "Epoch 1 Step 246/313 Test Loss: 1.520 | Test Acc: 45.382% (3587/7904)\n",
      "Epoch 1 Step 247/313 Test Loss: 1.520 | Test Acc: 45.350% (3599/7936)\n",
      "Epoch 1 Step 248/313 Test Loss: 1.521 | Test Acc: 45.319% (3611/7968)\n",
      "Epoch 1 Step 249/313 Test Loss: 1.521 | Test Acc: 45.362% (3629/8000)\n",
      "Epoch 1 Step 250/313 Test Loss: 1.521 | Test Acc: 45.381% (3645/8032)\n",
      "Epoch 1 Step 251/313 Test Loss: 1.521 | Test Acc: 45.362% (3658/8064)\n",
      "Epoch 1 Step 252/313 Test Loss: 1.522 | Test Acc: 45.368% (3673/8096)\n",
      "Epoch 1 Step 253/313 Test Loss: 1.522 | Test Acc: 45.349% (3686/8128)\n",
      "Epoch 1 Step 254/313 Test Loss: 1.522 | Test Acc: 45.355% (3701/8160)\n",
      "Epoch 1 Step 255/313 Test Loss: 1.522 | Test Acc: 45.337% (3714/8192)\n",
      "Epoch 1 Step 256/313 Test Loss: 1.523 | Test Acc: 45.294% (3725/8224)\n",
      "Epoch 1 Step 257/313 Test Loss: 1.522 | Test Acc: 45.349% (3744/8256)\n",
      "Epoch 1 Step 258/313 Test Loss: 1.522 | Test Acc: 45.319% (3756/8288)\n",
      "Epoch 1 Step 259/313 Test Loss: 1.523 | Test Acc: 45.240% (3764/8320)\n",
      "Epoch 1 Step 260/313 Test Loss: 1.524 | Test Acc: 45.199% (3775/8352)\n",
      "Epoch 1 Step 261/313 Test Loss: 1.524 | Test Acc: 45.169% (3787/8384)\n",
      "Epoch 1 Step 262/313 Test Loss: 1.523 | Test Acc: 45.188% (3803/8416)\n",
      "Epoch 1 Step 263/313 Test Loss: 1.524 | Test Acc: 45.123% (3812/8448)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Step 264/313 Test Loss: 1.524 | Test Acc: 45.118% (3826/8480)\n",
      "Epoch 1 Step 265/313 Test Loss: 1.524 | Test Acc: 45.089% (3838/8512)\n",
      "Epoch 1 Step 266/313 Test Loss: 1.525 | Test Acc: 45.084% (3852/8544)\n",
      "Epoch 1 Step 267/313 Test Loss: 1.524 | Test Acc: 45.114% (3869/8576)\n",
      "Epoch 1 Step 268/313 Test Loss: 1.524 | Test Acc: 45.086% (3881/8608)\n",
      "Epoch 1 Step 269/313 Test Loss: 1.524 | Test Acc: 45.069% (3894/8640)\n",
      "Epoch 1 Step 270/313 Test Loss: 1.525 | Test Acc: 45.007% (3903/8672)\n",
      "Epoch 1 Step 271/313 Test Loss: 1.525 | Test Acc: 44.979% (3915/8704)\n",
      "Epoch 1 Step 272/313 Test Loss: 1.525 | Test Acc: 44.986% (3930/8736)\n",
      "Epoch 1 Step 273/313 Test Loss: 1.525 | Test Acc: 44.970% (3943/8768)\n",
      "Epoch 1 Step 274/313 Test Loss: 1.525 | Test Acc: 44.943% (3955/8800)\n",
      "Epoch 1 Step 275/313 Test Loss: 1.525 | Test Acc: 44.950% (3970/8832)\n",
      "Epoch 1 Step 276/313 Test Loss: 1.525 | Test Acc: 44.957% (3985/8864)\n",
      "Epoch 1 Step 277/313 Test Loss: 1.524 | Test Acc: 45.009% (4004/8896)\n",
      "Epoch 1 Step 278/313 Test Loss: 1.524 | Test Acc: 45.072% (4024/8928)\n",
      "Epoch 1 Step 279/313 Test Loss: 1.525 | Test Acc: 45.011% (4033/8960)\n",
      "Epoch 1 Step 280/313 Test Loss: 1.525 | Test Acc: 45.018% (4048/8992)\n",
      "Epoch 1 Step 281/313 Test Loss: 1.524 | Test Acc: 45.058% (4066/9024)\n",
      "Epoch 1 Step 282/313 Test Loss: 1.524 | Test Acc: 45.064% (4081/9056)\n",
      "Epoch 1 Step 283/313 Test Loss: 1.524 | Test Acc: 45.070% (4096/9088)\n",
      "Epoch 1 Step 284/313 Test Loss: 1.524 | Test Acc: 45.099% (4113/9120)\n",
      "Epoch 1 Step 285/313 Test Loss: 1.525 | Test Acc: 45.083% (4126/9152)\n",
      "Epoch 1 Step 286/313 Test Loss: 1.524 | Test Acc: 45.100% (4142/9184)\n",
      "Epoch 1 Step 287/313 Test Loss: 1.523 | Test Acc: 45.171% (4163/9216)\n",
      "Epoch 1 Step 288/313 Test Loss: 1.522 | Test Acc: 45.231% (4183/9248)\n",
      "Epoch 1 Step 289/313 Test Loss: 1.521 | Test Acc: 45.269% (4201/9280)\n",
      "Epoch 1 Step 290/313 Test Loss: 1.522 | Test Acc: 45.200% (4209/9312)\n",
      "Epoch 1 Step 291/313 Test Loss: 1.522 | Test Acc: 45.184% (4222/9344)\n",
      "Epoch 1 Step 292/313 Test Loss: 1.522 | Test Acc: 45.190% (4237/9376)\n",
      "Epoch 1 Step 293/313 Test Loss: 1.523 | Test Acc: 45.196% (4252/9408)\n",
      "Epoch 1 Step 294/313 Test Loss: 1.524 | Test Acc: 45.212% (4268/9440)\n",
      "Epoch 1 Step 295/313 Test Loss: 1.524 | Test Acc: 45.207% (4282/9472)\n",
      "Epoch 1 Step 296/313 Test Loss: 1.523 | Test Acc: 45.234% (4299/9504)\n",
      "Epoch 1 Step 297/313 Test Loss: 1.523 | Test Acc: 45.260% (4316/9536)\n",
      "Epoch 1 Step 298/313 Test Loss: 1.522 | Test Acc: 45.265% (4331/9568)\n",
      "Epoch 1 Step 299/313 Test Loss: 1.522 | Test Acc: 45.292% (4348/9600)\n",
      "Epoch 1 Step 300/313 Test Loss: 1.522 | Test Acc: 45.287% (4362/9632)\n",
      "Epoch 1 Step 301/313 Test Loss: 1.522 | Test Acc: 45.281% (4376/9664)\n",
      "Epoch 1 Step 302/313 Test Loss: 1.522 | Test Acc: 45.287% (4391/9696)\n",
      "Epoch 1 Step 303/313 Test Loss: 1.522 | Test Acc: 45.292% (4406/9728)\n",
      "Epoch 1 Step 304/313 Test Loss: 1.523 | Test Acc: 45.246% (4416/9760)\n",
      "Epoch 1 Step 305/313 Test Loss: 1.523 | Test Acc: 45.261% (4432/9792)\n",
      "Epoch 1 Step 306/313 Test Loss: 1.524 | Test Acc: 45.226% (4443/9824)\n",
      "Epoch 1 Step 307/313 Test Loss: 1.523 | Test Acc: 45.221% (4457/9856)\n",
      "Epoch 1 Step 308/313 Test Loss: 1.524 | Test Acc: 45.206% (4470/9888)\n",
      "Epoch 1 Step 309/313 Test Loss: 1.524 | Test Acc: 45.222% (4486/9920)\n",
      "Epoch 1 Step 310/313 Test Loss: 1.524 | Test Acc: 45.207% (4499/9952)\n",
      "Epoch 1 Step 311/313 Test Loss: 1.524 | Test Acc: 45.162% (4509/9984)\n",
      "Epoch 1 Step 312/313 Test Loss: 1.524 | Test Acc: 45.140% (4514/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "Epoch 2 Step 0/1563 Loss: 1.568 | Acc: 43.750% (14/32)\n",
      "Epoch 2 Step 1/1563 Loss: 1.603 | Acc: 37.500% (24/64)\n",
      "Epoch 2 Step 2/1563 Loss: 1.623 | Acc: 37.500% (36/96)\n",
      "Epoch 2 Step 3/1563 Loss: 1.603 | Acc: 39.062% (50/128)\n",
      "Epoch 2 Step 4/1563 Loss: 1.610 | Acc: 39.375% (63/160)\n",
      "Epoch 2 Step 5/1563 Loss: 1.648 | Acc: 38.021% (73/192)\n",
      "Epoch 2 Step 6/1563 Loss: 1.607 | Acc: 39.732% (89/224)\n",
      "Epoch 2 Step 7/1563 Loss: 1.621 | Acc: 38.281% (98/256)\n",
      "Epoch 2 Step 8/1563 Loss: 1.620 | Acc: 38.542% (111/288)\n",
      "Epoch 2 Step 9/1563 Loss: 1.592 | Acc: 40.000% (128/320)\n",
      "Epoch 2 Step 10/1563 Loss: 1.567 | Acc: 41.477% (146/352)\n",
      "Epoch 2 Step 11/1563 Loss: 1.572 | Acc: 41.667% (160/384)\n",
      "Epoch 2 Step 12/1563 Loss: 1.568 | Acc: 42.548% (177/416)\n",
      "Epoch 2 Step 13/1563 Loss: 1.565 | Acc: 42.411% (190/448)\n",
      "Epoch 2 Step 14/1563 Loss: 1.567 | Acc: 43.125% (207/480)\n",
      "Epoch 2 Step 15/1563 Loss: 1.564 | Acc: 42.969% (220/512)\n",
      "Epoch 2 Step 16/1563 Loss: 1.561 | Acc: 42.831% (233/544)\n",
      "Epoch 2 Step 17/1563 Loss: 1.570 | Acc: 42.361% (244/576)\n",
      "Epoch 2 Step 18/1563 Loss: 1.562 | Acc: 42.599% (259/608)\n",
      "Epoch 2 Step 19/1563 Loss: 1.573 | Acc: 42.188% (270/640)\n",
      "Epoch 2 Step 20/1563 Loss: 1.576 | Acc: 41.815% (281/672)\n",
      "Epoch 2 Step 21/1563 Loss: 1.573 | Acc: 42.188% (297/704)\n",
      "Epoch 2 Step 22/1563 Loss: 1.581 | Acc: 42.255% (311/736)\n",
      "Epoch 2 Step 23/1563 Loss: 1.589 | Acc: 41.927% (322/768)\n",
      "Epoch 2 Step 24/1563 Loss: 1.595 | Acc: 42.125% (337/800)\n",
      "Epoch 2 Step 25/1563 Loss: 1.593 | Acc: 42.188% (351/832)\n",
      "Epoch 2 Step 26/1563 Loss: 1.586 | Acc: 42.245% (365/864)\n",
      "Epoch 2 Step 27/1563 Loss: 1.577 | Acc: 42.411% (380/896)\n",
      "Epoch 2 Step 28/1563 Loss: 1.586 | Acc: 42.349% (393/928)\n",
      "Epoch 2 Step 29/1563 Loss: 1.586 | Acc: 42.083% (404/960)\n",
      "Epoch 2 Step 30/1563 Loss: 1.582 | Acc: 42.036% (417/992)\n",
      "Epoch 2 Step 31/1563 Loss: 1.590 | Acc: 41.895% (429/1024)\n",
      "Epoch 2 Step 32/1563 Loss: 1.583 | Acc: 42.045% (444/1056)\n",
      "Epoch 2 Step 33/1563 Loss: 1.576 | Acc: 42.463% (462/1088)\n",
      "Epoch 2 Step 34/1563 Loss: 1.575 | Acc: 42.500% (476/1120)\n",
      "Epoch 2 Step 35/1563 Loss: 1.570 | Acc: 42.795% (493/1152)\n",
      "Epoch 2 Step 36/1563 Loss: 1.564 | Acc: 43.074% (510/1184)\n",
      "Epoch 2 Step 37/1563 Loss: 1.566 | Acc: 42.928% (522/1216)\n",
      "Epoch 2 Step 38/1563 Loss: 1.565 | Acc: 43.029% (537/1248)\n",
      "Epoch 2 Step 39/1563 Loss: 1.564 | Acc: 42.891% (549/1280)\n",
      "Epoch 2 Step 40/1563 Loss: 1.564 | Acc: 42.759% (561/1312)\n",
      "Epoch 2 Step 41/1563 Loss: 1.559 | Acc: 42.932% (577/1344)\n",
      "Epoch 2 Step 42/1563 Loss: 1.558 | Acc: 42.805% (589/1376)\n",
      "Epoch 2 Step 43/1563 Loss: 1.560 | Acc: 42.614% (600/1408)\n",
      "Epoch 2 Step 44/1563 Loss: 1.555 | Acc: 42.639% (614/1440)\n",
      "Epoch 2 Step 45/1563 Loss: 1.561 | Acc: 42.595% (627/1472)\n",
      "Epoch 2 Step 46/1563 Loss: 1.561 | Acc: 42.686% (642/1504)\n",
      "Epoch 2 Step 47/1563 Loss: 1.561 | Acc: 42.773% (657/1536)\n",
      "Epoch 2 Step 48/1563 Loss: 1.556 | Acc: 42.921% (673/1568)\n",
      "Epoch 2 Step 49/1563 Loss: 1.557 | Acc: 42.875% (686/1600)\n",
      "Epoch 2 Step 50/1563 Loss: 1.561 | Acc: 42.708% (697/1632)\n",
      "Epoch 2 Step 51/1563 Loss: 1.559 | Acc: 42.668% (710/1664)\n",
      "Epoch 2 Step 52/1563 Loss: 1.562 | Acc: 42.512% (721/1696)\n",
      "Epoch 2 Step 53/1563 Loss: 1.562 | Acc: 42.303% (731/1728)\n",
      "Epoch 2 Step 54/1563 Loss: 1.562 | Acc: 42.386% (746/1760)\n",
      "Epoch 2 Step 55/1563 Loss: 1.560 | Acc: 42.634% (764/1792)\n",
      "Epoch 2 Step 56/1563 Loss: 1.564 | Acc: 42.599% (777/1824)\n",
      "Epoch 2 Step 57/1563 Loss: 1.561 | Acc: 42.726% (793/1856)\n",
      "Epoch 2 Step 58/1563 Loss: 1.563 | Acc: 42.691% (806/1888)\n",
      "Epoch 2 Step 59/1563 Loss: 1.563 | Acc: 42.656% (819/1920)\n",
      "Epoch 2 Step 60/1563 Loss: 1.565 | Acc: 42.674% (833/1952)\n",
      "Epoch 2 Step 61/1563 Loss: 1.567 | Acc: 42.591% (845/1984)\n",
      "Epoch 2 Step 62/1563 Loss: 1.570 | Acc: 42.510% (857/2016)\n",
      "Epoch 2 Step 63/1563 Loss: 1.567 | Acc: 42.773% (876/2048)\n",
      "Epoch 2 Step 64/1563 Loss: 1.562 | Acc: 42.981% (894/2080)\n",
      "Epoch 2 Step 65/1563 Loss: 1.561 | Acc: 43.087% (910/2112)\n",
      "Epoch 2 Step 66/1563 Loss: 1.558 | Acc: 43.330% (929/2144)\n",
      "Epoch 2 Step 67/1563 Loss: 1.554 | Acc: 43.474% (946/2176)\n",
      "Epoch 2 Step 68/1563 Loss: 1.555 | Acc: 43.478% (960/2208)\n",
      "Epoch 2 Step 69/1563 Loss: 1.556 | Acc: 43.527% (975/2240)\n",
      "Epoch 2 Step 70/1563 Loss: 1.556 | Acc: 43.618% (991/2272)\n",
      "Epoch 2 Step 71/1563 Loss: 1.553 | Acc: 43.576% (1004/2304)\n",
      "Epoch 2 Step 72/1563 Loss: 1.552 | Acc: 43.664% (1020/2336)\n",
      "Epoch 2 Step 73/1563 Loss: 1.552 | Acc: 43.581% (1032/2368)\n",
      "Epoch 2 Step 74/1563 Loss: 1.551 | Acc: 43.708% (1049/2400)\n",
      "Epoch 2 Step 75/1563 Loss: 1.549 | Acc: 43.668% (1062/2432)\n",
      "Epoch 2 Step 76/1563 Loss: 1.549 | Acc: 43.750% (1078/2464)\n",
      "Epoch 2 Step 77/1563 Loss: 1.549 | Acc: 43.670% (1090/2496)\n",
      "Epoch 2 Step 78/1563 Loss: 1.550 | Acc: 43.592% (1102/2528)\n",
      "Epoch 2 Step 79/1563 Loss: 1.552 | Acc: 43.555% (1115/2560)\n",
      "Epoch 2 Step 80/1563 Loss: 1.552 | Acc: 43.596% (1130/2592)\n",
      "Epoch 2 Step 81/1563 Loss: 1.555 | Acc: 43.483% (1141/2624)\n",
      "Epoch 2 Step 82/1563 Loss: 1.549 | Acc: 43.750% (1162/2656)\n",
      "Epoch 2 Step 83/1563 Loss: 1.551 | Acc: 43.787% (1177/2688)\n",
      "Epoch 2 Step 84/1563 Loss: 1.548 | Acc: 43.897% (1194/2720)\n",
      "Epoch 2 Step 85/1563 Loss: 1.545 | Acc: 43.968% (1210/2752)\n",
      "Epoch 2 Step 86/1563 Loss: 1.543 | Acc: 43.966% (1224/2784)\n",
      "Epoch 2 Step 87/1563 Loss: 1.543 | Acc: 43.963% (1238/2816)\n",
      "Epoch 2 Step 88/1563 Loss: 1.548 | Acc: 43.820% (1248/2848)\n",
      "Epoch 2 Step 89/1563 Loss: 1.547 | Acc: 43.889% (1264/2880)\n",
      "Epoch 2 Step 90/1563 Loss: 1.545 | Acc: 43.922% (1279/2912)\n",
      "Epoch 2 Step 91/1563 Loss: 1.547 | Acc: 43.886% (1292/2944)\n",
      "Epoch 2 Step 92/1563 Loss: 1.547 | Acc: 43.817% (1304/2976)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 93/1563 Loss: 1.547 | Acc: 43.816% (1318/3008)\n",
      "Epoch 2 Step 94/1563 Loss: 1.545 | Acc: 43.914% (1335/3040)\n",
      "Epoch 2 Step 95/1563 Loss: 1.549 | Acc: 43.717% (1343/3072)\n",
      "Epoch 2 Step 96/1563 Loss: 1.551 | Acc: 43.589% (1353/3104)\n",
      "Epoch 2 Step 97/1563 Loss: 1.552 | Acc: 43.654% (1369/3136)\n",
      "Epoch 2 Step 98/1563 Loss: 1.551 | Acc: 43.750% (1386/3168)\n",
      "Epoch 2 Step 99/1563 Loss: 1.549 | Acc: 43.719% (1399/3200)\n",
      "Epoch 2 Step 100/1563 Loss: 1.551 | Acc: 43.657% (1411/3232)\n",
      "Epoch 2 Step 101/1563 Loss: 1.550 | Acc: 43.811% (1430/3264)\n",
      "Epoch 2 Step 102/1563 Loss: 1.548 | Acc: 43.871% (1446/3296)\n",
      "Epoch 2 Step 103/1563 Loss: 1.548 | Acc: 43.810% (1458/3328)\n",
      "Epoch 2 Step 104/1563 Loss: 1.547 | Acc: 43.810% (1472/3360)\n",
      "Epoch 2 Step 105/1563 Loss: 1.546 | Acc: 43.986% (1492/3392)\n",
      "Epoch 2 Step 106/1563 Loss: 1.548 | Acc: 43.925% (1504/3424)\n",
      "Epoch 2 Step 107/1563 Loss: 1.550 | Acc: 43.750% (1512/3456)\n",
      "Epoch 2 Step 108/1563 Loss: 1.553 | Acc: 43.635% (1522/3488)\n",
      "Epoch 2 Step 109/1563 Loss: 1.553 | Acc: 43.608% (1535/3520)\n",
      "Epoch 2 Step 110/1563 Loss: 1.552 | Acc: 43.666% (1551/3552)\n",
      "Epoch 2 Step 111/1563 Loss: 1.550 | Acc: 43.806% (1570/3584)\n",
      "Epoch 2 Step 112/1563 Loss: 1.549 | Acc: 43.861% (1586/3616)\n",
      "Epoch 2 Step 113/1563 Loss: 1.549 | Acc: 43.860% (1600/3648)\n",
      "Epoch 2 Step 114/1563 Loss: 1.550 | Acc: 43.913% (1616/3680)\n",
      "Epoch 2 Step 115/1563 Loss: 1.548 | Acc: 43.912% (1630/3712)\n",
      "Epoch 2 Step 116/1563 Loss: 1.550 | Acc: 43.884% (1643/3744)\n",
      "Epoch 2 Step 117/1563 Loss: 1.553 | Acc: 43.803% (1654/3776)\n",
      "Epoch 2 Step 118/1563 Loss: 1.553 | Acc: 43.829% (1669/3808)\n",
      "Epoch 2 Step 119/1563 Loss: 1.557 | Acc: 43.776% (1681/3840)\n",
      "Epoch 2 Step 120/1563 Loss: 1.556 | Acc: 43.776% (1695/3872)\n",
      "Epoch 2 Step 121/1563 Loss: 1.557 | Acc: 43.801% (1710/3904)\n",
      "Epoch 2 Step 122/1563 Loss: 1.556 | Acc: 43.750% (1722/3936)\n",
      "Epoch 2 Step 123/1563 Loss: 1.556 | Acc: 43.750% (1736/3968)\n",
      "Epoch 2 Step 124/1563 Loss: 1.556 | Acc: 43.750% (1750/4000)\n",
      "Epoch 2 Step 125/1563 Loss: 1.557 | Acc: 43.750% (1764/4032)\n",
      "Epoch 2 Step 126/1563 Loss: 1.554 | Acc: 43.848% (1782/4064)\n",
      "Epoch 2 Step 127/1563 Loss: 1.557 | Acc: 43.750% (1792/4096)\n",
      "Epoch 2 Step 128/1563 Loss: 1.556 | Acc: 43.750% (1806/4128)\n",
      "Epoch 2 Step 129/1563 Loss: 1.557 | Acc: 43.726% (1819/4160)\n",
      "Epoch 2 Step 130/1563 Loss: 1.557 | Acc: 43.750% (1834/4192)\n",
      "Epoch 2 Step 131/1563 Loss: 1.555 | Acc: 43.821% (1851/4224)\n",
      "Epoch 2 Step 132/1563 Loss: 1.555 | Acc: 43.820% (1865/4256)\n",
      "Epoch 2 Step 133/1563 Loss: 1.556 | Acc: 43.773% (1877/4288)\n",
      "Epoch 2 Step 134/1563 Loss: 1.555 | Acc: 43.819% (1893/4320)\n",
      "Epoch 2 Step 135/1563 Loss: 1.555 | Acc: 43.865% (1909/4352)\n",
      "Epoch 2 Step 136/1563 Loss: 1.555 | Acc: 43.887% (1924/4384)\n",
      "Epoch 2 Step 137/1563 Loss: 1.556 | Acc: 43.863% (1937/4416)\n",
      "Epoch 2 Step 138/1563 Loss: 1.557 | Acc: 43.817% (1949/4448)\n",
      "Epoch 2 Step 139/1563 Loss: 1.558 | Acc: 43.772% (1961/4480)\n",
      "Epoch 2 Step 140/1563 Loss: 1.560 | Acc: 43.661% (1970/4512)\n",
      "Epoch 2 Step 141/1563 Loss: 1.561 | Acc: 43.574% (1980/4544)\n",
      "Epoch 2 Step 142/1563 Loss: 1.562 | Acc: 43.510% (1991/4576)\n",
      "Epoch 2 Step 143/1563 Loss: 1.563 | Acc: 43.490% (2004/4608)\n",
      "Epoch 2 Step 144/1563 Loss: 1.563 | Acc: 43.448% (2016/4640)\n",
      "Epoch 2 Step 145/1563 Loss: 1.563 | Acc: 43.429% (2029/4672)\n",
      "Epoch 2 Step 146/1563 Loss: 1.564 | Acc: 43.367% (2040/4704)\n",
      "Epoch 2 Step 147/1563 Loss: 1.566 | Acc: 43.222% (2047/4736)\n",
      "Epoch 2 Step 148/1563 Loss: 1.565 | Acc: 43.226% (2061/4768)\n",
      "Epoch 2 Step 149/1563 Loss: 1.567 | Acc: 43.229% (2075/4800)\n",
      "Epoch 2 Step 150/1563 Loss: 1.566 | Acc: 43.233% (2089/4832)\n",
      "Epoch 2 Step 151/1563 Loss: 1.567 | Acc: 43.257% (2104/4864)\n",
      "Epoch 2 Step 152/1563 Loss: 1.566 | Acc: 43.321% (2121/4896)\n",
      "Epoch 2 Step 153/1563 Loss: 1.567 | Acc: 43.304% (2134/4928)\n",
      "Epoch 2 Step 154/1563 Loss: 1.569 | Acc: 43.327% (2149/4960)\n",
      "Epoch 2 Step 155/1563 Loss: 1.568 | Acc: 43.349% (2164/4992)\n",
      "Epoch 2 Step 156/1563 Loss: 1.569 | Acc: 43.272% (2174/5024)\n",
      "Epoch 2 Step 157/1563 Loss: 1.571 | Acc: 43.216% (2185/5056)\n",
      "Epoch 2 Step 158/1563 Loss: 1.570 | Acc: 43.239% (2200/5088)\n",
      "Epoch 2 Step 159/1563 Loss: 1.570 | Acc: 43.242% (2214/5120)\n",
      "Epoch 2 Step 160/1563 Loss: 1.570 | Acc: 43.226% (2227/5152)\n",
      "Epoch 2 Step 161/1563 Loss: 1.571 | Acc: 43.229% (2241/5184)\n",
      "Epoch 2 Step 162/1563 Loss: 1.569 | Acc: 43.290% (2258/5216)\n",
      "Epoch 2 Step 163/1563 Loss: 1.569 | Acc: 43.274% (2271/5248)\n",
      "Epoch 2 Step 164/1563 Loss: 1.569 | Acc: 43.220% (2282/5280)\n",
      "Epoch 2 Step 165/1563 Loss: 1.569 | Acc: 43.185% (2294/5312)\n",
      "Epoch 2 Step 166/1563 Loss: 1.570 | Acc: 43.132% (2305/5344)\n",
      "Epoch 2 Step 167/1563 Loss: 1.570 | Acc: 43.155% (2320/5376)\n",
      "Epoch 2 Step 168/1563 Loss: 1.571 | Acc: 43.047% (2328/5408)\n",
      "Epoch 2 Step 169/1563 Loss: 1.572 | Acc: 43.015% (2340/5440)\n",
      "Epoch 2 Step 170/1563 Loss: 1.571 | Acc: 43.056% (2356/5472)\n",
      "Epoch 2 Step 171/1563 Loss: 1.573 | Acc: 43.023% (2368/5504)\n",
      "Epoch 2 Step 172/1563 Loss: 1.570 | Acc: 43.118% (2387/5536)\n",
      "Epoch 2 Step 173/1563 Loss: 1.571 | Acc: 43.068% (2398/5568)\n",
      "Epoch 2 Step 174/1563 Loss: 1.571 | Acc: 43.089% (2413/5600)\n",
      "Epoch 2 Step 175/1563 Loss: 1.571 | Acc: 43.093% (2427/5632)\n",
      "Epoch 2 Step 176/1563 Loss: 1.571 | Acc: 43.079% (2440/5664)\n",
      "Epoch 2 Step 177/1563 Loss: 1.570 | Acc: 43.136% (2457/5696)\n",
      "Epoch 2 Step 178/1563 Loss: 1.568 | Acc: 43.209% (2475/5728)\n",
      "Epoch 2 Step 179/1563 Loss: 1.569 | Acc: 43.142% (2485/5760)\n",
      "Epoch 2 Step 180/1563 Loss: 1.569 | Acc: 43.146% (2499/5792)\n",
      "Epoch 2 Step 181/1563 Loss: 1.568 | Acc: 43.166% (2514/5824)\n",
      "Epoch 2 Step 182/1563 Loss: 1.566 | Acc: 43.255% (2533/5856)\n",
      "Epoch 2 Step 183/1563 Loss: 1.564 | Acc: 43.291% (2549/5888)\n",
      "Epoch 2 Step 184/1563 Loss: 1.565 | Acc: 43.294% (2563/5920)\n",
      "Epoch 2 Step 185/1563 Loss: 1.566 | Acc: 43.179% (2570/5952)\n",
      "Epoch 2 Step 186/1563 Loss: 1.565 | Acc: 43.232% (2587/5984)\n",
      "Epoch 2 Step 187/1563 Loss: 1.564 | Acc: 43.285% (2604/6016)\n",
      "Epoch 2 Step 188/1563 Loss: 1.564 | Acc: 43.320% (2620/6048)\n",
      "Epoch 2 Step 189/1563 Loss: 1.562 | Acc: 43.438% (2641/6080)\n",
      "Epoch 2 Step 190/1563 Loss: 1.562 | Acc: 43.455% (2656/6112)\n",
      "Epoch 2 Step 191/1563 Loss: 1.562 | Acc: 43.538% (2675/6144)\n",
      "Epoch 2 Step 192/1563 Loss: 1.561 | Acc: 43.604% (2693/6176)\n",
      "Epoch 2 Step 193/1563 Loss: 1.562 | Acc: 43.573% (2705/6208)\n",
      "Epoch 2 Step 194/1563 Loss: 1.562 | Acc: 43.590% (2720/6240)\n",
      "Epoch 2 Step 195/1563 Loss: 1.564 | Acc: 43.511% (2729/6272)\n",
      "Epoch 2 Step 196/1563 Loss: 1.565 | Acc: 43.512% (2743/6304)\n",
      "Epoch 2 Step 197/1563 Loss: 1.564 | Acc: 43.529% (2758/6336)\n",
      "Epoch 2 Step 198/1563 Loss: 1.563 | Acc: 43.562% (2774/6368)\n",
      "Epoch 2 Step 199/1563 Loss: 1.565 | Acc: 43.516% (2785/6400)\n",
      "Epoch 2 Step 200/1563 Loss: 1.564 | Acc: 43.424% (2793/6432)\n",
      "Epoch 2 Step 201/1563 Loss: 1.564 | Acc: 43.518% (2813/6464)\n",
      "Epoch 2 Step 202/1563 Loss: 1.564 | Acc: 43.519% (2827/6496)\n",
      "Epoch 2 Step 203/1563 Loss: 1.563 | Acc: 43.520% (2841/6528)\n",
      "Epoch 2 Step 204/1563 Loss: 1.563 | Acc: 43.537% (2856/6560)\n",
      "Epoch 2 Step 205/1563 Loss: 1.564 | Acc: 43.507% (2868/6592)\n",
      "Epoch 2 Step 206/1563 Loss: 1.563 | Acc: 43.524% (2883/6624)\n",
      "Epoch 2 Step 207/1563 Loss: 1.563 | Acc: 43.555% (2899/6656)\n",
      "Epoch 2 Step 208/1563 Loss: 1.562 | Acc: 43.541% (2912/6688)\n",
      "Epoch 2 Step 209/1563 Loss: 1.562 | Acc: 43.527% (2925/6720)\n",
      "Epoch 2 Step 210/1563 Loss: 1.562 | Acc: 43.572% (2942/6752)\n",
      "Epoch 2 Step 211/1563 Loss: 1.564 | Acc: 43.499% (2951/6784)\n",
      "Epoch 2 Step 212/1563 Loss: 1.563 | Acc: 43.515% (2966/6816)\n",
      "Epoch 2 Step 213/1563 Loss: 1.563 | Acc: 43.458% (2976/6848)\n",
      "Epoch 2 Step 214/1563 Loss: 1.564 | Acc: 43.430% (2988/6880)\n",
      "Epoch 2 Step 215/1563 Loss: 1.564 | Acc: 43.388% (2999/6912)\n",
      "Epoch 2 Step 216/1563 Loss: 1.566 | Acc: 43.318% (3008/6944)\n",
      "Epoch 2 Step 217/1563 Loss: 1.566 | Acc: 43.334% (3023/6976)\n",
      "Epoch 2 Step 218/1563 Loss: 1.567 | Acc: 43.322% (3036/7008)\n",
      "Epoch 2 Step 219/1563 Loss: 1.567 | Acc: 43.338% (3051/7040)\n",
      "Epoch 2 Step 220/1563 Loss: 1.567 | Acc: 43.326% (3064/7072)\n",
      "Epoch 2 Step 221/1563 Loss: 1.567 | Acc: 43.356% (3080/7104)\n",
      "Epoch 2 Step 222/1563 Loss: 1.566 | Acc: 43.386% (3096/7136)\n",
      "Epoch 2 Step 223/1563 Loss: 1.566 | Acc: 43.415% (3112/7168)\n",
      "Epoch 2 Step 224/1563 Loss: 1.568 | Acc: 43.361% (3122/7200)\n",
      "Epoch 2 Step 225/1563 Loss: 1.568 | Acc: 43.335% (3134/7232)\n",
      "Epoch 2 Step 226/1563 Loss: 1.568 | Acc: 43.323% (3147/7264)\n",
      "Epoch 2 Step 227/1563 Loss: 1.569 | Acc: 43.284% (3158/7296)\n",
      "Epoch 2 Step 228/1563 Loss: 1.569 | Acc: 43.313% (3174/7328)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 229/1563 Loss: 1.568 | Acc: 43.383% (3193/7360)\n",
      "Epoch 2 Step 230/1563 Loss: 1.567 | Acc: 43.385% (3207/7392)\n",
      "Epoch 2 Step 231/1563 Loss: 1.567 | Acc: 43.427% (3224/7424)\n",
      "Epoch 2 Step 232/1563 Loss: 1.567 | Acc: 43.415% (3237/7456)\n",
      "Epoch 2 Step 233/1563 Loss: 1.567 | Acc: 43.376% (3248/7488)\n",
      "Epoch 2 Step 234/1563 Loss: 1.569 | Acc: 43.338% (3259/7520)\n",
      "Epoch 2 Step 235/1563 Loss: 1.569 | Acc: 43.326% (3272/7552)\n",
      "Epoch 2 Step 236/1563 Loss: 1.569 | Acc: 43.354% (3288/7584)\n",
      "Epoch 2 Step 237/1563 Loss: 1.568 | Acc: 43.409% (3306/7616)\n",
      "Epoch 2 Step 238/1563 Loss: 1.568 | Acc: 43.358% (3316/7648)\n",
      "Epoch 2 Step 239/1563 Loss: 1.567 | Acc: 43.411% (3334/7680)\n",
      "Epoch 2 Step 240/1563 Loss: 1.566 | Acc: 43.426% (3349/7712)\n",
      "Epoch 2 Step 241/1563 Loss: 1.567 | Acc: 43.401% (3361/7744)\n",
      "Epoch 2 Step 242/1563 Loss: 1.568 | Acc: 43.313% (3368/7776)\n",
      "Epoch 2 Step 243/1563 Loss: 1.567 | Acc: 43.366% (3386/7808)\n",
      "Epoch 2 Step 244/1563 Loss: 1.569 | Acc: 43.355% (3399/7840)\n",
      "Epoch 2 Step 245/1563 Loss: 1.568 | Acc: 43.356% (3413/7872)\n",
      "Epoch 2 Step 246/1563 Loss: 1.568 | Acc: 43.320% (3424/7904)\n",
      "Epoch 2 Step 247/1563 Loss: 1.567 | Acc: 43.359% (3441/7936)\n",
      "Epoch 2 Step 248/1563 Loss: 1.567 | Acc: 43.336% (3453/7968)\n",
      "Epoch 2 Step 249/1563 Loss: 1.567 | Acc: 43.350% (3468/8000)\n",
      "Epoch 2 Step 250/1563 Loss: 1.567 | Acc: 43.339% (3481/8032)\n",
      "Epoch 2 Step 251/1563 Loss: 1.569 | Acc: 43.328% (3494/8064)\n",
      "Epoch 2 Step 252/1563 Loss: 1.568 | Acc: 43.342% (3509/8096)\n",
      "Epoch 2 Step 253/1563 Loss: 1.569 | Acc: 43.307% (3520/8128)\n",
      "Epoch 2 Step 254/1563 Loss: 1.570 | Acc: 43.272% (3531/8160)\n",
      "Epoch 2 Step 255/1563 Loss: 1.569 | Acc: 43.286% (3546/8192)\n",
      "Epoch 2 Step 256/1563 Loss: 1.569 | Acc: 43.324% (3563/8224)\n",
      "Epoch 2 Step 257/1563 Loss: 1.569 | Acc: 43.362% (3580/8256)\n",
      "Epoch 2 Step 258/1563 Loss: 1.568 | Acc: 43.376% (3595/8288)\n",
      "Epoch 2 Step 259/1563 Loss: 1.568 | Acc: 43.377% (3609/8320)\n",
      "Epoch 2 Step 260/1563 Loss: 1.569 | Acc: 43.319% (3618/8352)\n",
      "Epoch 2 Step 261/1563 Loss: 1.569 | Acc: 43.309% (3631/8384)\n",
      "Epoch 2 Step 262/1563 Loss: 1.570 | Acc: 43.239% (3639/8416)\n",
      "Epoch 2 Step 263/1563 Loss: 1.568 | Acc: 43.300% (3658/8448)\n",
      "Epoch 2 Step 264/1563 Loss: 1.568 | Acc: 43.337% (3675/8480)\n",
      "Epoch 2 Step 265/1563 Loss: 1.568 | Acc: 43.351% (3690/8512)\n",
      "Epoch 2 Step 266/1563 Loss: 1.567 | Acc: 43.399% (3708/8544)\n",
      "Epoch 2 Step 267/1563 Loss: 1.567 | Acc: 43.400% (3722/8576)\n",
      "Epoch 2 Step 268/1563 Loss: 1.567 | Acc: 43.401% (3736/8608)\n",
      "Epoch 2 Step 269/1563 Loss: 1.568 | Acc: 43.368% (3747/8640)\n",
      "Epoch 2 Step 270/1563 Loss: 1.567 | Acc: 43.369% (3761/8672)\n",
      "Epoch 2 Step 271/1563 Loss: 1.567 | Acc: 43.371% (3775/8704)\n",
      "Epoch 2 Step 272/1563 Loss: 1.568 | Acc: 43.349% (3787/8736)\n",
      "Epoch 2 Step 273/1563 Loss: 1.567 | Acc: 43.396% (3805/8768)\n",
      "Epoch 2 Step 274/1563 Loss: 1.568 | Acc: 43.386% (3818/8800)\n",
      "Epoch 2 Step 275/1563 Loss: 1.568 | Acc: 43.365% (3830/8832)\n",
      "Epoch 2 Step 276/1563 Loss: 1.569 | Acc: 43.321% (3840/8864)\n",
      "Epoch 2 Step 277/1563 Loss: 1.568 | Acc: 43.323% (3854/8896)\n",
      "Epoch 2 Step 278/1563 Loss: 1.567 | Acc: 43.336% (3869/8928)\n",
      "Epoch 2 Step 279/1563 Loss: 1.568 | Acc: 43.359% (3885/8960)\n",
      "Epoch 2 Step 280/1563 Loss: 1.567 | Acc: 43.383% (3901/8992)\n",
      "Epoch 2 Step 281/1563 Loss: 1.567 | Acc: 43.384% (3915/9024)\n",
      "Epoch 2 Step 282/1563 Loss: 1.568 | Acc: 43.341% (3925/9056)\n",
      "Epoch 2 Step 283/1563 Loss: 1.568 | Acc: 43.332% (3938/9088)\n",
      "Epoch 2 Step 284/1563 Loss: 1.569 | Acc: 43.311% (3950/9120)\n",
      "Epoch 2 Step 285/1563 Loss: 1.569 | Acc: 43.302% (3963/9152)\n",
      "Epoch 2 Step 286/1563 Loss: 1.569 | Acc: 43.314% (3978/9184)\n",
      "Epoch 2 Step 287/1563 Loss: 1.569 | Acc: 43.305% (3991/9216)\n",
      "Epoch 2 Step 288/1563 Loss: 1.569 | Acc: 43.274% (4002/9248)\n",
      "Epoch 2 Step 289/1563 Loss: 1.570 | Acc: 43.254% (4014/9280)\n",
      "Epoch 2 Step 290/1563 Loss: 1.570 | Acc: 43.267% (4029/9312)\n",
      "Epoch 2 Step 291/1563 Loss: 1.570 | Acc: 43.268% (4043/9344)\n",
      "Epoch 2 Step 292/1563 Loss: 1.569 | Acc: 43.291% (4059/9376)\n",
      "Epoch 2 Step 293/1563 Loss: 1.570 | Acc: 43.261% (4070/9408)\n",
      "Epoch 2 Step 294/1563 Loss: 1.571 | Acc: 43.199% (4078/9440)\n",
      "Epoch 2 Step 295/1563 Loss: 1.572 | Acc: 43.138% (4086/9472)\n",
      "Epoch 2 Step 296/1563 Loss: 1.571 | Acc: 43.192% (4105/9504)\n",
      "Epoch 2 Step 297/1563 Loss: 1.572 | Acc: 43.184% (4118/9536)\n",
      "Epoch 2 Step 298/1563 Loss: 1.571 | Acc: 43.175% (4131/9568)\n",
      "Epoch 2 Step 299/1563 Loss: 1.571 | Acc: 43.115% (4139/9600)\n",
      "Epoch 2 Step 300/1563 Loss: 1.572 | Acc: 43.137% (4155/9632)\n",
      "Epoch 2 Step 301/1563 Loss: 1.571 | Acc: 43.171% (4172/9664)\n",
      "Epoch 2 Step 302/1563 Loss: 1.572 | Acc: 43.193% (4188/9696)\n",
      "Epoch 2 Step 303/1563 Loss: 1.571 | Acc: 43.205% (4203/9728)\n",
      "Epoch 2 Step 304/1563 Loss: 1.570 | Acc: 43.238% (4220/9760)\n",
      "Epoch 2 Step 305/1563 Loss: 1.570 | Acc: 43.290% (4239/9792)\n",
      "Epoch 2 Step 306/1563 Loss: 1.569 | Acc: 43.302% (4254/9824)\n",
      "Epoch 2 Step 307/1563 Loss: 1.568 | Acc: 43.324% (4270/9856)\n",
      "Epoch 2 Step 308/1563 Loss: 1.567 | Acc: 43.376% (4289/9888)\n",
      "Epoch 2 Step 309/1563 Loss: 1.567 | Acc: 43.377% (4303/9920)\n",
      "Epoch 2 Step 310/1563 Loss: 1.568 | Acc: 43.358% (4315/9952)\n",
      "Epoch 2 Step 311/1563 Loss: 1.567 | Acc: 43.379% (4331/9984)\n",
      "Epoch 2 Step 312/1563 Loss: 1.566 | Acc: 43.440% (4351/10016)\n",
      "Epoch 2 Step 313/1563 Loss: 1.566 | Acc: 43.402% (4361/10048)\n",
      "Epoch 2 Step 314/1563 Loss: 1.567 | Acc: 43.383% (4373/10080)\n",
      "Epoch 2 Step 315/1563 Loss: 1.567 | Acc: 43.394% (4388/10112)\n",
      "Epoch 2 Step 316/1563 Loss: 1.567 | Acc: 43.405% (4403/10144)\n",
      "Epoch 2 Step 317/1563 Loss: 1.567 | Acc: 43.406% (4417/10176)\n",
      "Epoch 2 Step 318/1563 Loss: 1.567 | Acc: 43.388% (4429/10208)\n",
      "Epoch 2 Step 319/1563 Loss: 1.567 | Acc: 43.369% (4441/10240)\n",
      "Epoch 2 Step 320/1563 Loss: 1.567 | Acc: 43.331% (4451/10272)\n",
      "Epoch 2 Step 321/1563 Loss: 1.567 | Acc: 43.323% (4464/10304)\n",
      "Epoch 2 Step 322/1563 Loss: 1.566 | Acc: 43.344% (4480/10336)\n",
      "Epoch 2 Step 323/1563 Loss: 1.566 | Acc: 43.355% (4495/10368)\n",
      "Epoch 2 Step 324/1563 Loss: 1.565 | Acc: 43.375% (4511/10400)\n",
      "Epoch 2 Step 325/1563 Loss: 1.565 | Acc: 43.386% (4526/10432)\n",
      "Epoch 2 Step 326/1563 Loss: 1.564 | Acc: 43.416% (4543/10464)\n",
      "Epoch 2 Step 327/1563 Loss: 1.564 | Acc: 43.436% (4559/10496)\n",
      "Epoch 2 Step 328/1563 Loss: 1.564 | Acc: 43.427% (4572/10528)\n",
      "Epoch 2 Step 329/1563 Loss: 1.565 | Acc: 43.371% (4580/10560)\n",
      "Epoch 2 Step 330/1563 Loss: 1.565 | Acc: 43.420% (4599/10592)\n",
      "Epoch 2 Step 331/1563 Loss: 1.565 | Acc: 43.383% (4609/10624)\n",
      "Epoch 2 Step 332/1563 Loss: 1.565 | Acc: 43.337% (4618/10656)\n",
      "Epoch 2 Step 333/1563 Loss: 1.564 | Acc: 43.394% (4638/10688)\n",
      "Epoch 2 Step 334/1563 Loss: 1.564 | Acc: 43.386% (4651/10720)\n",
      "Epoch 2 Step 335/1563 Loss: 1.564 | Acc: 43.359% (4662/10752)\n",
      "Epoch 2 Step 336/1563 Loss: 1.565 | Acc: 43.342% (4674/10784)\n",
      "Epoch 2 Step 337/1563 Loss: 1.565 | Acc: 43.352% (4689/10816)\n",
      "Epoch 2 Step 338/1563 Loss: 1.566 | Acc: 43.289% (4696/10848)\n",
      "Epoch 2 Step 339/1563 Loss: 1.567 | Acc: 43.272% (4708/10880)\n",
      "Epoch 2 Step 340/1563 Loss: 1.566 | Acc: 43.283% (4723/10912)\n",
      "Epoch 2 Step 341/1563 Loss: 1.565 | Acc: 43.293% (4738/10944)\n",
      "Epoch 2 Step 342/1563 Loss: 1.566 | Acc: 43.267% (4749/10976)\n",
      "Epoch 2 Step 343/1563 Loss: 1.566 | Acc: 43.278% (4764/11008)\n",
      "Epoch 2 Step 344/1563 Loss: 1.565 | Acc: 43.315% (4782/11040)\n",
      "Epoch 2 Step 345/1563 Loss: 1.565 | Acc: 43.307% (4795/11072)\n",
      "Epoch 2 Step 346/1563 Loss: 1.565 | Acc: 43.291% (4807/11104)\n",
      "Epoch 2 Step 347/1563 Loss: 1.565 | Acc: 43.319% (4824/11136)\n",
      "Epoch 2 Step 348/1563 Loss: 1.565 | Acc: 43.329% (4839/11168)\n",
      "Epoch 2 Step 349/1563 Loss: 1.564 | Acc: 43.312% (4851/11200)\n",
      "Epoch 2 Step 350/1563 Loss: 1.564 | Acc: 43.269% (4860/11232)\n",
      "Epoch 2 Step 351/1563 Loss: 1.564 | Acc: 43.297% (4877/11264)\n",
      "Epoch 2 Step 352/1563 Loss: 1.563 | Acc: 43.343% (4896/11296)\n",
      "Epoch 2 Step 353/1563 Loss: 1.564 | Acc: 43.309% (4906/11328)\n",
      "Epoch 2 Step 354/1563 Loss: 1.565 | Acc: 43.301% (4919/11360)\n",
      "Epoch 2 Step 355/1563 Loss: 1.565 | Acc: 43.294% (4932/11392)\n",
      "Epoch 2 Step 356/1563 Loss: 1.565 | Acc: 43.321% (4949/11424)\n",
      "Epoch 2 Step 357/1563 Loss: 1.565 | Acc: 43.305% (4961/11456)\n",
      "Epoch 2 Step 358/1563 Loss: 1.566 | Acc: 43.297% (4974/11488)\n",
      "Epoch 2 Step 359/1563 Loss: 1.567 | Acc: 43.316% (4990/11520)\n",
      "Epoch 2 Step 360/1563 Loss: 1.566 | Acc: 43.369% (5010/11552)\n",
      "Epoch 2 Step 361/1563 Loss: 1.566 | Acc: 43.379% (5025/11584)\n",
      "Epoch 2 Step 362/1563 Loss: 1.566 | Acc: 43.371% (5038/11616)\n",
      "Epoch 2 Step 363/1563 Loss: 1.566 | Acc: 43.355% (5050/11648)\n",
      "Epoch 2 Step 364/1563 Loss: 1.566 | Acc: 43.382% (5067/11680)\n",
      "Epoch 2 Step 365/1563 Loss: 1.565 | Acc: 43.408% (5084/11712)\n",
      "Epoch 2 Step 366/1563 Loss: 1.566 | Acc: 43.392% (5096/11744)\n",
      "Epoch 2 Step 367/1563 Loss: 1.566 | Acc: 43.402% (5111/11776)\n",
      "Epoch 2 Step 368/1563 Loss: 1.566 | Acc: 43.377% (5122/11808)\n",
      "Epoch 2 Step 369/1563 Loss: 1.566 | Acc: 43.378% (5136/11840)\n",
      "Epoch 2 Step 370/1563 Loss: 1.566 | Acc: 43.388% (5151/11872)\n",
      "Epoch 2 Step 371/1563 Loss: 1.567 | Acc: 43.389% (5165/11904)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 372/1563 Loss: 1.566 | Acc: 43.415% (5182/11936)\n",
      "Epoch 2 Step 373/1563 Loss: 1.565 | Acc: 43.441% (5199/11968)\n",
      "Epoch 2 Step 374/1563 Loss: 1.565 | Acc: 43.467% (5216/12000)\n",
      "Epoch 2 Step 375/1563 Loss: 1.564 | Acc: 43.542% (5239/12032)\n",
      "Epoch 2 Step 376/1563 Loss: 1.564 | Acc: 43.518% (5250/12064)\n",
      "Epoch 2 Step 377/1563 Loss: 1.563 | Acc: 43.543% (5267/12096)\n",
      "Epoch 2 Step 378/1563 Loss: 1.564 | Acc: 43.511% (5277/12128)\n",
      "Epoch 2 Step 379/1563 Loss: 1.564 | Acc: 43.520% (5292/12160)\n",
      "Epoch 2 Step 380/1563 Loss: 1.564 | Acc: 43.504% (5304/12192)\n",
      "Epoch 2 Step 381/1563 Loss: 1.565 | Acc: 43.496% (5317/12224)\n",
      "Epoch 2 Step 382/1563 Loss: 1.566 | Acc: 43.464% (5327/12256)\n",
      "Epoch 2 Step 383/1563 Loss: 1.566 | Acc: 43.465% (5341/12288)\n",
      "Epoch 2 Step 384/1563 Loss: 1.566 | Acc: 43.433% (5351/12320)\n",
      "Epoch 2 Step 385/1563 Loss: 1.566 | Acc: 43.434% (5365/12352)\n",
      "Epoch 2 Step 386/1563 Loss: 1.566 | Acc: 43.451% (5381/12384)\n",
      "Epoch 2 Step 387/1563 Loss: 1.567 | Acc: 43.412% (5390/12416)\n",
      "Epoch 2 Step 388/1563 Loss: 1.567 | Acc: 43.397% (5402/12448)\n",
      "Epoch 2 Step 389/1563 Loss: 1.567 | Acc: 43.381% (5414/12480)\n",
      "Epoch 2 Step 390/1563 Loss: 1.567 | Acc: 43.366% (5426/12512)\n",
      "Epoch 2 Step 391/1563 Loss: 1.568 | Acc: 43.343% (5437/12544)\n",
      "Epoch 2 Step 392/1563 Loss: 1.567 | Acc: 43.376% (5455/12576)\n",
      "Epoch 2 Step 393/1563 Loss: 1.567 | Acc: 43.361% (5467/12608)\n",
      "Epoch 2 Step 394/1563 Loss: 1.567 | Acc: 43.347% (5479/12640)\n",
      "Epoch 2 Step 395/1563 Loss: 1.567 | Acc: 43.411% (5501/12672)\n",
      "Epoch 2 Step 396/1563 Loss: 1.566 | Acc: 43.459% (5521/12704)\n",
      "Epoch 2 Step 397/1563 Loss: 1.566 | Acc: 43.459% (5535/12736)\n",
      "Epoch 2 Step 398/1563 Loss: 1.566 | Acc: 43.460% (5549/12768)\n",
      "Epoch 2 Step 399/1563 Loss: 1.566 | Acc: 43.445% (5561/12800)\n",
      "Epoch 2 Step 400/1563 Loss: 1.566 | Acc: 43.469% (5578/12832)\n",
      "Epoch 2 Step 401/1563 Loss: 1.566 | Acc: 43.478% (5593/12864)\n",
      "Epoch 2 Step 402/1563 Loss: 1.565 | Acc: 43.471% (5606/12896)\n",
      "Epoch 2 Step 403/1563 Loss: 1.566 | Acc: 43.456% (5618/12928)\n",
      "Epoch 2 Step 404/1563 Loss: 1.566 | Acc: 43.465% (5633/12960)\n",
      "Epoch 2 Step 405/1563 Loss: 1.567 | Acc: 43.434% (5643/12992)\n",
      "Epoch 2 Step 406/1563 Loss: 1.567 | Acc: 43.412% (5654/13024)\n",
      "Epoch 2 Step 407/1563 Loss: 1.567 | Acc: 43.390% (5665/13056)\n",
      "Epoch 2 Step 408/1563 Loss: 1.567 | Acc: 43.414% (5682/13088)\n",
      "Epoch 2 Step 409/1563 Loss: 1.566 | Acc: 43.392% (5693/13120)\n",
      "Epoch 2 Step 410/1563 Loss: 1.565 | Acc: 43.431% (5712/13152)\n",
      "Epoch 2 Step 411/1563 Loss: 1.565 | Acc: 43.424% (5725/13184)\n",
      "Epoch 2 Step 412/1563 Loss: 1.566 | Acc: 43.402% (5736/13216)\n",
      "Epoch 2 Step 413/1563 Loss: 1.566 | Acc: 43.410% (5751/13248)\n",
      "Epoch 2 Step 414/1563 Loss: 1.565 | Acc: 43.411% (5765/13280)\n",
      "Epoch 2 Step 415/1563 Loss: 1.565 | Acc: 43.412% (5779/13312)\n",
      "Epoch 2 Step 416/1563 Loss: 1.566 | Acc: 43.413% (5793/13344)\n",
      "Epoch 2 Step 417/1563 Loss: 1.565 | Acc: 43.421% (5808/13376)\n",
      "Epoch 2 Step 418/1563 Loss: 1.565 | Acc: 43.437% (5824/13408)\n",
      "Epoch 2 Step 419/1563 Loss: 1.565 | Acc: 43.430% (5837/13440)\n",
      "Epoch 2 Step 420/1563 Loss: 1.565 | Acc: 43.431% (5851/13472)\n",
      "Epoch 2 Step 421/1563 Loss: 1.565 | Acc: 43.446% (5867/13504)\n",
      "Epoch 2 Step 422/1563 Loss: 1.564 | Acc: 43.469% (5884/13536)\n",
      "Epoch 2 Step 423/1563 Loss: 1.564 | Acc: 43.485% (5900/13568)\n",
      "Epoch 2 Step 424/1563 Loss: 1.563 | Acc: 43.507% (5917/13600)\n",
      "Epoch 2 Step 425/1563 Loss: 1.563 | Acc: 43.523% (5933/13632)\n",
      "Epoch 2 Step 426/1563 Loss: 1.564 | Acc: 43.523% (5947/13664)\n",
      "Epoch 2 Step 427/1563 Loss: 1.563 | Acc: 43.560% (5966/13696)\n",
      "Epoch 2 Step 428/1563 Loss: 1.563 | Acc: 43.568% (5981/13728)\n",
      "Epoch 2 Step 429/1563 Loss: 1.563 | Acc: 43.554% (5993/13760)\n",
      "Epoch 2 Step 430/1563 Loss: 1.562 | Acc: 43.590% (6012/13792)\n",
      "Epoch 2 Step 431/1563 Loss: 1.563 | Acc: 43.569% (6023/13824)\n",
      "Epoch 2 Step 432/1563 Loss: 1.563 | Acc: 43.584% (6039/13856)\n",
      "Epoch 2 Step 433/1563 Loss: 1.563 | Acc: 43.592% (6054/13888)\n",
      "Epoch 2 Step 434/1563 Loss: 1.563 | Acc: 43.578% (6066/13920)\n",
      "Epoch 2 Step 435/1563 Loss: 1.564 | Acc: 43.556% (6077/13952)\n",
      "Epoch 2 Step 436/1563 Loss: 1.563 | Acc: 43.557% (6091/13984)\n",
      "Epoch 2 Step 437/1563 Loss: 1.563 | Acc: 43.579% (6108/14016)\n",
      "Epoch 2 Step 438/1563 Loss: 1.563 | Acc: 43.565% (6120/14048)\n",
      "Epoch 2 Step 439/1563 Loss: 1.563 | Acc: 43.601% (6139/14080)\n",
      "Epoch 2 Step 440/1563 Loss: 1.563 | Acc: 43.587% (6151/14112)\n",
      "Epoch 2 Step 441/1563 Loss: 1.562 | Acc: 43.616% (6169/14144)\n",
      "Epoch 2 Step 442/1563 Loss: 1.563 | Acc: 43.623% (6184/14176)\n",
      "Epoch 2 Step 443/1563 Loss: 1.562 | Acc: 43.630% (6199/14208)\n",
      "Epoch 2 Step 444/1563 Loss: 1.562 | Acc: 43.666% (6218/14240)\n",
      "Epoch 2 Step 445/1563 Loss: 1.561 | Acc: 43.708% (6238/14272)\n",
      "Epoch 2 Step 446/1563 Loss: 1.561 | Acc: 43.708% (6252/14304)\n",
      "Epoch 2 Step 447/1563 Loss: 1.561 | Acc: 43.743% (6271/14336)\n",
      "Epoch 2 Step 448/1563 Loss: 1.561 | Acc: 43.764% (6288/14368)\n",
      "Epoch 2 Step 449/1563 Loss: 1.560 | Acc: 43.792% (6306/14400)\n",
      "Epoch 2 Step 450/1563 Loss: 1.560 | Acc: 43.792% (6320/14432)\n",
      "Epoch 2 Step 451/1563 Loss: 1.560 | Acc: 43.764% (6330/14464)\n",
      "Epoch 2 Step 452/1563 Loss: 1.560 | Acc: 43.757% (6343/14496)\n",
      "Epoch 2 Step 453/1563 Loss: 1.560 | Acc: 43.743% (6355/14528)\n",
      "Epoch 2 Step 454/1563 Loss: 1.560 | Acc: 43.750% (6370/14560)\n",
      "Epoch 2 Step 455/1563 Loss: 1.560 | Acc: 43.743% (6383/14592)\n",
      "Epoch 2 Step 456/1563 Loss: 1.560 | Acc: 43.757% (6399/14624)\n",
      "Epoch 2 Step 457/1563 Loss: 1.560 | Acc: 43.750% (6412/14656)\n",
      "Epoch 2 Step 458/1563 Loss: 1.560 | Acc: 43.757% (6427/14688)\n",
      "Epoch 2 Step 459/1563 Loss: 1.559 | Acc: 43.791% (6446/14720)\n",
      "Epoch 2 Step 460/1563 Loss: 1.559 | Acc: 43.797% (6461/14752)\n",
      "Epoch 2 Step 461/1563 Loss: 1.560 | Acc: 43.797% (6475/14784)\n",
      "Epoch 2 Step 462/1563 Loss: 1.559 | Acc: 43.831% (6494/14816)\n",
      "Epoch 2 Step 463/1563 Loss: 1.559 | Acc: 43.838% (6509/14848)\n",
      "Epoch 2 Step 464/1563 Loss: 1.558 | Acc: 43.851% (6525/14880)\n",
      "Epoch 2 Step 465/1563 Loss: 1.558 | Acc: 43.871% (6542/14912)\n",
      "Epoch 2 Step 466/1563 Loss: 1.558 | Acc: 43.864% (6555/14944)\n",
      "Epoch 2 Step 467/1563 Loss: 1.558 | Acc: 43.850% (6567/14976)\n",
      "Epoch 2 Step 468/1563 Loss: 1.558 | Acc: 43.870% (6584/15008)\n",
      "Epoch 2 Step 469/1563 Loss: 1.558 | Acc: 43.903% (6603/15040)\n",
      "Epoch 2 Step 470/1563 Loss: 1.558 | Acc: 43.903% (6617/15072)\n",
      "Epoch 2 Step 471/1563 Loss: 1.558 | Acc: 43.902% (6631/15104)\n",
      "Epoch 2 Step 472/1563 Loss: 1.558 | Acc: 43.889% (6643/15136)\n",
      "Epoch 2 Step 473/1563 Loss: 1.558 | Acc: 43.908% (6660/15168)\n",
      "Epoch 2 Step 474/1563 Loss: 1.557 | Acc: 43.941% (6679/15200)\n",
      "Epoch 2 Step 475/1563 Loss: 1.557 | Acc: 43.921% (6690/15232)\n",
      "Epoch 2 Step 476/1563 Loss: 1.557 | Acc: 43.953% (6709/15264)\n",
      "Epoch 2 Step 477/1563 Loss: 1.557 | Acc: 43.940% (6721/15296)\n",
      "Epoch 2 Step 478/1563 Loss: 1.557 | Acc: 43.939% (6735/15328)\n",
      "Epoch 2 Step 479/1563 Loss: 1.557 | Acc: 43.945% (6750/15360)\n",
      "Epoch 2 Step 480/1563 Loss: 1.557 | Acc: 43.938% (6763/15392)\n",
      "Epoch 2 Step 481/1563 Loss: 1.557 | Acc: 43.919% (6774/15424)\n",
      "Epoch 2 Step 482/1563 Loss: 1.556 | Acc: 43.931% (6790/15456)\n",
      "Epoch 2 Step 483/1563 Loss: 1.556 | Acc: 43.918% (6802/15488)\n",
      "Epoch 2 Step 484/1563 Loss: 1.556 | Acc: 43.930% (6818/15520)\n",
      "Epoch 2 Step 485/1563 Loss: 1.557 | Acc: 43.917% (6830/15552)\n",
      "Epoch 2 Step 486/1563 Loss: 1.556 | Acc: 43.943% (6848/15584)\n",
      "Epoch 2 Step 487/1563 Loss: 1.556 | Acc: 43.929% (6860/15616)\n",
      "Epoch 2 Step 488/1563 Loss: 1.556 | Acc: 43.929% (6874/15648)\n",
      "Epoch 2 Step 489/1563 Loss: 1.556 | Acc: 43.941% (6890/15680)\n",
      "Epoch 2 Step 490/1563 Loss: 1.557 | Acc: 43.960% (6907/15712)\n",
      "Epoch 2 Step 491/1563 Loss: 1.556 | Acc: 43.979% (6924/15744)\n",
      "Epoch 2 Step 492/1563 Loss: 1.557 | Acc: 43.940% (6932/15776)\n",
      "Epoch 2 Step 493/1563 Loss: 1.557 | Acc: 43.940% (6946/15808)\n",
      "Epoch 2 Step 494/1563 Loss: 1.557 | Acc: 43.939% (6960/15840)\n",
      "Epoch 2 Step 495/1563 Loss: 1.557 | Acc: 43.958% (6977/15872)\n",
      "Epoch 2 Step 496/1563 Loss: 1.557 | Acc: 43.913% (6984/15904)\n",
      "Epoch 2 Step 497/1563 Loss: 1.557 | Acc: 43.907% (6997/15936)\n",
      "Epoch 2 Step 498/1563 Loss: 1.558 | Acc: 43.907% (7011/15968)\n",
      "Epoch 2 Step 499/1563 Loss: 1.558 | Acc: 43.900% (7024/16000)\n",
      "Epoch 2 Step 500/1563 Loss: 1.558 | Acc: 43.906% (7039/16032)\n",
      "Epoch 2 Step 501/1563 Loss: 1.558 | Acc: 43.912% (7054/16064)\n",
      "Epoch 2 Step 502/1563 Loss: 1.558 | Acc: 43.924% (7070/16096)\n",
      "Epoch 2 Step 503/1563 Loss: 1.559 | Acc: 43.911% (7082/16128)\n",
      "Epoch 2 Step 504/1563 Loss: 1.559 | Acc: 43.892% (7093/16160)\n",
      "Epoch 2 Step 505/1563 Loss: 1.559 | Acc: 43.867% (7103/16192)\n",
      "Epoch 2 Step 506/1563 Loss: 1.559 | Acc: 43.892% (7121/16224)\n",
      "Epoch 2 Step 507/1563 Loss: 1.558 | Acc: 43.898% (7136/16256)\n",
      "Epoch 2 Step 508/1563 Loss: 1.559 | Acc: 43.891% (7149/16288)\n",
      "Epoch 2 Step 509/1563 Loss: 1.558 | Acc: 43.903% (7165/16320)\n",
      "Epoch 2 Step 510/1563 Loss: 1.558 | Acc: 43.903% (7179/16352)\n",
      "Epoch 2 Step 511/1563 Loss: 1.558 | Acc: 43.903% (7193/16384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 512/1563 Loss: 1.559 | Acc: 43.878% (7203/16416)\n",
      "Epoch 2 Step 513/1563 Loss: 1.559 | Acc: 43.872% (7216/16448)\n",
      "Epoch 2 Step 514/1563 Loss: 1.559 | Acc: 43.871% (7230/16480)\n",
      "Epoch 2 Step 515/1563 Loss: 1.559 | Acc: 43.847% (7240/16512)\n",
      "Epoch 2 Step 516/1563 Loss: 1.560 | Acc: 43.835% (7252/16544)\n",
      "Epoch 2 Step 517/1563 Loss: 1.560 | Acc: 43.865% (7271/16576)\n",
      "Epoch 2 Step 518/1563 Loss: 1.560 | Acc: 43.858% (7284/16608)\n",
      "Epoch 2 Step 519/1563 Loss: 1.560 | Acc: 43.852% (7297/16640)\n",
      "Epoch 2 Step 520/1563 Loss: 1.560 | Acc: 43.834% (7308/16672)\n",
      "Epoch 2 Step 521/1563 Loss: 1.559 | Acc: 43.840% (7323/16704)\n",
      "Epoch 2 Step 522/1563 Loss: 1.560 | Acc: 43.840% (7337/16736)\n",
      "Epoch 2 Step 523/1563 Loss: 1.559 | Acc: 43.839% (7351/16768)\n",
      "Epoch 2 Step 524/1563 Loss: 1.560 | Acc: 43.839% (7365/16800)\n",
      "Epoch 2 Step 525/1563 Loss: 1.560 | Acc: 43.833% (7378/16832)\n",
      "Epoch 2 Step 526/1563 Loss: 1.560 | Acc: 43.809% (7388/16864)\n",
      "Epoch 2 Step 527/1563 Loss: 1.560 | Acc: 43.797% (7400/16896)\n",
      "Epoch 2 Step 528/1563 Loss: 1.560 | Acc: 43.797% (7414/16928)\n",
      "Epoch 2 Step 529/1563 Loss: 1.560 | Acc: 43.797% (7428/16960)\n",
      "Epoch 2 Step 530/1563 Loss: 1.560 | Acc: 43.815% (7445/16992)\n",
      "Epoch 2 Step 531/1563 Loss: 1.559 | Acc: 43.832% (7462/17024)\n",
      "Epoch 2 Step 532/1563 Loss: 1.560 | Acc: 43.832% (7476/17056)\n",
      "Epoch 2 Step 533/1563 Loss: 1.559 | Acc: 43.820% (7488/17088)\n",
      "Epoch 2 Step 534/1563 Loss: 1.559 | Acc: 43.838% (7505/17120)\n",
      "Epoch 2 Step 535/1563 Loss: 1.559 | Acc: 43.837% (7519/17152)\n",
      "Epoch 2 Step 536/1563 Loss: 1.559 | Acc: 43.837% (7533/17184)\n",
      "Epoch 2 Step 537/1563 Loss: 1.559 | Acc: 43.837% (7547/17216)\n",
      "Epoch 2 Step 538/1563 Loss: 1.559 | Acc: 43.843% (7562/17248)\n",
      "Epoch 2 Step 539/1563 Loss: 1.559 | Acc: 43.831% (7574/17280)\n",
      "Epoch 2 Step 540/1563 Loss: 1.559 | Acc: 43.802% (7583/17312)\n",
      "Epoch 2 Step 541/1563 Loss: 1.559 | Acc: 43.796% (7596/17344)\n",
      "Epoch 2 Step 542/1563 Loss: 1.559 | Acc: 43.785% (7608/17376)\n",
      "Epoch 2 Step 543/1563 Loss: 1.560 | Acc: 43.779% (7621/17408)\n",
      "Epoch 2 Step 544/1563 Loss: 1.560 | Acc: 43.767% (7633/17440)\n",
      "Epoch 2 Step 545/1563 Loss: 1.560 | Acc: 43.790% (7651/17472)\n",
      "Epoch 2 Step 546/1563 Loss: 1.560 | Acc: 43.801% (7667/17504)\n",
      "Epoch 2 Step 547/1563 Loss: 1.560 | Acc: 43.801% (7681/17536)\n",
      "Epoch 2 Step 548/1563 Loss: 1.561 | Acc: 43.767% (7689/17568)\n",
      "Epoch 2 Step 549/1563 Loss: 1.561 | Acc: 43.773% (7704/17600)\n",
      "Epoch 2 Step 550/1563 Loss: 1.561 | Acc: 43.778% (7719/17632)\n",
      "Epoch 2 Step 551/1563 Loss: 1.560 | Acc: 43.801% (7737/17664)\n",
      "Epoch 2 Step 552/1563 Loss: 1.560 | Acc: 43.829% (7756/17696)\n",
      "Epoch 2 Step 553/1563 Loss: 1.559 | Acc: 43.829% (7770/17728)\n",
      "Epoch 2 Step 554/1563 Loss: 1.560 | Acc: 43.806% (7780/17760)\n",
      "Epoch 2 Step 555/1563 Loss: 1.560 | Acc: 43.812% (7795/17792)\n",
      "Epoch 2 Step 556/1563 Loss: 1.559 | Acc: 43.823% (7811/17824)\n",
      "Epoch 2 Step 557/1563 Loss: 1.559 | Acc: 43.834% (7827/17856)\n",
      "Epoch 2 Step 558/1563 Loss: 1.559 | Acc: 43.839% (7842/17888)\n",
      "Epoch 2 Step 559/1563 Loss: 1.559 | Acc: 43.828% (7854/17920)\n",
      "Epoch 2 Step 560/1563 Loss: 1.559 | Acc: 43.822% (7867/17952)\n",
      "Epoch 2 Step 561/1563 Loss: 1.559 | Acc: 43.833% (7883/17984)\n",
      "Epoch 2 Step 562/1563 Loss: 1.559 | Acc: 43.817% (7894/18016)\n",
      "Epoch 2 Step 563/1563 Loss: 1.559 | Acc: 43.822% (7909/18048)\n",
      "Epoch 2 Step 564/1563 Loss: 1.559 | Acc: 43.844% (7927/18080)\n",
      "Epoch 2 Step 565/1563 Loss: 1.559 | Acc: 43.816% (7936/18112)\n",
      "Epoch 2 Step 566/1563 Loss: 1.559 | Acc: 43.800% (7947/18144)\n",
      "Epoch 2 Step 567/1563 Loss: 1.559 | Acc: 43.822% (7965/18176)\n",
      "Epoch 2 Step 568/1563 Loss: 1.558 | Acc: 43.865% (7987/18208)\n",
      "Epoch 2 Step 569/1563 Loss: 1.559 | Acc: 43.876% (8003/18240)\n",
      "Epoch 2 Step 570/1563 Loss: 1.558 | Acc: 43.887% (8019/18272)\n",
      "Epoch 2 Step 571/1563 Loss: 1.558 | Acc: 43.898% (8035/18304)\n",
      "Epoch 2 Step 572/1563 Loss: 1.557 | Acc: 43.930% (8055/18336)\n",
      "Epoch 2 Step 573/1563 Loss: 1.557 | Acc: 43.924% (8068/18368)\n",
      "Epoch 2 Step 574/1563 Loss: 1.557 | Acc: 43.935% (8084/18400)\n",
      "Epoch 2 Step 575/1563 Loss: 1.557 | Acc: 43.940% (8099/18432)\n",
      "Epoch 2 Step 576/1563 Loss: 1.558 | Acc: 43.923% (8110/18464)\n",
      "Epoch 2 Step 577/1563 Loss: 1.558 | Acc: 43.896% (8119/18496)\n",
      "Epoch 2 Step 578/1563 Loss: 1.558 | Acc: 43.901% (8134/18528)\n",
      "Epoch 2 Step 579/1563 Loss: 1.558 | Acc: 43.895% (8147/18560)\n",
      "Epoch 2 Step 580/1563 Loss: 1.558 | Acc: 43.890% (8160/18592)\n",
      "Epoch 2 Step 581/1563 Loss: 1.558 | Acc: 43.900% (8176/18624)\n",
      "Epoch 2 Step 582/1563 Loss: 1.558 | Acc: 43.884% (8187/18656)\n",
      "Epoch 2 Step 583/1563 Loss: 1.558 | Acc: 43.878% (8200/18688)\n",
      "Epoch 2 Step 584/1563 Loss: 1.558 | Acc: 43.868% (8212/18720)\n",
      "Epoch 2 Step 585/1563 Loss: 1.557 | Acc: 43.889% (8230/18752)\n",
      "Epoch 2 Step 586/1563 Loss: 1.558 | Acc: 43.878% (8242/18784)\n",
      "Epoch 2 Step 587/1563 Loss: 1.558 | Acc: 43.872% (8255/18816)\n",
      "Epoch 2 Step 588/1563 Loss: 1.558 | Acc: 43.856% (8266/18848)\n",
      "Epoch 2 Step 589/1563 Loss: 1.558 | Acc: 43.856% (8280/18880)\n",
      "Epoch 2 Step 590/1563 Loss: 1.558 | Acc: 43.877% (8298/18912)\n",
      "Epoch 2 Step 591/1563 Loss: 1.558 | Acc: 43.871% (8311/18944)\n",
      "Epoch 2 Step 592/1563 Loss: 1.558 | Acc: 43.871% (8325/18976)\n",
      "Epoch 2 Step 593/1563 Loss: 1.557 | Acc: 43.897% (8344/19008)\n",
      "Epoch 2 Step 594/1563 Loss: 1.557 | Acc: 43.897% (8358/19040)\n",
      "Epoch 2 Step 595/1563 Loss: 1.557 | Acc: 43.902% (8373/19072)\n",
      "Epoch 2 Step 596/1563 Loss: 1.557 | Acc: 43.891% (8385/19104)\n",
      "Epoch 2 Step 597/1563 Loss: 1.557 | Acc: 43.907% (8402/19136)\n",
      "Epoch 2 Step 598/1563 Loss: 1.557 | Acc: 43.907% (8416/19168)\n",
      "Epoch 2 Step 599/1563 Loss: 1.557 | Acc: 43.901% (8429/19200)\n",
      "Epoch 2 Step 600/1563 Loss: 1.557 | Acc: 43.911% (8445/19232)\n",
      "Epoch 2 Step 601/1563 Loss: 1.557 | Acc: 43.916% (8460/19264)\n",
      "Epoch 2 Step 602/1563 Loss: 1.557 | Acc: 43.900% (8471/19296)\n",
      "Epoch 2 Step 603/1563 Loss: 1.558 | Acc: 43.895% (8484/19328)\n",
      "Epoch 2 Step 604/1563 Loss: 1.558 | Acc: 43.900% (8499/19360)\n",
      "Epoch 2 Step 605/1563 Loss: 1.558 | Acc: 43.905% (8514/19392)\n",
      "Epoch 2 Step 606/1563 Loss: 1.558 | Acc: 43.904% (8528/19424)\n",
      "Epoch 2 Step 607/1563 Loss: 1.558 | Acc: 43.909% (8543/19456)\n",
      "Epoch 2 Step 608/1563 Loss: 1.558 | Acc: 43.899% (8555/19488)\n",
      "Epoch 2 Step 609/1563 Loss: 1.558 | Acc: 43.888% (8567/19520)\n",
      "Epoch 2 Step 610/1563 Loss: 1.559 | Acc: 43.857% (8575/19552)\n",
      "Epoch 2 Step 611/1563 Loss: 1.559 | Acc: 43.867% (8591/19584)\n",
      "Epoch 2 Step 612/1563 Loss: 1.559 | Acc: 43.872% (8606/19616)\n",
      "Epoch 2 Step 613/1563 Loss: 1.558 | Acc: 43.893% (8624/19648)\n",
      "Epoch 2 Step 614/1563 Loss: 1.559 | Acc: 43.897% (8639/19680)\n",
      "Epoch 2 Step 615/1563 Loss: 1.558 | Acc: 43.933% (8660/19712)\n",
      "Epoch 2 Step 616/1563 Loss: 1.558 | Acc: 43.953% (8678/19744)\n",
      "Epoch 2 Step 617/1563 Loss: 1.558 | Acc: 43.952% (8692/19776)\n",
      "Epoch 2 Step 618/1563 Loss: 1.558 | Acc: 43.957% (8707/19808)\n",
      "Epoch 2 Step 619/1563 Loss: 1.558 | Acc: 43.957% (8721/19840)\n",
      "Epoch 2 Step 620/1563 Loss: 1.557 | Acc: 43.971% (8738/19872)\n",
      "Epoch 2 Step 621/1563 Loss: 1.557 | Acc: 43.986% (8755/19904)\n",
      "Epoch 2 Step 622/1563 Loss: 1.558 | Acc: 43.976% (8767/19936)\n",
      "Epoch 2 Step 623/1563 Loss: 1.558 | Acc: 43.965% (8779/19968)\n",
      "Epoch 2 Step 624/1563 Loss: 1.558 | Acc: 43.960% (8792/20000)\n",
      "Epoch 2 Step 625/1563 Loss: 1.558 | Acc: 43.965% (8807/20032)\n",
      "Epoch 2 Step 626/1563 Loss: 1.558 | Acc: 43.969% (8822/20064)\n",
      "Epoch 2 Step 627/1563 Loss: 1.558 | Acc: 43.969% (8836/20096)\n",
      "Epoch 2 Step 628/1563 Loss: 1.558 | Acc: 43.988% (8854/20128)\n",
      "Epoch 2 Step 629/1563 Loss: 1.558 | Acc: 43.978% (8866/20160)\n",
      "Epoch 2 Step 630/1563 Loss: 1.558 | Acc: 43.983% (8881/20192)\n",
      "Epoch 2 Step 631/1563 Loss: 1.558 | Acc: 43.992% (8897/20224)\n",
      "Epoch 2 Step 632/1563 Loss: 1.558 | Acc: 43.972% (8907/20256)\n",
      "Epoch 2 Step 633/1563 Loss: 1.558 | Acc: 43.967% (8920/20288)\n",
      "Epoch 2 Step 634/1563 Loss: 1.559 | Acc: 43.942% (8929/20320)\n",
      "Epoch 2 Step 635/1563 Loss: 1.559 | Acc: 43.937% (8942/20352)\n",
      "Epoch 2 Step 636/1563 Loss: 1.559 | Acc: 43.936% (8956/20384)\n",
      "Epoch 2 Step 637/1563 Loss: 1.559 | Acc: 43.946% (8972/20416)\n",
      "Epoch 2 Step 638/1563 Loss: 1.559 | Acc: 43.926% (8982/20448)\n",
      "Epoch 2 Step 639/1563 Loss: 1.559 | Acc: 43.936% (8998/20480)\n",
      "Epoch 2 Step 640/1563 Loss: 1.559 | Acc: 43.955% (9016/20512)\n",
      "Epoch 2 Step 641/1563 Loss: 1.559 | Acc: 43.969% (9033/20544)\n",
      "Epoch 2 Step 642/1563 Loss: 1.558 | Acc: 43.978% (9049/20576)\n",
      "Epoch 2 Step 643/1563 Loss: 1.559 | Acc: 43.973% (9062/20608)\n",
      "Epoch 2 Step 644/1563 Loss: 1.559 | Acc: 43.968% (9075/20640)\n",
      "Epoch 2 Step 645/1563 Loss: 1.559 | Acc: 43.953% (9086/20672)\n",
      "Epoch 2 Step 646/1563 Loss: 1.559 | Acc: 43.963% (9102/20704)\n",
      "Epoch 2 Step 647/1563 Loss: 1.559 | Acc: 43.962% (9116/20736)\n",
      "Epoch 2 Step 648/1563 Loss: 1.559 | Acc: 43.967% (9131/20768)\n",
      "Epoch 2 Step 649/1563 Loss: 1.559 | Acc: 43.957% (9143/20800)\n",
      "Epoch 2 Step 650/1563 Loss: 1.558 | Acc: 43.956% (9157/20832)\n",
      "Epoch 2 Step 651/1563 Loss: 1.558 | Acc: 43.961% (9172/20864)\n",
      "Epoch 2 Step 652/1563 Loss: 1.558 | Acc: 43.961% (9186/20896)\n",
      "Epoch 2 Step 653/1563 Loss: 1.559 | Acc: 43.927% (9193/20928)\n",
      "Epoch 2 Step 654/1563 Loss: 1.559 | Acc: 43.907% (9203/20960)\n",
      "Epoch 2 Step 655/1563 Loss: 1.559 | Acc: 43.902% (9216/20992)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 656/1563 Loss: 1.559 | Acc: 43.940% (9238/21024)\n",
      "Epoch 2 Step 657/1563 Loss: 1.559 | Acc: 43.940% (9252/21056)\n",
      "Epoch 2 Step 658/1563 Loss: 1.558 | Acc: 43.949% (9268/21088)\n",
      "Epoch 2 Step 659/1563 Loss: 1.558 | Acc: 43.958% (9284/21120)\n",
      "Epoch 2 Step 660/1563 Loss: 1.558 | Acc: 43.944% (9295/21152)\n",
      "Epoch 2 Step 661/1563 Loss: 1.558 | Acc: 43.944% (9309/21184)\n",
      "Epoch 2 Step 662/1563 Loss: 1.558 | Acc: 43.953% (9325/21216)\n",
      "Epoch 2 Step 663/1563 Loss: 1.558 | Acc: 43.957% (9340/21248)\n",
      "Epoch 2 Step 664/1563 Loss: 1.558 | Acc: 43.961% (9355/21280)\n",
      "Epoch 2 Step 665/1563 Loss: 1.557 | Acc: 43.975% (9372/21312)\n",
      "Epoch 2 Step 666/1563 Loss: 1.557 | Acc: 43.994% (9390/21344)\n",
      "Epoch 2 Step 667/1563 Loss: 1.558 | Acc: 43.975% (9400/21376)\n",
      "Epoch 2 Step 668/1563 Loss: 1.557 | Acc: 43.998% (9419/21408)\n",
      "Epoch 2 Step 669/1563 Loss: 1.557 | Acc: 44.007% (9435/21440)\n",
      "Epoch 2 Step 670/1563 Loss: 1.557 | Acc: 44.001% (9448/21472)\n",
      "Epoch 2 Step 671/1563 Loss: 1.557 | Acc: 44.001% (9462/21504)\n",
      "Epoch 2 Step 672/1563 Loss: 1.557 | Acc: 43.987% (9473/21536)\n",
      "Epoch 2 Step 673/1563 Loss: 1.557 | Acc: 43.959% (9481/21568)\n",
      "Epoch 2 Step 674/1563 Loss: 1.557 | Acc: 43.986% (9501/21600)\n",
      "Epoch 2 Step 675/1563 Loss: 1.557 | Acc: 43.990% (9516/21632)\n",
      "Epoch 2 Step 676/1563 Loss: 1.557 | Acc: 43.985% (9529/21664)\n",
      "Epoch 2 Step 677/1563 Loss: 1.558 | Acc: 43.953% (9536/21696)\n",
      "Epoch 2 Step 678/1563 Loss: 1.558 | Acc: 43.953% (9550/21728)\n",
      "Epoch 2 Step 679/1563 Loss: 1.558 | Acc: 43.948% (9563/21760)\n",
      "Epoch 2 Step 680/1563 Loss: 1.558 | Acc: 43.952% (9578/21792)\n",
      "Epoch 2 Step 681/1563 Loss: 1.558 | Acc: 43.965% (9595/21824)\n",
      "Epoch 2 Step 682/1563 Loss: 1.558 | Acc: 43.970% (9610/21856)\n",
      "Epoch 2 Step 683/1563 Loss: 1.558 | Acc: 43.974% (9625/21888)\n",
      "Epoch 2 Step 684/1563 Loss: 1.558 | Acc: 43.987% (9642/21920)\n",
      "Epoch 2 Step 685/1563 Loss: 1.557 | Acc: 43.991% (9657/21952)\n",
      "Epoch 2 Step 686/1563 Loss: 1.558 | Acc: 44.005% (9674/21984)\n",
      "Epoch 2 Step 687/1563 Loss: 1.558 | Acc: 43.977% (9682/22016)\n",
      "Epoch 2 Step 688/1563 Loss: 1.558 | Acc: 43.977% (9696/22048)\n",
      "Epoch 2 Step 689/1563 Loss: 1.558 | Acc: 43.990% (9713/22080)\n",
      "Epoch 2 Step 690/1563 Loss: 1.558 | Acc: 43.994% (9728/22112)\n",
      "Epoch 2 Step 691/1563 Loss: 1.558 | Acc: 44.003% (9744/22144)\n",
      "Epoch 2 Step 692/1563 Loss: 1.558 | Acc: 43.994% (9756/22176)\n",
      "Epoch 2 Step 693/1563 Loss: 1.558 | Acc: 43.993% (9770/22208)\n",
      "Epoch 2 Step 694/1563 Loss: 1.558 | Acc: 44.006% (9787/22240)\n",
      "Epoch 2 Step 695/1563 Loss: 1.558 | Acc: 43.997% (9799/22272)\n",
      "Epoch 2 Step 696/1563 Loss: 1.558 | Acc: 44.001% (9814/22304)\n",
      "Epoch 2 Step 697/1563 Loss: 1.558 | Acc: 44.014% (9831/22336)\n",
      "Epoch 2 Step 698/1563 Loss: 1.557 | Acc: 44.036% (9850/22368)\n",
      "Epoch 2 Step 699/1563 Loss: 1.557 | Acc: 44.036% (9864/22400)\n",
      "Epoch 2 Step 700/1563 Loss: 1.557 | Acc: 44.026% (9876/22432)\n",
      "Epoch 2 Step 701/1563 Loss: 1.557 | Acc: 44.013% (9887/22464)\n",
      "Epoch 2 Step 702/1563 Loss: 1.557 | Acc: 44.026% (9904/22496)\n",
      "Epoch 2 Step 703/1563 Loss: 1.558 | Acc: 44.025% (9918/22528)\n",
      "Epoch 2 Step 704/1563 Loss: 1.557 | Acc: 44.051% (9938/22560)\n",
      "Epoch 2 Step 705/1563 Loss: 1.557 | Acc: 44.060% (9954/22592)\n",
      "Epoch 2 Step 706/1563 Loss: 1.557 | Acc: 44.055% (9967/22624)\n",
      "Epoch 2 Step 707/1563 Loss: 1.557 | Acc: 44.072% (9985/22656)\n",
      "Epoch 2 Step 708/1563 Loss: 1.557 | Acc: 44.076% (10000/22688)\n",
      "Epoch 2 Step 709/1563 Loss: 1.558 | Acc: 44.067% (10012/22720)\n",
      "Epoch 2 Step 710/1563 Loss: 1.557 | Acc: 44.071% (10027/22752)\n",
      "Epoch 2 Step 711/1563 Loss: 1.557 | Acc: 44.066% (10040/22784)\n",
      "Epoch 2 Step 712/1563 Loss: 1.557 | Acc: 44.048% (10050/22816)\n",
      "Epoch 2 Step 713/1563 Loss: 1.557 | Acc: 44.078% (10071/22848)\n",
      "Epoch 2 Step 714/1563 Loss: 1.557 | Acc: 44.082% (10086/22880)\n",
      "Epoch 2 Step 715/1563 Loss: 1.557 | Acc: 44.099% (10104/22912)\n",
      "Epoch 2 Step 716/1563 Loss: 1.557 | Acc: 44.099% (10118/22944)\n",
      "Epoch 2 Step 717/1563 Loss: 1.557 | Acc: 44.098% (10132/22976)\n",
      "Epoch 2 Step 718/1563 Loss: 1.557 | Acc: 44.106% (10148/23008)\n",
      "Epoch 2 Step 719/1563 Loss: 1.557 | Acc: 44.115% (10164/23040)\n",
      "Epoch 2 Step 720/1563 Loss: 1.557 | Acc: 44.114% (10178/23072)\n",
      "Epoch 2 Step 721/1563 Loss: 1.557 | Acc: 44.105% (10190/23104)\n",
      "Epoch 2 Step 722/1563 Loss: 1.557 | Acc: 44.104% (10204/23136)\n",
      "Epoch 2 Step 723/1563 Loss: 1.557 | Acc: 44.108% (10219/23168)\n",
      "Epoch 2 Step 724/1563 Loss: 1.557 | Acc: 44.099% (10231/23200)\n",
      "Epoch 2 Step 725/1563 Loss: 1.557 | Acc: 44.099% (10245/23232)\n",
      "Epoch 2 Step 726/1563 Loss: 1.556 | Acc: 44.098% (10259/23264)\n",
      "Epoch 2 Step 727/1563 Loss: 1.556 | Acc: 44.106% (10275/23296)\n",
      "Epoch 2 Step 728/1563 Loss: 1.556 | Acc: 44.106% (10289/23328)\n",
      "Epoch 2 Step 729/1563 Loss: 1.556 | Acc: 44.110% (10304/23360)\n",
      "Epoch 2 Step 730/1563 Loss: 1.556 | Acc: 44.101% (10316/23392)\n",
      "Epoch 2 Step 731/1563 Loss: 1.556 | Acc: 44.100% (10330/23424)\n",
      "Epoch 2 Step 732/1563 Loss: 1.557 | Acc: 44.091% (10342/23456)\n",
      "Epoch 2 Step 733/1563 Loss: 1.556 | Acc: 44.099% (10358/23488)\n",
      "Epoch 2 Step 734/1563 Loss: 1.556 | Acc: 44.086% (10369/23520)\n",
      "Epoch 2 Step 735/1563 Loss: 1.556 | Acc: 44.098% (10386/23552)\n",
      "Epoch 2 Step 736/1563 Loss: 1.556 | Acc: 44.102% (10401/23584)\n",
      "Epoch 2 Step 737/1563 Loss: 1.556 | Acc: 44.106% (10416/23616)\n",
      "Epoch 2 Step 738/1563 Loss: 1.556 | Acc: 44.093% (10427/23648)\n",
      "Epoch 2 Step 739/1563 Loss: 1.556 | Acc: 44.096% (10442/23680)\n",
      "Epoch 2 Step 740/1563 Loss: 1.556 | Acc: 44.121% (10462/23712)\n",
      "Epoch 2 Step 741/1563 Loss: 1.556 | Acc: 44.116% (10475/23744)\n",
      "Epoch 2 Step 742/1563 Loss: 1.556 | Acc: 44.133% (10493/23776)\n",
      "Epoch 2 Step 743/1563 Loss: 1.555 | Acc: 44.149% (10511/23808)\n",
      "Epoch 2 Step 744/1563 Loss: 1.555 | Acc: 44.153% (10526/23840)\n",
      "Epoch 2 Step 745/1563 Loss: 1.556 | Acc: 44.144% (10538/23872)\n",
      "Epoch 2 Step 746/1563 Loss: 1.555 | Acc: 44.147% (10553/23904)\n",
      "Epoch 2 Step 747/1563 Loss: 1.556 | Acc: 44.147% (10567/23936)\n",
      "Epoch 2 Step 748/1563 Loss: 1.556 | Acc: 44.138% (10579/23968)\n",
      "Epoch 2 Step 749/1563 Loss: 1.556 | Acc: 44.125% (10590/24000)\n",
      "Epoch 2 Step 750/1563 Loss: 1.555 | Acc: 44.133% (10606/24032)\n",
      "Epoch 2 Step 751/1563 Loss: 1.555 | Acc: 44.124% (10618/24064)\n",
      "Epoch 2 Step 752/1563 Loss: 1.555 | Acc: 44.144% (10637/24096)\n",
      "Epoch 2 Step 753/1563 Loss: 1.555 | Acc: 44.144% (10651/24128)\n",
      "Epoch 2 Step 754/1563 Loss: 1.554 | Acc: 44.147% (10666/24160)\n",
      "Epoch 2 Step 755/1563 Loss: 1.554 | Acc: 44.159% (10683/24192)\n",
      "Epoch 2 Step 756/1563 Loss: 1.554 | Acc: 44.163% (10698/24224)\n",
      "Epoch 2 Step 757/1563 Loss: 1.554 | Acc: 44.125% (10703/24256)\n",
      "Epoch 2 Step 758/1563 Loss: 1.554 | Acc: 44.125% (10717/24288)\n",
      "Epoch 2 Step 759/1563 Loss: 1.554 | Acc: 44.120% (10730/24320)\n",
      "Epoch 2 Step 760/1563 Loss: 1.555 | Acc: 44.111% (10742/24352)\n",
      "Epoch 2 Step 761/1563 Loss: 1.554 | Acc: 44.119% (10758/24384)\n",
      "Epoch 2 Step 762/1563 Loss: 1.555 | Acc: 44.102% (10768/24416)\n",
      "Epoch 2 Step 763/1563 Loss: 1.555 | Acc: 44.098% (10781/24448)\n",
      "Epoch 2 Step 764/1563 Loss: 1.555 | Acc: 44.097% (10795/24480)\n",
      "Epoch 2 Step 765/1563 Loss: 1.555 | Acc: 44.097% (10809/24512)\n",
      "Epoch 2 Step 766/1563 Loss: 1.555 | Acc: 44.088% (10821/24544)\n",
      "Epoch 2 Step 767/1563 Loss: 1.555 | Acc: 44.084% (10834/24576)\n",
      "Epoch 2 Step 768/1563 Loss: 1.554 | Acc: 44.104% (10853/24608)\n",
      "Epoch 2 Step 769/1563 Loss: 1.554 | Acc: 44.095% (10865/24640)\n",
      "Epoch 2 Step 770/1563 Loss: 1.554 | Acc: 44.111% (10883/24672)\n",
      "Epoch 2 Step 771/1563 Loss: 1.554 | Acc: 44.114% (10898/24704)\n",
      "Epoch 2 Step 772/1563 Loss: 1.554 | Acc: 44.110% (10911/24736)\n",
      "Epoch 2 Step 773/1563 Loss: 1.553 | Acc: 44.109% (10925/24768)\n",
      "Epoch 2 Step 774/1563 Loss: 1.554 | Acc: 44.101% (10937/24800)\n",
      "Epoch 2 Step 775/1563 Loss: 1.554 | Acc: 44.100% (10951/24832)\n",
      "Epoch 2 Step 776/1563 Loss: 1.554 | Acc: 44.112% (10968/24864)\n",
      "Epoch 2 Step 777/1563 Loss: 1.553 | Acc: 44.136% (10988/24896)\n",
      "Epoch 2 Step 778/1563 Loss: 1.553 | Acc: 44.135% (11002/24928)\n",
      "Epoch 2 Step 779/1563 Loss: 1.554 | Acc: 44.131% (11015/24960)\n",
      "Epoch 2 Step 780/1563 Loss: 1.554 | Acc: 44.134% (11030/24992)\n",
      "Epoch 2 Step 781/1563 Loss: 1.553 | Acc: 44.134% (11044/25024)\n",
      "Epoch 2 Step 782/1563 Loss: 1.553 | Acc: 44.117% (11054/25056)\n",
      "Epoch 2 Step 783/1563 Loss: 1.553 | Acc: 44.121% (11069/25088)\n",
      "Epoch 2 Step 784/1563 Loss: 1.554 | Acc: 44.112% (11081/25120)\n",
      "Epoch 2 Step 785/1563 Loss: 1.553 | Acc: 44.136% (11101/25152)\n",
      "Epoch 2 Step 786/1563 Loss: 1.554 | Acc: 44.127% (11113/25184)\n",
      "Epoch 2 Step 787/1563 Loss: 1.553 | Acc: 44.143% (11131/25216)\n",
      "Epoch 2 Step 788/1563 Loss: 1.553 | Acc: 44.142% (11145/25248)\n",
      "Epoch 2 Step 789/1563 Loss: 1.553 | Acc: 44.130% (11156/25280)\n",
      "Epoch 2 Step 790/1563 Loss: 1.553 | Acc: 44.145% (11174/25312)\n",
      "Epoch 2 Step 791/1563 Loss: 1.553 | Acc: 44.145% (11188/25344)\n",
      "Epoch 2 Step 792/1563 Loss: 1.553 | Acc: 44.136% (11200/25376)\n",
      "Epoch 2 Step 793/1563 Loss: 1.552 | Acc: 44.163% (11221/25408)\n",
      "Epoch 2 Step 794/1563 Loss: 1.552 | Acc: 44.167% (11236/25440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 795/1563 Loss: 1.552 | Acc: 44.170% (11251/25472)\n",
      "Epoch 2 Step 796/1563 Loss: 1.552 | Acc: 44.185% (11269/25504)\n",
      "Epoch 2 Step 797/1563 Loss: 1.552 | Acc: 44.181% (11282/25536)\n",
      "Epoch 2 Step 798/1563 Loss: 1.552 | Acc: 44.184% (11297/25568)\n",
      "Epoch 2 Step 799/1563 Loss: 1.552 | Acc: 44.176% (11309/25600)\n",
      "Epoch 2 Step 800/1563 Loss: 1.552 | Acc: 44.160% (11319/25632)\n",
      "Epoch 2 Step 801/1563 Loss: 1.552 | Acc: 44.163% (11334/25664)\n",
      "Epoch 2 Step 802/1563 Loss: 1.552 | Acc: 44.155% (11346/25696)\n",
      "Epoch 2 Step 803/1563 Loss: 1.552 | Acc: 44.162% (11362/25728)\n",
      "Epoch 2 Step 804/1563 Loss: 1.552 | Acc: 44.173% (11379/25760)\n",
      "Epoch 2 Step 805/1563 Loss: 1.552 | Acc: 44.165% (11391/25792)\n",
      "Epoch 2 Step 806/1563 Loss: 1.552 | Acc: 44.164% (11405/25824)\n",
      "Epoch 2 Step 807/1563 Loss: 1.552 | Acc: 44.164% (11419/25856)\n",
      "Epoch 2 Step 808/1563 Loss: 1.552 | Acc: 44.159% (11432/25888)\n",
      "Epoch 2 Step 809/1563 Loss: 1.552 | Acc: 44.174% (11450/25920)\n",
      "Epoch 2 Step 810/1563 Loss: 1.551 | Acc: 44.193% (11469/25952)\n",
      "Epoch 2 Step 811/1563 Loss: 1.551 | Acc: 44.200% (11485/25984)\n",
      "Epoch 2 Step 812/1563 Loss: 1.551 | Acc: 44.196% (11498/26016)\n",
      "Epoch 2 Step 813/1563 Loss: 1.552 | Acc: 44.184% (11509/26048)\n",
      "Epoch 2 Step 814/1563 Loss: 1.551 | Acc: 44.199% (11527/26080)\n",
      "Epoch 2 Step 815/1563 Loss: 1.551 | Acc: 44.190% (11539/26112)\n",
      "Epoch 2 Step 816/1563 Loss: 1.551 | Acc: 44.205% (11557/26144)\n",
      "Epoch 2 Step 817/1563 Loss: 1.551 | Acc: 44.208% (11572/26176)\n",
      "Epoch 2 Step 818/1563 Loss: 1.551 | Acc: 44.193% (11582/26208)\n",
      "Epoch 2 Step 819/1563 Loss: 1.551 | Acc: 44.200% (11598/26240)\n",
      "Epoch 2 Step 820/1563 Loss: 1.551 | Acc: 44.207% (11614/26272)\n",
      "Epoch 2 Step 821/1563 Loss: 1.551 | Acc: 44.214% (11630/26304)\n",
      "Epoch 2 Step 822/1563 Loss: 1.551 | Acc: 44.209% (11643/26336)\n",
      "Epoch 2 Step 823/1563 Loss: 1.551 | Acc: 44.205% (11656/26368)\n",
      "Epoch 2 Step 824/1563 Loss: 1.551 | Acc: 44.216% (11673/26400)\n",
      "Epoch 2 Step 825/1563 Loss: 1.551 | Acc: 44.215% (11687/26432)\n",
      "Epoch 2 Step 826/1563 Loss: 1.551 | Acc: 44.200% (11697/26464)\n",
      "Epoch 2 Step 827/1563 Loss: 1.551 | Acc: 44.214% (11715/26496)\n",
      "Epoch 2 Step 828/1563 Loss: 1.551 | Acc: 44.217% (11730/26528)\n",
      "Epoch 2 Step 829/1563 Loss: 1.551 | Acc: 44.224% (11746/26560)\n",
      "Epoch 2 Step 830/1563 Loss: 1.551 | Acc: 44.224% (11760/26592)\n",
      "Epoch 2 Step 831/1563 Loss: 1.550 | Acc: 44.235% (11777/26624)\n",
      "Epoch 2 Step 832/1563 Loss: 1.550 | Acc: 44.234% (11791/26656)\n",
      "Epoch 2 Step 833/1563 Loss: 1.551 | Acc: 44.215% (11800/26688)\n",
      "Epoch 2 Step 834/1563 Loss: 1.551 | Acc: 44.225% (11817/26720)\n",
      "Epoch 2 Step 835/1563 Loss: 1.551 | Acc: 44.214% (11828/26752)\n",
      "Epoch 2 Step 836/1563 Loss: 1.551 | Acc: 44.213% (11842/26784)\n",
      "Epoch 2 Step 837/1563 Loss: 1.551 | Acc: 44.197% (11852/26816)\n",
      "Epoch 2 Step 838/1563 Loss: 1.551 | Acc: 44.190% (11864/26848)\n",
      "Epoch 2 Step 839/1563 Loss: 1.551 | Acc: 44.193% (11879/26880)\n",
      "Epoch 2 Step 840/1563 Loss: 1.551 | Acc: 44.181% (11890/26912)\n",
      "Epoch 2 Step 841/1563 Loss: 1.551 | Acc: 44.199% (11909/26944)\n",
      "Epoch 2 Step 842/1563 Loss: 1.551 | Acc: 44.202% (11924/26976)\n",
      "Epoch 2 Step 843/1563 Loss: 1.551 | Acc: 44.194% (11936/27008)\n",
      "Epoch 2 Step 844/1563 Loss: 1.551 | Acc: 44.197% (11951/27040)\n",
      "Epoch 2 Step 845/1563 Loss: 1.551 | Acc: 44.197% (11965/27072)\n",
      "Epoch 2 Step 846/1563 Loss: 1.551 | Acc: 44.196% (11979/27104)\n",
      "Epoch 2 Step 847/1563 Loss: 1.551 | Acc: 44.203% (11995/27136)\n",
      "Epoch 2 Step 848/1563 Loss: 1.551 | Acc: 44.195% (12007/27168)\n",
      "Epoch 2 Step 849/1563 Loss: 1.551 | Acc: 44.191% (12020/27200)\n",
      "Epoch 2 Step 850/1563 Loss: 1.550 | Acc: 44.202% (12037/27232)\n",
      "Epoch 2 Step 851/1563 Loss: 1.551 | Acc: 44.194% (12049/27264)\n",
      "Epoch 2 Step 852/1563 Loss: 1.551 | Acc: 44.190% (12062/27296)\n",
      "Epoch 2 Step 853/1563 Loss: 1.551 | Acc: 44.189% (12076/27328)\n",
      "Epoch 2 Step 854/1563 Loss: 1.551 | Acc: 44.185% (12089/27360)\n",
      "Epoch 2 Step 855/1563 Loss: 1.551 | Acc: 44.177% (12101/27392)\n",
      "Epoch 2 Step 856/1563 Loss: 1.551 | Acc: 44.173% (12114/27424)\n",
      "Epoch 2 Step 857/1563 Loss: 1.551 | Acc: 44.194% (12134/27456)\n",
      "Epoch 2 Step 858/1563 Loss: 1.551 | Acc: 44.201% (12150/27488)\n",
      "Epoch 2 Step 859/1563 Loss: 1.550 | Acc: 44.193% (12162/27520)\n",
      "Epoch 2 Step 860/1563 Loss: 1.551 | Acc: 44.182% (12173/27552)\n",
      "Epoch 2 Step 861/1563 Loss: 1.551 | Acc: 44.185% (12188/27584)\n",
      "Epoch 2 Step 862/1563 Loss: 1.551 | Acc: 44.206% (12208/27616)\n",
      "Epoch 2 Step 863/1563 Loss: 1.551 | Acc: 44.213% (12224/27648)\n",
      "Epoch 2 Step 864/1563 Loss: 1.551 | Acc: 44.202% (12235/27680)\n",
      "Epoch 2 Step 865/1563 Loss: 1.551 | Acc: 44.187% (12245/27712)\n",
      "Epoch 2 Step 866/1563 Loss: 1.551 | Acc: 44.186% (12259/27744)\n",
      "Epoch 2 Step 867/1563 Loss: 1.551 | Acc: 44.189% (12274/27776)\n",
      "Epoch 2 Step 868/1563 Loss: 1.551 | Acc: 44.182% (12286/27808)\n",
      "Epoch 2 Step 869/1563 Loss: 1.551 | Acc: 44.188% (12302/27840)\n",
      "Epoch 2 Step 870/1563 Loss: 1.551 | Acc: 44.191% (12317/27872)\n",
      "Epoch 2 Step 871/1563 Loss: 1.551 | Acc: 44.194% (12332/27904)\n",
      "Epoch 2 Step 872/1563 Loss: 1.551 | Acc: 44.219% (12353/27936)\n",
      "Epoch 2 Step 873/1563 Loss: 1.551 | Acc: 44.236% (12372/27968)\n",
      "Epoch 2 Step 874/1563 Loss: 1.551 | Acc: 44.221% (12382/28000)\n",
      "Epoch 2 Step 875/1563 Loss: 1.550 | Acc: 44.217% (12395/28032)\n",
      "Epoch 2 Step 876/1563 Loss: 1.550 | Acc: 44.224% (12411/28064)\n",
      "Epoch 2 Step 877/1563 Loss: 1.550 | Acc: 44.234% (12428/28096)\n",
      "Epoch 2 Step 878/1563 Loss: 1.550 | Acc: 44.241% (12444/28128)\n",
      "Epoch 2 Step 879/1563 Loss: 1.550 | Acc: 44.237% (12457/28160)\n",
      "Epoch 2 Step 880/1563 Loss: 1.550 | Acc: 44.236% (12471/28192)\n",
      "Epoch 2 Step 881/1563 Loss: 1.550 | Acc: 44.250% (12489/28224)\n",
      "Epoch 2 Step 882/1563 Loss: 1.550 | Acc: 44.245% (12502/28256)\n",
      "Epoch 2 Step 883/1563 Loss: 1.550 | Acc: 44.238% (12514/28288)\n",
      "Epoch 2 Step 884/1563 Loss: 1.550 | Acc: 44.230% (12526/28320)\n",
      "Epoch 2 Step 885/1563 Loss: 1.550 | Acc: 44.223% (12538/28352)\n",
      "Epoch 2 Step 886/1563 Loss: 1.550 | Acc: 44.233% (12555/28384)\n",
      "Epoch 2 Step 887/1563 Loss: 1.550 | Acc: 44.243% (12572/28416)\n",
      "Epoch 2 Step 888/1563 Loss: 1.550 | Acc: 44.263% (12592/28448)\n",
      "Epoch 2 Step 889/1563 Loss: 1.550 | Acc: 44.252% (12603/28480)\n",
      "Epoch 2 Step 890/1563 Loss: 1.550 | Acc: 44.262% (12620/28512)\n",
      "Epoch 2 Step 891/1563 Loss: 1.550 | Acc: 44.247% (12630/28544)\n",
      "Epoch 2 Step 892/1563 Loss: 1.550 | Acc: 44.268% (12650/28576)\n",
      "Epoch 2 Step 893/1563 Loss: 1.550 | Acc: 44.264% (12663/28608)\n",
      "Epoch 2 Step 894/1563 Loss: 1.550 | Acc: 44.253% (12674/28640)\n",
      "Epoch 2 Step 895/1563 Loss: 1.550 | Acc: 44.235% (12683/28672)\n",
      "Epoch 2 Step 896/1563 Loss: 1.550 | Acc: 44.234% (12697/28704)\n",
      "Epoch 2 Step 897/1563 Loss: 1.550 | Acc: 44.227% (12709/28736)\n",
      "Epoch 2 Step 898/1563 Loss: 1.550 | Acc: 44.233% (12725/28768)\n",
      "Epoch 2 Step 899/1563 Loss: 1.550 | Acc: 44.233% (12739/28800)\n",
      "Epoch 2 Step 900/1563 Loss: 1.550 | Acc: 44.236% (12754/28832)\n",
      "Epoch 2 Step 901/1563 Loss: 1.550 | Acc: 44.242% (12770/28864)\n",
      "Epoch 2 Step 902/1563 Loss: 1.550 | Acc: 44.252% (12787/28896)\n",
      "Epoch 2 Step 903/1563 Loss: 1.550 | Acc: 44.258% (12803/28928)\n",
      "Epoch 2 Step 904/1563 Loss: 1.549 | Acc: 44.271% (12821/28960)\n",
      "Epoch 2 Step 905/1563 Loss: 1.549 | Acc: 44.288% (12840/28992)\n",
      "Epoch 2 Step 906/1563 Loss: 1.549 | Acc: 44.277% (12851/29024)\n",
      "Epoch 2 Step 907/1563 Loss: 1.550 | Acc: 44.280% (12866/29056)\n",
      "Epoch 2 Step 908/1563 Loss: 1.549 | Acc: 44.286% (12882/29088)\n",
      "Epoch 2 Step 909/1563 Loss: 1.549 | Acc: 44.293% (12898/29120)\n",
      "Epoch 2 Step 910/1563 Loss: 1.549 | Acc: 44.292% (12912/29152)\n",
      "Epoch 2 Step 911/1563 Loss: 1.549 | Acc: 44.309% (12931/29184)\n",
      "Epoch 2 Step 912/1563 Loss: 1.549 | Acc: 44.322% (12949/29216)\n",
      "Epoch 2 Step 913/1563 Loss: 1.549 | Acc: 44.324% (12964/29248)\n",
      "Epoch 2 Step 914/1563 Loss: 1.549 | Acc: 44.317% (12976/29280)\n",
      "Epoch 2 Step 915/1563 Loss: 1.549 | Acc: 44.316% (12990/29312)\n",
      "Epoch 2 Step 916/1563 Loss: 1.549 | Acc: 44.309% (13002/29344)\n",
      "Epoch 2 Step 917/1563 Loss: 1.549 | Acc: 44.322% (13020/29376)\n",
      "Epoch 2 Step 918/1563 Loss: 1.549 | Acc: 44.318% (13033/29408)\n",
      "Epoch 2 Step 919/1563 Loss: 1.548 | Acc: 44.321% (13048/29440)\n",
      "Epoch 2 Step 920/1563 Loss: 1.548 | Acc: 44.330% (13065/29472)\n",
      "Epoch 2 Step 921/1563 Loss: 1.548 | Acc: 44.336% (13081/29504)\n",
      "Epoch 2 Step 922/1563 Loss: 1.548 | Acc: 44.332% (13094/29536)\n",
      "Epoch 2 Step 923/1563 Loss: 1.548 | Acc: 44.325% (13106/29568)\n",
      "Epoch 2 Step 924/1563 Loss: 1.548 | Acc: 44.331% (13122/29600)\n",
      "Epoch 2 Step 925/1563 Loss: 1.548 | Acc: 44.341% (13139/29632)\n",
      "Epoch 2 Step 926/1563 Loss: 1.548 | Acc: 44.340% (13153/29664)\n",
      "Epoch 2 Step 927/1563 Loss: 1.548 | Acc: 44.329% (13164/29696)\n",
      "Epoch 2 Step 928/1563 Loss: 1.548 | Acc: 44.325% (13177/29728)\n",
      "Epoch 2 Step 929/1563 Loss: 1.548 | Acc: 44.325% (13191/29760)\n",
      "Epoch 2 Step 930/1563 Loss: 1.548 | Acc: 44.324% (13205/29792)\n",
      "Epoch 2 Step 931/1563 Loss: 1.548 | Acc: 44.327% (13220/29824)\n",
      "Epoch 2 Step 932/1563 Loss: 1.548 | Acc: 44.329% (13235/29856)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 933/1563 Loss: 1.548 | Acc: 44.325% (13248/29888)\n",
      "Epoch 2 Step 934/1563 Loss: 1.549 | Acc: 44.318% (13260/29920)\n",
      "Epoch 2 Step 935/1563 Loss: 1.549 | Acc: 44.318% (13274/29952)\n",
      "Epoch 2 Step 936/1563 Loss: 1.549 | Acc: 44.314% (13287/29984)\n",
      "Epoch 2 Step 937/1563 Loss: 1.548 | Acc: 44.330% (13306/30016)\n",
      "Epoch 2 Step 938/1563 Loss: 1.548 | Acc: 44.332% (13321/30048)\n",
      "Epoch 2 Step 939/1563 Loss: 1.549 | Acc: 44.312% (13329/30080)\n",
      "Epoch 2 Step 940/1563 Loss: 1.549 | Acc: 44.318% (13345/30112)\n",
      "Epoch 2 Step 941/1563 Loss: 1.549 | Acc: 44.317% (13359/30144)\n",
      "Epoch 2 Step 942/1563 Loss: 1.549 | Acc: 44.307% (13370/30176)\n",
      "Epoch 2 Step 943/1563 Loss: 1.549 | Acc: 44.306% (13384/30208)\n",
      "Epoch 2 Step 944/1563 Loss: 1.549 | Acc: 44.296% (13395/30240)\n",
      "Epoch 2 Step 945/1563 Loss: 1.549 | Acc: 44.305% (13412/30272)\n",
      "Epoch 2 Step 946/1563 Loss: 1.549 | Acc: 44.311% (13428/30304)\n",
      "Epoch 2 Step 947/1563 Loss: 1.549 | Acc: 44.284% (13434/30336)\n",
      "Epoch 2 Step 948/1563 Loss: 1.549 | Acc: 44.283% (13448/30368)\n",
      "Epoch 2 Step 949/1563 Loss: 1.549 | Acc: 44.286% (13463/30400)\n",
      "Epoch 2 Step 950/1563 Loss: 1.549 | Acc: 44.282% (13476/30432)\n",
      "Epoch 2 Step 951/1563 Loss: 1.550 | Acc: 44.269% (13486/30464)\n",
      "Epoch 2 Step 952/1563 Loss: 1.550 | Acc: 44.271% (13501/30496)\n",
      "Epoch 2 Step 953/1563 Loss: 1.549 | Acc: 44.287% (13520/30528)\n",
      "Epoch 2 Step 954/1563 Loss: 1.549 | Acc: 44.293% (13536/30560)\n",
      "Epoch 2 Step 955/1563 Loss: 1.549 | Acc: 44.283% (13547/30592)\n",
      "Epoch 2 Step 956/1563 Loss: 1.549 | Acc: 44.282% (13561/30624)\n",
      "Epoch 2 Step 957/1563 Loss: 1.549 | Acc: 44.272% (13572/30656)\n",
      "Epoch 2 Step 958/1563 Loss: 1.549 | Acc: 44.271% (13586/30688)\n",
      "Epoch 2 Step 959/1563 Loss: 1.549 | Acc: 44.290% (13606/30720)\n",
      "Epoch 2 Step 960/1563 Loss: 1.549 | Acc: 44.293% (13621/30752)\n",
      "Epoch 2 Step 961/1563 Loss: 1.549 | Acc: 44.302% (13638/30784)\n",
      "Epoch 2 Step 962/1563 Loss: 1.549 | Acc: 44.289% (13648/30816)\n",
      "Epoch 2 Step 963/1563 Loss: 1.549 | Acc: 44.275% (13658/30848)\n",
      "Epoch 2 Step 964/1563 Loss: 1.550 | Acc: 44.268% (13670/30880)\n",
      "Epoch 2 Step 965/1563 Loss: 1.550 | Acc: 44.264% (13683/30912)\n",
      "Epoch 2 Step 966/1563 Loss: 1.550 | Acc: 44.277% (13701/30944)\n",
      "Epoch 2 Step 967/1563 Loss: 1.550 | Acc: 44.273% (13714/30976)\n",
      "Epoch 2 Step 968/1563 Loss: 1.549 | Acc: 44.285% (13732/31008)\n",
      "Epoch 2 Step 969/1563 Loss: 1.550 | Acc: 44.275% (13743/31040)\n",
      "Epoch 2 Step 970/1563 Loss: 1.549 | Acc: 44.268% (13755/31072)\n",
      "Epoch 2 Step 971/1563 Loss: 1.549 | Acc: 44.280% (13773/31104)\n",
      "Epoch 2 Step 972/1563 Loss: 1.549 | Acc: 44.290% (13790/31136)\n",
      "Epoch 2 Step 973/1563 Loss: 1.550 | Acc: 44.273% (13799/31168)\n",
      "Epoch 2 Step 974/1563 Loss: 1.550 | Acc: 44.282% (13816/31200)\n",
      "Epoch 2 Step 975/1563 Loss: 1.550 | Acc: 44.272% (13827/31232)\n",
      "Epoch 2 Step 976/1563 Loss: 1.550 | Acc: 44.252% (13835/31264)\n",
      "Epoch 2 Step 977/1563 Loss: 1.550 | Acc: 44.248% (13848/31296)\n",
      "Epoch 2 Step 978/1563 Loss: 1.550 | Acc: 44.248% (13862/31328)\n",
      "Epoch 2 Step 979/1563 Loss: 1.550 | Acc: 44.263% (13881/31360)\n",
      "Epoch 2 Step 980/1563 Loss: 1.550 | Acc: 44.260% (13894/31392)\n",
      "Epoch 2 Step 981/1563 Loss: 1.550 | Acc: 44.259% (13908/31424)\n",
      "Epoch 2 Step 982/1563 Loss: 1.550 | Acc: 44.265% (13924/31456)\n",
      "Epoch 2 Step 983/1563 Loss: 1.550 | Acc: 44.261% (13937/31488)\n",
      "Epoch 2 Step 984/1563 Loss: 1.550 | Acc: 44.251% (13948/31520)\n",
      "Epoch 2 Step 985/1563 Loss: 1.550 | Acc: 44.248% (13961/31552)\n",
      "Epoch 2 Step 986/1563 Loss: 1.550 | Acc: 44.244% (13974/31584)\n",
      "Epoch 2 Step 987/1563 Loss: 1.551 | Acc: 44.240% (13987/31616)\n",
      "Epoch 2 Step 988/1563 Loss: 1.551 | Acc: 44.246% (14003/31648)\n",
      "Epoch 2 Step 989/1563 Loss: 1.551 | Acc: 44.249% (14018/31680)\n",
      "Epoch 2 Step 990/1563 Loss: 1.551 | Acc: 44.255% (14034/31712)\n",
      "Epoch 2 Step 991/1563 Loss: 1.550 | Acc: 44.263% (14051/31744)\n",
      "Epoch 2 Step 992/1563 Loss: 1.550 | Acc: 44.263% (14065/31776)\n",
      "Epoch 2 Step 993/1563 Loss: 1.551 | Acc: 44.266% (14080/31808)\n",
      "Epoch 2 Step 994/1563 Loss: 1.550 | Acc: 44.278% (14098/31840)\n",
      "Epoch 2 Step 995/1563 Loss: 1.550 | Acc: 44.280% (14113/31872)\n",
      "Epoch 2 Step 996/1563 Loss: 1.550 | Acc: 44.292% (14131/31904)\n",
      "Epoch 2 Step 997/1563 Loss: 1.550 | Acc: 44.304% (14149/31936)\n",
      "Epoch 2 Step 998/1563 Loss: 1.550 | Acc: 44.301% (14162/31968)\n",
      "Epoch 2 Step 999/1563 Loss: 1.550 | Acc: 44.294% (14174/32000)\n",
      "Epoch 2 Step 1000/1563 Loss: 1.550 | Acc: 44.306% (14192/32032)\n",
      "Epoch 2 Step 1001/1563 Loss: 1.550 | Acc: 44.296% (14203/32064)\n",
      "Epoch 2 Step 1002/1563 Loss: 1.550 | Acc: 44.311% (14222/32096)\n",
      "Epoch 2 Step 1003/1563 Loss: 1.549 | Acc: 44.320% (14239/32128)\n",
      "Epoch 2 Step 1004/1563 Loss: 1.549 | Acc: 44.325% (14255/32160)\n",
      "Epoch 2 Step 1005/1563 Loss: 1.549 | Acc: 44.322% (14268/32192)\n",
      "Epoch 2 Step 1006/1563 Loss: 1.549 | Acc: 44.318% (14281/32224)\n",
      "Epoch 2 Step 1007/1563 Loss: 1.549 | Acc: 44.320% (14296/32256)\n",
      "Epoch 2 Step 1008/1563 Loss: 1.549 | Acc: 44.311% (14307/32288)\n",
      "Epoch 2 Step 1009/1563 Loss: 1.549 | Acc: 44.319% (14324/32320)\n",
      "Epoch 2 Step 1010/1563 Loss: 1.549 | Acc: 44.322% (14339/32352)\n",
      "Epoch 2 Step 1011/1563 Loss: 1.549 | Acc: 44.309% (14349/32384)\n",
      "Epoch 2 Step 1012/1563 Loss: 1.549 | Acc: 44.311% (14364/32416)\n",
      "Epoch 2 Step 1013/1563 Loss: 1.549 | Acc: 44.320% (14381/32448)\n",
      "Epoch 2 Step 1014/1563 Loss: 1.549 | Acc: 44.326% (14397/32480)\n",
      "Epoch 2 Step 1015/1563 Loss: 1.548 | Acc: 44.328% (14412/32512)\n",
      "Epoch 2 Step 1016/1563 Loss: 1.548 | Acc: 44.331% (14427/32544)\n",
      "Epoch 2 Step 1017/1563 Loss: 1.548 | Acc: 44.355% (14449/32576)\n",
      "Epoch 2 Step 1018/1563 Loss: 1.547 | Acc: 44.360% (14465/32608)\n",
      "Epoch 2 Step 1019/1563 Loss: 1.547 | Acc: 44.360% (14479/32640)\n",
      "Epoch 2 Step 1020/1563 Loss: 1.547 | Acc: 44.365% (14495/32672)\n",
      "Epoch 2 Step 1021/1563 Loss: 1.547 | Acc: 44.362% (14508/32704)\n",
      "Epoch 2 Step 1022/1563 Loss: 1.548 | Acc: 44.367% (14524/32736)\n",
      "Epoch 2 Step 1023/1563 Loss: 1.548 | Acc: 44.366% (14538/32768)\n",
      "Epoch 2 Step 1024/1563 Loss: 1.548 | Acc: 44.381% (14557/32800)\n",
      "Epoch 2 Step 1025/1563 Loss: 1.547 | Acc: 44.390% (14574/32832)\n",
      "Epoch 2 Step 1026/1563 Loss: 1.547 | Acc: 44.389% (14588/32864)\n",
      "Epoch 2 Step 1027/1563 Loss: 1.547 | Acc: 44.404% (14607/32896)\n",
      "Epoch 2 Step 1028/1563 Loss: 1.547 | Acc: 44.397% (14619/32928)\n",
      "Epoch 2 Step 1029/1563 Loss: 1.547 | Acc: 44.396% (14633/32960)\n",
      "Epoch 2 Step 1030/1563 Loss: 1.547 | Acc: 44.390% (14645/32992)\n",
      "Epoch 2 Step 1031/1563 Loss: 1.547 | Acc: 44.383% (14657/33024)\n",
      "Epoch 2 Step 1032/1563 Loss: 1.547 | Acc: 44.391% (14674/33056)\n",
      "Epoch 2 Step 1033/1563 Loss: 1.547 | Acc: 44.388% (14687/33088)\n",
      "Epoch 2 Step 1034/1563 Loss: 1.547 | Acc: 44.396% (14704/33120)\n",
      "Epoch 2 Step 1035/1563 Loss: 1.547 | Acc: 44.389% (14716/33152)\n",
      "Epoch 2 Step 1036/1563 Loss: 1.547 | Acc: 44.392% (14731/33184)\n",
      "Epoch 2 Step 1037/1563 Loss: 1.547 | Acc: 44.385% (14743/33216)\n",
      "Epoch 2 Step 1038/1563 Loss: 1.547 | Acc: 44.397% (14761/33248)\n",
      "Epoch 2 Step 1039/1563 Loss: 1.547 | Acc: 44.393% (14774/33280)\n",
      "Epoch 2 Step 1040/1563 Loss: 1.547 | Acc: 44.395% (14789/33312)\n",
      "Epoch 2 Step 1041/1563 Loss: 1.547 | Acc: 44.392% (14802/33344)\n",
      "Epoch 2 Step 1042/1563 Loss: 1.547 | Acc: 44.403% (14820/33376)\n",
      "Epoch 2 Step 1043/1563 Loss: 1.547 | Acc: 44.391% (14830/33408)\n",
      "Epoch 2 Step 1044/1563 Loss: 1.547 | Acc: 44.393% (14845/33440)\n",
      "Epoch 2 Step 1045/1563 Loss: 1.547 | Acc: 44.383% (14856/33472)\n",
      "Epoch 2 Step 1046/1563 Loss: 1.547 | Acc: 44.389% (14872/33504)\n",
      "Epoch 2 Step 1047/1563 Loss: 1.547 | Acc: 44.394% (14888/33536)\n",
      "Epoch 2 Step 1048/1563 Loss: 1.547 | Acc: 44.385% (14899/33568)\n",
      "Epoch 2 Step 1049/1563 Loss: 1.547 | Acc: 44.381% (14912/33600)\n",
      "Epoch 2 Step 1050/1563 Loss: 1.547 | Acc: 44.374% (14924/33632)\n",
      "Epoch 2 Step 1051/1563 Loss: 1.547 | Acc: 44.377% (14939/33664)\n",
      "Epoch 2 Step 1052/1563 Loss: 1.547 | Acc: 44.388% (14957/33696)\n",
      "Epoch 2 Step 1053/1563 Loss: 1.547 | Acc: 44.408% (14978/33728)\n",
      "Epoch 2 Step 1054/1563 Loss: 1.547 | Acc: 44.402% (14990/33760)\n",
      "Epoch 2 Step 1055/1563 Loss: 1.547 | Acc: 44.395% (15002/33792)\n",
      "Epoch 2 Step 1056/1563 Loss: 1.547 | Acc: 44.397% (15017/33824)\n",
      "Epoch 2 Step 1057/1563 Loss: 1.547 | Acc: 44.385% (15027/33856)\n",
      "Epoch 2 Step 1058/1563 Loss: 1.547 | Acc: 44.384% (15041/33888)\n",
      "Epoch 2 Step 1059/1563 Loss: 1.547 | Acc: 44.384% (15055/33920)\n",
      "Epoch 2 Step 1060/1563 Loss: 1.547 | Acc: 44.386% (15070/33952)\n",
      "Epoch 2 Step 1061/1563 Loss: 1.547 | Acc: 44.386% (15084/33984)\n",
      "Epoch 2 Step 1062/1563 Loss: 1.547 | Acc: 44.382% (15097/34016)\n",
      "Epoch 2 Step 1063/1563 Loss: 1.547 | Acc: 44.376% (15109/34048)\n",
      "Epoch 2 Step 1064/1563 Loss: 1.547 | Acc: 44.372% (15122/34080)\n",
      "Epoch 2 Step 1065/1563 Loss: 1.548 | Acc: 44.369% (15135/34112)\n",
      "Epoch 2 Step 1066/1563 Loss: 1.547 | Acc: 44.374% (15151/34144)\n",
      "Epoch 2 Step 1067/1563 Loss: 1.547 | Acc: 44.370% (15164/34176)\n",
      "Epoch 2 Step 1068/1563 Loss: 1.548 | Acc: 44.364% (15176/34208)\n",
      "Epoch 2 Step 1069/1563 Loss: 1.548 | Acc: 44.363% (15190/34240)\n",
      "Epoch 2 Step 1070/1563 Loss: 1.548 | Acc: 44.363% (15204/34272)\n",
      "Epoch 2 Step 1071/1563 Loss: 1.548 | Acc: 44.368% (15220/34304)\n",
      "Epoch 2 Step 1072/1563 Loss: 1.548 | Acc: 44.370% (15235/34336)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 1073/1563 Loss: 1.548 | Acc: 44.364% (15247/34368)\n",
      "Epoch 2 Step 1074/1563 Loss: 1.547 | Acc: 44.375% (15265/34400)\n",
      "Epoch 2 Step 1075/1563 Loss: 1.547 | Acc: 44.380% (15281/34432)\n",
      "Epoch 2 Step 1076/1563 Loss: 1.547 | Acc: 44.380% (15295/34464)\n",
      "Epoch 2 Step 1077/1563 Loss: 1.547 | Acc: 44.370% (15306/34496)\n",
      "Epoch 2 Step 1078/1563 Loss: 1.547 | Acc: 44.378% (15323/34528)\n",
      "Epoch 2 Step 1079/1563 Loss: 1.547 | Acc: 44.389% (15341/34560)\n",
      "Epoch 2 Step 1080/1563 Loss: 1.547 | Acc: 44.386% (15354/34592)\n",
      "Epoch 2 Step 1081/1563 Loss: 1.547 | Acc: 44.400% (15373/34624)\n",
      "Epoch 2 Step 1082/1563 Loss: 1.547 | Acc: 44.393% (15385/34656)\n",
      "Epoch 2 Step 1083/1563 Loss: 1.547 | Acc: 44.413% (15406/34688)\n",
      "Epoch 2 Step 1084/1563 Loss: 1.547 | Acc: 44.415% (15421/34720)\n",
      "Epoch 2 Step 1085/1563 Loss: 1.546 | Acc: 44.418% (15436/34752)\n",
      "Epoch 2 Step 1086/1563 Loss: 1.547 | Acc: 44.408% (15447/34784)\n",
      "Epoch 2 Step 1087/1563 Loss: 1.547 | Acc: 44.411% (15462/34816)\n",
      "Epoch 2 Step 1088/1563 Loss: 1.547 | Acc: 44.404% (15474/34848)\n",
      "Epoch 2 Step 1089/1563 Loss: 1.547 | Acc: 44.389% (15483/34880)\n",
      "Epoch 2 Step 1090/1563 Loss: 1.547 | Acc: 44.386% (15496/34912)\n",
      "Epoch 2 Step 1091/1563 Loss: 1.547 | Acc: 44.388% (15511/34944)\n",
      "Epoch 2 Step 1092/1563 Loss: 1.547 | Acc: 44.379% (15522/34976)\n",
      "Epoch 2 Step 1093/1563 Loss: 1.547 | Acc: 44.376% (15535/35008)\n",
      "Epoch 2 Step 1094/1563 Loss: 1.547 | Acc: 44.361% (15544/35040)\n",
      "Epoch 2 Step 1095/1563 Loss: 1.547 | Acc: 44.369% (15561/35072)\n",
      "Epoch 2 Step 1096/1563 Loss: 1.547 | Acc: 44.368% (15575/35104)\n",
      "Epoch 2 Step 1097/1563 Loss: 1.547 | Acc: 44.365% (15588/35136)\n",
      "Epoch 2 Step 1098/1563 Loss: 1.547 | Acc: 44.367% (15603/35168)\n",
      "Epoch 2 Step 1099/1563 Loss: 1.547 | Acc: 44.369% (15618/35200)\n",
      "Epoch 2 Step 1100/1563 Loss: 1.547 | Acc: 44.366% (15631/35232)\n",
      "Epoch 2 Step 1101/1563 Loss: 1.547 | Acc: 44.380% (15650/35264)\n",
      "Epoch 2 Step 1102/1563 Loss: 1.547 | Acc: 44.368% (15660/35296)\n",
      "Epoch 2 Step 1103/1563 Loss: 1.547 | Acc: 44.373% (15676/35328)\n",
      "Epoch 2 Step 1104/1563 Loss: 1.547 | Acc: 44.372% (15690/35360)\n",
      "Epoch 2 Step 1105/1563 Loss: 1.547 | Acc: 44.389% (15710/35392)\n",
      "Epoch 2 Step 1106/1563 Loss: 1.546 | Acc: 44.408% (15731/35424)\n",
      "Epoch 2 Step 1107/1563 Loss: 1.546 | Acc: 44.410% (15746/35456)\n",
      "Epoch 2 Step 1108/1563 Loss: 1.546 | Acc: 44.415% (15762/35488)\n",
      "Epoch 2 Step 1109/1563 Loss: 1.546 | Acc: 44.426% (15780/35520)\n",
      "Epoch 2 Step 1110/1563 Loss: 1.546 | Acc: 44.431% (15796/35552)\n",
      "Epoch 2 Step 1111/1563 Loss: 1.546 | Acc: 44.422% (15807/35584)\n",
      "Epoch 2 Step 1112/1563 Loss: 1.546 | Acc: 44.429% (15824/35616)\n",
      "Epoch 2 Step 1113/1563 Loss: 1.545 | Acc: 44.440% (15842/35648)\n",
      "Epoch 2 Step 1114/1563 Loss: 1.546 | Acc: 44.434% (15854/35680)\n",
      "Epoch 2 Step 1115/1563 Loss: 1.546 | Acc: 44.422% (15864/35712)\n",
      "Epoch 2 Step 1116/1563 Loss: 1.546 | Acc: 44.433% (15882/35744)\n",
      "Epoch 2 Step 1117/1563 Loss: 1.546 | Acc: 44.426% (15894/35776)\n",
      "Epoch 2 Step 1118/1563 Loss: 1.546 | Acc: 44.429% (15909/35808)\n",
      "Epoch 2 Step 1119/1563 Loss: 1.546 | Acc: 44.422% (15921/35840)\n",
      "Epoch 2 Step 1120/1563 Loss: 1.546 | Acc: 44.425% (15936/35872)\n",
      "Epoch 2 Step 1121/1563 Loss: 1.546 | Acc: 44.430% (15952/35904)\n",
      "Epoch 2 Step 1122/1563 Loss: 1.545 | Acc: 44.448% (15973/35936)\n",
      "Epoch 2 Step 1123/1563 Loss: 1.545 | Acc: 44.442% (15985/35968)\n",
      "Epoch 2 Step 1124/1563 Loss: 1.545 | Acc: 44.439% (15998/36000)\n",
      "Epoch 2 Step 1125/1563 Loss: 1.545 | Acc: 44.447% (16015/36032)\n",
      "Epoch 2 Step 1126/1563 Loss: 1.545 | Acc: 44.449% (16030/36064)\n",
      "Epoch 2 Step 1127/1563 Loss: 1.546 | Acc: 44.437% (16040/36096)\n",
      "Epoch 2 Step 1128/1563 Loss: 1.546 | Acc: 44.436% (16054/36128)\n",
      "Epoch 2 Step 1129/1563 Loss: 1.546 | Acc: 44.433% (16067/36160)\n",
      "Epoch 2 Step 1130/1563 Loss: 1.546 | Acc: 44.446% (16086/36192)\n",
      "Epoch 2 Step 1131/1563 Loss: 1.546 | Acc: 44.443% (16099/36224)\n",
      "Epoch 2 Step 1132/1563 Loss: 1.546 | Acc: 44.440% (16112/36256)\n",
      "Epoch 2 Step 1133/1563 Loss: 1.546 | Acc: 44.439% (16126/36288)\n",
      "Epoch 2 Step 1134/1563 Loss: 1.546 | Acc: 44.436% (16139/36320)\n",
      "Epoch 2 Step 1135/1563 Loss: 1.546 | Acc: 44.429% (16151/36352)\n",
      "Epoch 2 Step 1136/1563 Loss: 1.546 | Acc: 44.434% (16167/36384)\n",
      "Epoch 2 Step 1137/1563 Loss: 1.546 | Acc: 44.445% (16185/36416)\n",
      "Epoch 2 Step 1138/1563 Loss: 1.546 | Acc: 44.450% (16201/36448)\n",
      "Epoch 2 Step 1139/1563 Loss: 1.546 | Acc: 44.460% (16219/36480)\n",
      "Epoch 2 Step 1140/1563 Loss: 1.546 | Acc: 44.457% (16232/36512)\n",
      "Epoch 2 Step 1141/1563 Loss: 1.546 | Acc: 44.459% (16247/36544)\n",
      "Epoch 2 Step 1142/1563 Loss: 1.545 | Acc: 44.477% (16268/36576)\n",
      "Epoch 2 Step 1143/1563 Loss: 1.545 | Acc: 44.474% (16281/36608)\n",
      "Epoch 2 Step 1144/1563 Loss: 1.545 | Acc: 44.487% (16300/36640)\n",
      "Epoch 2 Step 1145/1563 Loss: 1.545 | Acc: 44.481% (16312/36672)\n",
      "Epoch 2 Step 1146/1563 Loss: 1.545 | Acc: 44.494% (16331/36704)\n",
      "Epoch 2 Step 1147/1563 Loss: 1.545 | Acc: 44.488% (16343/36736)\n",
      "Epoch 2 Step 1148/1563 Loss: 1.545 | Acc: 44.487% (16357/36768)\n",
      "Epoch 2 Step 1149/1563 Loss: 1.545 | Acc: 44.484% (16370/36800)\n",
      "Epoch 2 Step 1150/1563 Loss: 1.545 | Acc: 44.469% (16379/36832)\n",
      "Epoch 2 Step 1151/1563 Loss: 1.545 | Acc: 44.472% (16394/36864)\n",
      "Epoch 2 Step 1152/1563 Loss: 1.545 | Acc: 44.474% (16409/36896)\n",
      "Epoch 2 Step 1153/1563 Loss: 1.545 | Acc: 44.468% (16421/36928)\n",
      "Epoch 2 Step 1154/1563 Loss: 1.545 | Acc: 44.464% (16434/36960)\n",
      "Epoch 2 Step 1155/1563 Loss: 1.545 | Acc: 44.466% (16449/36992)\n",
      "Epoch 2 Step 1156/1563 Loss: 1.545 | Acc: 44.466% (16463/37024)\n",
      "Epoch 2 Step 1157/1563 Loss: 1.545 | Acc: 44.460% (16475/37056)\n",
      "Epoch 2 Step 1158/1563 Loss: 1.545 | Acc: 44.451% (16486/37088)\n",
      "Epoch 2 Step 1159/1563 Loss: 1.545 | Acc: 44.437% (16495/37120)\n",
      "Epoch 2 Step 1160/1563 Loss: 1.545 | Acc: 44.442% (16511/37152)\n",
      "Epoch 2 Step 1161/1563 Loss: 1.545 | Acc: 44.430% (16521/37184)\n",
      "Epoch 2 Step 1162/1563 Loss: 1.545 | Acc: 44.433% (16536/37216)\n",
      "Epoch 2 Step 1163/1563 Loss: 1.545 | Acc: 44.437% (16552/37248)\n",
      "Epoch 2 Step 1164/1563 Loss: 1.545 | Acc: 44.434% (16565/37280)\n",
      "Epoch 2 Step 1165/1563 Loss: 1.545 | Acc: 44.436% (16580/37312)\n",
      "Epoch 2 Step 1166/1563 Loss: 1.545 | Acc: 44.444% (16597/37344)\n",
      "Epoch 2 Step 1167/1563 Loss: 1.545 | Acc: 44.467% (16620/37376)\n",
      "Epoch 2 Step 1168/1563 Loss: 1.544 | Acc: 44.466% (16634/37408)\n",
      "Epoch 2 Step 1169/1563 Loss: 1.544 | Acc: 44.455% (16644/37440)\n",
      "Epoch 2 Step 1170/1563 Loss: 1.545 | Acc: 44.444% (16654/37472)\n",
      "Epoch 2 Step 1171/1563 Loss: 1.545 | Acc: 44.449% (16670/37504)\n",
      "Epoch 2 Step 1172/1563 Loss: 1.545 | Acc: 44.451% (16685/37536)\n",
      "Epoch 2 Step 1173/1563 Loss: 1.545 | Acc: 44.455% (16701/37568)\n",
      "Epoch 2 Step 1174/1563 Loss: 1.545 | Acc: 44.452% (16714/37600)\n",
      "Epoch 2 Step 1175/1563 Loss: 1.545 | Acc: 44.470% (16735/37632)\n",
      "Epoch 2 Step 1176/1563 Loss: 1.545 | Acc: 44.470% (16749/37664)\n",
      "Epoch 2 Step 1177/1563 Loss: 1.544 | Acc: 44.480% (16767/37696)\n",
      "Epoch 2 Step 1178/1563 Loss: 1.544 | Acc: 44.490% (16785/37728)\n",
      "Epoch 2 Step 1179/1563 Loss: 1.544 | Acc: 44.492% (16800/37760)\n",
      "Epoch 2 Step 1180/1563 Loss: 1.544 | Acc: 44.509% (16821/37792)\n",
      "Epoch 2 Step 1181/1563 Loss: 1.544 | Acc: 44.511% (16836/37824)\n",
      "Epoch 2 Step 1182/1563 Loss: 1.544 | Acc: 44.527% (16856/37856)\n",
      "Epoch 2 Step 1183/1563 Loss: 1.544 | Acc: 44.531% (16872/37888)\n",
      "Epoch 2 Step 1184/1563 Loss: 1.544 | Acc: 44.531% (16886/37920)\n",
      "Epoch 2 Step 1185/1563 Loss: 1.544 | Acc: 44.535% (16902/37952)\n",
      "Epoch 2 Step 1186/1563 Loss: 1.543 | Acc: 44.535% (16916/37984)\n",
      "Epoch 2 Step 1187/1563 Loss: 1.544 | Acc: 44.523% (16926/38016)\n",
      "Epoch 2 Step 1188/1563 Loss: 1.544 | Acc: 44.525% (16941/38048)\n",
      "Epoch 2 Step 1189/1563 Loss: 1.544 | Acc: 44.525% (16955/38080)\n",
      "Epoch 2 Step 1190/1563 Loss: 1.544 | Acc: 44.516% (16966/38112)\n",
      "Epoch 2 Step 1191/1563 Loss: 1.544 | Acc: 44.523% (16983/38144)\n",
      "Epoch 2 Step 1192/1563 Loss: 1.544 | Acc: 44.525% (16998/38176)\n",
      "Epoch 2 Step 1193/1563 Loss: 1.544 | Acc: 44.522% (17011/38208)\n",
      "Epoch 2 Step 1194/1563 Loss: 1.544 | Acc: 44.524% (17026/38240)\n",
      "Epoch 2 Step 1195/1563 Loss: 1.544 | Acc: 44.513% (17036/38272)\n",
      "Epoch 2 Step 1196/1563 Loss: 1.544 | Acc: 44.510% (17049/38304)\n",
      "Epoch 2 Step 1197/1563 Loss: 1.544 | Acc: 44.506% (17062/38336)\n",
      "Epoch 2 Step 1198/1563 Loss: 1.544 | Acc: 44.511% (17078/38368)\n",
      "Epoch 2 Step 1199/1563 Loss: 1.544 | Acc: 44.503% (17089/38400)\n",
      "Epoch 2 Step 1200/1563 Loss: 1.544 | Acc: 44.510% (17106/38432)\n",
      "Epoch 2 Step 1201/1563 Loss: 1.544 | Acc: 44.496% (17115/38464)\n",
      "Epoch 2 Step 1202/1563 Loss: 1.544 | Acc: 44.493% (17128/38496)\n",
      "Epoch 2 Step 1203/1563 Loss: 1.544 | Acc: 44.495% (17143/38528)\n",
      "Epoch 2 Step 1204/1563 Loss: 1.544 | Acc: 44.499% (17159/38560)\n",
      "Epoch 2 Step 1205/1563 Loss: 1.544 | Acc: 44.496% (17172/38592)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 1206/1563 Loss: 1.544 | Acc: 44.496% (17186/38624)\n",
      "Epoch 2 Step 1207/1563 Loss: 1.544 | Acc: 44.508% (17205/38656)\n",
      "Epoch 2 Step 1208/1563 Loss: 1.544 | Acc: 44.502% (17217/38688)\n",
      "Epoch 2 Step 1209/1563 Loss: 1.544 | Acc: 44.496% (17229/38720)\n",
      "Epoch 2 Step 1210/1563 Loss: 1.544 | Acc: 44.498% (17244/38752)\n",
      "Epoch 2 Step 1211/1563 Loss: 1.544 | Acc: 44.503% (17260/38784)\n",
      "Epoch 2 Step 1212/1563 Loss: 1.544 | Acc: 44.500% (17273/38816)\n",
      "Epoch 2 Step 1213/1563 Loss: 1.544 | Acc: 44.489% (17283/38848)\n",
      "Epoch 2 Step 1214/1563 Loss: 1.544 | Acc: 44.480% (17294/38880)\n",
      "Epoch 2 Step 1215/1563 Loss: 1.544 | Acc: 44.475% (17306/38912)\n",
      "Epoch 2 Step 1216/1563 Loss: 1.544 | Acc: 44.487% (17325/38944)\n",
      "Epoch 2 Step 1217/1563 Loss: 1.544 | Acc: 44.489% (17340/38976)\n",
      "Epoch 2 Step 1218/1563 Loss: 1.544 | Acc: 44.483% (17352/39008)\n",
      "Epoch 2 Step 1219/1563 Loss: 1.544 | Acc: 44.495% (17371/39040)\n",
      "Epoch 2 Step 1220/1563 Loss: 1.544 | Acc: 44.492% (17384/39072)\n",
      "Epoch 2 Step 1221/1563 Loss: 1.544 | Acc: 44.504% (17403/39104)\n",
      "Epoch 2 Step 1222/1563 Loss: 1.544 | Acc: 44.496% (17414/39136)\n",
      "Epoch 2 Step 1223/1563 Loss: 1.544 | Acc: 44.490% (17426/39168)\n",
      "Epoch 2 Step 1224/1563 Loss: 1.544 | Acc: 44.482% (17437/39200)\n",
      "Epoch 2 Step 1225/1563 Loss: 1.544 | Acc: 44.494% (17456/39232)\n",
      "Epoch 2 Step 1226/1563 Loss: 1.544 | Acc: 44.494% (17470/39264)\n",
      "Epoch 2 Step 1227/1563 Loss: 1.544 | Acc: 44.485% (17481/39296)\n",
      "Epoch 2 Step 1228/1563 Loss: 1.544 | Acc: 44.475% (17491/39328)\n",
      "Epoch 2 Step 1229/1563 Loss: 1.544 | Acc: 44.492% (17512/39360)\n",
      "Epoch 2 Step 1230/1563 Loss: 1.544 | Acc: 44.496% (17528/39392)\n",
      "Epoch 2 Step 1231/1563 Loss: 1.543 | Acc: 44.506% (17546/39424)\n",
      "Epoch 2 Step 1232/1563 Loss: 1.543 | Acc: 44.508% (17561/39456)\n",
      "Epoch 2 Step 1233/1563 Loss: 1.543 | Acc: 44.507% (17575/39488)\n",
      "Epoch 2 Step 1234/1563 Loss: 1.543 | Acc: 44.514% (17592/39520)\n",
      "Epoch 2 Step 1235/1563 Loss: 1.543 | Acc: 44.514% (17606/39552)\n",
      "Epoch 2 Step 1236/1563 Loss: 1.543 | Acc: 44.508% (17618/39584)\n",
      "Epoch 2 Step 1237/1563 Loss: 1.543 | Acc: 44.502% (17630/39616)\n",
      "Epoch 2 Step 1238/1563 Loss: 1.543 | Acc: 44.512% (17648/39648)\n",
      "Epoch 2 Step 1239/1563 Loss: 1.543 | Acc: 44.506% (17660/39680)\n",
      "Epoch 2 Step 1240/1563 Loss: 1.543 | Acc: 44.503% (17673/39712)\n",
      "Epoch 2 Step 1241/1563 Loss: 1.543 | Acc: 44.510% (17690/39744)\n",
      "Epoch 2 Step 1242/1563 Loss: 1.543 | Acc: 44.522% (17709/39776)\n",
      "Epoch 2 Step 1243/1563 Loss: 1.543 | Acc: 44.514% (17720/39808)\n",
      "Epoch 2 Step 1244/1563 Loss: 1.543 | Acc: 44.518% (17736/39840)\n",
      "Epoch 2 Step 1245/1563 Loss: 1.543 | Acc: 44.522% (17752/39872)\n",
      "Epoch 2 Step 1246/1563 Loss: 1.543 | Acc: 44.519% (17765/39904)\n",
      "Epoch 2 Step 1247/1563 Loss: 1.543 | Acc: 44.519% (17779/39936)\n",
      "Epoch 2 Step 1248/1563 Loss: 1.543 | Acc: 44.523% (17795/39968)\n",
      "Epoch 2 Step 1249/1563 Loss: 1.542 | Acc: 44.528% (17811/40000)\n",
      "Epoch 2 Step 1250/1563 Loss: 1.542 | Acc: 44.532% (17827/40032)\n",
      "Epoch 2 Step 1251/1563 Loss: 1.542 | Acc: 44.539% (17844/40064)\n",
      "Epoch 2 Step 1252/1563 Loss: 1.542 | Acc: 44.538% (17858/40096)\n",
      "Epoch 2 Step 1253/1563 Loss: 1.542 | Acc: 44.550% (17877/40128)\n",
      "Epoch 2 Step 1254/1563 Loss: 1.542 | Acc: 44.559% (17895/40160)\n",
      "Epoch 2 Step 1255/1563 Loss: 1.542 | Acc: 44.564% (17911/40192)\n",
      "Epoch 2 Step 1256/1563 Loss: 1.542 | Acc: 44.565% (17926/40224)\n",
      "Epoch 2 Step 1257/1563 Loss: 1.541 | Acc: 44.567% (17941/40256)\n",
      "Epoch 2 Step 1258/1563 Loss: 1.542 | Acc: 44.559% (17952/40288)\n",
      "Epoch 2 Step 1259/1563 Loss: 1.542 | Acc: 44.561% (17967/40320)\n",
      "Epoch 2 Step 1260/1563 Loss: 1.541 | Acc: 44.568% (17984/40352)\n",
      "Epoch 2 Step 1261/1563 Loss: 1.542 | Acc: 44.572% (18000/40384)\n",
      "Epoch 2 Step 1262/1563 Loss: 1.541 | Acc: 44.586% (18020/40416)\n",
      "Epoch 2 Step 1263/1563 Loss: 1.541 | Acc: 44.588% (18035/40448)\n",
      "Epoch 2 Step 1264/1563 Loss: 1.541 | Acc: 44.583% (18047/40480)\n",
      "Epoch 2 Step 1265/1563 Loss: 1.541 | Acc: 44.582% (18061/40512)\n",
      "Epoch 2 Step 1266/1563 Loss: 1.541 | Acc: 44.589% (18078/40544)\n",
      "Epoch 2 Step 1267/1563 Loss: 1.541 | Acc: 44.588% (18092/40576)\n",
      "Epoch 2 Step 1268/1563 Loss: 1.541 | Acc: 44.592% (18108/40608)\n",
      "Epoch 2 Step 1269/1563 Loss: 1.541 | Acc: 44.594% (18123/40640)\n",
      "Epoch 2 Step 1270/1563 Loss: 1.541 | Acc: 44.601% (18140/40672)\n",
      "Epoch 2 Step 1271/1563 Loss: 1.541 | Acc: 44.598% (18153/40704)\n",
      "Epoch 2 Step 1272/1563 Loss: 1.541 | Acc: 44.602% (18169/40736)\n",
      "Epoch 2 Step 1273/1563 Loss: 1.541 | Acc: 44.589% (18178/40768)\n",
      "Epoch 2 Step 1274/1563 Loss: 1.541 | Acc: 44.596% (18195/40800)\n",
      "Epoch 2 Step 1275/1563 Loss: 1.541 | Acc: 44.595% (18209/40832)\n",
      "Epoch 2 Step 1276/1563 Loss: 1.541 | Acc: 44.594% (18223/40864)\n",
      "Epoch 2 Step 1277/1563 Loss: 1.541 | Acc: 44.591% (18236/40896)\n",
      "Epoch 2 Step 1278/1563 Loss: 1.541 | Acc: 44.588% (18249/40928)\n",
      "Epoch 2 Step 1279/1563 Loss: 1.541 | Acc: 44.585% (18262/40960)\n",
      "Epoch 2 Step 1280/1563 Loss: 1.541 | Acc: 44.582% (18275/40992)\n",
      "Epoch 2 Step 1281/1563 Loss: 1.541 | Acc: 44.584% (18290/41024)\n",
      "Epoch 2 Step 1282/1563 Loss: 1.541 | Acc: 44.593% (18308/41056)\n",
      "Epoch 2 Step 1283/1563 Loss: 1.541 | Acc: 44.597% (18324/41088)\n",
      "Epoch 2 Step 1284/1563 Loss: 1.541 | Acc: 44.601% (18340/41120)\n",
      "Epoch 2 Step 1285/1563 Loss: 1.541 | Acc: 44.605% (18356/41152)\n",
      "Epoch 2 Step 1286/1563 Loss: 1.541 | Acc: 44.600% (18368/41184)\n",
      "Epoch 2 Step 1287/1563 Loss: 1.541 | Acc: 44.604% (18384/41216)\n",
      "Epoch 2 Step 1288/1563 Loss: 1.541 | Acc: 44.586% (18391/41248)\n",
      "Epoch 2 Step 1289/1563 Loss: 1.541 | Acc: 44.595% (18409/41280)\n",
      "Epoch 2 Step 1290/1563 Loss: 1.541 | Acc: 44.592% (18422/41312)\n",
      "Epoch 2 Step 1291/1563 Loss: 1.541 | Acc: 44.592% (18436/41344)\n",
      "Epoch 2 Step 1292/1563 Loss: 1.541 | Acc: 44.596% (18452/41376)\n",
      "Epoch 2 Step 1293/1563 Loss: 1.541 | Acc: 44.590% (18464/41408)\n",
      "Epoch 2 Step 1294/1563 Loss: 1.541 | Acc: 44.585% (18476/41440)\n",
      "Epoch 2 Step 1295/1563 Loss: 1.541 | Acc: 44.582% (18489/41472)\n",
      "Epoch 2 Step 1296/1563 Loss: 1.541 | Acc: 44.579% (18502/41504)\n",
      "Epoch 2 Step 1297/1563 Loss: 1.541 | Acc: 44.588% (18520/41536)\n",
      "Epoch 2 Step 1298/1563 Loss: 1.541 | Acc: 44.604% (18541/41568)\n",
      "Epoch 2 Step 1299/1563 Loss: 1.541 | Acc: 44.601% (18554/41600)\n",
      "Epoch 2 Step 1300/1563 Loss: 1.541 | Acc: 44.586% (18562/41632)\n",
      "Epoch 2 Step 1301/1563 Loss: 1.541 | Acc: 44.568% (18569/41664)\n",
      "Epoch 2 Step 1302/1563 Loss: 1.541 | Acc: 44.565% (18582/41696)\n",
      "Epoch 2 Step 1303/1563 Loss: 1.541 | Acc: 44.570% (18598/41728)\n",
      "Epoch 2 Step 1304/1563 Loss: 1.541 | Acc: 44.559% (18608/41760)\n",
      "Epoch 2 Step 1305/1563 Loss: 1.541 | Acc: 44.564% (18624/41792)\n",
      "Epoch 2 Step 1306/1563 Loss: 1.541 | Acc: 44.568% (18640/41824)\n",
      "Epoch 2 Step 1307/1563 Loss: 1.541 | Acc: 44.565% (18653/41856)\n",
      "Epoch 2 Step 1308/1563 Loss: 1.541 | Acc: 44.559% (18665/41888)\n",
      "Epoch 2 Step 1309/1563 Loss: 1.541 | Acc: 44.568% (18683/41920)\n",
      "Epoch 2 Step 1310/1563 Loss: 1.541 | Acc: 44.563% (18695/41952)\n",
      "Epoch 2 Step 1311/1563 Loss: 1.541 | Acc: 44.557% (18707/41984)\n",
      "Epoch 2 Step 1312/1563 Loss: 1.541 | Acc: 44.552% (18719/42016)\n",
      "Epoch 2 Step 1313/1563 Loss: 1.541 | Acc: 44.540% (18728/42048)\n",
      "Epoch 2 Step 1314/1563 Loss: 1.541 | Acc: 44.553% (18748/42080)\n",
      "Epoch 2 Step 1315/1563 Loss: 1.541 | Acc: 44.564% (18767/42112)\n",
      "Epoch 2 Step 1316/1563 Loss: 1.541 | Acc: 44.557% (18778/42144)\n",
      "Epoch 2 Step 1317/1563 Loss: 1.541 | Acc: 44.559% (18793/42176)\n",
      "Epoch 2 Step 1318/1563 Loss: 1.540 | Acc: 44.567% (18811/42208)\n",
      "Epoch 2 Step 1319/1563 Loss: 1.540 | Acc: 44.569% (18826/42240)\n",
      "Epoch 2 Step 1320/1563 Loss: 1.540 | Acc: 44.587% (18848/42272)\n",
      "Epoch 2 Step 1321/1563 Loss: 1.540 | Acc: 44.580% (18859/42304)\n",
      "Epoch 2 Step 1322/1563 Loss: 1.540 | Acc: 44.574% (18871/42336)\n",
      "Epoch 2 Step 1323/1563 Loss: 1.541 | Acc: 44.571% (18884/42368)\n",
      "Epoch 2 Step 1324/1563 Loss: 1.541 | Acc: 44.578% (18901/42400)\n",
      "Epoch 2 Step 1325/1563 Loss: 1.541 | Acc: 44.570% (18912/42432)\n",
      "Epoch 2 Step 1326/1563 Loss: 1.541 | Acc: 44.565% (18924/42464)\n",
      "Epoch 2 Step 1327/1563 Loss: 1.541 | Acc: 44.559% (18936/42496)\n",
      "Epoch 2 Step 1328/1563 Loss: 1.541 | Acc: 44.559% (18950/42528)\n",
      "Epoch 2 Step 1329/1563 Loss: 1.541 | Acc: 44.549% (18960/42560)\n",
      "Epoch 2 Step 1330/1563 Loss: 1.541 | Acc: 44.546% (18973/42592)\n",
      "Epoch 2 Step 1331/1563 Loss: 1.541 | Acc: 44.550% (18989/42624)\n",
      "Epoch 2 Step 1332/1563 Loss: 1.541 | Acc: 44.561% (19008/42656)\n",
      "Epoch 2 Step 1333/1563 Loss: 1.541 | Acc: 44.549% (19017/42688)\n",
      "Epoch 2 Step 1334/1563 Loss: 1.541 | Acc: 44.544% (19029/42720)\n",
      "Epoch 2 Step 1335/1563 Loss: 1.541 | Acc: 44.550% (19046/42752)\n",
      "Epoch 2 Step 1336/1563 Loss: 1.541 | Acc: 44.559% (19064/42784)\n",
      "Epoch 2 Step 1337/1563 Loss: 1.541 | Acc: 44.549% (19074/42816)\n",
      "Epoch 2 Step 1338/1563 Loss: 1.541 | Acc: 44.546% (19087/42848)\n",
      "Epoch 2 Step 1339/1563 Loss: 1.541 | Acc: 44.541% (19099/42880)\n",
      "Epoch 2 Step 1340/1563 Loss: 1.541 | Acc: 44.538% (19112/42912)\n",
      "Epoch 2 Step 1341/1563 Loss: 1.541 | Acc: 44.539% (19127/42944)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 1342/1563 Loss: 1.541 | Acc: 44.539% (19141/42976)\n",
      "Epoch 2 Step 1343/1563 Loss: 1.541 | Acc: 44.538% (19155/43008)\n",
      "Epoch 2 Step 1344/1563 Loss: 1.541 | Acc: 44.538% (19169/43040)\n",
      "Epoch 2 Step 1345/1563 Loss: 1.541 | Acc: 44.532% (19181/43072)\n",
      "Epoch 2 Step 1346/1563 Loss: 1.541 | Acc: 44.518% (19189/43104)\n",
      "Epoch 2 Step 1347/1563 Loss: 1.541 | Acc: 44.517% (19203/43136)\n",
      "Epoch 2 Step 1348/1563 Loss: 1.541 | Acc: 44.514% (19216/43168)\n",
      "Epoch 2 Step 1349/1563 Loss: 1.541 | Acc: 44.509% (19228/43200)\n",
      "Epoch 2 Step 1350/1563 Loss: 1.541 | Acc: 44.509% (19242/43232)\n",
      "Epoch 2 Step 1351/1563 Loss: 1.541 | Acc: 44.499% (19252/43264)\n",
      "Epoch 2 Step 1352/1563 Loss: 1.542 | Acc: 44.487% (19261/43296)\n",
      "Epoch 2 Step 1353/1563 Loss: 1.542 | Acc: 44.479% (19272/43328)\n",
      "Epoch 2 Step 1354/1563 Loss: 1.542 | Acc: 44.472% (19283/43360)\n",
      "Epoch 2 Step 1355/1563 Loss: 1.542 | Acc: 44.474% (19298/43392)\n",
      "Epoch 2 Step 1356/1563 Loss: 1.542 | Acc: 44.475% (19313/43424)\n",
      "Epoch 2 Step 1357/1563 Loss: 1.542 | Acc: 44.475% (19327/43456)\n",
      "Epoch 2 Step 1358/1563 Loss: 1.542 | Acc: 44.484% (19345/43488)\n",
      "Epoch 2 Step 1359/1563 Loss: 1.542 | Acc: 44.478% (19357/43520)\n",
      "Epoch 2 Step 1360/1563 Loss: 1.542 | Acc: 44.473% (19369/43552)\n",
      "Epoch 2 Step 1361/1563 Loss: 1.542 | Acc: 44.477% (19385/43584)\n",
      "Epoch 2 Step 1362/1563 Loss: 1.542 | Acc: 44.481% (19401/43616)\n",
      "Epoch 2 Step 1363/1563 Loss: 1.542 | Acc: 44.483% (19416/43648)\n",
      "Epoch 2 Step 1364/1563 Loss: 1.542 | Acc: 44.485% (19431/43680)\n",
      "Epoch 2 Step 1365/1563 Loss: 1.542 | Acc: 44.491% (19448/43712)\n",
      "Epoch 2 Step 1366/1563 Loss: 1.542 | Acc: 44.488% (19461/43744)\n",
      "Epoch 2 Step 1367/1563 Loss: 1.542 | Acc: 44.476% (19470/43776)\n",
      "Epoch 2 Step 1368/1563 Loss: 1.542 | Acc: 44.476% (19484/43808)\n",
      "Epoch 2 Step 1369/1563 Loss: 1.542 | Acc: 44.478% (19499/43840)\n",
      "Epoch 2 Step 1370/1563 Loss: 1.542 | Acc: 44.473% (19511/43872)\n",
      "Epoch 2 Step 1371/1563 Loss: 1.542 | Acc: 44.472% (19525/43904)\n",
      "Epoch 2 Step 1372/1563 Loss: 1.542 | Acc: 44.474% (19540/43936)\n",
      "Epoch 2 Step 1373/1563 Loss: 1.542 | Acc: 44.480% (19557/43968)\n",
      "Epoch 2 Step 1374/1563 Loss: 1.542 | Acc: 44.489% (19575/44000)\n",
      "Epoch 2 Step 1375/1563 Loss: 1.542 | Acc: 44.497% (19593/44032)\n",
      "Epoch 2 Step 1376/1563 Loss: 1.542 | Acc: 44.494% (19606/44064)\n",
      "Epoch 2 Step 1377/1563 Loss: 1.542 | Acc: 44.489% (19618/44096)\n",
      "Epoch 2 Step 1378/1563 Loss: 1.542 | Acc: 44.496% (19635/44128)\n",
      "Epoch 2 Step 1379/1563 Loss: 1.542 | Acc: 44.502% (19652/44160)\n",
      "Epoch 2 Step 1380/1563 Loss: 1.541 | Acc: 44.510% (19670/44192)\n",
      "Epoch 2 Step 1381/1563 Loss: 1.541 | Acc: 44.521% (19689/44224)\n",
      "Epoch 2 Step 1382/1563 Loss: 1.541 | Acc: 44.516% (19701/44256)\n",
      "Epoch 2 Step 1383/1563 Loss: 1.541 | Acc: 44.524% (19719/44288)\n",
      "Epoch 2 Step 1384/1563 Loss: 1.541 | Acc: 44.524% (19733/44320)\n",
      "Epoch 2 Step 1385/1563 Loss: 1.541 | Acc: 44.530% (19750/44352)\n",
      "Epoch 2 Step 1386/1563 Loss: 1.541 | Acc: 44.530% (19764/44384)\n",
      "Epoch 2 Step 1387/1563 Loss: 1.541 | Acc: 44.529% (19778/44416)\n",
      "Epoch 2 Step 1388/1563 Loss: 1.541 | Acc: 44.528% (19792/44448)\n",
      "Epoch 2 Step 1389/1563 Loss: 1.541 | Acc: 44.535% (19809/44480)\n",
      "Epoch 2 Step 1390/1563 Loss: 1.541 | Acc: 44.534% (19823/44512)\n",
      "Epoch 2 Step 1391/1563 Loss: 1.541 | Acc: 44.536% (19838/44544)\n",
      "Epoch 2 Step 1392/1563 Loss: 1.541 | Acc: 44.542% (19855/44576)\n",
      "Epoch 2 Step 1393/1563 Loss: 1.541 | Acc: 44.535% (19866/44608)\n",
      "Epoch 2 Step 1394/1563 Loss: 1.541 | Acc: 44.534% (19880/44640)\n",
      "Epoch 2 Step 1395/1563 Loss: 1.541 | Acc: 44.536% (19895/44672)\n",
      "Epoch 2 Step 1396/1563 Loss: 1.540 | Acc: 44.546% (19914/44704)\n",
      "Epoch 2 Step 1397/1563 Loss: 1.540 | Acc: 44.541% (19926/44736)\n",
      "Epoch 2 Step 1398/1563 Loss: 1.540 | Acc: 44.545% (19942/44768)\n",
      "Epoch 2 Step 1399/1563 Loss: 1.540 | Acc: 44.556% (19961/44800)\n",
      "Epoch 2 Step 1400/1563 Loss: 1.540 | Acc: 44.555% (19975/44832)\n",
      "Epoch 2 Step 1401/1563 Loss: 1.540 | Acc: 44.550% (19987/44864)\n",
      "Epoch 2 Step 1402/1563 Loss: 1.540 | Acc: 44.554% (20003/44896)\n",
      "Epoch 2 Step 1403/1563 Loss: 1.540 | Acc: 44.554% (20017/44928)\n",
      "Epoch 2 Step 1404/1563 Loss: 1.540 | Acc: 44.551% (20030/44960)\n",
      "Epoch 2 Step 1405/1563 Loss: 1.540 | Acc: 44.552% (20045/44992)\n",
      "Epoch 2 Step 1406/1563 Loss: 1.540 | Acc: 44.547% (20057/45024)\n",
      "Epoch 2 Step 1407/1563 Loss: 1.540 | Acc: 44.551% (20073/45056)\n",
      "Epoch 2 Step 1408/1563 Loss: 1.540 | Acc: 44.553% (20088/45088)\n",
      "Epoch 2 Step 1409/1563 Loss: 1.540 | Acc: 44.543% (20098/45120)\n",
      "Epoch 2 Step 1410/1563 Loss: 1.540 | Acc: 44.541% (20111/45152)\n",
      "Epoch 2 Step 1411/1563 Loss: 1.540 | Acc: 44.545% (20127/45184)\n",
      "Epoch 2 Step 1412/1563 Loss: 1.540 | Acc: 44.544% (20141/45216)\n",
      "Epoch 2 Step 1413/1563 Loss: 1.541 | Acc: 44.543% (20155/45248)\n",
      "Epoch 2 Step 1414/1563 Loss: 1.541 | Acc: 44.549% (20172/45280)\n",
      "Epoch 2 Step 1415/1563 Loss: 1.540 | Acc: 44.556% (20189/45312)\n",
      "Epoch 2 Step 1416/1563 Loss: 1.540 | Acc: 44.548% (20200/45344)\n",
      "Epoch 2 Step 1417/1563 Loss: 1.540 | Acc: 44.550% (20215/45376)\n",
      "Epoch 2 Step 1418/1563 Loss: 1.540 | Acc: 44.554% (20231/45408)\n",
      "Epoch 2 Step 1419/1563 Loss: 1.540 | Acc: 44.549% (20243/45440)\n",
      "Epoch 2 Step 1420/1563 Loss: 1.540 | Acc: 44.542% (20254/45472)\n",
      "Epoch 2 Step 1421/1563 Loss: 1.541 | Acc: 44.539% (20267/45504)\n",
      "Epoch 2 Step 1422/1563 Loss: 1.540 | Acc: 44.554% (20288/45536)\n",
      "Epoch 2 Step 1423/1563 Loss: 1.540 | Acc: 44.555% (20303/45568)\n",
      "Epoch 2 Step 1424/1563 Loss: 1.540 | Acc: 44.561% (20320/45600)\n",
      "Epoch 2 Step 1425/1563 Loss: 1.540 | Acc: 44.556% (20332/45632)\n",
      "Epoch 2 Step 1426/1563 Loss: 1.540 | Acc: 44.558% (20347/45664)\n",
      "Epoch 2 Step 1427/1563 Loss: 1.540 | Acc: 44.568% (20366/45696)\n",
      "Epoch 2 Step 1428/1563 Loss: 1.540 | Acc: 44.568% (20380/45728)\n",
      "Epoch 2 Step 1429/1563 Loss: 1.540 | Acc: 44.567% (20394/45760)\n",
      "Epoch 2 Step 1430/1563 Loss: 1.540 | Acc: 44.556% (20403/45792)\n",
      "Epoch 2 Step 1431/1563 Loss: 1.540 | Acc: 44.551% (20415/45824)\n",
      "Epoch 2 Step 1432/1563 Loss: 1.540 | Acc: 44.555% (20431/45856)\n",
      "Epoch 2 Step 1433/1563 Loss: 1.540 | Acc: 44.556% (20446/45888)\n",
      "Epoch 2 Step 1434/1563 Loss: 1.540 | Acc: 44.554% (20459/45920)\n",
      "Epoch 2 Step 1435/1563 Loss: 1.540 | Acc: 44.560% (20476/45952)\n",
      "Epoch 2 Step 1436/1563 Loss: 1.540 | Acc: 44.559% (20490/45984)\n",
      "Epoch 2 Step 1437/1563 Loss: 1.540 | Acc: 44.554% (20502/46016)\n",
      "Epoch 2 Step 1438/1563 Loss: 1.540 | Acc: 44.564% (20521/46048)\n",
      "Epoch 2 Step 1439/1563 Loss: 1.540 | Acc: 44.570% (20538/46080)\n",
      "Epoch 2 Step 1440/1563 Loss: 1.540 | Acc: 44.565% (20550/46112)\n",
      "Epoch 2 Step 1441/1563 Loss: 1.540 | Acc: 44.558% (20561/46144)\n",
      "Epoch 2 Step 1442/1563 Loss: 1.540 | Acc: 44.556% (20574/46176)\n",
      "Epoch 2 Step 1443/1563 Loss: 1.540 | Acc: 44.568% (20594/46208)\n",
      "Epoch 2 Step 1444/1563 Loss: 1.540 | Acc: 44.567% (20608/46240)\n",
      "Epoch 2 Step 1445/1563 Loss: 1.540 | Acc: 44.578% (20627/46272)\n",
      "Epoch 2 Step 1446/1563 Loss: 1.540 | Acc: 44.571% (20638/46304)\n",
      "Epoch 2 Step 1447/1563 Loss: 1.540 | Acc: 44.581% (20657/46336)\n",
      "Epoch 2 Step 1448/1563 Loss: 1.540 | Acc: 44.574% (20668/46368)\n",
      "Epoch 2 Step 1449/1563 Loss: 1.540 | Acc: 44.571% (20681/46400)\n",
      "Epoch 2 Step 1450/1563 Loss: 1.540 | Acc: 44.575% (20697/46432)\n",
      "Epoch 2 Step 1451/1563 Loss: 1.541 | Acc: 44.568% (20708/46464)\n",
      "Epoch 2 Step 1452/1563 Loss: 1.540 | Acc: 44.576% (20726/46496)\n",
      "Epoch 2 Step 1453/1563 Loss: 1.540 | Acc: 44.582% (20743/46528)\n",
      "Epoch 2 Step 1454/1563 Loss: 1.540 | Acc: 44.575% (20754/46560)\n",
      "Epoch 2 Step 1455/1563 Loss: 1.540 | Acc: 44.578% (20770/46592)\n",
      "Epoch 2 Step 1456/1563 Loss: 1.540 | Acc: 44.578% (20784/46624)\n",
      "Epoch 2 Step 1457/1563 Loss: 1.540 | Acc: 44.586% (20802/46656)\n",
      "Epoch 2 Step 1458/1563 Loss: 1.540 | Acc: 44.587% (20817/46688)\n",
      "Epoch 2 Step 1459/1563 Loss: 1.540 | Acc: 44.591% (20833/46720)\n",
      "Epoch 2 Step 1460/1563 Loss: 1.540 | Acc: 44.586% (20845/46752)\n",
      "Epoch 2 Step 1461/1563 Loss: 1.540 | Acc: 44.586% (20859/46784)\n",
      "Epoch 2 Step 1462/1563 Loss: 1.539 | Acc: 44.589% (20875/46816)\n",
      "Epoch 2 Step 1463/1563 Loss: 1.539 | Acc: 44.580% (20885/46848)\n",
      "Epoch 2 Step 1464/1563 Loss: 1.540 | Acc: 44.578% (20898/46880)\n",
      "Epoch 2 Step 1465/1563 Loss: 1.540 | Acc: 44.575% (20911/46912)\n",
      "Epoch 2 Step 1466/1563 Loss: 1.539 | Acc: 44.587% (20931/46944)\n",
      "Epoch 2 Step 1467/1563 Loss: 1.539 | Acc: 44.582% (20943/46976)\n",
      "Epoch 2 Step 1468/1563 Loss: 1.539 | Acc: 44.590% (20961/47008)\n",
      "Epoch 2 Step 1469/1563 Loss: 1.539 | Acc: 44.581% (20971/47040)\n",
      "Epoch 2 Step 1470/1563 Loss: 1.539 | Acc: 44.583% (20986/47072)\n",
      "Epoch 2 Step 1471/1563 Loss: 1.539 | Acc: 44.584% (21001/47104)\n",
      "Epoch 2 Step 1472/1563 Loss: 1.539 | Acc: 44.580% (21013/47136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 1473/1563 Loss: 1.539 | Acc: 44.587% (21031/47168)\n",
      "Epoch 2 Step 1474/1563 Loss: 1.539 | Acc: 44.583% (21043/47200)\n",
      "Epoch 2 Step 1475/1563 Loss: 1.539 | Acc: 44.584% (21058/47232)\n",
      "Epoch 2 Step 1476/1563 Loss: 1.539 | Acc: 44.584% (21072/47264)\n",
      "Epoch 2 Step 1477/1563 Loss: 1.539 | Acc: 44.589% (21089/47296)\n",
      "Epoch 2 Step 1478/1563 Loss: 1.539 | Acc: 44.587% (21102/47328)\n",
      "Epoch 2 Step 1479/1563 Loss: 1.539 | Acc: 44.601% (21123/47360)\n",
      "Epoch 2 Step 1480/1563 Loss: 1.538 | Acc: 44.605% (21139/47392)\n",
      "Epoch 2 Step 1481/1563 Loss: 1.539 | Acc: 44.602% (21152/47424)\n",
      "Epoch 2 Step 1482/1563 Loss: 1.539 | Acc: 44.603% (21167/47456)\n",
      "Epoch 2 Step 1483/1563 Loss: 1.539 | Acc: 44.599% (21179/47488)\n",
      "Epoch 2 Step 1484/1563 Loss: 1.538 | Acc: 44.609% (21198/47520)\n",
      "Epoch 2 Step 1485/1563 Loss: 1.538 | Acc: 44.616% (21216/47552)\n",
      "Epoch 2 Step 1486/1563 Loss: 1.538 | Acc: 44.618% (21231/47584)\n",
      "Epoch 2 Step 1487/1563 Loss: 1.538 | Acc: 44.617% (21245/47616)\n",
      "Epoch 2 Step 1488/1563 Loss: 1.538 | Acc: 44.627% (21264/47648)\n",
      "Epoch 2 Step 1489/1563 Loss: 1.538 | Acc: 44.622% (21276/47680)\n",
      "Epoch 2 Step 1490/1563 Loss: 1.538 | Acc: 44.628% (21293/47712)\n",
      "Epoch 2 Step 1491/1563 Loss: 1.538 | Acc: 44.630% (21308/47744)\n",
      "Epoch 2 Step 1492/1563 Loss: 1.538 | Acc: 44.637% (21326/47776)\n",
      "Epoch 2 Step 1493/1563 Loss: 1.538 | Acc: 44.637% (21340/47808)\n",
      "Epoch 2 Step 1494/1563 Loss: 1.538 | Acc: 44.628% (21350/47840)\n",
      "Epoch 2 Step 1495/1563 Loss: 1.538 | Acc: 44.623% (21362/47872)\n",
      "Epoch 2 Step 1496/1563 Loss: 1.538 | Acc: 44.627% (21378/47904)\n",
      "Epoch 2 Step 1497/1563 Loss: 1.538 | Acc: 44.622% (21390/47936)\n",
      "Epoch 2 Step 1498/1563 Loss: 1.538 | Acc: 44.619% (21403/47968)\n",
      "Epoch 2 Step 1499/1563 Loss: 1.538 | Acc: 44.627% (21421/48000)\n",
      "Epoch 2 Step 1500/1563 Loss: 1.538 | Acc: 44.631% (21437/48032)\n",
      "Epoch 2 Step 1501/1563 Loss: 1.538 | Acc: 44.626% (21449/48064)\n",
      "Epoch 2 Step 1502/1563 Loss: 1.538 | Acc: 44.632% (21466/48096)\n",
      "Epoch 2 Step 1503/1563 Loss: 1.538 | Acc: 44.641% (21485/48128)\n",
      "Epoch 2 Step 1504/1563 Loss: 1.538 | Acc: 44.647% (21502/48160)\n",
      "Epoch 2 Step 1505/1563 Loss: 1.538 | Acc: 44.655% (21520/48192)\n",
      "Epoch 2 Step 1506/1563 Loss: 1.538 | Acc: 44.662% (21538/48224)\n",
      "Epoch 2 Step 1507/1563 Loss: 1.538 | Acc: 44.654% (21548/48256)\n",
      "Epoch 2 Step 1508/1563 Loss: 1.538 | Acc: 44.645% (21558/48288)\n",
      "Epoch 2 Step 1509/1563 Loss: 1.538 | Acc: 44.650% (21575/48320)\n",
      "Epoch 2 Step 1510/1563 Loss: 1.538 | Acc: 44.656% (21592/48352)\n",
      "Epoch 2 Step 1511/1563 Loss: 1.538 | Acc: 44.661% (21609/48384)\n",
      "Epoch 2 Step 1512/1563 Loss: 1.538 | Acc: 44.663% (21624/48416)\n",
      "Epoch 2 Step 1513/1563 Loss: 1.538 | Acc: 44.652% (21633/48448)\n",
      "Epoch 2 Step 1514/1563 Loss: 1.538 | Acc: 44.651% (21647/48480)\n",
      "Epoch 2 Step 1515/1563 Loss: 1.538 | Acc: 44.655% (21663/48512)\n",
      "Epoch 2 Step 1516/1563 Loss: 1.537 | Acc: 44.661% (21680/48544)\n",
      "Epoch 2 Step 1517/1563 Loss: 1.537 | Acc: 44.660% (21694/48576)\n",
      "Epoch 2 Step 1518/1563 Loss: 1.538 | Acc: 44.651% (21704/48608)\n",
      "Epoch 2 Step 1519/1563 Loss: 1.538 | Acc: 44.653% (21719/48640)\n",
      "Epoch 2 Step 1520/1563 Loss: 1.538 | Acc: 44.658% (21736/48672)\n",
      "Epoch 2 Step 1521/1563 Loss: 1.538 | Acc: 44.655% (21749/48704)\n",
      "Epoch 2 Step 1522/1563 Loss: 1.537 | Acc: 44.663% (21767/48736)\n",
      "Epoch 2 Step 1523/1563 Loss: 1.537 | Acc: 44.675% (21787/48768)\n",
      "Epoch 2 Step 1524/1563 Loss: 1.537 | Acc: 44.674% (21801/48800)\n",
      "Epoch 2 Step 1525/1563 Loss: 1.537 | Acc: 44.678% (21817/48832)\n",
      "Epoch 2 Step 1526/1563 Loss: 1.537 | Acc: 44.681% (21833/48864)\n",
      "Epoch 2 Step 1527/1563 Loss: 1.537 | Acc: 44.674% (21844/48896)\n",
      "Epoch 2 Step 1528/1563 Loss: 1.537 | Acc: 44.678% (21860/48928)\n",
      "Epoch 2 Step 1529/1563 Loss: 1.537 | Acc: 44.683% (21877/48960)\n",
      "Epoch 2 Step 1530/1563 Loss: 1.537 | Acc: 44.697% (21898/48992)\n",
      "Epoch 2 Step 1531/1563 Loss: 1.537 | Acc: 44.699% (21913/49024)\n",
      "Epoch 2 Step 1532/1563 Loss: 1.537 | Acc: 44.700% (21928/49056)\n",
      "Epoch 2 Step 1533/1563 Loss: 1.537 | Acc: 44.707% (21946/49088)\n",
      "Epoch 2 Step 1534/1563 Loss: 1.537 | Acc: 44.705% (21959/49120)\n",
      "Epoch 2 Step 1535/1563 Loss: 1.537 | Acc: 44.700% (21971/49152)\n",
      "Epoch 2 Step 1536/1563 Loss: 1.537 | Acc: 44.706% (21988/49184)\n",
      "Epoch 2 Step 1537/1563 Loss: 1.537 | Acc: 44.703% (22001/49216)\n",
      "Epoch 2 Step 1538/1563 Loss: 1.536 | Acc: 44.706% (22017/49248)\n",
      "Epoch 2 Step 1539/1563 Loss: 1.536 | Acc: 44.704% (22030/49280)\n",
      "Epoch 2 Step 1540/1563 Loss: 1.536 | Acc: 44.699% (22042/49312)\n",
      "Epoch 2 Step 1541/1563 Loss: 1.536 | Acc: 44.698% (22056/49344)\n",
      "Epoch 2 Step 1542/1563 Loss: 1.536 | Acc: 44.698% (22070/49376)\n",
      "Epoch 2 Step 1543/1563 Loss: 1.536 | Acc: 44.693% (22082/49408)\n",
      "Epoch 2 Step 1544/1563 Loss: 1.536 | Acc: 44.703% (22101/49440)\n",
      "Epoch 2 Step 1545/1563 Loss: 1.536 | Acc: 44.708% (22118/49472)\n",
      "Epoch 2 Step 1546/1563 Loss: 1.536 | Acc: 44.710% (22133/49504)\n",
      "Epoch 2 Step 1547/1563 Loss: 1.536 | Acc: 44.711% (22148/49536)\n",
      "Epoch 2 Step 1548/1563 Loss: 1.536 | Acc: 44.712% (22163/49568)\n",
      "Epoch 2 Step 1549/1563 Loss: 1.535 | Acc: 44.720% (22181/49600)\n",
      "Epoch 2 Step 1550/1563 Loss: 1.535 | Acc: 44.719% (22195/49632)\n",
      "Epoch 2 Step 1551/1563 Loss: 1.535 | Acc: 44.712% (22206/49664)\n",
      "Epoch 2 Step 1552/1563 Loss: 1.535 | Acc: 44.716% (22222/49696)\n",
      "Epoch 2 Step 1553/1563 Loss: 1.535 | Acc: 44.721% (22239/49728)\n",
      "Epoch 2 Step 1554/1563 Loss: 1.535 | Acc: 44.719% (22252/49760)\n",
      "Epoch 2 Step 1555/1563 Loss: 1.535 | Acc: 44.718% (22266/49792)\n",
      "Epoch 2 Step 1556/1563 Loss: 1.535 | Acc: 44.715% (22279/49824)\n",
      "Epoch 2 Step 1557/1563 Loss: 1.535 | Acc: 44.721% (22296/49856)\n",
      "Epoch 2 Step 1558/1563 Loss: 1.535 | Acc: 44.714% (22307/49888)\n",
      "Epoch 2 Step 1559/1563 Loss: 1.535 | Acc: 44.714% (22321/49920)\n",
      "Epoch 2 Step 1560/1563 Loss: 1.535 | Acc: 44.717% (22337/49952)\n",
      "Epoch 2 Step 1561/1563 Loss: 1.535 | Acc: 44.726% (22356/49984)\n",
      "Epoch 2 Step 1562/1563 Loss: 1.535 | Acc: 44.724% (22362/50000)\n",
      "Epoch 2 Step 0/313 Test Loss: 1.266 | Test Acc: 53.125% (17/32)\n",
      "Epoch 2 Step 1/313 Test Loss: 1.321 | Test Acc: 53.125% (34/64)\n",
      "Epoch 2 Step 2/313 Test Loss: 1.400 | Test Acc: 51.042% (49/96)\n",
      "Epoch 2 Step 3/313 Test Loss: 1.382 | Test Acc: 47.656% (61/128)\n",
      "Epoch 2 Step 4/313 Test Loss: 1.407 | Test Acc: 47.500% (76/160)\n",
      "Epoch 2 Step 5/313 Test Loss: 1.420 | Test Acc: 46.875% (90/192)\n",
      "Epoch 2 Step 6/313 Test Loss: 1.445 | Test Acc: 45.982% (103/224)\n",
      "Epoch 2 Step 7/313 Test Loss: 1.444 | Test Acc: 46.094% (118/256)\n",
      "Epoch 2 Step 8/313 Test Loss: 1.450 | Test Acc: 45.486% (131/288)\n",
      "Epoch 2 Step 9/313 Test Loss: 1.421 | Test Acc: 46.562% (149/320)\n",
      "Epoch 2 Step 10/313 Test Loss: 1.420 | Test Acc: 46.591% (164/352)\n",
      "Epoch 2 Step 11/313 Test Loss: 1.435 | Test Acc: 46.615% (179/384)\n",
      "Epoch 2 Step 12/313 Test Loss: 1.430 | Test Acc: 46.394% (193/416)\n",
      "Epoch 2 Step 13/313 Test Loss: 1.444 | Test Acc: 45.982% (206/448)\n",
      "Epoch 2 Step 14/313 Test Loss: 1.452 | Test Acc: 45.625% (219/480)\n",
      "Epoch 2 Step 15/313 Test Loss: 1.440 | Test Acc: 45.898% (235/512)\n",
      "Epoch 2 Step 16/313 Test Loss: 1.432 | Test Acc: 45.956% (250/544)\n",
      "Epoch 2 Step 17/313 Test Loss: 1.424 | Test Acc: 46.181% (266/576)\n",
      "Epoch 2 Step 18/313 Test Loss: 1.422 | Test Acc: 46.546% (283/608)\n",
      "Epoch 2 Step 19/313 Test Loss: 1.407 | Test Acc: 47.344% (303/640)\n",
      "Epoch 2 Step 20/313 Test Loss: 1.397 | Test Acc: 47.470% (319/672)\n",
      "Epoch 2 Step 21/313 Test Loss: 1.404 | Test Acc: 47.443% (334/704)\n",
      "Epoch 2 Step 22/313 Test Loss: 1.400 | Test Acc: 47.690% (351/736)\n",
      "Epoch 2 Step 23/313 Test Loss: 1.402 | Test Acc: 47.526% (365/768)\n",
      "Epoch 2 Step 24/313 Test Loss: 1.403 | Test Acc: 47.125% (377/800)\n",
      "Epoch 2 Step 25/313 Test Loss: 1.401 | Test Acc: 47.837% (398/832)\n",
      "Epoch 2 Step 26/313 Test Loss: 1.401 | Test Acc: 47.917% (414/864)\n",
      "Epoch 2 Step 27/313 Test Loss: 1.394 | Test Acc: 48.438% (434/896)\n",
      "Epoch 2 Step 28/313 Test Loss: 1.388 | Test Acc: 48.599% (451/928)\n",
      "Epoch 2 Step 29/313 Test Loss: 1.379 | Test Acc: 48.854% (469/960)\n",
      "Epoch 2 Step 30/313 Test Loss: 1.374 | Test Acc: 49.093% (487/992)\n",
      "Epoch 2 Step 31/313 Test Loss: 1.367 | Test Acc: 49.219% (504/1024)\n",
      "Epoch 2 Step 32/313 Test Loss: 1.376 | Test Acc: 49.053% (518/1056)\n",
      "Epoch 2 Step 33/313 Test Loss: 1.376 | Test Acc: 48.897% (532/1088)\n",
      "Epoch 2 Step 34/313 Test Loss: 1.365 | Test Acc: 49.107% (550/1120)\n",
      "Epoch 2 Step 35/313 Test Loss: 1.373 | Test Acc: 48.611% (560/1152)\n",
      "Epoch 2 Step 36/313 Test Loss: 1.370 | Test Acc: 48.733% (577/1184)\n",
      "Epoch 2 Step 37/313 Test Loss: 1.372 | Test Acc: 48.766% (593/1216)\n",
      "Epoch 2 Step 38/313 Test Loss: 1.378 | Test Acc: 48.638% (607/1248)\n",
      "Epoch 2 Step 39/313 Test Loss: 1.376 | Test Acc: 48.672% (623/1280)\n",
      "Epoch 2 Step 40/313 Test Loss: 1.379 | Test Acc: 48.399% (635/1312)\n",
      "Epoch 2 Step 41/313 Test Loss: 1.383 | Test Acc: 48.289% (649/1344)\n",
      "Epoch 2 Step 42/313 Test Loss: 1.378 | Test Acc: 48.256% (664/1376)\n",
      "Epoch 2 Step 43/313 Test Loss: 1.384 | Test Acc: 48.153% (678/1408)\n",
      "Epoch 2 Step 44/313 Test Loss: 1.386 | Test Acc: 48.125% (693/1440)\n",
      "Epoch 2 Step 45/313 Test Loss: 1.385 | Test Acc: 47.894% (705/1472)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 46/313 Test Loss: 1.387 | Test Acc: 47.872% (720/1504)\n",
      "Epoch 2 Step 47/313 Test Loss: 1.388 | Test Acc: 47.917% (736/1536)\n",
      "Epoch 2 Step 48/313 Test Loss: 1.384 | Test Acc: 48.087% (754/1568)\n",
      "Epoch 2 Step 49/313 Test Loss: 1.391 | Test Acc: 48.000% (768/1600)\n",
      "Epoch 2 Step 50/313 Test Loss: 1.395 | Test Acc: 47.978% (783/1632)\n",
      "Epoch 2 Step 51/313 Test Loss: 1.395 | Test Acc: 48.257% (803/1664)\n",
      "Epoch 2 Step 52/313 Test Loss: 1.394 | Test Acc: 48.526% (823/1696)\n",
      "Epoch 2 Step 53/313 Test Loss: 1.398 | Test Acc: 48.438% (837/1728)\n",
      "Epoch 2 Step 54/313 Test Loss: 1.401 | Test Acc: 48.295% (850/1760)\n",
      "Epoch 2 Step 55/313 Test Loss: 1.399 | Test Acc: 48.270% (865/1792)\n",
      "Epoch 2 Step 56/313 Test Loss: 1.401 | Test Acc: 48.300% (881/1824)\n",
      "Epoch 2 Step 57/313 Test Loss: 1.402 | Test Acc: 48.384% (898/1856)\n",
      "Epoch 2 Step 58/313 Test Loss: 1.403 | Test Acc: 48.411% (914/1888)\n",
      "Epoch 2 Step 59/313 Test Loss: 1.405 | Test Acc: 48.542% (932/1920)\n",
      "Epoch 2 Step 60/313 Test Loss: 1.406 | Test Acc: 48.361% (944/1952)\n",
      "Epoch 2 Step 61/313 Test Loss: 1.406 | Test Acc: 48.438% (961/1984)\n",
      "Epoch 2 Step 62/313 Test Loss: 1.410 | Test Acc: 48.413% (976/2016)\n",
      "Epoch 2 Step 63/313 Test Loss: 1.408 | Test Acc: 48.438% (992/2048)\n",
      "Epoch 2 Step 64/313 Test Loss: 1.407 | Test Acc: 48.269% (1004/2080)\n",
      "Epoch 2 Step 65/313 Test Loss: 1.405 | Test Acc: 48.201% (1018/2112)\n",
      "Epoch 2 Step 66/313 Test Loss: 1.406 | Test Acc: 48.274% (1035/2144)\n",
      "Epoch 2 Step 67/313 Test Loss: 1.409 | Test Acc: 48.162% (1048/2176)\n",
      "Epoch 2 Step 68/313 Test Loss: 1.411 | Test Acc: 48.098% (1062/2208)\n",
      "Epoch 2 Step 69/313 Test Loss: 1.409 | Test Acc: 48.348% (1083/2240)\n",
      "Epoch 2 Step 70/313 Test Loss: 1.408 | Test Acc: 48.548% (1103/2272)\n",
      "Epoch 2 Step 71/313 Test Loss: 1.408 | Test Acc: 48.524% (1118/2304)\n",
      "Epoch 2 Step 72/313 Test Loss: 1.411 | Test Acc: 48.502% (1133/2336)\n",
      "Epoch 2 Step 73/313 Test Loss: 1.412 | Test Acc: 48.649% (1152/2368)\n",
      "Epoch 2 Step 74/313 Test Loss: 1.411 | Test Acc: 48.708% (1169/2400)\n",
      "Epoch 2 Step 75/313 Test Loss: 1.412 | Test Acc: 48.684% (1184/2432)\n",
      "Epoch 2 Step 76/313 Test Loss: 1.411 | Test Acc: 48.782% (1202/2464)\n",
      "Epoch 2 Step 77/313 Test Loss: 1.408 | Test Acc: 48.798% (1218/2496)\n",
      "Epoch 2 Step 78/313 Test Loss: 1.412 | Test Acc: 48.695% (1231/2528)\n",
      "Epoch 2 Step 79/313 Test Loss: 1.416 | Test Acc: 48.594% (1244/2560)\n",
      "Epoch 2 Step 80/313 Test Loss: 1.417 | Test Acc: 48.573% (1259/2592)\n",
      "Epoch 2 Step 81/313 Test Loss: 1.417 | Test Acc: 48.628% (1276/2624)\n",
      "Epoch 2 Step 82/313 Test Loss: 1.418 | Test Acc: 48.682% (1293/2656)\n",
      "Epoch 2 Step 83/313 Test Loss: 1.417 | Test Acc: 48.847% (1313/2688)\n",
      "Epoch 2 Step 84/313 Test Loss: 1.417 | Test Acc: 48.824% (1328/2720)\n",
      "Epoch 2 Step 85/313 Test Loss: 1.418 | Test Acc: 48.801% (1343/2752)\n",
      "Epoch 2 Step 86/313 Test Loss: 1.419 | Test Acc: 48.743% (1357/2784)\n",
      "Epoch 2 Step 87/313 Test Loss: 1.419 | Test Acc: 48.757% (1373/2816)\n",
      "Epoch 2 Step 88/313 Test Loss: 1.420 | Test Acc: 48.701% (1387/2848)\n",
      "Epoch 2 Step 89/313 Test Loss: 1.419 | Test Acc: 48.681% (1402/2880)\n",
      "Epoch 2 Step 90/313 Test Loss: 1.419 | Test Acc: 48.764% (1420/2912)\n",
      "Epoch 2 Step 91/313 Test Loss: 1.416 | Test Acc: 48.879% (1439/2944)\n",
      "Epoch 2 Step 92/313 Test Loss: 1.416 | Test Acc: 48.790% (1452/2976)\n",
      "Epoch 2 Step 93/313 Test Loss: 1.415 | Test Acc: 48.870% (1470/3008)\n",
      "Epoch 2 Step 94/313 Test Loss: 1.416 | Test Acc: 48.882% (1486/3040)\n",
      "Epoch 2 Step 95/313 Test Loss: 1.415 | Test Acc: 48.893% (1502/3072)\n",
      "Epoch 2 Step 96/313 Test Loss: 1.415 | Test Acc: 48.840% (1516/3104)\n",
      "Epoch 2 Step 97/313 Test Loss: 1.415 | Test Acc: 48.756% (1529/3136)\n",
      "Epoch 2 Step 98/313 Test Loss: 1.415 | Test Acc: 48.801% (1546/3168)\n",
      "Epoch 2 Step 99/313 Test Loss: 1.414 | Test Acc: 48.812% (1562/3200)\n",
      "Epoch 2 Step 100/313 Test Loss: 1.415 | Test Acc: 48.731% (1575/3232)\n",
      "Epoch 2 Step 101/313 Test Loss: 1.414 | Test Acc: 48.744% (1591/3264)\n",
      "Epoch 2 Step 102/313 Test Loss: 1.412 | Test Acc: 48.847% (1610/3296)\n",
      "Epoch 2 Step 103/313 Test Loss: 1.413 | Test Acc: 48.738% (1622/3328)\n",
      "Epoch 2 Step 104/313 Test Loss: 1.413 | Test Acc: 48.750% (1638/3360)\n",
      "Epoch 2 Step 105/313 Test Loss: 1.411 | Test Acc: 48.791% (1655/3392)\n",
      "Epoch 2 Step 106/313 Test Loss: 1.412 | Test Acc: 48.715% (1668/3424)\n",
      "Epoch 2 Step 107/313 Test Loss: 1.413 | Test Acc: 48.756% (1685/3456)\n",
      "Epoch 2 Step 108/313 Test Loss: 1.411 | Test Acc: 48.882% (1705/3488)\n",
      "Epoch 2 Step 109/313 Test Loss: 1.413 | Test Acc: 48.807% (1718/3520)\n",
      "Epoch 2 Step 110/313 Test Loss: 1.413 | Test Acc: 48.846% (1735/3552)\n",
      "Epoch 2 Step 111/313 Test Loss: 1.412 | Test Acc: 48.884% (1752/3584)\n",
      "Epoch 2 Step 112/313 Test Loss: 1.413 | Test Acc: 48.866% (1767/3616)\n",
      "Epoch 2 Step 113/313 Test Loss: 1.413 | Test Acc: 48.821% (1781/3648)\n",
      "Epoch 2 Step 114/313 Test Loss: 1.412 | Test Acc: 48.913% (1800/3680)\n",
      "Epoch 2 Step 115/313 Test Loss: 1.411 | Test Acc: 48.895% (1815/3712)\n",
      "Epoch 2 Step 116/313 Test Loss: 1.410 | Test Acc: 48.878% (1830/3744)\n",
      "Epoch 2 Step 117/313 Test Loss: 1.412 | Test Acc: 48.914% (1847/3776)\n",
      "Epoch 2 Step 118/313 Test Loss: 1.411 | Test Acc: 49.028% (1867/3808)\n",
      "Epoch 2 Step 119/313 Test Loss: 1.408 | Test Acc: 49.167% (1888/3840)\n",
      "Epoch 2 Step 120/313 Test Loss: 1.406 | Test Acc: 49.174% (1904/3872)\n",
      "Epoch 2 Step 121/313 Test Loss: 1.404 | Test Acc: 49.155% (1919/3904)\n",
      "Epoch 2 Step 122/313 Test Loss: 1.405 | Test Acc: 49.111% (1933/3936)\n",
      "Epoch 2 Step 123/313 Test Loss: 1.402 | Test Acc: 49.168% (1951/3968)\n",
      "Epoch 2 Step 124/313 Test Loss: 1.405 | Test Acc: 49.175% (1967/4000)\n",
      "Epoch 2 Step 125/313 Test Loss: 1.404 | Test Acc: 49.256% (1986/4032)\n",
      "Epoch 2 Step 126/313 Test Loss: 1.408 | Test Acc: 49.213% (2000/4064)\n",
      "Epoch 2 Step 127/313 Test Loss: 1.405 | Test Acc: 49.243% (2017/4096)\n",
      "Epoch 2 Step 128/313 Test Loss: 1.407 | Test Acc: 49.128% (2028/4128)\n",
      "Epoch 2 Step 129/313 Test Loss: 1.406 | Test Acc: 49.183% (2046/4160)\n",
      "Epoch 2 Step 130/313 Test Loss: 1.405 | Test Acc: 49.308% (2067/4192)\n",
      "Epoch 2 Step 131/313 Test Loss: 1.404 | Test Acc: 49.337% (2084/4224)\n",
      "Epoch 2 Step 132/313 Test Loss: 1.404 | Test Acc: 49.295% (2098/4256)\n",
      "Epoch 2 Step 133/313 Test Loss: 1.404 | Test Acc: 49.324% (2115/4288)\n",
      "Epoch 2 Step 134/313 Test Loss: 1.405 | Test Acc: 49.352% (2132/4320)\n",
      "Epoch 2 Step 135/313 Test Loss: 1.403 | Test Acc: 49.517% (2155/4352)\n",
      "Epoch 2 Step 136/313 Test Loss: 1.402 | Test Acc: 49.567% (2173/4384)\n",
      "Epoch 2 Step 137/313 Test Loss: 1.401 | Test Acc: 49.638% (2192/4416)\n",
      "Epoch 2 Step 138/313 Test Loss: 1.400 | Test Acc: 49.730% (2212/4448)\n",
      "Epoch 2 Step 139/313 Test Loss: 1.401 | Test Acc: 49.732% (2228/4480)\n",
      "Epoch 2 Step 140/313 Test Loss: 1.400 | Test Acc: 49.778% (2246/4512)\n",
      "Epoch 2 Step 141/313 Test Loss: 1.400 | Test Acc: 49.780% (2262/4544)\n",
      "Epoch 2 Step 142/313 Test Loss: 1.401 | Test Acc: 49.803% (2279/4576)\n",
      "Epoch 2 Step 143/313 Test Loss: 1.403 | Test Acc: 49.674% (2289/4608)\n",
      "Epoch 2 Step 144/313 Test Loss: 1.404 | Test Acc: 49.612% (2302/4640)\n",
      "Epoch 2 Step 145/313 Test Loss: 1.403 | Test Acc: 49.743% (2324/4672)\n",
      "Epoch 2 Step 146/313 Test Loss: 1.403 | Test Acc: 49.681% (2337/4704)\n",
      "Epoch 2 Step 147/313 Test Loss: 1.403 | Test Acc: 49.662% (2352/4736)\n",
      "Epoch 2 Step 148/313 Test Loss: 1.405 | Test Acc: 49.685% (2369/4768)\n",
      "Epoch 2 Step 149/313 Test Loss: 1.404 | Test Acc: 49.729% (2387/4800)\n",
      "Epoch 2 Step 150/313 Test Loss: 1.405 | Test Acc: 49.648% (2399/4832)\n",
      "Epoch 2 Step 151/313 Test Loss: 1.403 | Test Acc: 49.753% (2420/4864)\n",
      "Epoch 2 Step 152/313 Test Loss: 1.402 | Test Acc: 49.755% (2436/4896)\n",
      "Epoch 2 Step 153/313 Test Loss: 1.402 | Test Acc: 49.797% (2454/4928)\n",
      "Epoch 2 Step 154/313 Test Loss: 1.402 | Test Acc: 49.819% (2471/4960)\n",
      "Epoch 2 Step 155/313 Test Loss: 1.402 | Test Acc: 49.860% (2489/4992)\n",
      "Epoch 2 Step 156/313 Test Loss: 1.402 | Test Acc: 49.841% (2504/5024)\n",
      "Epoch 2 Step 157/313 Test Loss: 1.402 | Test Acc: 49.802% (2518/5056)\n",
      "Epoch 2 Step 158/313 Test Loss: 1.403 | Test Acc: 49.725% (2530/5088)\n",
      "Epoch 2 Step 159/313 Test Loss: 1.405 | Test Acc: 49.688% (2544/5120)\n",
      "Epoch 2 Step 160/313 Test Loss: 1.404 | Test Acc: 49.767% (2564/5152)\n",
      "Epoch 2 Step 161/313 Test Loss: 1.403 | Test Acc: 49.788% (2581/5184)\n",
      "Epoch 2 Step 162/313 Test Loss: 1.403 | Test Acc: 49.789% (2597/5216)\n",
      "Epoch 2 Step 163/313 Test Loss: 1.404 | Test Acc: 49.790% (2613/5248)\n",
      "Epoch 2 Step 164/313 Test Loss: 1.404 | Test Acc: 49.697% (2624/5280)\n",
      "Epoch 2 Step 165/313 Test Loss: 1.404 | Test Acc: 49.699% (2640/5312)\n",
      "Epoch 2 Step 166/313 Test Loss: 1.406 | Test Acc: 49.644% (2653/5344)\n",
      "Epoch 2 Step 167/313 Test Loss: 1.407 | Test Acc: 49.628% (2668/5376)\n",
      "Epoch 2 Step 168/313 Test Loss: 1.407 | Test Acc: 49.575% (2681/5408)\n",
      "Epoch 2 Step 169/313 Test Loss: 1.407 | Test Acc: 49.614% (2699/5440)\n",
      "Epoch 2 Step 170/313 Test Loss: 1.406 | Test Acc: 49.653% (2717/5472)\n",
      "Epoch 2 Step 171/313 Test Loss: 1.406 | Test Acc: 49.691% (2735/5504)\n",
      "Epoch 2 Step 172/313 Test Loss: 1.407 | Test Acc: 49.675% (2750/5536)\n",
      "Epoch 2 Step 173/313 Test Loss: 1.408 | Test Acc: 49.623% (2763/5568)\n",
      "Epoch 2 Step 174/313 Test Loss: 1.407 | Test Acc: 49.661% (2781/5600)\n",
      "Epoch 2 Step 175/313 Test Loss: 1.410 | Test Acc: 49.627% (2795/5632)\n",
      "Epoch 2 Step 176/313 Test Loss: 1.411 | Test Acc: 49.541% (2806/5664)\n",
      "Epoch 2 Step 177/313 Test Loss: 1.410 | Test Acc: 49.614% (2826/5696)\n",
      "Epoch 2 Step 178/313 Test Loss: 1.408 | Test Acc: 49.668% (2845/5728)\n",
      "Epoch 2 Step 179/313 Test Loss: 1.408 | Test Acc: 49.583% (2856/5760)\n",
      "Epoch 2 Step 180/313 Test Loss: 1.407 | Test Acc: 49.689% (2878/5792)\n",
      "Epoch 2 Step 181/313 Test Loss: 1.407 | Test Acc: 49.639% (2891/5824)\n",
      "Epoch 2 Step 182/313 Test Loss: 1.409 | Test Acc: 49.607% (2905/5856)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Step 183/313 Test Loss: 1.409 | Test Acc: 49.609% (2921/5888)\n",
      "Epoch 2 Step 184/313 Test Loss: 1.410 | Test Acc: 49.578% (2935/5920)\n",
      "Epoch 2 Step 185/313 Test Loss: 1.410 | Test Acc: 49.580% (2951/5952)\n",
      "Epoch 2 Step 186/313 Test Loss: 1.409 | Test Acc: 49.616% (2969/5984)\n",
      "Epoch 2 Step 187/313 Test Loss: 1.409 | Test Acc: 49.568% (2982/6016)\n",
      "Epoch 2 Step 188/313 Test Loss: 1.408 | Test Acc: 49.554% (2997/6048)\n",
      "Epoch 2 Step 189/313 Test Loss: 1.409 | Test Acc: 49.539% (3012/6080)\n",
      "Epoch 2 Step 190/313 Test Loss: 1.408 | Test Acc: 49.542% (3028/6112)\n",
      "Epoch 2 Step 191/313 Test Loss: 1.407 | Test Acc: 49.593% (3047/6144)\n",
      "Epoch 2 Step 192/313 Test Loss: 1.408 | Test Acc: 49.514% (3058/6176)\n",
      "Epoch 2 Step 193/313 Test Loss: 1.408 | Test Acc: 49.533% (3075/6208)\n",
      "Epoch 2 Step 194/313 Test Loss: 1.408 | Test Acc: 49.503% (3089/6240)\n",
      "Epoch 2 Step 195/313 Test Loss: 1.410 | Test Acc: 49.426% (3100/6272)\n",
      "Epoch 2 Step 196/313 Test Loss: 1.411 | Test Acc: 49.445% (3117/6304)\n",
      "Epoch 2 Step 197/313 Test Loss: 1.411 | Test Acc: 49.448% (3133/6336)\n",
      "Epoch 2 Step 198/313 Test Loss: 1.409 | Test Acc: 49.529% (3154/6368)\n",
      "Epoch 2 Step 199/313 Test Loss: 1.410 | Test Acc: 49.484% (3167/6400)\n",
      "Epoch 2 Step 200/313 Test Loss: 1.410 | Test Acc: 49.487% (3183/6432)\n",
      "Epoch 2 Step 201/313 Test Loss: 1.411 | Test Acc: 49.459% (3197/6464)\n",
      "Epoch 2 Step 202/313 Test Loss: 1.413 | Test Acc: 49.415% (3210/6496)\n",
      "Epoch 2 Step 203/313 Test Loss: 1.413 | Test Acc: 49.418% (3226/6528)\n",
      "Epoch 2 Step 204/313 Test Loss: 1.415 | Test Acc: 49.329% (3236/6560)\n",
      "Epoch 2 Step 205/313 Test Loss: 1.416 | Test Acc: 49.272% (3248/6592)\n",
      "Epoch 2 Step 206/313 Test Loss: 1.416 | Test Acc: 49.290% (3265/6624)\n",
      "Epoch 2 Step 207/313 Test Loss: 1.415 | Test Acc: 49.264% (3279/6656)\n",
      "Epoch 2 Step 208/313 Test Loss: 1.415 | Test Acc: 49.252% (3294/6688)\n",
      "Epoch 2 Step 209/313 Test Loss: 1.415 | Test Acc: 49.226% (3308/6720)\n",
      "Epoch 2 Step 210/313 Test Loss: 1.415 | Test Acc: 49.230% (3324/6752)\n",
      "Epoch 2 Step 211/313 Test Loss: 1.415 | Test Acc: 49.160% (3335/6784)\n",
      "Epoch 2 Step 212/313 Test Loss: 1.413 | Test Acc: 49.266% (3358/6816)\n",
      "Epoch 2 Step 213/313 Test Loss: 1.414 | Test Acc: 49.226% (3371/6848)\n",
      "Epoch 2 Step 214/313 Test Loss: 1.415 | Test Acc: 49.157% (3382/6880)\n",
      "Epoch 2 Step 215/313 Test Loss: 1.415 | Test Acc: 49.175% (3399/6912)\n",
      "Epoch 2 Step 216/313 Test Loss: 1.415 | Test Acc: 49.179% (3415/6944)\n",
      "Epoch 2 Step 217/313 Test Loss: 1.416 | Test Acc: 49.126% (3427/6976)\n",
      "Epoch 2 Step 218/313 Test Loss: 1.418 | Test Acc: 49.044% (3437/7008)\n",
      "Epoch 2 Step 219/313 Test Loss: 1.417 | Test Acc: 49.034% (3452/7040)\n",
      "Epoch 2 Step 220/313 Test Loss: 1.418 | Test Acc: 49.010% (3466/7072)\n",
      "Epoch 2 Step 221/313 Test Loss: 1.417 | Test Acc: 49.029% (3483/7104)\n",
      "Epoch 2 Step 222/313 Test Loss: 1.417 | Test Acc: 49.061% (3501/7136)\n",
      "Epoch 2 Step 223/313 Test Loss: 1.417 | Test Acc: 49.023% (3514/7168)\n",
      "Epoch 2 Step 224/313 Test Loss: 1.418 | Test Acc: 49.014% (3529/7200)\n",
      "Epoch 2 Step 225/313 Test Loss: 1.419 | Test Acc: 49.018% (3545/7232)\n",
      "Epoch 2 Step 226/313 Test Loss: 1.420 | Test Acc: 49.009% (3560/7264)\n",
      "Epoch 2 Step 227/313 Test Loss: 1.419 | Test Acc: 49.041% (3578/7296)\n",
      "Epoch 2 Step 228/313 Test Loss: 1.419 | Test Acc: 49.017% (3592/7328)\n",
      "Epoch 2 Step 229/313 Test Loss: 1.418 | Test Acc: 49.076% (3612/7360)\n",
      "Epoch 2 Step 230/313 Test Loss: 1.418 | Test Acc: 49.107% (3630/7392)\n",
      "Epoch 2 Step 231/313 Test Loss: 1.418 | Test Acc: 49.057% (3642/7424)\n",
      "Epoch 2 Step 232/313 Test Loss: 1.418 | Test Acc: 49.048% (3657/7456)\n",
      "Epoch 2 Step 233/313 Test Loss: 1.417 | Test Acc: 49.092% (3676/7488)\n",
      "Epoch 2 Step 234/313 Test Loss: 1.417 | Test Acc: 49.069% (3690/7520)\n",
      "Epoch 2 Step 235/313 Test Loss: 1.417 | Test Acc: 49.126% (3710/7552)\n",
      "Epoch 2 Step 236/313 Test Loss: 1.417 | Test Acc: 49.103% (3724/7584)\n",
      "Epoch 2 Step 237/313 Test Loss: 1.418 | Test Acc: 49.055% (3736/7616)\n",
      "Epoch 2 Step 238/313 Test Loss: 1.418 | Test Acc: 49.059% (3752/7648)\n",
      "Epoch 2 Step 239/313 Test Loss: 1.418 | Test Acc: 49.076% (3769/7680)\n",
      "Epoch 2 Step 240/313 Test Loss: 1.416 | Test Acc: 49.118% (3788/7712)\n",
      "Epoch 2 Step 241/313 Test Loss: 1.417 | Test Acc: 49.148% (3806/7744)\n",
      "Epoch 2 Step 242/313 Test Loss: 1.416 | Test Acc: 49.177% (3824/7776)\n",
      "Epoch 2 Step 243/313 Test Loss: 1.416 | Test Acc: 49.193% (3841/7808)\n",
      "Epoch 2 Step 244/313 Test Loss: 1.416 | Test Acc: 49.158% (3854/7840)\n",
      "Epoch 2 Step 245/313 Test Loss: 1.417 | Test Acc: 49.136% (3868/7872)\n",
      "Epoch 2 Step 246/313 Test Loss: 1.417 | Test Acc: 49.190% (3888/7904)\n",
      "Epoch 2 Step 247/313 Test Loss: 1.416 | Test Acc: 49.181% (3903/7936)\n",
      "Epoch 2 Step 248/313 Test Loss: 1.418 | Test Acc: 49.134% (3915/7968)\n",
      "Epoch 2 Step 249/313 Test Loss: 1.418 | Test Acc: 49.163% (3933/8000)\n",
      "Epoch 2 Step 250/313 Test Loss: 1.418 | Test Acc: 49.116% (3945/8032)\n",
      "Epoch 2 Step 251/313 Test Loss: 1.419 | Test Acc: 49.082% (3958/8064)\n",
      "Epoch 2 Step 252/313 Test Loss: 1.419 | Test Acc: 49.086% (3974/8096)\n",
      "Epoch 2 Step 253/313 Test Loss: 1.420 | Test Acc: 49.040% (3986/8128)\n",
      "Epoch 2 Step 254/313 Test Loss: 1.420 | Test Acc: 49.007% (3999/8160)\n",
      "Epoch 2 Step 255/313 Test Loss: 1.420 | Test Acc: 48.975% (4012/8192)\n",
      "Epoch 2 Step 256/313 Test Loss: 1.420 | Test Acc: 48.942% (4025/8224)\n",
      "Epoch 2 Step 257/313 Test Loss: 1.420 | Test Acc: 48.958% (4042/8256)\n",
      "Epoch 2 Step 258/313 Test Loss: 1.421 | Test Acc: 48.926% (4055/8288)\n",
      "Epoch 2 Step 259/313 Test Loss: 1.421 | Test Acc: 48.870% (4066/8320)\n",
      "Epoch 2 Step 260/313 Test Loss: 1.422 | Test Acc: 48.815% (4077/8352)\n",
      "Epoch 2 Step 261/313 Test Loss: 1.422 | Test Acc: 48.795% (4091/8384)\n",
      "Epoch 2 Step 262/313 Test Loss: 1.422 | Test Acc: 48.752% (4103/8416)\n",
      "Epoch 2 Step 263/313 Test Loss: 1.422 | Test Acc: 48.733% (4117/8448)\n",
      "Epoch 2 Step 264/313 Test Loss: 1.422 | Test Acc: 48.750% (4134/8480)\n",
      "Epoch 2 Step 265/313 Test Loss: 1.423 | Test Acc: 48.684% (4144/8512)\n",
      "Epoch 2 Step 266/313 Test Loss: 1.423 | Test Acc: 48.701% (4161/8544)\n",
      "Epoch 2 Step 267/313 Test Loss: 1.423 | Test Acc: 48.682% (4175/8576)\n",
      "Epoch 2 Step 268/313 Test Loss: 1.423 | Test Acc: 48.629% (4186/8608)\n",
      "Epoch 2 Step 269/313 Test Loss: 1.423 | Test Acc: 48.611% (4200/8640)\n",
      "Epoch 2 Step 270/313 Test Loss: 1.424 | Test Acc: 48.559% (4211/8672)\n",
      "Epoch 2 Step 271/313 Test Loss: 1.424 | Test Acc: 48.541% (4225/8704)\n",
      "Epoch 2 Step 272/313 Test Loss: 1.423 | Test Acc: 48.581% (4244/8736)\n",
      "Epoch 2 Step 273/313 Test Loss: 1.423 | Test Acc: 48.552% (4257/8768)\n",
      "Epoch 2 Step 274/313 Test Loss: 1.423 | Test Acc: 48.557% (4273/8800)\n",
      "Epoch 2 Step 275/313 Test Loss: 1.423 | Test Acc: 48.551% (4288/8832)\n",
      "Epoch 2 Step 276/313 Test Loss: 1.424 | Test Acc: 48.556% (4304/8864)\n",
      "Epoch 2 Step 277/313 Test Loss: 1.423 | Test Acc: 48.595% (4323/8896)\n",
      "Epoch 2 Step 278/313 Test Loss: 1.423 | Test Acc: 48.611% (4340/8928)\n",
      "Epoch 2 Step 279/313 Test Loss: 1.424 | Test Acc: 48.560% (4351/8960)\n",
      "Epoch 2 Step 280/313 Test Loss: 1.424 | Test Acc: 48.543% (4365/8992)\n",
      "Epoch 2 Step 281/313 Test Loss: 1.423 | Test Acc: 48.570% (4383/9024)\n",
      "Epoch 2 Step 282/313 Test Loss: 1.424 | Test Acc: 48.542% (4396/9056)\n",
      "Epoch 2 Step 283/313 Test Loss: 1.423 | Test Acc: 48.559% (4413/9088)\n",
      "Epoch 2 Step 284/313 Test Loss: 1.423 | Test Acc: 48.596% (4432/9120)\n",
      "Epoch 2 Step 285/313 Test Loss: 1.423 | Test Acc: 48.601% (4448/9152)\n",
      "Epoch 2 Step 286/313 Test Loss: 1.422 | Test Acc: 48.639% (4467/9184)\n",
      "Epoch 2 Step 287/313 Test Loss: 1.421 | Test Acc: 48.687% (4487/9216)\n",
      "Epoch 2 Step 288/313 Test Loss: 1.421 | Test Acc: 48.702% (4504/9248)\n",
      "Epoch 2 Step 289/313 Test Loss: 1.420 | Test Acc: 48.728% (4522/9280)\n",
      "Epoch 2 Step 290/313 Test Loss: 1.421 | Test Acc: 48.668% (4532/9312)\n",
      "Epoch 2 Step 291/313 Test Loss: 1.421 | Test Acc: 48.673% (4548/9344)\n",
      "Epoch 2 Step 292/313 Test Loss: 1.421 | Test Acc: 48.699% (4566/9376)\n",
      "Epoch 2 Step 293/313 Test Loss: 1.422 | Test Acc: 48.661% (4578/9408)\n",
      "Epoch 2 Step 294/313 Test Loss: 1.421 | Test Acc: 48.655% (4593/9440)\n",
      "Epoch 2 Step 295/313 Test Loss: 1.421 | Test Acc: 48.680% (4611/9472)\n",
      "Epoch 2 Step 296/313 Test Loss: 1.421 | Test Acc: 48.695% (4628/9504)\n",
      "Epoch 2 Step 297/313 Test Loss: 1.422 | Test Acc: 48.668% (4641/9536)\n",
      "Epoch 2 Step 298/313 Test Loss: 1.421 | Test Acc: 48.694% (4659/9568)\n",
      "Epoch 2 Step 299/313 Test Loss: 1.421 | Test Acc: 48.708% (4676/9600)\n",
      "Epoch 2 Step 300/313 Test Loss: 1.421 | Test Acc: 48.723% (4693/9632)\n",
      "Epoch 2 Step 301/313 Test Loss: 1.422 | Test Acc: 48.686% (4705/9664)\n",
      "Epoch 2 Step 302/313 Test Loss: 1.422 | Test Acc: 48.670% (4719/9696)\n",
      "Epoch 2 Step 303/313 Test Loss: 1.421 | Test Acc: 48.715% (4739/9728)\n",
      "Epoch 2 Step 304/313 Test Loss: 1.422 | Test Acc: 48.678% (4751/9760)\n",
      "Epoch 2 Step 305/313 Test Loss: 1.421 | Test Acc: 48.703% (4769/9792)\n",
      "Epoch 2 Step 306/313 Test Loss: 1.422 | Test Acc: 48.707% (4785/9824)\n",
      "Epoch 2 Step 307/313 Test Loss: 1.423 | Test Acc: 48.711% (4801/9856)\n",
      "Epoch 2 Step 308/313 Test Loss: 1.423 | Test Acc: 48.685% (4814/9888)\n",
      "Epoch 2 Step 309/313 Test Loss: 1.423 | Test Acc: 48.669% (4828/9920)\n",
      "Epoch 2 Step 310/313 Test Loss: 1.423 | Test Acc: 48.643% (4841/9952)\n",
      "Epoch 2 Step 311/313 Test Loss: 1.423 | Test Acc: 48.628% (4855/9984)\n",
      "Epoch 2 Step 312/313 Test Loss: 1.424 | Test Acc: 48.590% (4859/10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "Epoch 3 Step 0/1563 Loss: 1.387 | Acc: 56.250% (18/32)\n",
      "Epoch 3 Step 1/1563 Loss: 1.488 | Acc: 48.438% (31/64)\n",
      "Epoch 3 Step 2/1563 Loss: 1.537 | Acc: 50.000% (48/96)\n",
      "Epoch 3 Step 3/1563 Loss: 1.563 | Acc: 48.438% (62/128)\n",
      "Epoch 3 Step 4/1563 Loss: 1.565 | Acc: 48.125% (77/160)\n",
      "Epoch 3 Step 5/1563 Loss: 1.597 | Acc: 45.312% (87/192)\n",
      "Epoch 3 Step 6/1563 Loss: 1.611 | Acc: 44.196% (99/224)\n",
      "Epoch 3 Step 7/1563 Loss: 1.622 | Acc: 44.531% (114/256)\n",
      "Epoch 3 Step 8/1563 Loss: 1.626 | Acc: 44.097% (127/288)\n",
      "Epoch 3 Step 9/1563 Loss: 1.608 | Acc: 45.312% (145/320)\n",
      "Epoch 3 Step 10/1563 Loss: 1.575 | Acc: 46.307% (163/352)\n",
      "Epoch 3 Step 11/1563 Loss: 1.550 | Acc: 46.354% (178/384)\n",
      "Epoch 3 Step 12/1563 Loss: 1.548 | Acc: 46.154% (192/416)\n",
      "Epoch 3 Step 13/1563 Loss: 1.521 | Acc: 47.768% (214/448)\n",
      "Epoch 3 Step 14/1563 Loss: 1.514 | Acc: 47.500% (228/480)\n",
      "Epoch 3 Step 15/1563 Loss: 1.516 | Acc: 47.266% (242/512)\n",
      "Epoch 3 Step 16/1563 Loss: 1.514 | Acc: 47.059% (256/544)\n",
      "Epoch 3 Step 17/1563 Loss: 1.524 | Acc: 46.701% (269/576)\n",
      "Epoch 3 Step 18/1563 Loss: 1.516 | Acc: 46.875% (285/608)\n",
      "Epoch 3 Step 19/1563 Loss: 1.535 | Acc: 45.469% (291/640)\n",
      "Epoch 3 Step 20/1563 Loss: 1.536 | Acc: 45.089% (303/672)\n",
      "Epoch 3 Step 21/1563 Loss: 1.532 | Acc: 45.170% (318/704)\n",
      "Epoch 3 Step 22/1563 Loss: 1.524 | Acc: 45.788% (337/736)\n",
      "Epoch 3 Step 23/1563 Loss: 1.513 | Acc: 46.224% (355/768)\n",
      "Epoch 3 Step 24/1563 Loss: 1.510 | Acc: 46.625% (373/800)\n",
      "Epoch 3 Step 25/1563 Loss: 1.510 | Acc: 46.394% (386/832)\n",
      "Epoch 3 Step 26/1563 Loss: 1.518 | Acc: 46.065% (398/864)\n",
      "Epoch 3 Step 27/1563 Loss: 1.510 | Acc: 46.317% (415/896)\n",
      "Epoch 3 Step 28/1563 Loss: 1.512 | Acc: 46.121% (428/928)\n",
      "Epoch 3 Step 29/1563 Loss: 1.507 | Acc: 46.354% (445/960)\n",
      "Epoch 3 Step 30/1563 Loss: 1.503 | Acc: 46.573% (462/992)\n",
      "Epoch 3 Step 31/1563 Loss: 1.502 | Acc: 46.582% (477/1024)\n",
      "Epoch 3 Step 32/1563 Loss: 1.510 | Acc: 46.117% (487/1056)\n",
      "Epoch 3 Step 33/1563 Loss: 1.507 | Acc: 46.232% (503/1088)\n",
      "Epoch 3 Step 34/1563 Loss: 1.504 | Acc: 45.982% (515/1120)\n",
      "Epoch 3 Step 35/1563 Loss: 1.506 | Acc: 46.181% (532/1152)\n",
      "Epoch 3 Step 36/1563 Loss: 1.506 | Acc: 46.453% (550/1184)\n",
      "Epoch 3 Step 37/1563 Loss: 1.502 | Acc: 46.382% (564/1216)\n",
      "Epoch 3 Step 38/1563 Loss: 1.497 | Acc: 46.554% (581/1248)\n",
      "Epoch 3 Step 39/1563 Loss: 1.495 | Acc: 46.719% (598/1280)\n",
      "Epoch 3 Step 40/1563 Loss: 1.492 | Acc: 46.799% (614/1312)\n",
      "Epoch 3 Step 41/1563 Loss: 1.496 | Acc: 46.577% (626/1344)\n",
      "Epoch 3 Step 42/1563 Loss: 1.501 | Acc: 46.512% (640/1376)\n",
      "Epoch 3 Step 43/1563 Loss: 1.502 | Acc: 46.449% (654/1408)\n",
      "Epoch 3 Step 44/1563 Loss: 1.506 | Acc: 46.250% (666/1440)\n",
      "Epoch 3 Step 45/1563 Loss: 1.509 | Acc: 45.856% (675/1472)\n",
      "Epoch 3 Step 46/1563 Loss: 1.505 | Acc: 45.944% (691/1504)\n",
      "Epoch 3 Step 47/1563 Loss: 1.510 | Acc: 45.898% (705/1536)\n",
      "Epoch 3 Step 48/1563 Loss: 1.511 | Acc: 46.110% (723/1568)\n",
      "Epoch 3 Step 49/1563 Loss: 1.508 | Acc: 46.250% (740/1600)\n",
      "Epoch 3 Step 50/1563 Loss: 1.507 | Acc: 46.262% (755/1632)\n",
      "Epoch 3 Step 51/1563 Loss: 1.510 | Acc: 46.154% (768/1664)\n",
      "Epoch 3 Step 52/1563 Loss: 1.513 | Acc: 45.991% (780/1696)\n",
      "Epoch 3 Step 53/1563 Loss: 1.511 | Acc: 45.949% (794/1728)\n",
      "Epoch 3 Step 54/1563 Loss: 1.511 | Acc: 45.909% (808/1760)\n",
      "Epoch 3 Step 55/1563 Loss: 1.502 | Acc: 46.373% (831/1792)\n",
      "Epoch 3 Step 56/1563 Loss: 1.501 | Acc: 46.546% (849/1824)\n",
      "Epoch 3 Step 57/1563 Loss: 1.504 | Acc: 46.444% (862/1856)\n",
      "Epoch 3 Step 58/1563 Loss: 1.510 | Acc: 46.398% (876/1888)\n",
      "Epoch 3 Step 59/1563 Loss: 1.508 | Acc: 46.458% (892/1920)\n",
      "Epoch 3 Step 60/1563 Loss: 1.513 | Acc: 46.465% (907/1952)\n",
      "Epoch 3 Step 61/1563 Loss: 1.511 | Acc: 46.421% (921/1984)\n",
      "Epoch 3 Step 62/1563 Loss: 1.510 | Acc: 46.528% (938/2016)\n",
      "Epoch 3 Step 63/1563 Loss: 1.514 | Acc: 46.387% (950/2048)\n",
      "Epoch 3 Step 64/1563 Loss: 1.511 | Acc: 46.298% (963/2080)\n",
      "Epoch 3 Step 65/1563 Loss: 1.507 | Acc: 46.449% (981/2112)\n",
      "Epoch 3 Step 66/1563 Loss: 1.510 | Acc: 46.315% (993/2144)\n",
      "Epoch 3 Step 67/1563 Loss: 1.507 | Acc: 46.278% (1007/2176)\n",
      "Epoch 3 Step 68/1563 Loss: 1.504 | Acc: 46.332% (1023/2208)\n",
      "Epoch 3 Step 69/1563 Loss: 1.503 | Acc: 46.250% (1036/2240)\n",
      "Epoch 3 Step 70/1563 Loss: 1.506 | Acc: 46.215% (1050/2272)\n",
      "Epoch 3 Step 71/1563 Loss: 1.502 | Acc: 46.311% (1067/2304)\n",
      "Epoch 3 Step 72/1563 Loss: 1.500 | Acc: 46.404% (1084/2336)\n",
      "Epoch 3 Step 73/1563 Loss: 1.500 | Acc: 46.368% (1098/2368)\n",
      "Epoch 3 Step 74/1563 Loss: 1.499 | Acc: 46.208% (1109/2400)\n",
      "Epoch 3 Step 75/1563 Loss: 1.503 | Acc: 46.135% (1122/2432)\n",
      "Epoch 3 Step 76/1563 Loss: 1.500 | Acc: 46.185% (1138/2464)\n",
      "Epoch 3 Step 77/1563 Loss: 1.501 | Acc: 46.154% (1152/2496)\n",
      "Epoch 3 Step 78/1563 Loss: 1.501 | Acc: 46.163% (1167/2528)\n",
      "Epoch 3 Step 79/1563 Loss: 1.499 | Acc: 46.289% (1185/2560)\n",
      "Epoch 3 Step 80/1563 Loss: 1.497 | Acc: 46.412% (1203/2592)\n",
      "Epoch 3 Step 81/1563 Loss: 1.496 | Acc: 46.380% (1217/2624)\n",
      "Epoch 3 Step 82/1563 Loss: 1.500 | Acc: 46.160% (1226/2656)\n",
      "Epoch 3 Step 83/1563 Loss: 1.497 | Acc: 46.205% (1242/2688)\n",
      "Epoch 3 Step 84/1563 Loss: 1.499 | Acc: 46.213% (1257/2720)\n",
      "Epoch 3 Step 85/1563 Loss: 1.499 | Acc: 45.967% (1265/2752)\n",
      "Epoch 3 Step 86/1563 Loss: 1.500 | Acc: 45.869% (1277/2784)\n",
      "Epoch 3 Step 87/1563 Loss: 1.501 | Acc: 45.845% (1291/2816)\n",
      "Epoch 3 Step 88/1563 Loss: 1.502 | Acc: 45.716% (1302/2848)\n",
      "Epoch 3 Step 89/1563 Loss: 1.506 | Acc: 45.660% (1315/2880)\n",
      "Epoch 3 Step 90/1563 Loss: 1.505 | Acc: 45.707% (1331/2912)\n",
      "Epoch 3 Step 91/1563 Loss: 1.507 | Acc: 45.652% (1344/2944)\n",
      "Epoch 3 Step 92/1563 Loss: 1.504 | Acc: 45.632% (1358/2976)\n",
      "Epoch 3 Step 93/1563 Loss: 1.502 | Acc: 45.811% (1378/3008)\n",
      "Epoch 3 Step 94/1563 Loss: 1.501 | Acc: 45.888% (1395/3040)\n",
      "Epoch 3 Step 95/1563 Loss: 1.502 | Acc: 45.703% (1404/3072)\n",
      "Epoch 3 Step 96/1563 Loss: 1.498 | Acc: 45.909% (1425/3104)\n",
      "Epoch 3 Step 97/1563 Loss: 1.500 | Acc: 45.855% (1438/3136)\n",
      "Epoch 3 Step 98/1563 Loss: 1.498 | Acc: 45.991% (1457/3168)\n",
      "Epoch 3 Step 99/1563 Loss: 1.500 | Acc: 45.906% (1469/3200)\n",
      "Epoch 3 Step 100/1563 Loss: 1.499 | Acc: 46.009% (1487/3232)\n",
      "Epoch 3 Step 101/1563 Loss: 1.495 | Acc: 46.140% (1506/3264)\n",
      "Epoch 3 Step 102/1563 Loss: 1.493 | Acc: 46.177% (1522/3296)\n",
      "Epoch 3 Step 103/1563 Loss: 1.495 | Acc: 46.154% (1536/3328)\n",
      "Epoch 3 Step 104/1563 Loss: 1.493 | Acc: 46.220% (1553/3360)\n",
      "Epoch 3 Step 105/1563 Loss: 1.492 | Acc: 46.256% (1569/3392)\n",
      "Epoch 3 Step 106/1563 Loss: 1.494 | Acc: 46.116% (1579/3424)\n",
      "Epoch 3 Step 107/1563 Loss: 1.499 | Acc: 45.920% (1587/3456)\n",
      "Epoch 3 Step 108/1563 Loss: 1.498 | Acc: 45.986% (1604/3488)\n",
      "Epoch 3 Step 109/1563 Loss: 1.500 | Acc: 45.938% (1617/3520)\n",
      "Epoch 3 Step 110/1563 Loss: 1.502 | Acc: 45.918% (1631/3552)\n",
      "Epoch 3 Step 111/1563 Loss: 1.504 | Acc: 45.926% (1646/3584)\n",
      "Epoch 3 Step 112/1563 Loss: 1.502 | Acc: 45.935% (1661/3616)\n",
      "Epoch 3 Step 113/1563 Loss: 1.503 | Acc: 45.998% (1678/3648)\n",
      "Epoch 3 Step 114/1563 Loss: 1.503 | Acc: 46.005% (1693/3680)\n",
      "Epoch 3 Step 115/1563 Loss: 1.502 | Acc: 46.013% (1708/3712)\n",
      "Epoch 3 Step 116/1563 Loss: 1.504 | Acc: 45.833% (1716/3744)\n",
      "Epoch 3 Step 117/1563 Loss: 1.506 | Acc: 45.789% (1729/3776)\n",
      "Epoch 3 Step 118/1563 Loss: 1.507 | Acc: 45.746% (1742/3808)\n",
      "Epoch 3 Step 119/1563 Loss: 1.508 | Acc: 45.755% (1757/3840)\n",
      "Epoch 3 Step 120/1563 Loss: 1.507 | Acc: 45.816% (1774/3872)\n",
      "Epoch 3 Step 121/1563 Loss: 1.506 | Acc: 45.825% (1789/3904)\n",
      "Epoch 3 Step 122/1563 Loss: 1.504 | Acc: 45.935% (1808/3936)\n",
      "Epoch 3 Step 123/1563 Loss: 1.504 | Acc: 45.892% (1821/3968)\n",
      "Epoch 3 Step 124/1563 Loss: 1.504 | Acc: 45.950% (1838/4000)\n",
      "Epoch 3 Step 125/1563 Loss: 1.503 | Acc: 45.957% (1853/4032)\n",
      "Epoch 3 Step 126/1563 Loss: 1.502 | Acc: 46.038% (1871/4064)\n",
      "Epoch 3 Step 127/1563 Loss: 1.502 | Acc: 46.021% (1885/4096)\n",
      "Epoch 3 Step 128/1563 Loss: 1.503 | Acc: 46.027% (1900/4128)\n",
      "Epoch 3 Step 129/1563 Loss: 1.505 | Acc: 46.010% (1914/4160)\n",
      "Epoch 3 Step 130/1563 Loss: 1.505 | Acc: 46.016% (1929/4192)\n",
      "Epoch 3 Step 131/1563 Loss: 1.503 | Acc: 46.117% (1948/4224)\n",
      "Epoch 3 Step 132/1563 Loss: 1.501 | Acc: 46.194% (1966/4256)\n",
      "Epoch 3 Step 133/1563 Loss: 1.501 | Acc: 46.129% (1978/4288)\n",
      "Epoch 3 Step 134/1563 Loss: 1.501 | Acc: 46.157% (1994/4320)\n",
      "Epoch 3 Step 135/1563 Loss: 1.501 | Acc: 46.117% (2007/4352)\n",
      "Epoch 3 Step 136/1563 Loss: 1.500 | Acc: 46.054% (2019/4384)\n",
      "Epoch 3 Step 137/1563 Loss: 1.501 | Acc: 46.105% (2036/4416)\n",
      "Epoch 3 Step 138/1563 Loss: 1.500 | Acc: 46.133% (2052/4448)\n",
      "Epoch 3 Step 139/1563 Loss: 1.499 | Acc: 46.116% (2066/4480)\n",
      "Epoch 3 Step 140/1563 Loss: 1.500 | Acc: 46.099% (2080/4512)\n",
      "Epoch 3 Step 141/1563 Loss: 1.499 | Acc: 46.083% (2094/4544)\n",
      "Epoch 3 Step 142/1563 Loss: 1.499 | Acc: 46.154% (2112/4576)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 143/1563 Loss: 1.502 | Acc: 45.964% (2118/4608)\n",
      "Epoch 3 Step 144/1563 Loss: 1.501 | Acc: 45.927% (2131/4640)\n",
      "Epoch 3 Step 145/1563 Loss: 1.502 | Acc: 45.826% (2141/4672)\n",
      "Epoch 3 Step 146/1563 Loss: 1.501 | Acc: 45.791% (2154/4704)\n",
      "Epoch 3 Step 147/1563 Loss: 1.500 | Acc: 45.840% (2171/4736)\n",
      "Epoch 3 Step 148/1563 Loss: 1.501 | Acc: 45.847% (2186/4768)\n",
      "Epoch 3 Step 149/1563 Loss: 1.501 | Acc: 45.833% (2200/4800)\n",
      "Epoch 3 Step 150/1563 Loss: 1.501 | Acc: 45.902% (2218/4832)\n",
      "Epoch 3 Step 151/1563 Loss: 1.500 | Acc: 45.888% (2232/4864)\n",
      "Epoch 3 Step 152/1563 Loss: 1.501 | Acc: 45.833% (2244/4896)\n",
      "Epoch 3 Step 153/1563 Loss: 1.499 | Acc: 45.921% (2263/4928)\n",
      "Epoch 3 Step 154/1563 Loss: 1.501 | Acc: 45.867% (2275/4960)\n",
      "Epoch 3 Step 155/1563 Loss: 1.500 | Acc: 45.813% (2287/4992)\n",
      "Epoch 3 Step 156/1563 Loss: 1.498 | Acc: 45.920% (2307/5024)\n",
      "Epoch 3 Step 157/1563 Loss: 1.496 | Acc: 46.005% (2326/5056)\n",
      "Epoch 3 Step 158/1563 Loss: 1.496 | Acc: 46.069% (2344/5088)\n",
      "Epoch 3 Step 159/1563 Loss: 1.496 | Acc: 46.035% (2357/5120)\n",
      "Epoch 3 Step 160/1563 Loss: 1.497 | Acc: 46.002% (2370/5152)\n",
      "Epoch 3 Step 161/1563 Loss: 1.497 | Acc: 46.084% (2389/5184)\n",
      "Epoch 3 Step 162/1563 Loss: 1.497 | Acc: 46.051% (2402/5216)\n",
      "Epoch 3 Step 163/1563 Loss: 1.496 | Acc: 46.113% (2420/5248)\n",
      "Epoch 3 Step 164/1563 Loss: 1.499 | Acc: 46.042% (2431/5280)\n",
      "Epoch 3 Step 165/1563 Loss: 1.499 | Acc: 46.122% (2450/5312)\n",
      "Epoch 3 Step 166/1563 Loss: 1.496 | Acc: 46.239% (2471/5344)\n",
      "Epoch 3 Step 167/1563 Loss: 1.497 | Acc: 46.280% (2488/5376)\n",
      "Epoch 3 Step 168/1563 Loss: 1.497 | Acc: 46.283% (2503/5408)\n",
      "Epoch 3 Step 169/1563 Loss: 1.497 | Acc: 46.213% (2514/5440)\n",
      "Epoch 3 Step 170/1563 Loss: 1.496 | Acc: 46.217% (2529/5472)\n",
      "Epoch 3 Step 171/1563 Loss: 1.496 | Acc: 46.148% (2540/5504)\n",
      "Epoch 3 Step 172/1563 Loss: 1.497 | Acc: 46.098% (2552/5536)\n",
      "Epoch 3 Step 173/1563 Loss: 1.495 | Acc: 46.210% (2573/5568)\n",
      "Epoch 3 Step 174/1563 Loss: 1.494 | Acc: 46.268% (2591/5600)\n",
      "Epoch 3 Step 175/1563 Loss: 1.493 | Acc: 46.360% (2611/5632)\n",
      "Epoch 3 Step 176/1563 Loss: 1.493 | Acc: 46.416% (2629/5664)\n",
      "Epoch 3 Step 177/1563 Loss: 1.493 | Acc: 46.436% (2645/5696)\n",
      "Epoch 3 Step 178/1563 Loss: 1.492 | Acc: 46.369% (2656/5728)\n",
      "Epoch 3 Step 179/1563 Loss: 1.494 | Acc: 46.302% (2667/5760)\n",
      "Epoch 3 Step 180/1563 Loss: 1.495 | Acc: 46.202% (2676/5792)\n",
      "Epoch 3 Step 181/1563 Loss: 1.496 | Acc: 46.205% (2691/5824)\n",
      "Epoch 3 Step 182/1563 Loss: 1.496 | Acc: 46.192% (2705/5856)\n",
      "Epoch 3 Step 183/1563 Loss: 1.498 | Acc: 46.162% (2718/5888)\n",
      "Epoch 3 Step 184/1563 Loss: 1.498 | Acc: 46.166% (2733/5920)\n",
      "Epoch 3 Step 185/1563 Loss: 1.498 | Acc: 46.186% (2749/5952)\n",
      "Epoch 3 Step 186/1563 Loss: 1.500 | Acc: 46.156% (2762/5984)\n",
      "Epoch 3 Step 187/1563 Loss: 1.499 | Acc: 46.160% (2777/6016)\n",
      "Epoch 3 Step 188/1563 Loss: 1.499 | Acc: 46.197% (2794/6048)\n",
      "Epoch 3 Step 189/1563 Loss: 1.500 | Acc: 46.184% (2808/6080)\n",
      "Epoch 3 Step 190/1563 Loss: 1.500 | Acc: 46.171% (2822/6112)\n",
      "Epoch 3 Step 191/1563 Loss: 1.501 | Acc: 46.110% (2833/6144)\n",
      "Epoch 3 Step 192/1563 Loss: 1.499 | Acc: 46.146% (2850/6176)\n",
      "Epoch 3 Step 193/1563 Loss: 1.500 | Acc: 46.118% (2863/6208)\n",
      "Epoch 3 Step 194/1563 Loss: 1.499 | Acc: 46.106% (2877/6240)\n",
      "Epoch 3 Step 195/1563 Loss: 1.498 | Acc: 46.142% (2894/6272)\n",
      "Epoch 3 Step 196/1563 Loss: 1.500 | Acc: 46.114% (2907/6304)\n",
      "Epoch 3 Step 197/1563 Loss: 1.500 | Acc: 46.086% (2920/6336)\n",
      "Epoch 3 Step 198/1563 Loss: 1.499 | Acc: 46.058% (2933/6368)\n",
      "Epoch 3 Step 199/1563 Loss: 1.498 | Acc: 46.125% (2952/6400)\n",
      "Epoch 3 Step 200/1563 Loss: 1.500 | Acc: 46.067% (2963/6432)\n",
      "Epoch 3 Step 201/1563 Loss: 1.500 | Acc: 46.040% (2976/6464)\n",
      "Epoch 3 Step 202/1563 Loss: 1.501 | Acc: 46.013% (2989/6496)\n",
      "Epoch 3 Step 203/1563 Loss: 1.501 | Acc: 46.002% (3003/6528)\n",
      "Epoch 3 Step 204/1563 Loss: 1.502 | Acc: 45.930% (3013/6560)\n",
      "Epoch 3 Step 205/1563 Loss: 1.502 | Acc: 45.919% (3027/6592)\n",
      "Epoch 3 Step 206/1563 Loss: 1.502 | Acc: 45.924% (3042/6624)\n",
      "Epoch 3 Step 207/1563 Loss: 1.502 | Acc: 45.898% (3055/6656)\n",
      "Epoch 3 Step 208/1563 Loss: 1.501 | Acc: 45.963% (3074/6688)\n",
      "Epoch 3 Step 209/1563 Loss: 1.502 | Acc: 45.952% (3088/6720)\n",
      "Epoch 3 Step 210/1563 Loss: 1.502 | Acc: 45.957% (3103/6752)\n",
      "Epoch 3 Step 211/1563 Loss: 1.501 | Acc: 45.946% (3117/6784)\n",
      "Epoch 3 Step 212/1563 Loss: 1.500 | Acc: 45.936% (3131/6816)\n",
      "Epoch 3 Step 213/1563 Loss: 1.501 | Acc: 45.911% (3144/6848)\n",
      "Epoch 3 Step 214/1563 Loss: 1.502 | Acc: 45.843% (3154/6880)\n",
      "Epoch 3 Step 215/1563 Loss: 1.502 | Acc: 45.862% (3170/6912)\n",
      "Epoch 3 Step 216/1563 Loss: 1.504 | Acc: 45.781% (3179/6944)\n",
      "Epoch 3 Step 217/1563 Loss: 1.502 | Acc: 45.872% (3200/6976)\n",
      "Epoch 3 Step 218/1563 Loss: 1.502 | Acc: 45.905% (3217/7008)\n",
      "Epoch 3 Step 219/1563 Loss: 1.502 | Acc: 45.881% (3230/7040)\n",
      "Epoch 3 Step 220/1563 Loss: 1.502 | Acc: 45.871% (3244/7072)\n",
      "Epoch 3 Step 221/1563 Loss: 1.501 | Acc: 45.876% (3259/7104)\n",
      "Epoch 3 Step 222/1563 Loss: 1.503 | Acc: 45.852% (3272/7136)\n",
      "Epoch 3 Step 223/1563 Loss: 1.503 | Acc: 45.759% (3280/7168)\n",
      "Epoch 3 Step 224/1563 Loss: 1.503 | Acc: 45.750% (3294/7200)\n",
      "Epoch 3 Step 225/1563 Loss: 1.503 | Acc: 45.741% (3308/7232)\n",
      "Epoch 3 Step 226/1563 Loss: 1.504 | Acc: 45.719% (3321/7264)\n",
      "Epoch 3 Step 227/1563 Loss: 1.503 | Acc: 45.765% (3339/7296)\n",
      "Epoch 3 Step 228/1563 Loss: 1.502 | Acc: 45.756% (3353/7328)\n",
      "Epoch 3 Step 229/1563 Loss: 1.502 | Acc: 45.747% (3367/7360)\n",
      "Epoch 3 Step 230/1563 Loss: 1.502 | Acc: 45.752% (3382/7392)\n",
      "Epoch 3 Step 231/1563 Loss: 1.502 | Acc: 45.770% (3398/7424)\n",
      "Epoch 3 Step 232/1563 Loss: 1.502 | Acc: 45.829% (3417/7456)\n",
      "Epoch 3 Step 233/1563 Loss: 1.503 | Acc: 45.807% (3430/7488)\n",
      "Epoch 3 Step 234/1563 Loss: 1.502 | Acc: 45.878% (3450/7520)\n",
      "Epoch 3 Step 235/1563 Loss: 1.503 | Acc: 45.869% (3464/7552)\n",
      "Epoch 3 Step 236/1563 Loss: 1.503 | Acc: 45.873% (3479/7584)\n",
      "Epoch 3 Step 237/1563 Loss: 1.503 | Acc: 45.864% (3493/7616)\n",
      "Epoch 3 Step 238/1563 Loss: 1.504 | Acc: 45.829% (3505/7648)\n",
      "Epoch 3 Step 239/1563 Loss: 1.504 | Acc: 45.820% (3519/7680)\n",
      "Epoch 3 Step 240/1563 Loss: 1.504 | Acc: 45.838% (3535/7712)\n",
      "Epoch 3 Step 241/1563 Loss: 1.504 | Acc: 45.855% (3551/7744)\n",
      "Epoch 3 Step 242/1563 Loss: 1.504 | Acc: 45.885% (3568/7776)\n",
      "Epoch 3 Step 243/1563 Loss: 1.503 | Acc: 45.902% (3584/7808)\n",
      "Epoch 3 Step 244/1563 Loss: 1.502 | Acc: 45.944% (3602/7840)\n",
      "Epoch 3 Step 245/1563 Loss: 1.502 | Acc: 45.960% (3618/7872)\n",
      "Epoch 3 Step 246/1563 Loss: 1.501 | Acc: 46.015% (3637/7904)\n",
      "Epoch 3 Step 247/1563 Loss: 1.500 | Acc: 46.031% (3653/7936)\n",
      "Epoch 3 Step 248/1563 Loss: 1.499 | Acc: 46.009% (3666/7968)\n",
      "Epoch 3 Step 249/1563 Loss: 1.499 | Acc: 46.025% (3682/8000)\n",
      "Epoch 3 Step 250/1563 Loss: 1.499 | Acc: 46.016% (3696/8032)\n",
      "Epoch 3 Step 251/1563 Loss: 1.498 | Acc: 46.069% (3715/8064)\n",
      "Epoch 3 Step 252/1563 Loss: 1.498 | Acc: 46.072% (3730/8096)\n",
      "Epoch 3 Step 253/1563 Loss: 1.496 | Acc: 46.112% (3748/8128)\n",
      "Epoch 3 Step 254/1563 Loss: 1.496 | Acc: 46.140% (3765/8160)\n",
      "Epoch 3 Step 255/1563 Loss: 1.496 | Acc: 46.118% (3778/8192)\n",
      "Epoch 3 Step 256/1563 Loss: 1.496 | Acc: 46.109% (3792/8224)\n",
      "Epoch 3 Step 257/1563 Loss: 1.494 | Acc: 46.148% (3810/8256)\n",
      "Epoch 3 Step 258/1563 Loss: 1.495 | Acc: 46.127% (3823/8288)\n",
      "Epoch 3 Step 259/1563 Loss: 1.494 | Acc: 46.142% (3839/8320)\n",
      "Epoch 3 Step 260/1563 Loss: 1.493 | Acc: 46.145% (3854/8352)\n",
      "Epoch 3 Step 261/1563 Loss: 1.494 | Acc: 46.112% (3866/8384)\n",
      "Epoch 3 Step 262/1563 Loss: 1.493 | Acc: 46.150% (3884/8416)\n",
      "Epoch 3 Step 263/1563 Loss: 1.494 | Acc: 46.106% (3895/8448)\n",
      "Epoch 3 Step 264/1563 Loss: 1.494 | Acc: 46.085% (3908/8480)\n",
      "Epoch 3 Step 265/1563 Loss: 1.493 | Acc: 46.100% (3924/8512)\n",
      "Epoch 3 Step 266/1563 Loss: 1.494 | Acc: 46.079% (3937/8544)\n",
      "Epoch 3 Step 267/1563 Loss: 1.494 | Acc: 46.070% (3951/8576)\n",
      "Epoch 3 Step 268/1563 Loss: 1.494 | Acc: 46.062% (3965/8608)\n",
      "Epoch 3 Step 269/1563 Loss: 1.493 | Acc: 46.088% (3982/8640)\n",
      "Epoch 3 Step 270/1563 Loss: 1.492 | Acc: 46.091% (3997/8672)\n",
      "Epoch 3 Step 271/1563 Loss: 1.492 | Acc: 46.082% (4011/8704)\n",
      "Epoch 3 Step 272/1563 Loss: 1.492 | Acc: 46.120% (4029/8736)\n",
      "Epoch 3 Step 273/1563 Loss: 1.492 | Acc: 46.099% (4042/8768)\n",
      "Epoch 3 Step 274/1563 Loss: 1.492 | Acc: 46.125% (4059/8800)\n",
      "Epoch 3 Step 275/1563 Loss: 1.492 | Acc: 46.116% (4073/8832)\n",
      "Epoch 3 Step 276/1563 Loss: 1.491 | Acc: 46.130% (4089/8864)\n",
      "Epoch 3 Step 277/1563 Loss: 1.491 | Acc: 46.133% (4104/8896)\n",
      "Epoch 3 Step 278/1563 Loss: 1.490 | Acc: 46.169% (4122/8928)\n",
      "Epoch 3 Step 279/1563 Loss: 1.490 | Acc: 46.161% (4136/8960)\n",
      "Epoch 3 Step 280/1563 Loss: 1.490 | Acc: 46.152% (4150/8992)\n",
      "Epoch 3 Step 281/1563 Loss: 1.491 | Acc: 46.144% (4164/9024)\n",
      "Epoch 3 Step 282/1563 Loss: 1.490 | Acc: 46.179% (4182/9056)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 283/1563 Loss: 1.489 | Acc: 46.193% (4198/9088)\n",
      "Epoch 3 Step 284/1563 Loss: 1.489 | Acc: 46.206% (4214/9120)\n",
      "Epoch 3 Step 285/1563 Loss: 1.490 | Acc: 46.176% (4226/9152)\n",
      "Epoch 3 Step 286/1563 Loss: 1.490 | Acc: 46.124% (4236/9184)\n",
      "Epoch 3 Step 287/1563 Loss: 1.490 | Acc: 46.159% (4254/9216)\n",
      "Epoch 3 Step 288/1563 Loss: 1.490 | Acc: 46.151% (4268/9248)\n",
      "Epoch 3 Step 289/1563 Loss: 1.490 | Acc: 46.153% (4283/9280)\n",
      "Epoch 3 Step 290/1563 Loss: 1.490 | Acc: 46.134% (4296/9312)\n",
      "Epoch 3 Step 291/1563 Loss: 1.490 | Acc: 46.115% (4309/9344)\n",
      "Epoch 3 Step 292/1563 Loss: 1.490 | Acc: 46.128% (4325/9376)\n",
      "Epoch 3 Step 293/1563 Loss: 1.490 | Acc: 46.110% (4338/9408)\n",
      "Epoch 3 Step 294/1563 Loss: 1.490 | Acc: 46.081% (4350/9440)\n",
      "Epoch 3 Step 295/1563 Loss: 1.490 | Acc: 46.030% (4360/9472)\n",
      "Epoch 3 Step 296/1563 Loss: 1.490 | Acc: 46.023% (4374/9504)\n",
      "Epoch 3 Step 297/1563 Loss: 1.491 | Acc: 45.984% (4385/9536)\n",
      "Epoch 3 Step 298/1563 Loss: 1.491 | Acc: 45.945% (4396/9568)\n",
      "Epoch 3 Step 299/1563 Loss: 1.491 | Acc: 46.000% (4416/9600)\n",
      "Epoch 3 Step 300/1563 Loss: 1.491 | Acc: 45.941% (4425/9632)\n",
      "Epoch 3 Step 301/1563 Loss: 1.492 | Acc: 45.923% (4438/9664)\n",
      "Epoch 3 Step 302/1563 Loss: 1.492 | Acc: 45.906% (4451/9696)\n",
      "Epoch 3 Step 303/1563 Loss: 1.491 | Acc: 45.919% (4467/9728)\n",
      "Epoch 3 Step 304/1563 Loss: 1.491 | Acc: 45.963% (4486/9760)\n",
      "Epoch 3 Step 305/1563 Loss: 1.490 | Acc: 45.976% (4502/9792)\n",
      "Epoch 3 Step 306/1563 Loss: 1.490 | Acc: 46.010% (4520/9824)\n",
      "Epoch 3 Step 307/1563 Loss: 1.489 | Acc: 46.013% (4535/9856)\n",
      "Epoch 3 Step 308/1563 Loss: 1.489 | Acc: 46.005% (4549/9888)\n",
      "Epoch 3 Step 309/1563 Loss: 1.490 | Acc: 45.958% (4559/9920)\n",
      "Epoch 3 Step 310/1563 Loss: 1.489 | Acc: 45.991% (4577/9952)\n",
      "Epoch 3 Step 311/1563 Loss: 1.489 | Acc: 45.984% (4591/9984)\n",
      "Epoch 3 Step 312/1563 Loss: 1.489 | Acc: 46.016% (4609/10016)\n",
      "Epoch 3 Step 313/1563 Loss: 1.488 | Acc: 46.039% (4626/10048)\n",
      "Epoch 3 Step 314/1563 Loss: 1.489 | Acc: 46.042% (4641/10080)\n",
      "Epoch 3 Step 315/1563 Loss: 1.488 | Acc: 46.064% (4658/10112)\n",
      "Epoch 3 Step 316/1563 Loss: 1.488 | Acc: 46.096% (4676/10144)\n",
      "Epoch 3 Step 317/1563 Loss: 1.489 | Acc: 46.069% (4688/10176)\n",
      "Epoch 3 Step 318/1563 Loss: 1.488 | Acc: 46.091% (4705/10208)\n",
      "Epoch 3 Step 319/1563 Loss: 1.489 | Acc: 46.055% (4716/10240)\n",
      "Epoch 3 Step 320/1563 Loss: 1.489 | Acc: 46.038% (4729/10272)\n",
      "Epoch 3 Step 321/1563 Loss: 1.489 | Acc: 46.040% (4744/10304)\n",
      "Epoch 3 Step 322/1563 Loss: 1.491 | Acc: 46.004% (4755/10336)\n",
      "Epoch 3 Step 323/1563 Loss: 1.491 | Acc: 45.988% (4768/10368)\n",
      "Epoch 3 Step 324/1563 Loss: 1.491 | Acc: 46.010% (4785/10400)\n",
      "Epoch 3 Step 325/1563 Loss: 1.491 | Acc: 45.964% (4795/10432)\n",
      "Epoch 3 Step 326/1563 Loss: 1.492 | Acc: 45.948% (4808/10464)\n",
      "Epoch 3 Step 327/1563 Loss: 1.492 | Acc: 45.932% (4821/10496)\n",
      "Epoch 3 Step 328/1563 Loss: 1.491 | Acc: 45.935% (4836/10528)\n",
      "Epoch 3 Step 329/1563 Loss: 1.492 | Acc: 45.928% (4850/10560)\n",
      "Epoch 3 Step 330/1563 Loss: 1.492 | Acc: 45.912% (4863/10592)\n",
      "Epoch 3 Step 331/1563 Loss: 1.492 | Acc: 45.896% (4876/10624)\n",
      "Epoch 3 Step 332/1563 Loss: 1.491 | Acc: 45.937% (4895/10656)\n",
      "Epoch 3 Step 333/1563 Loss: 1.491 | Acc: 45.958% (4912/10688)\n",
      "Epoch 3 Step 334/1563 Loss: 1.492 | Acc: 45.951% (4926/10720)\n",
      "Epoch 3 Step 335/1563 Loss: 1.491 | Acc: 45.954% (4941/10752)\n",
      "Epoch 3 Step 336/1563 Loss: 1.490 | Acc: 46.022% (4963/10784)\n",
      "Epoch 3 Step 337/1563 Loss: 1.490 | Acc: 46.024% (4978/10816)\n",
      "Epoch 3 Step 338/1563 Loss: 1.490 | Acc: 46.045% (4995/10848)\n",
      "Epoch 3 Step 339/1563 Loss: 1.489 | Acc: 46.085% (5014/10880)\n",
      "Epoch 3 Step 340/1563 Loss: 1.488 | Acc: 46.105% (5031/10912)\n",
      "Epoch 3 Step 341/1563 Loss: 1.488 | Acc: 46.089% (5044/10944)\n",
      "Epoch 3 Step 342/1563 Loss: 1.487 | Acc: 46.073% (5057/10976)\n",
      "Epoch 3 Step 343/1563 Loss: 1.488 | Acc: 46.048% (5069/11008)\n",
      "Epoch 3 Step 344/1563 Loss: 1.488 | Acc: 46.033% (5082/11040)\n",
      "Epoch 3 Step 345/1563 Loss: 1.487 | Acc: 46.035% (5097/11072)\n",
      "Epoch 3 Step 346/1563 Loss: 1.487 | Acc: 46.046% (5113/11104)\n",
      "Epoch 3 Step 347/1563 Loss: 1.486 | Acc: 46.121% (5136/11136)\n",
      "Epoch 3 Step 348/1563 Loss: 1.486 | Acc: 46.105% (5149/11168)\n",
      "Epoch 3 Step 349/1563 Loss: 1.486 | Acc: 46.062% (5159/11200)\n",
      "Epoch 3 Step 350/1563 Loss: 1.485 | Acc: 46.127% (5181/11232)\n",
      "Epoch 3 Step 351/1563 Loss: 1.486 | Acc: 46.103% (5193/11264)\n",
      "Epoch 3 Step 352/1563 Loss: 1.486 | Acc: 46.105% (5208/11296)\n",
      "Epoch 3 Step 353/1563 Loss: 1.486 | Acc: 46.116% (5224/11328)\n",
      "Epoch 3 Step 354/1563 Loss: 1.485 | Acc: 46.153% (5243/11360)\n",
      "Epoch 3 Step 355/1563 Loss: 1.485 | Acc: 46.094% (5251/11392)\n",
      "Epoch 3 Step 356/1563 Loss: 1.485 | Acc: 46.122% (5269/11424)\n",
      "Epoch 3 Step 357/1563 Loss: 1.484 | Acc: 46.142% (5286/11456)\n",
      "Epoch 3 Step 358/1563 Loss: 1.484 | Acc: 46.118% (5298/11488)\n",
      "Epoch 3 Step 359/1563 Loss: 1.484 | Acc: 46.102% (5311/11520)\n",
      "Epoch 3 Step 360/1563 Loss: 1.485 | Acc: 46.096% (5325/11552)\n",
      "Epoch 3 Step 361/1563 Loss: 1.484 | Acc: 46.124% (5343/11584)\n",
      "Epoch 3 Step 362/1563 Loss: 1.484 | Acc: 46.152% (5361/11616)\n",
      "Epoch 3 Step 363/1563 Loss: 1.484 | Acc: 46.154% (5376/11648)\n",
      "Epoch 3 Step 364/1563 Loss: 1.483 | Acc: 46.164% (5392/11680)\n",
      "Epoch 3 Step 365/1563 Loss: 1.484 | Acc: 46.166% (5407/11712)\n",
      "Epoch 3 Step 366/1563 Loss: 1.483 | Acc: 46.168% (5422/11744)\n",
      "Epoch 3 Step 367/1563 Loss: 1.484 | Acc: 46.153% (5435/11776)\n",
      "Epoch 3 Step 368/1563 Loss: 1.484 | Acc: 46.113% (5445/11808)\n",
      "Epoch 3 Step 369/1563 Loss: 1.484 | Acc: 46.106% (5459/11840)\n",
      "Epoch 3 Step 370/1563 Loss: 1.483 | Acc: 46.117% (5475/11872)\n",
      "Epoch 3 Step 371/1563 Loss: 1.483 | Acc: 46.127% (5491/11904)\n",
      "Epoch 3 Step 372/1563 Loss: 1.484 | Acc: 46.096% (5502/11936)\n",
      "Epoch 3 Step 373/1563 Loss: 1.484 | Acc: 46.073% (5514/11968)\n",
      "Epoch 3 Step 374/1563 Loss: 1.485 | Acc: 46.050% (5526/12000)\n",
      "Epoch 3 Step 375/1563 Loss: 1.485 | Acc: 46.052% (5541/12032)\n",
      "Epoch 3 Step 376/1563 Loss: 1.484 | Acc: 46.088% (5560/12064)\n",
      "Epoch 3 Step 377/1563 Loss: 1.484 | Acc: 46.114% (5578/12096)\n",
      "Epoch 3 Step 378/1563 Loss: 1.484 | Acc: 46.108% (5592/12128)\n",
      "Epoch 3 Step 379/1563 Loss: 1.485 | Acc: 46.094% (5605/12160)\n",
      "Epoch 3 Step 380/1563 Loss: 1.485 | Acc: 46.112% (5622/12192)\n",
      "Epoch 3 Step 381/1563 Loss: 1.486 | Acc: 46.065% (5631/12224)\n",
      "Epoch 3 Step 382/1563 Loss: 1.486 | Acc: 46.084% (5648/12256)\n",
      "Epoch 3 Step 383/1563 Loss: 1.485 | Acc: 46.110% (5666/12288)\n",
      "Epoch 3 Step 384/1563 Loss: 1.485 | Acc: 46.096% (5679/12320)\n",
      "Epoch 3 Step 385/1563 Loss: 1.486 | Acc: 46.098% (5694/12352)\n",
      "Epoch 3 Step 386/1563 Loss: 1.486 | Acc: 46.140% (5714/12384)\n",
      "Epoch 3 Step 387/1563 Loss: 1.486 | Acc: 46.134% (5728/12416)\n",
      "Epoch 3 Step 388/1563 Loss: 1.486 | Acc: 46.128% (5742/12448)\n",
      "Epoch 3 Step 389/1563 Loss: 1.486 | Acc: 46.154% (5760/12480)\n",
      "Epoch 3 Step 390/1563 Loss: 1.486 | Acc: 46.140% (5773/12512)\n",
      "Epoch 3 Step 391/1563 Loss: 1.486 | Acc: 46.165% (5791/12544)\n",
      "Epoch 3 Step 392/1563 Loss: 1.485 | Acc: 46.231% (5814/12576)\n",
      "Epoch 3 Step 393/1563 Loss: 1.486 | Acc: 46.225% (5828/12608)\n",
      "Epoch 3 Step 394/1563 Loss: 1.486 | Acc: 46.242% (5845/12640)\n",
      "Epoch 3 Step 395/1563 Loss: 1.486 | Acc: 46.236% (5859/12672)\n",
      "Epoch 3 Step 396/1563 Loss: 1.486 | Acc: 46.261% (5877/12704)\n",
      "Epoch 3 Step 397/1563 Loss: 1.486 | Acc: 46.294% (5896/12736)\n",
      "Epoch 3 Step 398/1563 Loss: 1.487 | Acc: 46.264% (5907/12768)\n",
      "Epoch 3 Step 399/1563 Loss: 1.487 | Acc: 46.258% (5921/12800)\n",
      "Epoch 3 Step 400/1563 Loss: 1.488 | Acc: 46.236% (5933/12832)\n",
      "Epoch 3 Step 401/1563 Loss: 1.487 | Acc: 46.276% (5953/12864)\n",
      "Epoch 3 Step 402/1563 Loss: 1.487 | Acc: 46.270% (5967/12896)\n",
      "Epoch 3 Step 403/1563 Loss: 1.488 | Acc: 46.272% (5982/12928)\n",
      "Epoch 3 Step 404/1563 Loss: 1.489 | Acc: 46.227% (5991/12960)\n",
      "Epoch 3 Step 405/1563 Loss: 1.490 | Acc: 46.190% (6001/12992)\n",
      "Epoch 3 Step 406/1563 Loss: 1.489 | Acc: 46.238% (6022/13024)\n",
      "Epoch 3 Step 407/1563 Loss: 1.489 | Acc: 46.232% (6036/13056)\n",
      "Epoch 3 Step 408/1563 Loss: 1.490 | Acc: 46.233% (6051/13088)\n",
      "Epoch 3 Step 409/1563 Loss: 1.490 | Acc: 46.242% (6067/13120)\n",
      "Epoch 3 Step 410/1563 Loss: 1.489 | Acc: 46.221% (6079/13152)\n",
      "Epoch 3 Step 411/1563 Loss: 1.489 | Acc: 46.253% (6098/13184)\n",
      "Epoch 3 Step 412/1563 Loss: 1.490 | Acc: 46.224% (6109/13216)\n",
      "Epoch 3 Step 413/1563 Loss: 1.489 | Acc: 46.248% (6127/13248)\n",
      "Epoch 3 Step 414/1563 Loss: 1.489 | Acc: 46.235% (6140/13280)\n",
      "Epoch 3 Step 415/1563 Loss: 1.490 | Acc: 46.229% (6154/13312)\n",
      "Epoch 3 Step 416/1563 Loss: 1.490 | Acc: 46.223% (6168/13344)\n",
      "Epoch 3 Step 417/1563 Loss: 1.491 | Acc: 46.172% (6176/13376)\n",
      "Epoch 3 Step 418/1563 Loss: 1.491 | Acc: 46.174% (6191/13408)\n",
      "Epoch 3 Step 419/1563 Loss: 1.492 | Acc: 46.131% (6200/13440)\n",
      "Epoch 3 Step 420/1563 Loss: 1.492 | Acc: 46.125% (6214/13472)\n",
      "Epoch 3 Step 421/1563 Loss: 1.492 | Acc: 46.142% (6231/13504)\n",
      "Epoch 3 Step 422/1563 Loss: 1.492 | Acc: 46.136% (6245/13536)\n",
      "Epoch 3 Step 423/1563 Loss: 1.492 | Acc: 46.145% (6261/13568)\n",
      "Epoch 3 Step 424/1563 Loss: 1.492 | Acc: 46.103% (6270/13600)\n",
      "Epoch 3 Step 425/1563 Loss: 1.493 | Acc: 46.127% (6288/13632)\n",
      "Epoch 3 Step 426/1563 Loss: 1.494 | Acc: 46.121% (6302/13664)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 427/1563 Loss: 1.494 | Acc: 46.116% (6316/13696)\n",
      "Epoch 3 Step 428/1563 Loss: 1.494 | Acc: 46.103% (6329/13728)\n",
      "Epoch 3 Step 429/1563 Loss: 1.494 | Acc: 46.097% (6343/13760)\n",
      "Epoch 3 Step 430/1563 Loss: 1.494 | Acc: 46.099% (6358/13792)\n",
      "Epoch 3 Step 431/1563 Loss: 1.494 | Acc: 46.087% (6371/13824)\n",
      "Epoch 3 Step 432/1563 Loss: 1.494 | Acc: 46.088% (6386/13856)\n",
      "Epoch 3 Step 433/1563 Loss: 1.495 | Acc: 46.097% (6402/13888)\n",
      "Epoch 3 Step 434/1563 Loss: 1.495 | Acc: 46.085% (6415/13920)\n",
      "Epoch 3 Step 435/1563 Loss: 1.494 | Acc: 46.094% (6431/13952)\n",
      "Epoch 3 Step 436/1563 Loss: 1.494 | Acc: 46.081% (6444/13984)\n",
      "Epoch 3 Step 437/1563 Loss: 1.494 | Acc: 46.062% (6456/14016)\n",
      "Epoch 3 Step 438/1563 Loss: 1.495 | Acc: 46.063% (6471/14048)\n",
      "Epoch 3 Step 439/1563 Loss: 1.495 | Acc: 46.044% (6483/14080)\n",
      "Epoch 3 Step 440/1563 Loss: 1.495 | Acc: 46.067% (6501/14112)\n",
      "Epoch 3 Step 441/1563 Loss: 1.495 | Acc: 46.055% (6514/14144)\n",
      "Epoch 3 Step 442/1563 Loss: 1.495 | Acc: 46.036% (6526/14176)\n",
      "Epoch 3 Step 443/1563 Loss: 1.495 | Acc: 46.044% (6542/14208)\n",
      "Epoch 3 Step 444/1563 Loss: 1.495 | Acc: 46.011% (6552/14240)\n",
      "Epoch 3 Step 445/1563 Loss: 1.496 | Acc: 46.013% (6567/14272)\n",
      "Epoch 3 Step 446/1563 Loss: 1.496 | Acc: 45.987% (6578/14304)\n",
      "Epoch 3 Step 447/1563 Loss: 1.495 | Acc: 46.024% (6598/14336)\n",
      "Epoch 3 Step 448/1563 Loss: 1.495 | Acc: 46.019% (6612/14368)\n",
      "Epoch 3 Step 449/1563 Loss: 1.495 | Acc: 46.028% (6628/14400)\n",
      "Epoch 3 Step 450/1563 Loss: 1.495 | Acc: 46.030% (6643/14432)\n",
      "Epoch 3 Step 451/1563 Loss: 1.494 | Acc: 46.052% (6661/14464)\n",
      "Epoch 3 Step 452/1563 Loss: 1.495 | Acc: 46.020% (6671/14496)\n",
      "Epoch 3 Step 453/1563 Loss: 1.495 | Acc: 46.021% (6686/14528)\n",
      "Epoch 3 Step 454/1563 Loss: 1.496 | Acc: 45.975% (6694/14560)\n",
      "Epoch 3 Step 455/1563 Loss: 1.495 | Acc: 46.005% (6713/14592)\n",
      "Epoch 3 Step 456/1563 Loss: 1.495 | Acc: 45.986% (6725/14624)\n",
      "Epoch 3 Step 457/1563 Loss: 1.495 | Acc: 46.002% (6742/14656)\n",
      "Epoch 3 Step 458/1563 Loss: 1.495 | Acc: 45.983% (6754/14688)\n",
      "Epoch 3 Step 459/1563 Loss: 1.495 | Acc: 45.992% (6770/14720)\n",
      "Epoch 3 Step 460/1563 Loss: 1.494 | Acc: 46.001% (6786/14752)\n",
      "Epoch 3 Step 461/1563 Loss: 1.494 | Acc: 45.982% (6798/14784)\n",
      "Epoch 3 Step 462/1563 Loss: 1.493 | Acc: 46.011% (6817/14816)\n",
      "Epoch 3 Step 463/1563 Loss: 1.493 | Acc: 46.006% (6831/14848)\n",
      "Epoch 3 Step 464/1563 Loss: 1.494 | Acc: 46.008% (6846/14880)\n",
      "Epoch 3 Step 465/1563 Loss: 1.494 | Acc: 45.983% (6857/14912)\n",
      "Epoch 3 Step 466/1563 Loss: 1.493 | Acc: 46.005% (6875/14944)\n",
      "Epoch 3 Step 467/1563 Loss: 1.493 | Acc: 46.000% (6889/14976)\n",
      "Epoch 3 Step 468/1563 Loss: 1.493 | Acc: 46.015% (6906/15008)\n",
      "Epoch 3 Step 469/1563 Loss: 1.493 | Acc: 46.024% (6922/15040)\n",
      "Epoch 3 Step 470/1563 Loss: 1.493 | Acc: 46.019% (6936/15072)\n",
      "Epoch 3 Step 471/1563 Loss: 1.494 | Acc: 46.021% (6951/15104)\n",
      "Epoch 3 Step 472/1563 Loss: 1.494 | Acc: 46.023% (6966/15136)\n",
      "Epoch 3 Step 473/1563 Loss: 1.494 | Acc: 46.011% (6979/15168)\n",
      "Epoch 3 Step 474/1563 Loss: 1.494 | Acc: 45.993% (6991/15200)\n",
      "Epoch 3 Step 475/1563 Loss: 1.494 | Acc: 45.989% (7005/15232)\n",
      "Epoch 3 Step 476/1563 Loss: 1.494 | Acc: 45.977% (7018/15264)\n",
      "Epoch 3 Step 477/1563 Loss: 1.494 | Acc: 45.979% (7033/15296)\n",
      "Epoch 3 Step 478/1563 Loss: 1.494 | Acc: 45.994% (7050/15328)\n",
      "Epoch 3 Step 479/1563 Loss: 1.494 | Acc: 45.996% (7065/15360)\n",
      "Epoch 3 Step 480/1563 Loss: 1.494 | Acc: 46.004% (7081/15392)\n",
      "Epoch 3 Step 481/1563 Loss: 1.494 | Acc: 46.013% (7097/15424)\n",
      "Epoch 3 Step 482/1563 Loss: 1.494 | Acc: 45.982% (7107/15456)\n",
      "Epoch 3 Step 483/1563 Loss: 1.494 | Acc: 45.965% (7119/15488)\n",
      "Epoch 3 Step 484/1563 Loss: 1.494 | Acc: 45.979% (7136/15520)\n",
      "Epoch 3 Step 485/1563 Loss: 1.494 | Acc: 45.981% (7151/15552)\n",
      "Epoch 3 Step 486/1563 Loss: 1.493 | Acc: 46.028% (7173/15584)\n",
      "Epoch 3 Step 487/1563 Loss: 1.493 | Acc: 46.036% (7189/15616)\n",
      "Epoch 3 Step 488/1563 Loss: 1.492 | Acc: 46.031% (7203/15648)\n",
      "Epoch 3 Step 489/1563 Loss: 1.492 | Acc: 46.052% (7221/15680)\n",
      "Epoch 3 Step 490/1563 Loss: 1.492 | Acc: 46.073% (7239/15712)\n",
      "Epoch 3 Step 491/1563 Loss: 1.491 | Acc: 46.094% (7257/15744)\n",
      "Epoch 3 Step 492/1563 Loss: 1.492 | Acc: 46.083% (7270/15776)\n",
      "Epoch 3 Step 493/1563 Loss: 1.491 | Acc: 46.116% (7290/15808)\n",
      "Epoch 3 Step 494/1563 Loss: 1.491 | Acc: 46.117% (7305/15840)\n",
      "Epoch 3 Step 495/1563 Loss: 1.491 | Acc: 46.100% (7317/15872)\n",
      "Epoch 3 Step 496/1563 Loss: 1.491 | Acc: 46.133% (7337/15904)\n",
      "Epoch 3 Step 497/1563 Loss: 1.490 | Acc: 46.141% (7353/15936)\n",
      "Epoch 3 Step 498/1563 Loss: 1.490 | Acc: 46.167% (7372/15968)\n",
      "Epoch 3 Step 499/1563 Loss: 1.489 | Acc: 46.188% (7390/16000)\n",
      "Epoch 3 Step 500/1563 Loss: 1.490 | Acc: 46.183% (7404/16032)\n",
      "Epoch 3 Step 501/1563 Loss: 1.490 | Acc: 46.178% (7418/16064)\n",
      "Epoch 3 Step 502/1563 Loss: 1.490 | Acc: 46.210% (7438/16096)\n",
      "Epoch 3 Step 503/1563 Loss: 1.490 | Acc: 46.212% (7453/16128)\n",
      "Epoch 3 Step 504/1563 Loss: 1.490 | Acc: 46.213% (7468/16160)\n",
      "Epoch 3 Step 505/1563 Loss: 1.490 | Acc: 46.208% (7482/16192)\n",
      "Epoch 3 Step 506/1563 Loss: 1.489 | Acc: 46.222% (7499/16224)\n",
      "Epoch 3 Step 507/1563 Loss: 1.490 | Acc: 46.204% (7511/16256)\n",
      "Epoch 3 Step 508/1563 Loss: 1.490 | Acc: 46.187% (7523/16288)\n",
      "Epoch 3 Step 509/1563 Loss: 1.489 | Acc: 46.170% (7535/16320)\n",
      "Epoch 3 Step 510/1563 Loss: 1.490 | Acc: 46.172% (7550/16352)\n",
      "Epoch 3 Step 511/1563 Loss: 1.490 | Acc: 46.173% (7565/16384)\n",
      "Epoch 3 Step 512/1563 Loss: 1.490 | Acc: 46.168% (7579/16416)\n",
      "Epoch 3 Step 513/1563 Loss: 1.490 | Acc: 46.164% (7593/16448)\n",
      "Epoch 3 Step 514/1563 Loss: 1.490 | Acc: 46.183% (7611/16480)\n",
      "Epoch 3 Step 515/1563 Loss: 1.489 | Acc: 46.191% (7627/16512)\n",
      "Epoch 3 Step 516/1563 Loss: 1.489 | Acc: 46.174% (7639/16544)\n",
      "Epoch 3 Step 517/1563 Loss: 1.489 | Acc: 46.175% (7654/16576)\n",
      "Epoch 3 Step 518/1563 Loss: 1.489 | Acc: 46.183% (7670/16608)\n",
      "Epoch 3 Step 519/1563 Loss: 1.490 | Acc: 46.160% (7681/16640)\n",
      "Epoch 3 Step 520/1563 Loss: 1.490 | Acc: 46.167% (7697/16672)\n",
      "Epoch 3 Step 521/1563 Loss: 1.489 | Acc: 46.181% (7714/16704)\n",
      "Epoch 3 Step 522/1563 Loss: 1.489 | Acc: 46.182% (7729/16736)\n",
      "Epoch 3 Step 523/1563 Loss: 1.489 | Acc: 46.195% (7746/16768)\n",
      "Epoch 3 Step 524/1563 Loss: 1.488 | Acc: 46.232% (7767/16800)\n",
      "Epoch 3 Step 525/1563 Loss: 1.488 | Acc: 46.221% (7780/16832)\n",
      "Epoch 3 Step 526/1563 Loss: 1.488 | Acc: 46.217% (7794/16864)\n",
      "Epoch 3 Step 527/1563 Loss: 1.488 | Acc: 46.224% (7810/16896)\n",
      "Epoch 3 Step 528/1563 Loss: 1.488 | Acc: 46.249% (7829/16928)\n",
      "Epoch 3 Step 529/1563 Loss: 1.488 | Acc: 46.256% (7845/16960)\n",
      "Epoch 3 Step 530/1563 Loss: 1.488 | Acc: 46.245% (7858/16992)\n",
      "Epoch 3 Step 531/1563 Loss: 1.489 | Acc: 46.241% (7872/17024)\n",
      "Epoch 3 Step 532/1563 Loss: 1.489 | Acc: 46.242% (7887/17056)\n",
      "Epoch 3 Step 533/1563 Loss: 1.489 | Acc: 46.237% (7901/17088)\n",
      "Epoch 3 Step 534/1563 Loss: 1.489 | Acc: 46.215% (7912/17120)\n",
      "Epoch 3 Step 535/1563 Loss: 1.489 | Acc: 46.205% (7925/17152)\n",
      "Epoch 3 Step 536/1563 Loss: 1.490 | Acc: 46.177% (7935/17184)\n",
      "Epoch 3 Step 537/1563 Loss: 1.489 | Acc: 46.184% (7951/17216)\n",
      "Epoch 3 Step 538/1563 Loss: 1.489 | Acc: 46.197% (7968/17248)\n",
      "Epoch 3 Step 539/1563 Loss: 1.489 | Acc: 46.198% (7983/17280)\n",
      "Epoch 3 Step 540/1563 Loss: 1.489 | Acc: 46.216% (8001/17312)\n",
      "Epoch 3 Step 541/1563 Loss: 1.489 | Acc: 46.206% (8014/17344)\n",
      "Epoch 3 Step 542/1563 Loss: 1.489 | Acc: 46.196% (8027/17376)\n",
      "Epoch 3 Step 543/1563 Loss: 1.489 | Acc: 46.197% (8042/17408)\n",
      "Epoch 3 Step 544/1563 Loss: 1.489 | Acc: 46.181% (8054/17440)\n",
      "Epoch 3 Step 545/1563 Loss: 1.489 | Acc: 46.148% (8063/17472)\n",
      "Epoch 3 Step 546/1563 Loss: 1.489 | Acc: 46.144% (8077/17504)\n",
      "Epoch 3 Step 547/1563 Loss: 1.489 | Acc: 46.139% (8091/17536)\n",
      "Epoch 3 Step 548/1563 Loss: 1.489 | Acc: 46.146% (8107/17568)\n",
      "Epoch 3 Step 549/1563 Loss: 1.490 | Acc: 46.131% (8119/17600)\n",
      "Epoch 3 Step 550/1563 Loss: 1.490 | Acc: 46.098% (8128/17632)\n",
      "Epoch 3 Step 551/1563 Loss: 1.490 | Acc: 46.139% (8150/17664)\n",
      "Epoch 3 Step 552/1563 Loss: 1.490 | Acc: 46.146% (8166/17696)\n",
      "Epoch 3 Step 553/1563 Loss: 1.491 | Acc: 46.142% (8180/17728)\n",
      "Epoch 3 Step 554/1563 Loss: 1.490 | Acc: 46.143% (8195/17760)\n",
      "Epoch 3 Step 555/1563 Loss: 1.490 | Acc: 46.116% (8205/17792)\n",
      "Epoch 3 Step 556/1563 Loss: 1.490 | Acc: 46.084% (8214/17824)\n",
      "Epoch 3 Step 557/1563 Loss: 1.491 | Acc: 46.085% (8229/17856)\n",
      "Epoch 3 Step 558/1563 Loss: 1.491 | Acc: 46.104% (8247/17888)\n",
      "Epoch 3 Step 559/1563 Loss: 1.491 | Acc: 46.110% (8263/17920)\n",
      "Epoch 3 Step 560/1563 Loss: 1.490 | Acc: 46.129% (8281/17952)\n",
      "Epoch 3 Step 561/1563 Loss: 1.490 | Acc: 46.130% (8296/17984)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 562/1563 Loss: 1.489 | Acc: 46.120% (8309/18016)\n",
      "Epoch 3 Step 563/1563 Loss: 1.489 | Acc: 46.149% (8329/18048)\n",
      "Epoch 3 Step 564/1563 Loss: 1.489 | Acc: 46.134% (8341/18080)\n",
      "Epoch 3 Step 565/1563 Loss: 1.489 | Acc: 46.168% (8362/18112)\n",
      "Epoch 3 Step 566/1563 Loss: 1.489 | Acc: 46.197% (8382/18144)\n",
      "Epoch 3 Step 567/1563 Loss: 1.489 | Acc: 46.198% (8397/18176)\n",
      "Epoch 3 Step 568/1563 Loss: 1.489 | Acc: 46.188% (8410/18208)\n",
      "Epoch 3 Step 569/1563 Loss: 1.488 | Acc: 46.206% (8428/18240)\n",
      "Epoch 3 Step 570/1563 Loss: 1.488 | Acc: 46.202% (8442/18272)\n",
      "Epoch 3 Step 571/1563 Loss: 1.488 | Acc: 46.208% (8458/18304)\n",
      "Epoch 3 Step 572/1563 Loss: 1.487 | Acc: 46.221% (8475/18336)\n",
      "Epoch 3 Step 573/1563 Loss: 1.488 | Acc: 46.227% (8491/18368)\n",
      "Epoch 3 Step 574/1563 Loss: 1.488 | Acc: 46.223% (8505/18400)\n",
      "Epoch 3 Step 575/1563 Loss: 1.488 | Acc: 46.208% (8517/18432)\n",
      "Epoch 3 Step 576/1563 Loss: 1.488 | Acc: 46.187% (8528/18464)\n",
      "Epoch 3 Step 577/1563 Loss: 1.488 | Acc: 46.172% (8540/18496)\n",
      "Epoch 3 Step 578/1563 Loss: 1.488 | Acc: 46.168% (8554/18528)\n",
      "Epoch 3 Step 579/1563 Loss: 1.489 | Acc: 46.126% (8561/18560)\n",
      "Epoch 3 Step 580/1563 Loss: 1.488 | Acc: 46.138% (8578/18592)\n",
      "Epoch 3 Step 581/1563 Loss: 1.489 | Acc: 46.118% (8589/18624)\n",
      "Epoch 3 Step 582/1563 Loss: 1.489 | Acc: 46.130% (8606/18656)\n",
      "Epoch 3 Step 583/1563 Loss: 1.489 | Acc: 46.121% (8619/18688)\n",
      "Epoch 3 Step 584/1563 Loss: 1.489 | Acc: 46.111% (8632/18720)\n",
      "Epoch 3 Step 585/1563 Loss: 1.490 | Acc: 46.102% (8645/18752)\n",
      "Epoch 3 Step 586/1563 Loss: 1.489 | Acc: 46.108% (8661/18784)\n",
      "Epoch 3 Step 587/1563 Loss: 1.489 | Acc: 46.110% (8676/18816)\n",
      "Epoch 3 Step 588/1563 Loss: 1.489 | Acc: 46.132% (8695/18848)\n",
      "Epoch 3 Step 589/1563 Loss: 1.489 | Acc: 46.139% (8711/18880)\n",
      "Epoch 3 Step 590/1563 Loss: 1.489 | Acc: 46.135% (8725/18912)\n",
      "Epoch 3 Step 591/1563 Loss: 1.489 | Acc: 46.141% (8741/18944)\n",
      "Epoch 3 Step 592/1563 Loss: 1.489 | Acc: 46.137% (8755/18976)\n",
      "Epoch 3 Step 593/1563 Loss: 1.488 | Acc: 46.149% (8772/19008)\n",
      "Epoch 3 Step 594/1563 Loss: 1.488 | Acc: 46.176% (8792/19040)\n",
      "Epoch 3 Step 595/1563 Loss: 1.487 | Acc: 46.188% (8809/19072)\n",
      "Epoch 3 Step 596/1563 Loss: 1.487 | Acc: 46.189% (8824/19104)\n",
      "Epoch 3 Step 597/1563 Loss: 1.487 | Acc: 46.185% (8838/19136)\n",
      "Epoch 3 Step 598/1563 Loss: 1.487 | Acc: 46.207% (8857/19168)\n",
      "Epoch 3 Step 599/1563 Loss: 1.486 | Acc: 46.234% (8877/19200)\n",
      "Epoch 3 Step 600/1563 Loss: 1.486 | Acc: 46.230% (8891/19232)\n",
      "Epoch 3 Step 601/1563 Loss: 1.486 | Acc: 46.247% (8909/19264)\n",
      "Epoch 3 Step 602/1563 Loss: 1.486 | Acc: 46.248% (8924/19296)\n",
      "Epoch 3 Step 603/1563 Loss: 1.486 | Acc: 46.249% (8939/19328)\n",
      "Epoch 3 Step 604/1563 Loss: 1.486 | Acc: 46.214% (8947/19360)\n",
      "Epoch 3 Step 605/1563 Loss: 1.486 | Acc: 46.210% (8961/19392)\n",
      "Epoch 3 Step 606/1563 Loss: 1.487 | Acc: 46.190% (8972/19424)\n",
      "Epoch 3 Step 607/1563 Loss: 1.487 | Acc: 46.176% (8984/19456)\n",
      "Epoch 3 Step 608/1563 Loss: 1.487 | Acc: 46.182% (9000/19488)\n",
      "Epoch 3 Step 609/1563 Loss: 1.487 | Acc: 46.173% (9013/19520)\n",
      "Epoch 3 Step 610/1563 Loss: 1.487 | Acc: 46.169% (9027/19552)\n",
      "Epoch 3 Step 611/1563 Loss: 1.487 | Acc: 46.160% (9040/19584)\n",
      "Epoch 3 Step 612/1563 Loss: 1.487 | Acc: 46.161% (9055/19616)\n",
      "Epoch 3 Step 613/1563 Loss: 1.487 | Acc: 46.157% (9069/19648)\n",
      "Epoch 3 Step 614/1563 Loss: 1.488 | Acc: 46.138% (9080/19680)\n",
      "Epoch 3 Step 615/1563 Loss: 1.488 | Acc: 46.139% (9095/19712)\n",
      "Epoch 3 Step 616/1563 Loss: 1.488 | Acc: 46.156% (9113/19744)\n",
      "Epoch 3 Step 617/1563 Loss: 1.488 | Acc: 46.167% (9130/19776)\n",
      "Epoch 3 Step 618/1563 Loss: 1.488 | Acc: 46.178% (9147/19808)\n",
      "Epoch 3 Step 619/1563 Loss: 1.488 | Acc: 46.169% (9160/19840)\n",
      "Epoch 3 Step 620/1563 Loss: 1.488 | Acc: 46.186% (9178/19872)\n",
      "Epoch 3 Step 621/1563 Loss: 1.488 | Acc: 46.177% (9191/19904)\n",
      "Epoch 3 Step 622/1563 Loss: 1.488 | Acc: 46.143% (9199/19936)\n",
      "Epoch 3 Step 623/1563 Loss: 1.488 | Acc: 46.139% (9213/19968)\n",
      "Epoch 3 Step 624/1563 Loss: 1.489 | Acc: 46.105% (9221/20000)\n",
      "Epoch 3 Step 625/1563 Loss: 1.489 | Acc: 46.091% (9233/20032)\n",
      "Epoch 3 Step 626/1563 Loss: 1.489 | Acc: 46.097% (9249/20064)\n",
      "Epoch 3 Step 627/1563 Loss: 1.488 | Acc: 46.094% (9263/20096)\n",
      "Epoch 3 Step 628/1563 Loss: 1.489 | Acc: 46.075% (9274/20128)\n",
      "Epoch 3 Step 629/1563 Loss: 1.489 | Acc: 46.071% (9288/20160)\n",
      "Epoch 3 Step 630/1563 Loss: 1.489 | Acc: 46.053% (9299/20192)\n",
      "Epoch 3 Step 631/1563 Loss: 1.489 | Acc: 46.054% (9314/20224)\n",
      "Epoch 3 Step 632/1563 Loss: 1.489 | Acc: 46.036% (9325/20256)\n",
      "Epoch 3 Step 633/1563 Loss: 1.489 | Acc: 46.037% (9340/20288)\n",
      "Epoch 3 Step 634/1563 Loss: 1.489 | Acc: 46.043% (9356/20320)\n",
      "Epoch 3 Step 635/1563 Loss: 1.489 | Acc: 46.025% (9367/20352)\n",
      "Epoch 3 Step 636/1563 Loss: 1.489 | Acc: 46.041% (9385/20384)\n",
      "Epoch 3 Step 637/1563 Loss: 1.489 | Acc: 46.037% (9399/20416)\n",
      "Epoch 3 Step 638/1563 Loss: 1.488 | Acc: 46.053% (9417/20448)\n",
      "Epoch 3 Step 639/1563 Loss: 1.488 | Acc: 46.064% (9434/20480)\n",
      "Epoch 3 Step 640/1563 Loss: 1.488 | Acc: 46.061% (9448/20512)\n",
      "Epoch 3 Step 641/1563 Loss: 1.488 | Acc: 46.062% (9463/20544)\n",
      "Epoch 3 Step 642/1563 Loss: 1.488 | Acc: 46.078% (9481/20576)\n",
      "Epoch 3 Step 643/1563 Loss: 1.488 | Acc: 46.074% (9495/20608)\n",
      "Epoch 3 Step 644/1563 Loss: 1.488 | Acc: 46.085% (9512/20640)\n",
      "Epoch 3 Step 645/1563 Loss: 1.488 | Acc: 46.077% (9525/20672)\n",
      "Epoch 3 Step 646/1563 Loss: 1.488 | Acc: 46.064% (9537/20704)\n",
      "Epoch 3 Step 647/1563 Loss: 1.488 | Acc: 46.089% (9557/20736)\n",
      "Epoch 3 Step 648/1563 Loss: 1.488 | Acc: 46.071% (9568/20768)\n",
      "Epoch 3 Step 649/1563 Loss: 1.488 | Acc: 46.072% (9583/20800)\n",
      "Epoch 3 Step 650/1563 Loss: 1.487 | Acc: 46.088% (9601/20832)\n",
      "Epoch 3 Step 651/1563 Loss: 1.488 | Acc: 46.079% (9614/20864)\n",
      "Epoch 3 Step 652/1563 Loss: 1.488 | Acc: 46.085% (9630/20896)\n",
      "Epoch 3 Step 653/1563 Loss: 1.488 | Acc: 46.106% (9649/20928)\n",
      "Epoch 3 Step 654/1563 Loss: 1.487 | Acc: 46.126% (9668/20960)\n",
      "Epoch 3 Step 655/1563 Loss: 1.487 | Acc: 46.146% (9687/20992)\n",
      "Epoch 3 Step 656/1563 Loss: 1.487 | Acc: 46.162% (9705/21024)\n",
      "Epoch 3 Step 657/1563 Loss: 1.487 | Acc: 46.182% (9724/21056)\n",
      "Epoch 3 Step 658/1563 Loss: 1.486 | Acc: 46.206% (9744/21088)\n",
      "Epoch 3 Step 659/1563 Loss: 1.486 | Acc: 46.203% (9758/21120)\n",
      "Epoch 3 Step 660/1563 Loss: 1.486 | Acc: 46.194% (9771/21152)\n",
      "Epoch 3 Step 661/1563 Loss: 1.486 | Acc: 46.191% (9785/21184)\n",
      "Epoch 3 Step 662/1563 Loss: 1.486 | Acc: 46.192% (9800/21216)\n",
      "Epoch 3 Step 663/1563 Loss: 1.486 | Acc: 46.197% (9816/21248)\n",
      "Epoch 3 Step 664/1563 Loss: 1.486 | Acc: 46.203% (9832/21280)\n",
      "Epoch 3 Step 665/1563 Loss: 1.486 | Acc: 46.185% (9843/21312)\n",
      "Epoch 3 Step 666/1563 Loss: 1.487 | Acc: 46.177% (9856/21344)\n",
      "Epoch 3 Step 667/1563 Loss: 1.487 | Acc: 46.183% (9872/21376)\n",
      "Epoch 3 Step 668/1563 Loss: 1.486 | Acc: 46.184% (9887/21408)\n",
      "Epoch 3 Step 669/1563 Loss: 1.486 | Acc: 46.194% (9904/21440)\n",
      "Epoch 3 Step 670/1563 Loss: 1.487 | Acc: 46.162% (9912/21472)\n",
      "Epoch 3 Step 671/1563 Loss: 1.487 | Acc: 46.159% (9926/21504)\n",
      "Epoch 3 Step 672/1563 Loss: 1.487 | Acc: 46.141% (9937/21536)\n",
      "Epoch 3 Step 673/1563 Loss: 1.487 | Acc: 46.166% (9957/21568)\n",
      "Epoch 3 Step 674/1563 Loss: 1.487 | Acc: 46.171% (9973/21600)\n",
      "Epoch 3 Step 675/1563 Loss: 1.487 | Acc: 46.140% (9981/21632)\n",
      "Epoch 3 Step 676/1563 Loss: 1.487 | Acc: 46.136% (9995/21664)\n",
      "Epoch 3 Step 677/1563 Loss: 1.487 | Acc: 46.142% (10011/21696)\n",
      "Epoch 3 Step 678/1563 Loss: 1.487 | Acc: 46.148% (10027/21728)\n",
      "Epoch 3 Step 679/1563 Loss: 1.487 | Acc: 46.135% (10039/21760)\n",
      "Epoch 3 Step 680/1563 Loss: 1.487 | Acc: 46.132% (10053/21792)\n",
      "Epoch 3 Step 681/1563 Loss: 1.487 | Acc: 46.133% (10068/21824)\n",
      "Epoch 3 Step 682/1563 Loss: 1.488 | Acc: 46.125% (10081/21856)\n",
      "Epoch 3 Step 683/1563 Loss: 1.487 | Acc: 46.126% (10096/21888)\n",
      "Epoch 3 Step 684/1563 Loss: 1.487 | Acc: 46.136% (10113/21920)\n",
      "Epoch 3 Step 685/1563 Loss: 1.487 | Acc: 46.146% (10130/21952)\n",
      "Epoch 3 Step 686/1563 Loss: 1.487 | Acc: 46.134% (10142/21984)\n",
      "Epoch 3 Step 687/1563 Loss: 1.487 | Acc: 46.130% (10156/22016)\n",
      "Epoch 3 Step 688/1563 Loss: 1.487 | Acc: 46.131% (10171/22048)\n",
      "Epoch 3 Step 689/1563 Loss: 1.487 | Acc: 46.128% (10185/22080)\n",
      "Epoch 3 Step 690/1563 Loss: 1.487 | Acc: 46.124% (10199/22112)\n",
      "Epoch 3 Step 691/1563 Loss: 1.487 | Acc: 46.125% (10214/22144)\n",
      "Epoch 3 Step 692/1563 Loss: 1.487 | Acc: 46.126% (10229/22176)\n",
      "Epoch 3 Step 693/1563 Loss: 1.487 | Acc: 46.146% (10248/22208)\n",
      "Epoch 3 Step 694/1563 Loss: 1.487 | Acc: 46.151% (10264/22240)\n",
      "Epoch 3 Step 695/1563 Loss: 1.486 | Acc: 46.157% (10280/22272)\n",
      "Epoch 3 Step 696/1563 Loss: 1.487 | Acc: 46.144% (10292/22304)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 697/1563 Loss: 1.487 | Acc: 46.145% (10307/22336)\n",
      "Epoch 3 Step 698/1563 Loss: 1.487 | Acc: 46.137% (10320/22368)\n",
      "Epoch 3 Step 699/1563 Loss: 1.487 | Acc: 46.143% (10336/22400)\n",
      "Epoch 3 Step 700/1563 Loss: 1.487 | Acc: 46.162% (10355/22432)\n",
      "Epoch 3 Step 701/1563 Loss: 1.487 | Acc: 46.167% (10371/22464)\n",
      "Epoch 3 Step 702/1563 Loss: 1.487 | Acc: 46.168% (10386/22496)\n",
      "Epoch 3 Step 703/1563 Loss: 1.487 | Acc: 46.165% (10400/22528)\n",
      "Epoch 3 Step 704/1563 Loss: 1.487 | Acc: 46.179% (10418/22560)\n",
      "Epoch 3 Step 705/1563 Loss: 1.487 | Acc: 46.180% (10433/22592)\n",
      "Epoch 3 Step 706/1563 Loss: 1.487 | Acc: 46.163% (10444/22624)\n",
      "Epoch 3 Step 707/1563 Loss: 1.487 | Acc: 46.164% (10459/22656)\n",
      "Epoch 3 Step 708/1563 Loss: 1.487 | Acc: 46.165% (10474/22688)\n",
      "Epoch 3 Step 709/1563 Loss: 1.487 | Acc: 46.166% (10489/22720)\n",
      "Epoch 3 Step 710/1563 Loss: 1.488 | Acc: 46.167% (10504/22752)\n",
      "Epoch 3 Step 711/1563 Loss: 1.487 | Acc: 46.177% (10521/22784)\n",
      "Epoch 3 Step 712/1563 Loss: 1.488 | Acc: 46.161% (10532/22816)\n",
      "Epoch 3 Step 713/1563 Loss: 1.488 | Acc: 46.162% (10547/22848)\n",
      "Epoch 3 Step 714/1563 Loss: 1.488 | Acc: 46.158% (10561/22880)\n",
      "Epoch 3 Step 715/1563 Loss: 1.488 | Acc: 46.181% (10581/22912)\n",
      "Epoch 3 Step 716/1563 Loss: 1.487 | Acc: 46.191% (10598/22944)\n",
      "Epoch 3 Step 717/1563 Loss: 1.487 | Acc: 46.196% (10614/22976)\n",
      "Epoch 3 Step 718/1563 Loss: 1.488 | Acc: 46.175% (10624/23008)\n",
      "Epoch 3 Step 719/1563 Loss: 1.488 | Acc: 46.168% (10637/23040)\n",
      "Epoch 3 Step 720/1563 Loss: 1.488 | Acc: 46.173% (10653/23072)\n",
      "Epoch 3 Step 721/1563 Loss: 1.488 | Acc: 46.169% (10667/23104)\n",
      "Epoch 3 Step 722/1563 Loss: 1.488 | Acc: 46.153% (10678/23136)\n",
      "Epoch 3 Step 723/1563 Loss: 1.489 | Acc: 46.133% (10688/23168)\n",
      "Epoch 3 Step 724/1563 Loss: 1.489 | Acc: 46.129% (10702/23200)\n",
      "Epoch 3 Step 725/1563 Loss: 1.489 | Acc: 46.113% (10713/23232)\n",
      "Epoch 3 Step 726/1563 Loss: 1.489 | Acc: 46.123% (10730/23264)\n",
      "Epoch 3 Step 727/1563 Loss: 1.489 | Acc: 46.128% (10746/23296)\n",
      "Epoch 3 Step 728/1563 Loss: 1.489 | Acc: 46.142% (10764/23328)\n",
      "Epoch 3 Step 729/1563 Loss: 1.488 | Acc: 46.134% (10777/23360)\n",
      "Epoch 3 Step 730/1563 Loss: 1.489 | Acc: 46.127% (10790/23392)\n",
      "Epoch 3 Step 731/1563 Loss: 1.489 | Acc: 46.115% (10802/23424)\n",
      "Epoch 3 Step 732/1563 Loss: 1.489 | Acc: 46.125% (10819/23456)\n",
      "Epoch 3 Step 733/1563 Loss: 1.489 | Acc: 46.130% (10835/23488)\n",
      "Epoch 3 Step 734/1563 Loss: 1.489 | Acc: 46.122% (10848/23520)\n",
      "Epoch 3 Step 735/1563 Loss: 1.489 | Acc: 46.128% (10864/23552)\n",
      "Epoch 3 Step 736/1563 Loss: 1.489 | Acc: 46.129% (10879/23584)\n",
      "Epoch 3 Step 737/1563 Loss: 1.489 | Acc: 46.113% (10890/23616)\n",
      "Epoch 3 Step 738/1563 Loss: 1.489 | Acc: 46.127% (10908/23648)\n",
      "Epoch 3 Step 739/1563 Loss: 1.489 | Acc: 46.123% (10922/23680)\n",
      "Epoch 3 Step 740/1563 Loss: 1.488 | Acc: 46.141% (10941/23712)\n",
      "Epoch 3 Step 741/1563 Loss: 1.488 | Acc: 46.138% (10955/23744)\n",
      "Epoch 3 Step 742/1563 Loss: 1.488 | Acc: 46.131% (10968/23776)\n",
      "Epoch 3 Step 743/1563 Loss: 1.489 | Acc: 46.123% (10981/23808)\n",
      "Epoch 3 Step 744/1563 Loss: 1.489 | Acc: 46.112% (10993/23840)\n",
      "Epoch 3 Step 745/1563 Loss: 1.489 | Acc: 46.113% (11008/23872)\n",
      "Epoch 3 Step 746/1563 Loss: 1.488 | Acc: 46.130% (11027/23904)\n",
      "Epoch 3 Step 747/1563 Loss: 1.489 | Acc: 46.131% (11042/23936)\n",
      "Epoch 3 Step 748/1563 Loss: 1.489 | Acc: 46.120% (11054/23968)\n",
      "Epoch 3 Step 749/1563 Loss: 1.488 | Acc: 46.146% (11075/24000)\n",
      "Epoch 3 Step 750/1563 Loss: 1.488 | Acc: 46.147% (11090/24032)\n",
      "Epoch 3 Step 751/1563 Loss: 1.488 | Acc: 46.148% (11105/24064)\n",
      "Epoch 3 Step 752/1563 Loss: 1.488 | Acc: 46.140% (11118/24096)\n",
      "Epoch 3 Step 753/1563 Loss: 1.488 | Acc: 46.133% (11131/24128)\n",
      "Epoch 3 Step 754/1563 Loss: 1.489 | Acc: 46.126% (11144/24160)\n",
      "Epoch 3 Step 755/1563 Loss: 1.488 | Acc: 46.123% (11158/24192)\n",
      "Epoch 3 Step 756/1563 Loss: 1.489 | Acc: 46.120% (11172/24224)\n",
      "Epoch 3 Step 757/1563 Loss: 1.489 | Acc: 46.108% (11184/24256)\n",
      "Epoch 3 Step 758/1563 Loss: 1.489 | Acc: 46.126% (11203/24288)\n",
      "Epoch 3 Step 759/1563 Loss: 1.489 | Acc: 46.127% (11218/24320)\n",
      "Epoch 3 Step 760/1563 Loss: 1.488 | Acc: 46.140% (11236/24352)\n",
      "Epoch 3 Step 761/1563 Loss: 1.488 | Acc: 46.153% (11254/24384)\n",
      "Epoch 3 Step 762/1563 Loss: 1.488 | Acc: 46.146% (11267/24416)\n",
      "Epoch 3 Step 763/1563 Loss: 1.488 | Acc: 46.151% (11283/24448)\n",
      "Epoch 3 Step 764/1563 Loss: 1.488 | Acc: 46.152% (11298/24480)\n",
      "Epoch 3 Step 765/1563 Loss: 1.488 | Acc: 46.149% (11312/24512)\n",
      "Epoch 3 Step 766/1563 Loss: 1.487 | Acc: 46.154% (11328/24544)\n",
      "Epoch 3 Step 767/1563 Loss: 1.487 | Acc: 46.159% (11344/24576)\n",
      "Epoch 3 Step 768/1563 Loss: 1.487 | Acc: 46.160% (11359/24608)\n",
      "Epoch 3 Step 769/1563 Loss: 1.487 | Acc: 46.140% (11369/24640)\n",
      "Epoch 3 Step 770/1563 Loss: 1.487 | Acc: 46.137% (11383/24672)\n",
      "Epoch 3 Step 771/1563 Loss: 1.487 | Acc: 46.130% (11396/24704)\n",
      "Epoch 3 Step 772/1563 Loss: 1.488 | Acc: 46.107% (11405/24736)\n",
      "Epoch 3 Step 773/1563 Loss: 1.488 | Acc: 46.108% (11420/24768)\n",
      "Epoch 3 Step 774/1563 Loss: 1.488 | Acc: 46.105% (11434/24800)\n",
      "Epoch 3 Step 775/1563 Loss: 1.488 | Acc: 46.102% (11448/24832)\n",
      "Epoch 3 Step 776/1563 Loss: 1.489 | Acc: 46.099% (11462/24864)\n",
      "Epoch 3 Step 777/1563 Loss: 1.489 | Acc: 46.108% (11479/24896)\n",
      "Epoch 3 Step 778/1563 Loss: 1.489 | Acc: 46.097% (11491/24928)\n",
      "Epoch 3 Step 779/1563 Loss: 1.489 | Acc: 46.086% (11503/24960)\n",
      "Epoch 3 Step 780/1563 Loss: 1.489 | Acc: 46.091% (11519/24992)\n",
      "Epoch 3 Step 781/1563 Loss: 1.489 | Acc: 46.088% (11533/25024)\n",
      "Epoch 3 Step 782/1563 Loss: 1.489 | Acc: 46.113% (11554/25056)\n",
      "Epoch 3 Step 783/1563 Loss: 1.489 | Acc: 46.110% (11568/25088)\n",
      "Epoch 3 Step 784/1563 Loss: 1.489 | Acc: 46.091% (11578/25120)\n",
      "Epoch 3 Step 785/1563 Loss: 1.489 | Acc: 46.084% (11591/25152)\n",
      "Epoch 3 Step 786/1563 Loss: 1.489 | Acc: 46.093% (11608/25184)\n",
      "Epoch 3 Step 787/1563 Loss: 1.489 | Acc: 46.094% (11623/25216)\n",
      "Epoch 3 Step 788/1563 Loss: 1.489 | Acc: 46.107% (11641/25248)\n",
      "Epoch 3 Step 789/1563 Loss: 1.489 | Acc: 46.108% (11656/25280)\n",
      "Epoch 3 Step 790/1563 Loss: 1.488 | Acc: 46.132% (11677/25312)\n",
      "Epoch 3 Step 791/1563 Loss: 1.488 | Acc: 46.157% (11698/25344)\n",
      "Epoch 3 Step 792/1563 Loss: 1.488 | Acc: 46.177% (11718/25376)\n",
      "Epoch 3 Step 793/1563 Loss: 1.487 | Acc: 46.194% (11737/25408)\n",
      "Epoch 3 Step 794/1563 Loss: 1.487 | Acc: 46.207% (11755/25440)\n",
      "Epoch 3 Step 795/1563 Loss: 1.487 | Acc: 46.223% (11774/25472)\n",
      "Epoch 3 Step 796/1563 Loss: 1.487 | Acc: 46.228% (11790/25504)\n",
      "Epoch 3 Step 797/1563 Loss: 1.487 | Acc: 46.225% (11804/25536)\n",
      "Epoch 3 Step 798/1563 Loss: 1.487 | Acc: 46.210% (11815/25568)\n",
      "Epoch 3 Step 799/1563 Loss: 1.487 | Acc: 46.227% (11834/25600)\n",
      "Epoch 3 Step 800/1563 Loss: 1.486 | Acc: 46.239% (11852/25632)\n",
      "Epoch 3 Step 801/1563 Loss: 1.486 | Acc: 46.244% (11868/25664)\n",
      "Epoch 3 Step 802/1563 Loss: 1.486 | Acc: 46.248% (11884/25696)\n",
      "Epoch 3 Step 803/1563 Loss: 1.486 | Acc: 46.249% (11899/25728)\n",
      "Epoch 3 Step 804/1563 Loss: 1.486 | Acc: 46.266% (11918/25760)\n",
      "Epoch 3 Step 805/1563 Loss: 1.486 | Acc: 46.270% (11934/25792)\n",
      "Epoch 3 Step 806/1563 Loss: 1.486 | Acc: 46.255% (11945/25824)\n",
      "Epoch 3 Step 807/1563 Loss: 1.486 | Acc: 46.264% (11962/25856)\n",
      "Epoch 3 Step 808/1563 Loss: 1.486 | Acc: 46.272% (11979/25888)\n",
      "Epoch 3 Step 809/1563 Loss: 1.486 | Acc: 46.265% (11992/25920)\n",
      "Epoch 3 Step 810/1563 Loss: 1.486 | Acc: 46.270% (12008/25952)\n",
      "Epoch 3 Step 811/1563 Loss: 1.486 | Acc: 46.275% (12024/25984)\n",
      "Epoch 3 Step 812/1563 Loss: 1.486 | Acc: 46.272% (12038/26016)\n",
      "Epoch 3 Step 813/1563 Loss: 1.486 | Acc: 46.272% (12053/26048)\n",
      "Epoch 3 Step 814/1563 Loss: 1.487 | Acc: 46.258% (12064/26080)\n",
      "Epoch 3 Step 815/1563 Loss: 1.487 | Acc: 46.258% (12079/26112)\n",
      "Epoch 3 Step 816/1563 Loss: 1.487 | Acc: 46.248% (12091/26144)\n",
      "Epoch 3 Step 817/1563 Loss: 1.487 | Acc: 46.252% (12107/26176)\n",
      "Epoch 3 Step 818/1563 Loss: 1.486 | Acc: 46.284% (12130/26208)\n",
      "Epoch 3 Step 819/1563 Loss: 1.486 | Acc: 46.284% (12145/26240)\n",
      "Epoch 3 Step 820/1563 Loss: 1.486 | Acc: 46.281% (12159/26272)\n",
      "Epoch 3 Step 821/1563 Loss: 1.486 | Acc: 46.286% (12175/26304)\n",
      "Epoch 3 Step 822/1563 Loss: 1.486 | Acc: 46.275% (12187/26336)\n",
      "Epoch 3 Step 823/1563 Loss: 1.486 | Acc: 46.291% (12206/26368)\n",
      "Epoch 3 Step 824/1563 Loss: 1.486 | Acc: 46.288% (12220/26400)\n",
      "Epoch 3 Step 825/1563 Loss: 1.486 | Acc: 46.292% (12236/26432)\n",
      "Epoch 3 Step 826/1563 Loss: 1.486 | Acc: 46.289% (12250/26464)\n",
      "Epoch 3 Step 827/1563 Loss: 1.486 | Acc: 46.290% (12265/26496)\n",
      "Epoch 3 Step 828/1563 Loss: 1.486 | Acc: 46.276% (12276/26528)\n",
      "Epoch 3 Step 829/1563 Loss: 1.486 | Acc: 46.276% (12291/26560)\n",
      "Epoch 3 Step 830/1563 Loss: 1.486 | Acc: 46.277% (12306/26592)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 831/1563 Loss: 1.486 | Acc: 46.244% (12312/26624)\n",
      "Epoch 3 Step 832/1563 Loss: 1.486 | Acc: 46.248% (12328/26656)\n",
      "Epoch 3 Step 833/1563 Loss: 1.487 | Acc: 46.234% (12339/26688)\n",
      "Epoch 3 Step 834/1563 Loss: 1.486 | Acc: 46.243% (12356/26720)\n",
      "Epoch 3 Step 835/1563 Loss: 1.486 | Acc: 46.251% (12373/26752)\n",
      "Epoch 3 Step 836/1563 Loss: 1.486 | Acc: 46.255% (12389/26784)\n",
      "Epoch 3 Step 837/1563 Loss: 1.487 | Acc: 46.245% (12401/26816)\n",
      "Epoch 3 Step 838/1563 Loss: 1.486 | Acc: 46.253% (12418/26848)\n",
      "Epoch 3 Step 839/1563 Loss: 1.486 | Acc: 46.246% (12431/26880)\n",
      "Epoch 3 Step 840/1563 Loss: 1.487 | Acc: 46.247% (12446/26912)\n",
      "Epoch 3 Step 841/1563 Loss: 1.487 | Acc: 46.248% (12461/26944)\n",
      "Epoch 3 Step 842/1563 Loss: 1.487 | Acc: 46.260% (12479/26976)\n",
      "Epoch 3 Step 843/1563 Loss: 1.487 | Acc: 46.268% (12496/27008)\n",
      "Epoch 3 Step 844/1563 Loss: 1.486 | Acc: 46.276% (12513/27040)\n",
      "Epoch 3 Step 845/1563 Loss: 1.486 | Acc: 46.299% (12534/27072)\n",
      "Epoch 3 Step 846/1563 Loss: 1.486 | Acc: 46.288% (12546/27104)\n",
      "Epoch 3 Step 847/1563 Loss: 1.486 | Acc: 46.282% (12559/27136)\n",
      "Epoch 3 Step 848/1563 Loss: 1.486 | Acc: 46.293% (12577/27168)\n",
      "Epoch 3 Step 849/1563 Loss: 1.486 | Acc: 46.290% (12591/27200)\n",
      "Epoch 3 Step 850/1563 Loss: 1.486 | Acc: 46.306% (12610/27232)\n",
      "Epoch 3 Step 851/1563 Loss: 1.486 | Acc: 46.303% (12624/27264)\n",
      "Epoch 3 Step 852/1563 Loss: 1.486 | Acc: 46.311% (12641/27296)\n",
      "Epoch 3 Step 853/1563 Loss: 1.486 | Acc: 46.300% (12653/27328)\n",
      "Epoch 3 Step 854/1563 Loss: 1.486 | Acc: 46.301% (12668/27360)\n",
      "Epoch 3 Step 855/1563 Loss: 1.485 | Acc: 46.309% (12685/27392)\n",
      "Epoch 3 Step 856/1563 Loss: 1.485 | Acc: 46.306% (12699/27424)\n",
      "Epoch 3 Step 857/1563 Loss: 1.485 | Acc: 46.310% (12715/27456)\n",
      "Epoch 3 Step 858/1563 Loss: 1.485 | Acc: 46.329% (12735/27488)\n",
      "Epoch 3 Step 859/1563 Loss: 1.485 | Acc: 46.305% (12743/27520)\n",
      "Epoch 3 Step 860/1563 Loss: 1.485 | Acc: 46.305% (12758/27552)\n",
      "Epoch 3 Step 861/1563 Loss: 1.486 | Acc: 46.306% (12773/27584)\n",
      "Epoch 3 Step 862/1563 Loss: 1.486 | Acc: 46.292% (12784/27616)\n",
      "Epoch 3 Step 863/1563 Loss: 1.486 | Acc: 46.304% (12802/27648)\n",
      "Epoch 3 Step 864/1563 Loss: 1.486 | Acc: 46.297% (12815/27680)\n",
      "Epoch 3 Step 865/1563 Loss: 1.486 | Acc: 46.280% (12825/27712)\n",
      "Epoch 3 Step 866/1563 Loss: 1.486 | Acc: 46.291% (12843/27744)\n",
      "Epoch 3 Step 867/1563 Loss: 1.486 | Acc: 46.303% (12861/27776)\n",
      "Epoch 3 Step 868/1563 Loss: 1.486 | Acc: 46.307% (12877/27808)\n",
      "Epoch 3 Step 869/1563 Loss: 1.486 | Acc: 46.311% (12893/27840)\n",
      "Epoch 3 Step 870/1563 Loss: 1.486 | Acc: 46.312% (12908/27872)\n",
      "Epoch 3 Step 871/1563 Loss: 1.486 | Acc: 46.309% (12922/27904)\n",
      "Epoch 3 Step 872/1563 Loss: 1.486 | Acc: 46.309% (12937/27936)\n",
      "Epoch 3 Step 873/1563 Loss: 1.486 | Acc: 46.324% (12956/27968)\n",
      "Epoch 3 Step 874/1563 Loss: 1.486 | Acc: 46.318% (12969/28000)\n",
      "Epoch 3 Step 875/1563 Loss: 1.485 | Acc: 46.329% (12987/28032)\n",
      "Epoch 3 Step 876/1563 Loss: 1.485 | Acc: 46.355% (13009/28064)\n",
      "Epoch 3 Step 877/1563 Loss: 1.485 | Acc: 46.362% (13026/28096)\n",
      "Epoch 3 Step 878/1563 Loss: 1.485 | Acc: 46.367% (13042/28128)\n",
      "Epoch 3 Step 879/1563 Loss: 1.485 | Acc: 46.367% (13057/28160)\n",
      "Epoch 3 Step 880/1563 Loss: 1.485 | Acc: 46.357% (13069/28192)\n",
      "Epoch 3 Step 881/1563 Loss: 1.485 | Acc: 46.351% (13082/28224)\n",
      "Epoch 3 Step 882/1563 Loss: 1.485 | Acc: 46.351% (13097/28256)\n",
      "Epoch 3 Step 883/1563 Loss: 1.485 | Acc: 46.359% (13114/28288)\n",
      "Epoch 3 Step 884/1563 Loss: 1.485 | Acc: 46.363% (13130/28320)\n",
      "Epoch 3 Step 885/1563 Loss: 1.485 | Acc: 46.371% (13147/28352)\n",
      "Epoch 3 Step 886/1563 Loss: 1.485 | Acc: 46.350% (13156/28384)\n",
      "Epoch 3 Step 887/1563 Loss: 1.485 | Acc: 46.347% (13170/28416)\n",
      "Epoch 3 Step 888/1563 Loss: 1.485 | Acc: 46.355% (13187/28448)\n",
      "Epoch 3 Step 889/1563 Loss: 1.485 | Acc: 46.345% (13199/28480)\n",
      "Epoch 3 Step 890/1563 Loss: 1.485 | Acc: 46.338% (13212/28512)\n",
      "Epoch 3 Step 891/1563 Loss: 1.485 | Acc: 46.346% (13229/28544)\n",
      "Epoch 3 Step 892/1563 Loss: 1.485 | Acc: 46.368% (13250/28576)\n",
      "Epoch 3 Step 893/1563 Loss: 1.485 | Acc: 46.368% (13265/28608)\n",
      "Epoch 3 Step 894/1563 Loss: 1.485 | Acc: 46.358% (13277/28640)\n",
      "Epoch 3 Step 895/1563 Loss: 1.485 | Acc: 46.362% (13293/28672)\n",
      "Epoch 3 Step 896/1563 Loss: 1.485 | Acc: 46.363% (13308/28704)\n",
      "Epoch 3 Step 897/1563 Loss: 1.485 | Acc: 46.353% (13320/28736)\n",
      "Epoch 3 Step 898/1563 Loss: 1.485 | Acc: 46.347% (13333/28768)\n",
      "Epoch 3 Step 899/1563 Loss: 1.485 | Acc: 46.344% (13347/28800)\n",
      "Epoch 3 Step 900/1563 Loss: 1.485 | Acc: 46.358% (13366/28832)\n",
      "Epoch 3 Step 901/1563 Loss: 1.485 | Acc: 46.369% (13384/28864)\n",
      "Epoch 3 Step 902/1563 Loss: 1.485 | Acc: 46.349% (13393/28896)\n",
      "Epoch 3 Step 903/1563 Loss: 1.485 | Acc: 46.353% (13409/28928)\n",
      "Epoch 3 Step 904/1563 Loss: 1.485 | Acc: 46.350% (13423/28960)\n",
      "Epoch 3 Step 905/1563 Loss: 1.485 | Acc: 46.340% (13435/28992)\n",
      "Epoch 3 Step 906/1563 Loss: 1.485 | Acc: 46.341% (13450/29024)\n",
      "Epoch 3 Step 907/1563 Loss: 1.485 | Acc: 46.359% (13470/29056)\n",
      "Epoch 3 Step 908/1563 Loss: 1.485 | Acc: 46.346% (13481/29088)\n",
      "Epoch 3 Step 909/1563 Loss: 1.485 | Acc: 46.353% (13498/29120)\n",
      "Epoch 3 Step 910/1563 Loss: 1.485 | Acc: 46.350% (13512/29152)\n",
      "Epoch 3 Step 911/1563 Loss: 1.485 | Acc: 46.351% (13527/29184)\n",
      "Epoch 3 Step 912/1563 Loss: 1.485 | Acc: 46.355% (13543/29216)\n",
      "Epoch 3 Step 913/1563 Loss: 1.485 | Acc: 46.348% (13556/29248)\n",
      "Epoch 3 Step 914/1563 Loss: 1.485 | Acc: 46.342% (13569/29280)\n",
      "Epoch 3 Step 915/1563 Loss: 1.485 | Acc: 46.350% (13586/29312)\n",
      "Epoch 3 Step 916/1563 Loss: 1.486 | Acc: 46.337% (13597/29344)\n",
      "Epoch 3 Step 917/1563 Loss: 1.485 | Acc: 46.344% (13614/29376)\n",
      "Epoch 3 Step 918/1563 Loss: 1.485 | Acc: 46.351% (13631/29408)\n",
      "Epoch 3 Step 919/1563 Loss: 1.485 | Acc: 46.355% (13647/29440)\n",
      "Epoch 3 Step 920/1563 Loss: 1.485 | Acc: 46.369% (13666/29472)\n",
      "Epoch 3 Step 921/1563 Loss: 1.484 | Acc: 46.360% (13678/29504)\n",
      "Epoch 3 Step 922/1563 Loss: 1.484 | Acc: 46.371% (13696/29536)\n",
      "Epoch 3 Step 923/1563 Loss: 1.484 | Acc: 46.361% (13708/29568)\n",
      "Epoch 3 Step 924/1563 Loss: 1.484 | Acc: 46.348% (13719/29600)\n",
      "Epoch 3 Step 925/1563 Loss: 1.484 | Acc: 46.352% (13735/29632)\n",
      "Epoch 3 Step 926/1563 Loss: 1.484 | Acc: 46.352% (13750/29664)\n",
      "Epoch 3 Step 927/1563 Loss: 1.484 | Acc: 46.360% (13767/29696)\n",
      "Epoch 3 Step 928/1563 Loss: 1.485 | Acc: 46.364% (13783/29728)\n",
      "Epoch 3 Step 929/1563 Loss: 1.484 | Acc: 46.378% (13802/29760)\n",
      "Epoch 3 Step 930/1563 Loss: 1.484 | Acc: 46.368% (13814/29792)\n",
      "Epoch 3 Step 931/1563 Loss: 1.484 | Acc: 46.365% (13828/29824)\n",
      "Epoch 3 Step 932/1563 Loss: 1.485 | Acc: 46.366% (13843/29856)\n",
      "Epoch 3 Step 933/1563 Loss: 1.484 | Acc: 46.363% (13857/29888)\n",
      "Epoch 3 Step 934/1563 Loss: 1.484 | Acc: 46.357% (13870/29920)\n",
      "Epoch 3 Step 935/1563 Loss: 1.484 | Acc: 46.358% (13885/29952)\n",
      "Epoch 3 Step 936/1563 Loss: 1.484 | Acc: 46.365% (13902/29984)\n",
      "Epoch 3 Step 937/1563 Loss: 1.484 | Acc: 46.372% (13919/30016)\n",
      "Epoch 3 Step 938/1563 Loss: 1.484 | Acc: 46.359% (13930/30048)\n",
      "Epoch 3 Step 939/1563 Loss: 1.484 | Acc: 46.363% (13946/30080)\n",
      "Epoch 3 Step 940/1563 Loss: 1.484 | Acc: 46.380% (13966/30112)\n",
      "Epoch 3 Step 941/1563 Loss: 1.483 | Acc: 46.397% (13986/30144)\n",
      "Epoch 3 Step 942/1563 Loss: 1.484 | Acc: 46.391% (13999/30176)\n",
      "Epoch 3 Step 943/1563 Loss: 1.483 | Acc: 46.398% (14016/30208)\n",
      "Epoch 3 Step 944/1563 Loss: 1.483 | Acc: 46.402% (14032/30240)\n",
      "Epoch 3 Step 945/1563 Loss: 1.483 | Acc: 46.409% (14049/30272)\n",
      "Epoch 3 Step 946/1563 Loss: 1.483 | Acc: 46.420% (14067/30304)\n",
      "Epoch 3 Step 947/1563 Loss: 1.483 | Acc: 46.410% (14079/30336)\n",
      "Epoch 3 Step 948/1563 Loss: 1.483 | Acc: 46.407% (14093/30368)\n",
      "Epoch 3 Step 949/1563 Loss: 1.483 | Acc: 46.401% (14106/30400)\n",
      "Epoch 3 Step 950/1563 Loss: 1.483 | Acc: 46.402% (14121/30432)\n",
      "Epoch 3 Step 951/1563 Loss: 1.483 | Acc: 46.406% (14137/30464)\n",
      "Epoch 3 Step 952/1563 Loss: 1.483 | Acc: 46.413% (14154/30496)\n",
      "Epoch 3 Step 953/1563 Loss: 1.483 | Acc: 46.410% (14168/30528)\n",
      "Epoch 3 Step 954/1563 Loss: 1.483 | Acc: 46.397% (14179/30560)\n",
      "Epoch 3 Step 955/1563 Loss: 1.483 | Acc: 46.408% (14197/30592)\n",
      "Epoch 3 Step 956/1563 Loss: 1.483 | Acc: 46.411% (14213/30624)\n",
      "Epoch 3 Step 957/1563 Loss: 1.482 | Acc: 46.418% (14230/30656)\n",
      "Epoch 3 Step 958/1563 Loss: 1.483 | Acc: 46.412% (14243/30688)\n",
      "Epoch 3 Step 959/1563 Loss: 1.483 | Acc: 46.393% (14252/30720)\n",
      "Epoch 3 Step 960/1563 Loss: 1.483 | Acc: 46.384% (14264/30752)\n",
      "Epoch 3 Step 961/1563 Loss: 1.483 | Acc: 46.378% (14277/30784)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 962/1563 Loss: 1.483 | Acc: 46.379% (14292/30816)\n",
      "Epoch 3 Step 963/1563 Loss: 1.483 | Acc: 46.389% (14310/30848)\n",
      "Epoch 3 Step 964/1563 Loss: 1.483 | Acc: 46.389% (14325/30880)\n",
      "Epoch 3 Step 965/1563 Loss: 1.484 | Acc: 46.380% (14337/30912)\n",
      "Epoch 3 Step 966/1563 Loss: 1.484 | Acc: 46.381% (14352/30944)\n",
      "Epoch 3 Step 967/1563 Loss: 1.483 | Acc: 46.394% (14371/30976)\n",
      "Epoch 3 Step 968/1563 Loss: 1.483 | Acc: 46.401% (14388/31008)\n",
      "Epoch 3 Step 969/1563 Loss: 1.483 | Acc: 46.395% (14401/31040)\n",
      "Epoch 3 Step 970/1563 Loss: 1.483 | Acc: 46.395% (14416/31072)\n",
      "Epoch 3 Step 971/1563 Loss: 1.483 | Acc: 46.406% (14434/31104)\n",
      "Epoch 3 Step 972/1563 Loss: 1.483 | Acc: 46.403% (14448/31136)\n",
      "Epoch 3 Step 973/1563 Loss: 1.483 | Acc: 46.400% (14462/31168)\n",
      "Epoch 3 Step 974/1563 Loss: 1.483 | Acc: 46.391% (14474/31200)\n",
      "Epoch 3 Step 975/1563 Loss: 1.484 | Acc: 46.388% (14488/31232)\n",
      "Epoch 3 Step 976/1563 Loss: 1.483 | Acc: 46.395% (14505/31264)\n",
      "Epoch 3 Step 977/1563 Loss: 1.484 | Acc: 46.386% (14517/31296)\n",
      "Epoch 3 Step 978/1563 Loss: 1.483 | Acc: 46.387% (14532/31328)\n",
      "Epoch 3 Step 979/1563 Loss: 1.484 | Acc: 46.378% (14544/31360)\n",
      "Epoch 3 Step 980/1563 Loss: 1.484 | Acc: 46.372% (14557/31392)\n",
      "Epoch 3 Step 981/1563 Loss: 1.484 | Acc: 46.366% (14570/31424)\n",
      "Epoch 3 Step 982/1563 Loss: 1.484 | Acc: 46.366% (14585/31456)\n",
      "Epoch 3 Step 983/1563 Loss: 1.484 | Acc: 46.364% (14599/31488)\n",
      "Epoch 3 Step 984/1563 Loss: 1.484 | Acc: 46.364% (14614/31520)\n",
      "Epoch 3 Step 985/1563 Loss: 1.483 | Acc: 46.377% (14633/31552)\n",
      "Epoch 3 Step 986/1563 Loss: 1.483 | Acc: 46.375% (14647/31584)\n",
      "Epoch 3 Step 987/1563 Loss: 1.484 | Acc: 46.359% (14657/31616)\n",
      "Epoch 3 Step 988/1563 Loss: 1.483 | Acc: 46.366% (14674/31648)\n",
      "Epoch 3 Step 989/1563 Loss: 1.483 | Acc: 46.367% (14689/31680)\n",
      "Epoch 3 Step 990/1563 Loss: 1.484 | Acc: 46.364% (14703/31712)\n",
      "Epoch 3 Step 991/1563 Loss: 1.484 | Acc: 46.355% (14715/31744)\n",
      "Epoch 3 Step 992/1563 Loss: 1.484 | Acc: 46.353% (14729/31776)\n",
      "Epoch 3 Step 993/1563 Loss: 1.484 | Acc: 46.341% (14740/31808)\n",
      "Epoch 3 Step 994/1563 Loss: 1.484 | Acc: 46.363% (14762/31840)\n",
      "Epoch 3 Step 995/1563 Loss: 1.483 | Acc: 46.370% (14779/31872)\n",
      "Epoch 3 Step 996/1563 Loss: 1.483 | Acc: 46.380% (14797/31904)\n",
      "Epoch 3 Step 997/1563 Loss: 1.483 | Acc: 46.380% (14812/31936)\n",
      "Epoch 3 Step 998/1563 Loss: 1.484 | Acc: 46.371% (14824/31968)\n",
      "Epoch 3 Step 999/1563 Loss: 1.484 | Acc: 46.366% (14837/32000)\n",
      "Epoch 3 Step 1000/1563 Loss: 1.484 | Acc: 46.357% (14849/32032)\n",
      "Epoch 3 Step 1001/1563 Loss: 1.484 | Acc: 46.351% (14862/32064)\n",
      "Epoch 3 Step 1002/1563 Loss: 1.484 | Acc: 46.355% (14878/32096)\n",
      "Epoch 3 Step 1003/1563 Loss: 1.484 | Acc: 46.355% (14893/32128)\n",
      "Epoch 3 Step 1004/1563 Loss: 1.484 | Acc: 46.350% (14906/32160)\n",
      "Epoch 3 Step 1005/1563 Loss: 1.484 | Acc: 46.344% (14919/32192)\n",
      "Epoch 3 Step 1006/1563 Loss: 1.483 | Acc: 46.363% (14940/32224)\n",
      "Epoch 3 Step 1007/1563 Loss: 1.483 | Acc: 46.367% (14956/32256)\n",
      "Epoch 3 Step 1008/1563 Loss: 1.483 | Acc: 46.370% (14972/32288)\n",
      "Epoch 3 Step 1009/1563 Loss: 1.484 | Acc: 46.377% (14989/32320)\n",
      "Epoch 3 Step 1010/1563 Loss: 1.483 | Acc: 46.384% (15006/32352)\n",
      "Epoch 3 Step 1011/1563 Loss: 1.483 | Acc: 46.387% (15022/32384)\n",
      "Epoch 3 Step 1012/1563 Loss: 1.483 | Acc: 46.388% (15037/32416)\n",
      "Epoch 3 Step 1013/1563 Loss: 1.483 | Acc: 46.385% (15051/32448)\n",
      "Epoch 3 Step 1014/1563 Loss: 1.483 | Acc: 46.389% (15067/32480)\n",
      "Epoch 3 Step 1015/1563 Loss: 1.483 | Acc: 46.389% (15082/32512)\n",
      "Epoch 3 Step 1016/1563 Loss: 1.483 | Acc: 46.405% (15102/32544)\n",
      "Epoch 3 Step 1017/1563 Loss: 1.483 | Acc: 46.405% (15117/32576)\n",
      "Epoch 3 Step 1018/1563 Loss: 1.483 | Acc: 46.403% (15131/32608)\n",
      "Epoch 3 Step 1019/1563 Loss: 1.483 | Acc: 46.391% (15142/32640)\n",
      "Epoch 3 Step 1020/1563 Loss: 1.483 | Acc: 46.382% (15154/32672)\n",
      "Epoch 3 Step 1021/1563 Loss: 1.482 | Acc: 46.395% (15173/32704)\n",
      "Epoch 3 Step 1022/1563 Loss: 1.483 | Acc: 46.398% (15189/32736)\n",
      "Epoch 3 Step 1023/1563 Loss: 1.482 | Acc: 46.405% (15206/32768)\n",
      "Epoch 3 Step 1024/1563 Loss: 1.482 | Acc: 46.405% (15221/32800)\n",
      "Epoch 3 Step 1025/1563 Loss: 1.482 | Acc: 46.409% (15237/32832)\n",
      "Epoch 3 Step 1026/1563 Loss: 1.482 | Acc: 46.403% (15250/32864)\n",
      "Epoch 3 Step 1027/1563 Loss: 1.482 | Acc: 46.404% (15265/32896)\n",
      "Epoch 3 Step 1028/1563 Loss: 1.482 | Acc: 46.407% (15281/32928)\n",
      "Epoch 3 Step 1029/1563 Loss: 1.482 | Acc: 46.411% (15297/32960)\n",
      "Epoch 3 Step 1030/1563 Loss: 1.482 | Acc: 46.417% (15314/32992)\n",
      "Epoch 3 Step 1031/1563 Loss: 1.482 | Acc: 46.415% (15328/33024)\n",
      "Epoch 3 Step 1032/1563 Loss: 1.482 | Acc: 46.415% (15343/33056)\n",
      "Epoch 3 Step 1033/1563 Loss: 1.482 | Acc: 46.413% (15357/33088)\n",
      "Epoch 3 Step 1034/1563 Loss: 1.482 | Acc: 46.419% (15374/33120)\n",
      "Epoch 3 Step 1035/1563 Loss: 1.482 | Acc: 46.404% (15384/33152)\n",
      "Epoch 3 Step 1036/1563 Loss: 1.482 | Acc: 46.414% (15402/33184)\n",
      "Epoch 3 Step 1037/1563 Loss: 1.482 | Acc: 46.420% (15419/33216)\n",
      "Epoch 3 Step 1038/1563 Loss: 1.482 | Acc: 46.415% (15432/33248)\n",
      "Epoch 3 Step 1039/1563 Loss: 1.482 | Acc: 46.424% (15450/33280)\n",
      "Epoch 3 Step 1040/1563 Loss: 1.482 | Acc: 46.425% (15465/33312)\n",
      "Epoch 3 Step 1041/1563 Loss: 1.482 | Acc: 46.428% (15481/33344)\n",
      "Epoch 3 Step 1042/1563 Loss: 1.483 | Acc: 46.420% (15493/33376)\n",
      "Epoch 3 Step 1043/1563 Loss: 1.483 | Acc: 46.411% (15505/33408)\n",
      "Epoch 3 Step 1044/1563 Loss: 1.483 | Acc: 46.417% (15522/33440)\n",
      "Epoch 3 Step 1045/1563 Loss: 1.483 | Acc: 46.424% (15539/33472)\n",
      "Epoch 3 Step 1046/1563 Loss: 1.482 | Acc: 46.439% (15559/33504)\n",
      "Epoch 3 Step 1047/1563 Loss: 1.483 | Acc: 46.437% (15573/33536)\n",
      "Epoch 3 Step 1048/1563 Loss: 1.482 | Acc: 46.437% (15588/33568)\n",
      "Epoch 3 Step 1049/1563 Loss: 1.482 | Acc: 46.438% (15603/33600)\n",
      "Epoch 3 Step 1050/1563 Loss: 1.482 | Acc: 46.435% (15617/33632)\n",
      "Epoch 3 Step 1051/1563 Loss: 1.483 | Acc: 46.426% (15629/33664)\n",
      "Epoch 3 Step 1052/1563 Loss: 1.483 | Acc: 46.421% (15642/33696)\n",
      "Epoch 3 Step 1053/1563 Loss: 1.483 | Acc: 46.410% (15653/33728)\n",
      "Epoch 3 Step 1054/1563 Loss: 1.483 | Acc: 46.413% (15669/33760)\n",
      "Epoch 3 Step 1055/1563 Loss: 1.483 | Acc: 46.413% (15684/33792)\n",
      "Epoch 3 Step 1056/1563 Loss: 1.483 | Acc: 46.405% (15696/33824)\n",
      "Epoch 3 Step 1057/1563 Loss: 1.484 | Acc: 46.394% (15707/33856)\n",
      "Epoch 3 Step 1058/1563 Loss: 1.484 | Acc: 46.394% (15722/33888)\n",
      "Epoch 3 Step 1059/1563 Loss: 1.484 | Acc: 46.397% (15738/33920)\n",
      "Epoch 3 Step 1060/1563 Loss: 1.484 | Acc: 46.398% (15753/33952)\n",
      "Epoch 3 Step 1061/1563 Loss: 1.483 | Acc: 46.407% (15771/33984)\n",
      "Epoch 3 Step 1062/1563 Loss: 1.483 | Acc: 46.416% (15789/34016)\n",
      "Epoch 3 Step 1063/1563 Loss: 1.483 | Acc: 46.420% (15805/34048)\n",
      "Epoch 3 Step 1064/1563 Loss: 1.483 | Acc: 46.420% (15820/34080)\n",
      "Epoch 3 Step 1065/1563 Loss: 1.483 | Acc: 46.418% (15834/34112)\n",
      "Epoch 3 Step 1066/1563 Loss: 1.483 | Acc: 46.415% (15848/34144)\n",
      "Epoch 3 Step 1067/1563 Loss: 1.483 | Acc: 46.421% (15865/34176)\n",
      "Epoch 3 Step 1068/1563 Loss: 1.483 | Acc: 46.410% (15876/34208)\n",
      "Epoch 3 Step 1069/1563 Loss: 1.484 | Acc: 46.399% (15887/34240)\n",
      "Epoch 3 Step 1070/1563 Loss: 1.484 | Acc: 46.382% (15896/34272)\n",
      "Epoch 3 Step 1071/1563 Loss: 1.484 | Acc: 46.388% (15913/34304)\n",
      "Epoch 3 Step 1072/1563 Loss: 1.484 | Acc: 46.386% (15927/34336)\n",
      "Epoch 3 Step 1073/1563 Loss: 1.484 | Acc: 46.372% (15937/34368)\n",
      "Epoch 3 Step 1074/1563 Loss: 1.484 | Acc: 46.384% (15956/34400)\n",
      "Epoch 3 Step 1075/1563 Loss: 1.484 | Acc: 46.387% (15972/34432)\n",
      "Epoch 3 Step 1076/1563 Loss: 1.484 | Acc: 46.379% (15984/34464)\n",
      "Epoch 3 Step 1077/1563 Loss: 1.484 | Acc: 46.362% (15993/34496)\n",
      "Epoch 3 Step 1078/1563 Loss: 1.484 | Acc: 46.354% (16005/34528)\n",
      "Epoch 3 Step 1079/1563 Loss: 1.484 | Acc: 46.354% (16020/34560)\n",
      "Epoch 3 Step 1080/1563 Loss: 1.484 | Acc: 46.352% (16034/34592)\n",
      "Epoch 3 Step 1081/1563 Loss: 1.484 | Acc: 46.352% (16049/34624)\n",
      "Epoch 3 Step 1082/1563 Loss: 1.483 | Acc: 46.344% (16061/34656)\n",
      "Epoch 3 Step 1083/1563 Loss: 1.484 | Acc: 46.333% (16072/34688)\n",
      "Epoch 3 Step 1084/1563 Loss: 1.484 | Acc: 46.325% (16084/34720)\n",
      "Epoch 3 Step 1085/1563 Loss: 1.484 | Acc: 46.323% (16098/34752)\n",
      "Epoch 3 Step 1086/1563 Loss: 1.484 | Acc: 46.320% (16112/34784)\n",
      "Epoch 3 Step 1087/1563 Loss: 1.484 | Acc: 46.301% (16120/34816)\n",
      "Epoch 3 Step 1088/1563 Loss: 1.484 | Acc: 46.304% (16136/34848)\n",
      "Epoch 3 Step 1089/1563 Loss: 1.485 | Acc: 46.287% (16145/34880)\n",
      "Epoch 3 Step 1090/1563 Loss: 1.485 | Acc: 46.288% (16160/34912)\n",
      "Epoch 3 Step 1091/1563 Loss: 1.484 | Acc: 46.297% (16178/34944)\n",
      "Epoch 3 Step 1092/1563 Loss: 1.484 | Acc: 46.297% (16193/34976)\n",
      "Epoch 3 Step 1093/1563 Loss: 1.484 | Acc: 46.312% (16213/35008)\n",
      "Epoch 3 Step 1094/1563 Loss: 1.484 | Acc: 46.318% (16230/35040)\n",
      "Epoch 3 Step 1095/1563 Loss: 1.484 | Acc: 46.308% (16241/35072)\n",
      "Epoch 3 Step 1096/1563 Loss: 1.484 | Acc: 46.305% (16255/35104)\n",
      "Epoch 3 Step 1097/1563 Loss: 1.484 | Acc: 46.300% (16268/35136)\n",
      "Epoch 3 Step 1098/1563 Loss: 1.484 | Acc: 46.306% (16285/35168)\n",
      "Epoch 3 Step 1099/1563 Loss: 1.484 | Acc: 46.310% (16301/35200)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 1100/1563 Loss: 1.484 | Acc: 46.310% (16316/35232)\n",
      "Epoch 3 Step 1101/1563 Loss: 1.484 | Acc: 46.297% (16326/35264)\n",
      "Epoch 3 Step 1102/1563 Loss: 1.484 | Acc: 46.291% (16339/35296)\n",
      "Epoch 3 Step 1103/1563 Loss: 1.484 | Acc: 46.295% (16355/35328)\n",
      "Epoch 3 Step 1104/1563 Loss: 1.484 | Acc: 46.287% (16367/35360)\n",
      "Epoch 3 Step 1105/1563 Loss: 1.484 | Acc: 46.273% (16377/35392)\n",
      "Epoch 3 Step 1106/1563 Loss: 1.484 | Acc: 46.274% (16392/35424)\n",
      "Epoch 3 Step 1107/1563 Loss: 1.484 | Acc: 46.274% (16407/35456)\n",
      "Epoch 3 Step 1108/1563 Loss: 1.484 | Acc: 46.272% (16421/35488)\n",
      "Epoch 3 Step 1109/1563 Loss: 1.484 | Acc: 46.270% (16435/35520)\n",
      "Epoch 3 Step 1110/1563 Loss: 1.484 | Acc: 46.259% (16446/35552)\n",
      "Epoch 3 Step 1111/1563 Loss: 1.484 | Acc: 46.262% (16462/35584)\n",
      "Epoch 3 Step 1112/1563 Loss: 1.484 | Acc: 46.257% (16475/35616)\n",
      "Epoch 3 Step 1113/1563 Loss: 1.484 | Acc: 46.255% (16489/35648)\n",
      "Epoch 3 Step 1114/1563 Loss: 1.484 | Acc: 46.253% (16503/35680)\n",
      "Epoch 3 Step 1115/1563 Loss: 1.485 | Acc: 46.239% (16513/35712)\n",
      "Epoch 3 Step 1116/1563 Loss: 1.485 | Acc: 46.237% (16527/35744)\n",
      "Epoch 3 Step 1117/1563 Loss: 1.485 | Acc: 46.229% (16539/35776)\n",
      "Epoch 3 Step 1118/1563 Loss: 1.485 | Acc: 46.230% (16554/35808)\n",
      "Epoch 3 Step 1119/1563 Loss: 1.485 | Acc: 46.233% (16570/35840)\n",
      "Epoch 3 Step 1120/1563 Loss: 1.485 | Acc: 46.231% (16584/35872)\n",
      "Epoch 3 Step 1121/1563 Loss: 1.485 | Acc: 46.232% (16599/35904)\n",
      "Epoch 3 Step 1122/1563 Loss: 1.485 | Acc: 46.232% (16614/35936)\n",
      "Epoch 3 Step 1123/1563 Loss: 1.485 | Acc: 46.236% (16630/35968)\n",
      "Epoch 3 Step 1124/1563 Loss: 1.485 | Acc: 46.233% (16644/36000)\n",
      "Epoch 3 Step 1125/1563 Loss: 1.485 | Acc: 46.237% (16660/36032)\n",
      "Epoch 3 Step 1126/1563 Loss: 1.485 | Acc: 46.240% (16676/36064)\n",
      "Epoch 3 Step 1127/1563 Loss: 1.485 | Acc: 46.227% (16686/36096)\n",
      "Epoch 3 Step 1128/1563 Loss: 1.485 | Acc: 46.230% (16702/36128)\n",
      "Epoch 3 Step 1129/1563 Loss: 1.485 | Acc: 46.239% (16720/36160)\n",
      "Epoch 3 Step 1130/1563 Loss: 1.485 | Acc: 46.234% (16733/36192)\n",
      "Epoch 3 Step 1131/1563 Loss: 1.485 | Acc: 46.240% (16750/36224)\n",
      "Epoch 3 Step 1132/1563 Loss: 1.485 | Acc: 46.246% (16767/36256)\n",
      "Epoch 3 Step 1133/1563 Loss: 1.485 | Acc: 46.236% (16778/36288)\n",
      "Epoch 3 Step 1134/1563 Loss: 1.485 | Acc: 46.220% (16787/36320)\n",
      "Epoch 3 Step 1135/1563 Loss: 1.485 | Acc: 46.229% (16805/36352)\n",
      "Epoch 3 Step 1136/1563 Loss: 1.485 | Acc: 46.232% (16821/36384)\n",
      "Epoch 3 Step 1137/1563 Loss: 1.485 | Acc: 46.221% (16832/36416)\n",
      "Epoch 3 Step 1138/1563 Loss: 1.485 | Acc: 46.219% (16846/36448)\n",
      "Epoch 3 Step 1139/1563 Loss: 1.485 | Acc: 46.225% (16863/36480)\n",
      "Epoch 3 Step 1140/1563 Loss: 1.484 | Acc: 46.231% (16880/36512)\n",
      "Epoch 3 Step 1141/1563 Loss: 1.485 | Acc: 46.243% (16899/36544)\n",
      "Epoch 3 Step 1142/1563 Loss: 1.485 | Acc: 46.235% (16911/36576)\n",
      "Epoch 3 Step 1143/1563 Loss: 1.485 | Acc: 46.239% (16927/36608)\n",
      "Epoch 3 Step 1144/1563 Loss: 1.485 | Acc: 46.239% (16942/36640)\n",
      "Epoch 3 Step 1145/1563 Loss: 1.485 | Acc: 46.237% (16956/36672)\n",
      "Epoch 3 Step 1146/1563 Loss: 1.484 | Acc: 46.243% (16973/36704)\n",
      "Epoch 3 Step 1147/1563 Loss: 1.484 | Acc: 46.254% (16992/36736)\n",
      "Epoch 3 Step 1148/1563 Loss: 1.484 | Acc: 46.255% (17007/36768)\n",
      "Epoch 3 Step 1149/1563 Loss: 1.484 | Acc: 46.255% (17022/36800)\n",
      "Epoch 3 Step 1150/1563 Loss: 1.484 | Acc: 46.259% (17038/36832)\n",
      "Epoch 3 Step 1151/1563 Loss: 1.484 | Acc: 46.267% (17056/36864)\n",
      "Epoch 3 Step 1152/1563 Loss: 1.484 | Acc: 46.273% (17073/36896)\n",
      "Epoch 3 Step 1153/1563 Loss: 1.484 | Acc: 46.268% (17086/36928)\n",
      "Epoch 3 Step 1154/1563 Loss: 1.484 | Acc: 46.264% (17099/36960)\n",
      "Epoch 3 Step 1155/1563 Loss: 1.484 | Acc: 46.278% (17119/36992)\n",
      "Epoch 3 Step 1156/1563 Loss: 1.484 | Acc: 46.275% (17133/37024)\n",
      "Epoch 3 Step 1157/1563 Loss: 1.484 | Acc: 46.281% (17150/37056)\n",
      "Epoch 3 Step 1158/1563 Loss: 1.484 | Acc: 46.279% (17164/37088)\n",
      "Epoch 3 Step 1159/1563 Loss: 1.484 | Acc: 46.272% (17176/37120)\n",
      "Epoch 3 Step 1160/1563 Loss: 1.484 | Acc: 46.272% (17191/37152)\n",
      "Epoch 3 Step 1161/1563 Loss: 1.484 | Acc: 46.275% (17207/37184)\n",
      "Epoch 3 Step 1162/1563 Loss: 1.484 | Acc: 46.295% (17229/37216)\n",
      "Epoch 3 Step 1163/1563 Loss: 1.484 | Acc: 46.303% (17247/37248)\n",
      "Epoch 3 Step 1164/1563 Loss: 1.484 | Acc: 46.301% (17261/37280)\n",
      "Epoch 3 Step 1165/1563 Loss: 1.484 | Acc: 46.299% (17275/37312)\n",
      "Epoch 3 Step 1166/1563 Loss: 1.484 | Acc: 46.307% (17293/37344)\n",
      "Epoch 3 Step 1167/1563 Loss: 1.484 | Acc: 46.310% (17309/37376)\n",
      "Epoch 3 Step 1168/1563 Loss: 1.484 | Acc: 46.314% (17325/37408)\n",
      "Epoch 3 Step 1169/1563 Loss: 1.483 | Acc: 46.327% (17345/37440)\n",
      "Epoch 3 Step 1170/1563 Loss: 1.483 | Acc: 46.333% (17362/37472)\n",
      "Epoch 3 Step 1171/1563 Loss: 1.483 | Acc: 46.326% (17374/37504)\n",
      "Epoch 3 Step 1172/1563 Loss: 1.483 | Acc: 46.321% (17387/37536)\n",
      "Epoch 3 Step 1173/1563 Loss: 1.483 | Acc: 46.316% (17400/37568)\n",
      "Epoch 3 Step 1174/1563 Loss: 1.484 | Acc: 46.303% (17410/37600)\n",
      "Epoch 3 Step 1175/1563 Loss: 1.483 | Acc: 46.309% (17427/37632)\n",
      "Epoch 3 Step 1176/1563 Loss: 1.483 | Acc: 46.309% (17442/37664)\n",
      "Epoch 3 Step 1177/1563 Loss: 1.483 | Acc: 46.313% (17458/37696)\n",
      "Epoch 3 Step 1178/1563 Loss: 1.483 | Acc: 46.329% (17479/37728)\n",
      "Epoch 3 Step 1179/1563 Loss: 1.483 | Acc: 46.329% (17494/37760)\n",
      "Epoch 3 Step 1180/1563 Loss: 1.483 | Acc: 46.325% (17507/37792)\n",
      "Epoch 3 Step 1181/1563 Loss: 1.483 | Acc: 46.330% (17524/37824)\n",
      "Epoch 3 Step 1182/1563 Loss: 1.483 | Acc: 46.333% (17540/37856)\n",
      "Epoch 3 Step 1183/1563 Loss: 1.483 | Acc: 46.334% (17555/37888)\n",
      "Epoch 3 Step 1184/1563 Loss: 1.483 | Acc: 46.329% (17568/37920)\n",
      "Epoch 3 Step 1185/1563 Loss: 1.483 | Acc: 46.332% (17584/37952)\n",
      "Epoch 3 Step 1186/1563 Loss: 1.483 | Acc: 46.346% (17604/37984)\n",
      "Epoch 3 Step 1187/1563 Loss: 1.483 | Acc: 46.341% (17617/38016)\n",
      "Epoch 3 Step 1188/1563 Loss: 1.483 | Acc: 46.341% (17632/38048)\n",
      "Epoch 3 Step 1189/1563 Loss: 1.483 | Acc: 46.337% (17645/38080)\n",
      "Epoch 3 Step 1190/1563 Loss: 1.483 | Acc: 46.353% (17666/38112)\n",
      "Epoch 3 Step 1191/1563 Loss: 1.483 | Acc: 46.356% (17682/38144)\n",
      "Epoch 3 Step 1192/1563 Loss: 1.483 | Acc: 46.359% (17698/38176)\n",
      "Epoch 3 Step 1193/1563 Loss: 1.483 | Acc: 46.338% (17705/38208)\n",
      "Epoch 3 Step 1194/1563 Loss: 1.483 | Acc: 46.331% (17717/38240)\n",
      "Epoch 3 Step 1195/1563 Loss: 1.483 | Acc: 46.334% (17733/38272)\n",
      "Epoch 3 Step 1196/1563 Loss: 1.483 | Acc: 46.345% (17752/38304)\n",
      "Epoch 3 Step 1197/1563 Loss: 1.483 | Acc: 46.351% (17769/38336)\n",
      "Epoch 3 Step 1198/1563 Loss: 1.482 | Acc: 46.362% (17788/38368)\n",
      "Epoch 3 Step 1199/1563 Loss: 1.483 | Acc: 46.359% (17802/38400)\n",
      "Epoch 3 Step 1200/1563 Loss: 1.483 | Acc: 46.368% (17820/38432)\n",
      "Epoch 3 Step 1201/1563 Loss: 1.483 | Acc: 46.360% (17832/38464)\n",
      "Epoch 3 Step 1202/1563 Loss: 1.482 | Acc: 46.371% (17851/38496)\n",
      "Epoch 3 Step 1203/1563 Loss: 1.482 | Acc: 46.364% (17863/38528)\n",
      "Epoch 3 Step 1204/1563 Loss: 1.482 | Acc: 46.362% (17877/38560)\n",
      "Epoch 3 Step 1205/1563 Loss: 1.482 | Acc: 46.352% (17888/38592)\n",
      "Epoch 3 Step 1206/1563 Loss: 1.482 | Acc: 46.352% (17903/38624)\n",
      "Epoch 3 Step 1207/1563 Loss: 1.482 | Acc: 46.345% (17915/38656)\n",
      "Epoch 3 Step 1208/1563 Loss: 1.483 | Acc: 46.345% (17930/38688)\n",
      "Epoch 3 Step 1209/1563 Loss: 1.483 | Acc: 46.333% (17940/38720)\n",
      "Epoch 3 Step 1210/1563 Loss: 1.483 | Acc: 46.336% (17956/38752)\n",
      "Epoch 3 Step 1211/1563 Loss: 1.483 | Acc: 46.336% (17971/38784)\n",
      "Epoch 3 Step 1212/1563 Loss: 1.483 | Acc: 46.329% (17983/38816)\n",
      "Epoch 3 Step 1213/1563 Loss: 1.483 | Acc: 46.337% (18001/38848)\n",
      "Epoch 3 Step 1214/1563 Loss: 1.483 | Acc: 46.343% (18018/38880)\n",
      "Epoch 3 Step 1215/1563 Loss: 1.483 | Acc: 46.346% (18034/38912)\n",
      "Epoch 3 Step 1216/1563 Loss: 1.483 | Acc: 46.351% (18051/38944)\n",
      "Epoch 3 Step 1217/1563 Loss: 1.483 | Acc: 46.359% (18069/38976)\n",
      "Epoch 3 Step 1218/1563 Loss: 1.483 | Acc: 46.360% (18084/39008)\n",
      "Epoch 3 Step 1219/1563 Loss: 1.483 | Acc: 46.360% (18099/39040)\n",
      "Epoch 3 Step 1220/1563 Loss: 1.483 | Acc: 46.363% (18115/39072)\n",
      "Epoch 3 Step 1221/1563 Loss: 1.483 | Acc: 46.366% (18131/39104)\n",
      "Epoch 3 Step 1222/1563 Loss: 1.483 | Acc: 46.372% (18148/39136)\n",
      "Epoch 3 Step 1223/1563 Loss: 1.483 | Acc: 46.377% (18165/39168)\n",
      "Epoch 3 Step 1224/1563 Loss: 1.483 | Acc: 46.385% (18183/39200)\n",
      "Epoch 3 Step 1225/1563 Loss: 1.483 | Acc: 46.393% (18201/39232)\n",
      "Epoch 3 Step 1226/1563 Loss: 1.482 | Acc: 46.404% (18220/39264)\n",
      "Epoch 3 Step 1227/1563 Loss: 1.482 | Acc: 46.407% (18236/39296)\n",
      "Epoch 3 Step 1228/1563 Loss: 1.483 | Acc: 46.407% (18251/39328)\n",
      "Epoch 3 Step 1229/1563 Loss: 1.483 | Acc: 46.402% (18264/39360)\n",
      "Epoch 3 Step 1230/1563 Loss: 1.483 | Acc: 46.405% (18280/39392)\n",
      "Epoch 3 Step 1231/1563 Loss: 1.483 | Acc: 46.391% (18289/39424)\n",
      "Epoch 3 Step 1232/1563 Loss: 1.483 | Acc: 46.388% (18303/39456)\n",
      "Epoch 3 Step 1233/1563 Loss: 1.483 | Acc: 46.376% (18313/39488)\n",
      "Epoch 3 Step 1234/1563 Loss: 1.483 | Acc: 46.379% (18329/39520)\n",
      "Epoch 3 Step 1235/1563 Loss: 1.483 | Acc: 46.382% (18345/39552)\n",
      "Epoch 3 Step 1236/1563 Loss: 1.483 | Acc: 46.377% (18358/39584)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 1237/1563 Loss: 1.483 | Acc: 46.378% (18373/39616)\n",
      "Epoch 3 Step 1238/1563 Loss: 1.483 | Acc: 46.378% (18388/39648)\n",
      "Epoch 3 Step 1239/1563 Loss: 1.483 | Acc: 46.376% (18402/39680)\n",
      "Epoch 3 Step 1240/1563 Loss: 1.483 | Acc: 46.369% (18414/39712)\n",
      "Epoch 3 Step 1241/1563 Loss: 1.483 | Acc: 46.364% (18427/39744)\n",
      "Epoch 3 Step 1242/1563 Loss: 1.483 | Acc: 46.370% (18444/39776)\n",
      "Epoch 3 Step 1243/1563 Loss: 1.483 | Acc: 46.373% (18460/39808)\n",
      "Epoch 3 Step 1244/1563 Loss: 1.483 | Acc: 46.358% (18469/39840)\n",
      "Epoch 3 Step 1245/1563 Loss: 1.483 | Acc: 46.356% (18483/39872)\n",
      "Epoch 3 Step 1246/1563 Loss: 1.483 | Acc: 46.344% (18493/39904)\n",
      "Epoch 3 Step 1247/1563 Loss: 1.483 | Acc: 46.349% (18510/39936)\n",
      "Epoch 3 Step 1248/1563 Loss: 1.483 | Acc: 46.360% (18529/39968)\n",
      "Epoch 3 Step 1249/1563 Loss: 1.483 | Acc: 46.370% (18548/40000)\n",
      "Epoch 3 Step 1250/1563 Loss: 1.483 | Acc: 46.368% (18562/40032)\n",
      "Epoch 3 Step 1251/1563 Loss: 1.483 | Acc: 46.353% (18571/40064)\n",
      "Epoch 3 Step 1252/1563 Loss: 1.483 | Acc: 46.344% (18582/40096)\n",
      "Epoch 3 Step 1253/1563 Loss: 1.483 | Acc: 46.352% (18600/40128)\n",
      "Epoch 3 Step 1254/1563 Loss: 1.483 | Acc: 46.352% (18615/40160)\n",
      "Epoch 3 Step 1255/1563 Loss: 1.483 | Acc: 46.350% (18629/40192)\n",
      "Epoch 3 Step 1256/1563 Loss: 1.483 | Acc: 46.338% (18639/40224)\n",
      "Epoch 3 Step 1257/1563 Loss: 1.483 | Acc: 46.333% (18652/40256)\n",
      "Epoch 3 Step 1258/1563 Loss: 1.483 | Acc: 46.339% (18669/40288)\n",
      "Epoch 3 Step 1259/1563 Loss: 1.483 | Acc: 46.339% (18684/40320)\n",
      "Epoch 3 Step 1260/1563 Loss: 1.483 | Acc: 46.342% (18700/40352)\n",
      "Epoch 3 Step 1261/1563 Loss: 1.484 | Acc: 46.338% (18713/40384)\n",
      "Epoch 3 Step 1262/1563 Loss: 1.483 | Acc: 46.343% (18730/40416)\n",
      "Epoch 3 Step 1263/1563 Loss: 1.484 | Acc: 46.343% (18745/40448)\n",
      "Epoch 3 Step 1264/1563 Loss: 1.483 | Acc: 46.346% (18761/40480)\n",
      "Epoch 3 Step 1265/1563 Loss: 1.484 | Acc: 46.342% (18774/40512)\n",
      "Epoch 3 Step 1266/1563 Loss: 1.484 | Acc: 46.350% (18792/40544)\n",
      "Epoch 3 Step 1267/1563 Loss: 1.484 | Acc: 46.348% (18806/40576)\n",
      "Epoch 3 Step 1268/1563 Loss: 1.484 | Acc: 46.346% (18820/40608)\n",
      "Epoch 3 Step 1269/1563 Loss: 1.484 | Acc: 46.351% (18837/40640)\n",
      "Epoch 3 Step 1270/1563 Loss: 1.484 | Acc: 46.346% (18850/40672)\n",
      "Epoch 3 Step 1271/1563 Loss: 1.484 | Acc: 46.344% (18864/40704)\n",
      "Epoch 3 Step 1272/1563 Loss: 1.484 | Acc: 46.355% (18883/40736)\n",
      "Epoch 3 Step 1273/1563 Loss: 1.484 | Acc: 46.348% (18895/40768)\n",
      "Epoch 3 Step 1274/1563 Loss: 1.484 | Acc: 46.348% (18910/40800)\n",
      "Epoch 3 Step 1275/1563 Loss: 1.484 | Acc: 46.351% (18926/40832)\n",
      "Epoch 3 Step 1276/1563 Loss: 1.484 | Acc: 46.361% (18945/40864)\n",
      "Epoch 3 Step 1277/1563 Loss: 1.484 | Acc: 46.357% (18958/40896)\n",
      "Epoch 3 Step 1278/1563 Loss: 1.483 | Acc: 46.364% (18976/40928)\n",
      "Epoch 3 Step 1279/1563 Loss: 1.484 | Acc: 46.367% (18992/40960)\n",
      "Epoch 3 Step 1280/1563 Loss: 1.484 | Acc: 46.358% (19003/40992)\n",
      "Epoch 3 Step 1281/1563 Loss: 1.484 | Acc: 46.366% (19021/41024)\n",
      "Epoch 3 Step 1282/1563 Loss: 1.484 | Acc: 46.364% (19035/41056)\n",
      "Epoch 3 Step 1283/1563 Loss: 1.484 | Acc: 46.357% (19047/41088)\n",
      "Epoch 3 Step 1284/1563 Loss: 1.484 | Acc: 46.350% (19059/41120)\n",
      "Epoch 3 Step 1285/1563 Loss: 1.484 | Acc: 46.340% (19070/41152)\n",
      "Epoch 3 Step 1286/1563 Loss: 1.484 | Acc: 46.353% (19090/41184)\n",
      "Epoch 3 Step 1287/1563 Loss: 1.484 | Acc: 46.370% (19112/41216)\n",
      "Epoch 3 Step 1288/1563 Loss: 1.483 | Acc: 46.376% (19129/41248)\n",
      "Epoch 3 Step 1289/1563 Loss: 1.483 | Acc: 46.383% (19147/41280)\n",
      "Epoch 3 Step 1290/1563 Loss: 1.483 | Acc: 46.391% (19165/41312)\n",
      "Epoch 3 Step 1291/1563 Loss: 1.483 | Acc: 46.401% (19184/41344)\n",
      "Epoch 3 Step 1292/1563 Loss: 1.483 | Acc: 46.401% (19199/41376)\n",
      "Epoch 3 Step 1293/1563 Loss: 1.483 | Acc: 46.399% (19213/41408)\n",
      "Epoch 3 Step 1294/1563 Loss: 1.483 | Acc: 46.395% (19226/41440)\n",
      "Epoch 3 Step 1295/1563 Loss: 1.483 | Acc: 46.386% (19237/41472)\n",
      "Epoch 3 Step 1296/1563 Loss: 1.483 | Acc: 46.388% (19253/41504)\n",
      "Epoch 3 Step 1297/1563 Loss: 1.483 | Acc: 46.379% (19264/41536)\n",
      "Epoch 3 Step 1298/1563 Loss: 1.483 | Acc: 46.377% (19278/41568)\n",
      "Epoch 3 Step 1299/1563 Loss: 1.483 | Acc: 46.373% (19291/41600)\n",
      "Epoch 3 Step 1300/1563 Loss: 1.483 | Acc: 46.380% (19309/41632)\n",
      "Epoch 3 Step 1301/1563 Loss: 1.483 | Acc: 46.385% (19326/41664)\n",
      "Epoch 3 Step 1302/1563 Loss: 1.483 | Acc: 46.379% (19338/41696)\n",
      "Epoch 3 Step 1303/1563 Loss: 1.483 | Acc: 46.389% (19357/41728)\n",
      "Epoch 3 Step 1304/1563 Loss: 1.483 | Acc: 46.379% (19368/41760)\n",
      "Epoch 3 Step 1305/1563 Loss: 1.483 | Acc: 46.382% (19384/41792)\n",
      "Epoch 3 Step 1306/1563 Loss: 1.483 | Acc: 46.385% (19400/41824)\n",
      "Epoch 3 Step 1307/1563 Loss: 1.483 | Acc: 46.397% (19420/41856)\n",
      "Epoch 3 Step 1308/1563 Loss: 1.483 | Acc: 46.405% (19438/41888)\n",
      "Epoch 3 Step 1309/1563 Loss: 1.483 | Acc: 46.391% (19447/41920)\n",
      "Epoch 3 Step 1310/1563 Loss: 1.483 | Acc: 46.398% (19465/41952)\n",
      "Epoch 3 Step 1311/1563 Loss: 1.483 | Acc: 46.384% (19474/41984)\n",
      "Epoch 3 Step 1312/1563 Loss: 1.483 | Acc: 46.387% (19490/42016)\n",
      "Epoch 3 Step 1313/1563 Loss: 1.483 | Acc: 46.387% (19505/42048)\n",
      "Epoch 3 Step 1314/1563 Loss: 1.483 | Acc: 46.395% (19523/42080)\n",
      "Epoch 3 Step 1315/1563 Loss: 1.483 | Acc: 46.393% (19537/42112)\n",
      "Epoch 3 Step 1316/1563 Loss: 1.483 | Acc: 46.396% (19553/42144)\n",
      "Epoch 3 Step 1317/1563 Loss: 1.483 | Acc: 46.406% (19572/42176)\n",
      "Epoch 3 Step 1318/1563 Loss: 1.483 | Acc: 46.406% (19587/42208)\n",
      "Epoch 3 Step 1319/1563 Loss: 1.483 | Acc: 46.402% (19600/42240)\n",
      "Epoch 3 Step 1320/1563 Loss: 1.483 | Acc: 46.397% (19613/42272)\n",
      "Epoch 3 Step 1321/1563 Loss: 1.483 | Acc: 46.400% (19629/42304)\n",
      "Epoch 3 Step 1322/1563 Loss: 1.482 | Acc: 46.403% (19645/42336)\n",
      "Epoch 3 Step 1323/1563 Loss: 1.482 | Acc: 46.405% (19661/42368)\n",
      "Epoch 3 Step 1324/1563 Loss: 1.482 | Acc: 46.410% (19678/42400)\n",
      "Epoch 3 Step 1325/1563 Loss: 1.482 | Acc: 46.427% (19700/42432)\n",
      "Epoch 3 Step 1326/1563 Loss: 1.482 | Acc: 46.418% (19711/42464)\n",
      "Epoch 3 Step 1327/1563 Loss: 1.482 | Acc: 46.418% (19726/42496)\n",
      "Epoch 3 Step 1328/1563 Loss: 1.482 | Acc: 46.414% (19739/42528)\n",
      "Epoch 3 Step 1329/1563 Loss: 1.482 | Acc: 46.419% (19756/42560)\n",
      "Epoch 3 Step 1330/1563 Loss: 1.482 | Acc: 46.417% (19770/42592)\n",
      "Epoch 3 Step 1331/1563 Loss: 1.482 | Acc: 46.408% (19781/42624)\n",
      "Epoch 3 Step 1332/1563 Loss: 1.482 | Acc: 46.404% (19794/42656)\n",
      "Epoch 3 Step 1333/1563 Loss: 1.482 | Acc: 46.411% (19812/42688)\n",
      "Epoch 3 Step 1334/1563 Loss: 1.481 | Acc: 46.419% (19830/42720)\n",
      "Epoch 3 Step 1335/1563 Loss: 1.481 | Acc: 46.426% (19848/42752)\n",
      "Epoch 3 Step 1336/1563 Loss: 1.481 | Acc: 46.417% (19859/42784)\n",
      "Epoch 3 Step 1337/1563 Loss: 1.481 | Acc: 46.417% (19874/42816)\n",
      "Epoch 3 Step 1338/1563 Loss: 1.481 | Acc: 46.420% (19890/42848)\n",
      "Epoch 3 Step 1339/1563 Loss: 1.481 | Acc: 46.434% (19911/42880)\n",
      "Epoch 3 Step 1340/1563 Loss: 1.481 | Acc: 46.437% (19927/42912)\n",
      "Epoch 3 Step 1341/1563 Loss: 1.481 | Acc: 46.451% (19948/42944)\n",
      "Epoch 3 Step 1342/1563 Loss: 1.480 | Acc: 46.465% (19969/42976)\n",
      "Epoch 3 Step 1343/1563 Loss: 1.480 | Acc: 46.468% (19985/43008)\n",
      "Epoch 3 Step 1344/1563 Loss: 1.480 | Acc: 46.457% (19995/43040)\n",
      "Epoch 3 Step 1345/1563 Loss: 1.480 | Acc: 46.457% (20010/43072)\n",
      "Epoch 3 Step 1346/1563 Loss: 1.480 | Acc: 46.455% (20024/43104)\n",
      "Epoch 3 Step 1347/1563 Loss: 1.480 | Acc: 46.453% (20038/43136)\n",
      "Epoch 3 Step 1348/1563 Loss: 1.480 | Acc: 46.451% (20052/43168)\n",
      "Epoch 3 Step 1349/1563 Loss: 1.480 | Acc: 46.451% (20067/43200)\n",
      "Epoch 3 Step 1350/1563 Loss: 1.480 | Acc: 46.456% (20084/43232)\n",
      "Epoch 3 Step 1351/1563 Loss: 1.480 | Acc: 46.468% (20104/43264)\n",
      "Epoch 3 Step 1352/1563 Loss: 1.480 | Acc: 46.468% (20119/43296)\n",
      "Epoch 3 Step 1353/1563 Loss: 1.480 | Acc: 46.469% (20134/43328)\n",
      "Epoch 3 Step 1354/1563 Loss: 1.480 | Acc: 46.467% (20148/43360)\n",
      "Epoch 3 Step 1355/1563 Loss: 1.480 | Acc: 46.474% (20166/43392)\n",
      "Epoch 3 Step 1356/1563 Loss: 1.480 | Acc: 46.481% (20184/43424)\n",
      "Epoch 3 Step 1357/1563 Loss: 1.480 | Acc: 46.479% (20198/43456)\n",
      "Epoch 3 Step 1358/1563 Loss: 1.480 | Acc: 46.463% (20206/43488)\n",
      "Epoch 3 Step 1359/1563 Loss: 1.480 | Acc: 46.461% (20220/43520)\n",
      "Epoch 3 Step 1360/1563 Loss: 1.480 | Acc: 46.466% (20237/43552)\n",
      "Epoch 3 Step 1361/1563 Loss: 1.480 | Acc: 46.471% (20254/43584)\n",
      "Epoch 3 Step 1362/1563 Loss: 1.479 | Acc: 46.483% (20274/43616)\n",
      "Epoch 3 Step 1363/1563 Loss: 1.480 | Acc: 46.481% (20288/43648)\n",
      "Epoch 3 Step 1364/1563 Loss: 1.480 | Acc: 46.481% (20303/43680)\n",
      "Epoch 3 Step 1365/1563 Loss: 1.479 | Acc: 46.477% (20316/43712)\n",
      "Epoch 3 Step 1366/1563 Loss: 1.479 | Acc: 46.473% (20329/43744)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 1367/1563 Loss: 1.479 | Acc: 46.466% (20341/43776)\n",
      "Epoch 3 Step 1368/1563 Loss: 1.479 | Acc: 46.473% (20359/43808)\n",
      "Epoch 3 Step 1369/1563 Loss: 1.479 | Acc: 46.474% (20374/43840)\n",
      "Epoch 3 Step 1370/1563 Loss: 1.479 | Acc: 46.465% (20385/43872)\n",
      "Epoch 3 Step 1371/1563 Loss: 1.480 | Acc: 46.454% (20395/43904)\n",
      "Epoch 3 Step 1372/1563 Loss: 1.480 | Acc: 46.461% (20413/43936)\n",
      "Epoch 3 Step 1373/1563 Loss: 1.479 | Acc: 46.466% (20430/43968)\n",
      "Epoch 3 Step 1374/1563 Loss: 1.479 | Acc: 46.464% (20444/44000)\n",
      "Epoch 3 Step 1375/1563 Loss: 1.480 | Acc: 46.464% (20459/44032)\n",
      "Epoch 3 Step 1376/1563 Loss: 1.480 | Acc: 46.455% (20470/44064)\n",
      "Epoch 3 Step 1377/1563 Loss: 1.480 | Acc: 46.449% (20482/44096)\n",
      "Epoch 3 Step 1378/1563 Loss: 1.480 | Acc: 46.451% (20498/44128)\n",
      "Epoch 3 Step 1379/1563 Loss: 1.480 | Acc: 46.442% (20509/44160)\n",
      "Epoch 3 Step 1380/1563 Loss: 1.480 | Acc: 46.441% (20523/44192)\n",
      "Epoch 3 Step 1381/1563 Loss: 1.480 | Acc: 46.434% (20535/44224)\n",
      "Epoch 3 Step 1382/1563 Loss: 1.480 | Acc: 46.430% (20548/44256)\n",
      "Epoch 3 Step 1383/1563 Loss: 1.481 | Acc: 46.430% (20563/44288)\n",
      "Epoch 3 Step 1384/1563 Loss: 1.480 | Acc: 46.435% (20580/44320)\n",
      "Epoch 3 Step 1385/1563 Loss: 1.481 | Acc: 46.431% (20593/44352)\n",
      "Epoch 3 Step 1386/1563 Loss: 1.481 | Acc: 46.431% (20608/44384)\n",
      "Epoch 3 Step 1387/1563 Loss: 1.481 | Acc: 46.436% (20625/44416)\n",
      "Epoch 3 Step 1388/1563 Loss: 1.481 | Acc: 46.436% (20640/44448)\n",
      "Epoch 3 Step 1389/1563 Loss: 1.481 | Acc: 46.437% (20655/44480)\n",
      "Epoch 3 Step 1390/1563 Loss: 1.480 | Acc: 46.441% (20672/44512)\n",
      "Epoch 3 Step 1391/1563 Loss: 1.480 | Acc: 46.453% (20692/44544)\n",
      "Epoch 3 Step 1392/1563 Loss: 1.480 | Acc: 46.458% (20709/44576)\n",
      "Epoch 3 Step 1393/1563 Loss: 1.480 | Acc: 46.460% (20725/44608)\n",
      "Epoch 3 Step 1394/1563 Loss: 1.480 | Acc: 46.447% (20734/44640)\n",
      "Epoch 3 Step 1395/1563 Loss: 1.480 | Acc: 46.447% (20749/44672)\n",
      "Epoch 3 Step 1396/1563 Loss: 1.480 | Acc: 46.459% (20769/44704)\n",
      "Epoch 3 Step 1397/1563 Loss: 1.480 | Acc: 46.466% (20787/44736)\n",
      "Epoch 3 Step 1398/1563 Loss: 1.480 | Acc: 46.471% (20804/44768)\n",
      "Epoch 3 Step 1399/1563 Loss: 1.480 | Acc: 46.469% (20818/44800)\n",
      "Epoch 3 Step 1400/1563 Loss: 1.480 | Acc: 46.469% (20833/44832)\n",
      "Epoch 3 Step 1401/1563 Loss: 1.480 | Acc: 46.476% (20851/44864)\n",
      "Epoch 3 Step 1402/1563 Loss: 1.480 | Acc: 46.476% (20866/44896)\n",
      "Epoch 3 Step 1403/1563 Loss: 1.480 | Acc: 46.485% (20885/44928)\n",
      "Epoch 3 Step 1404/1563 Loss: 1.480 | Acc: 46.479% (20897/44960)\n",
      "Epoch 3 Step 1405/1563 Loss: 1.480 | Acc: 46.488% (20916/44992)\n",
      "Epoch 3 Step 1406/1563 Loss: 1.480 | Acc: 46.486% (20930/45024)\n",
      "Epoch 3 Step 1407/1563 Loss: 1.480 | Acc: 46.487% (20945/45056)\n",
      "Epoch 3 Step 1408/1563 Loss: 1.479 | Acc: 46.487% (20960/45088)\n",
      "Epoch 3 Step 1409/1563 Loss: 1.480 | Acc: 46.485% (20974/45120)\n",
      "Epoch 3 Step 1410/1563 Loss: 1.480 | Acc: 46.485% (20989/45152)\n",
      "Epoch 3 Step 1411/1563 Loss: 1.480 | Acc: 46.488% (21005/45184)\n",
      "Epoch 3 Step 1412/1563 Loss: 1.479 | Acc: 46.503% (21027/45216)\n",
      "Epoch 3 Step 1413/1563 Loss: 1.479 | Acc: 46.510% (21045/45248)\n",
      "Epoch 3 Step 1414/1563 Loss: 1.479 | Acc: 46.515% (21062/45280)\n",
      "Epoch 3 Step 1415/1563 Loss: 1.479 | Acc: 46.511% (21075/45312)\n",
      "Epoch 3 Step 1416/1563 Loss: 1.479 | Acc: 46.511% (21090/45344)\n",
      "Epoch 3 Step 1417/1563 Loss: 1.480 | Acc: 46.505% (21102/45376)\n",
      "Epoch 3 Step 1418/1563 Loss: 1.480 | Acc: 46.505% (21117/45408)\n",
      "Epoch 3 Step 1419/1563 Loss: 1.480 | Acc: 46.514% (21136/45440)\n",
      "Epoch 3 Step 1420/1563 Loss: 1.480 | Acc: 46.517% (21152/45472)\n",
      "Epoch 3 Step 1421/1563 Loss: 1.479 | Acc: 46.526% (21171/45504)\n",
      "Epoch 3 Step 1422/1563 Loss: 1.479 | Acc: 46.524% (21185/45536)\n",
      "Epoch 3 Step 1423/1563 Loss: 1.480 | Acc: 46.519% (21198/45568)\n",
      "Epoch 3 Step 1424/1563 Loss: 1.480 | Acc: 46.518% (21212/45600)\n",
      "Epoch 3 Step 1425/1563 Loss: 1.480 | Acc: 46.513% (21225/45632)\n",
      "Epoch 3 Step 1426/1563 Loss: 1.480 | Acc: 46.518% (21242/45664)\n",
      "Epoch 3 Step 1427/1563 Loss: 1.480 | Acc: 46.516% (21256/45696)\n",
      "Epoch 3 Step 1428/1563 Loss: 1.480 | Acc: 46.523% (21274/45728)\n",
      "Epoch 3 Step 1429/1563 Loss: 1.480 | Acc: 46.525% (21290/45760)\n",
      "Epoch 3 Step 1430/1563 Loss: 1.480 | Acc: 46.528% (21306/45792)\n",
      "Epoch 3 Step 1431/1563 Loss: 1.480 | Acc: 46.528% (21321/45824)\n",
      "Epoch 3 Step 1432/1563 Loss: 1.480 | Acc: 46.528% (21336/45856)\n",
      "Epoch 3 Step 1433/1563 Loss: 1.480 | Acc: 46.518% (21346/45888)\n",
      "Epoch 3 Step 1434/1563 Loss: 1.480 | Acc: 46.520% (21362/45920)\n",
      "Epoch 3 Step 1435/1563 Loss: 1.480 | Acc: 46.514% (21374/45952)\n",
      "Epoch 3 Step 1436/1563 Loss: 1.480 | Acc: 46.521% (21392/45984)\n",
      "Epoch 3 Step 1437/1563 Loss: 1.480 | Acc: 46.525% (21409/46016)\n",
      "Epoch 3 Step 1438/1563 Loss: 1.480 | Acc: 46.517% (21420/46048)\n",
      "Epoch 3 Step 1439/1563 Loss: 1.481 | Acc: 46.504% (21429/46080)\n",
      "Epoch 3 Step 1440/1563 Loss: 1.481 | Acc: 46.504% (21444/46112)\n",
      "Epoch 3 Step 1441/1563 Loss: 1.481 | Acc: 46.509% (21461/46144)\n",
      "Epoch 3 Step 1442/1563 Loss: 1.480 | Acc: 46.507% (21475/46176)\n",
      "Epoch 3 Step 1443/1563 Loss: 1.480 | Acc: 46.509% (21491/46208)\n",
      "Epoch 3 Step 1444/1563 Loss: 1.480 | Acc: 46.505% (21504/46240)\n",
      "Epoch 3 Step 1445/1563 Loss: 1.480 | Acc: 46.510% (21521/46272)\n",
      "Epoch 3 Step 1446/1563 Loss: 1.480 | Acc: 46.504% (21533/46304)\n",
      "Epoch 3 Step 1447/1563 Loss: 1.480 | Acc: 46.502% (21547/46336)\n",
      "Epoch 3 Step 1448/1563 Loss: 1.480 | Acc: 46.493% (21558/46368)\n",
      "Epoch 3 Step 1449/1563 Loss: 1.480 | Acc: 46.489% (21571/46400)\n",
      "Epoch 3 Step 1450/1563 Loss: 1.480 | Acc: 46.502% (21592/46432)\n",
      "Epoch 3 Step 1451/1563 Loss: 1.480 | Acc: 46.498% (21605/46464)\n",
      "Epoch 3 Step 1452/1563 Loss: 1.480 | Acc: 46.505% (21623/46496)\n",
      "Epoch 3 Step 1453/1563 Loss: 1.480 | Acc: 46.501% (21636/46528)\n",
      "Epoch 3 Step 1454/1563 Loss: 1.480 | Acc: 46.499% (21650/46560)\n",
      "Epoch 3 Step 1455/1563 Loss: 1.480 | Acc: 46.514% (21672/46592)\n",
      "Epoch 3 Step 1456/1563 Loss: 1.480 | Acc: 46.508% (21684/46624)\n",
      "Epoch 3 Step 1457/1563 Loss: 1.480 | Acc: 46.508% (21699/46656)\n",
      "Epoch 3 Step 1458/1563 Loss: 1.480 | Acc: 46.504% (21712/46688)\n",
      "Epoch 3 Step 1459/1563 Loss: 1.480 | Acc: 46.507% (21728/46720)\n",
      "Epoch 3 Step 1460/1563 Loss: 1.480 | Acc: 46.501% (21740/46752)\n",
      "Epoch 3 Step 1461/1563 Loss: 1.480 | Acc: 46.505% (21757/46784)\n",
      "Epoch 3 Step 1462/1563 Loss: 1.480 | Acc: 46.505% (21772/46816)\n",
      "Epoch 3 Step 1463/1563 Loss: 1.480 | Acc: 46.514% (21791/46848)\n",
      "Epoch 3 Step 1464/1563 Loss: 1.480 | Acc: 46.517% (21807/46880)\n",
      "Epoch 3 Step 1465/1563 Loss: 1.480 | Acc: 46.523% (21825/46912)\n",
      "Epoch 3 Step 1466/1563 Loss: 1.480 | Acc: 46.509% (21833/46944)\n",
      "Epoch 3 Step 1467/1563 Loss: 1.480 | Acc: 46.511% (21849/46976)\n",
      "Epoch 3 Step 1468/1563 Loss: 1.480 | Acc: 46.520% (21868/47008)\n",
      "Epoch 3 Step 1469/1563 Loss: 1.480 | Acc: 46.516% (21881/47040)\n",
      "Epoch 3 Step 1470/1563 Loss: 1.479 | Acc: 46.531% (21903/47072)\n",
      "Epoch 3 Step 1471/1563 Loss: 1.480 | Acc: 46.529% (21917/47104)\n",
      "Epoch 3 Step 1472/1563 Loss: 1.480 | Acc: 46.525% (21930/47136)\n",
      "Epoch 3 Step 1473/1563 Loss: 1.480 | Acc: 46.525% (21945/47168)\n",
      "Epoch 3 Step 1474/1563 Loss: 1.480 | Acc: 46.521% (21958/47200)\n",
      "Epoch 3 Step 1475/1563 Loss: 1.480 | Acc: 46.515% (21970/47232)\n",
      "Epoch 3 Step 1476/1563 Loss: 1.480 | Acc: 46.509% (21982/47264)\n",
      "Epoch 3 Step 1477/1563 Loss: 1.480 | Acc: 46.507% (21996/47296)\n",
      "Epoch 3 Step 1478/1563 Loss: 1.480 | Acc: 46.509% (22012/47328)\n",
      "Epoch 3 Step 1479/1563 Loss: 1.480 | Acc: 46.514% (22029/47360)\n",
      "Epoch 3 Step 1480/1563 Loss: 1.480 | Acc: 46.510% (22042/47392)\n",
      "Epoch 3 Step 1481/1563 Loss: 1.480 | Acc: 46.508% (22056/47424)\n",
      "Epoch 3 Step 1482/1563 Loss: 1.480 | Acc: 46.510% (22072/47456)\n",
      "Epoch 3 Step 1483/1563 Loss: 1.480 | Acc: 46.500% (22082/47488)\n",
      "Epoch 3 Step 1484/1563 Loss: 1.480 | Acc: 46.498% (22096/47520)\n",
      "Epoch 3 Step 1485/1563 Loss: 1.480 | Acc: 46.488% (22106/47552)\n",
      "Epoch 3 Step 1486/1563 Loss: 1.480 | Acc: 46.482% (22118/47584)\n",
      "Epoch 3 Step 1487/1563 Loss: 1.480 | Acc: 46.486% (22135/47616)\n",
      "Epoch 3 Step 1488/1563 Loss: 1.480 | Acc: 46.483% (22148/47648)\n",
      "Epoch 3 Step 1489/1563 Loss: 1.480 | Acc: 46.485% (22164/47680)\n",
      "Epoch 3 Step 1490/1563 Loss: 1.480 | Acc: 46.481% (22177/47712)\n",
      "Epoch 3 Step 1491/1563 Loss: 1.480 | Acc: 46.477% (22190/47744)\n",
      "Epoch 3 Step 1492/1563 Loss: 1.480 | Acc: 46.473% (22203/47776)\n",
      "Epoch 3 Step 1493/1563 Loss: 1.480 | Acc: 46.478% (22220/47808)\n",
      "Epoch 3 Step 1494/1563 Loss: 1.480 | Acc: 46.478% (22235/47840)\n",
      "Epoch 3 Step 1495/1563 Loss: 1.480 | Acc: 46.476% (22249/47872)\n",
      "Epoch 3 Step 1496/1563 Loss: 1.480 | Acc: 46.495% (22273/47904)\n",
      "Epoch 3 Step 1497/1563 Loss: 1.480 | Acc: 46.489% (22285/47936)\n",
      "Epoch 3 Step 1498/1563 Loss: 1.480 | Acc: 46.483% (22297/47968)\n",
      "Epoch 3 Step 1499/1563 Loss: 1.480 | Acc: 46.477% (22309/48000)\n",
      "Epoch 3 Step 1500/1563 Loss: 1.480 | Acc: 46.465% (22318/48032)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 1501/1563 Loss: 1.480 | Acc: 46.467% (22334/48064)\n",
      "Epoch 3 Step 1502/1563 Loss: 1.480 | Acc: 46.470% (22350/48096)\n",
      "Epoch 3 Step 1503/1563 Loss: 1.480 | Acc: 46.470% (22365/48128)\n",
      "Epoch 3 Step 1504/1563 Loss: 1.480 | Acc: 46.464% (22377/48160)\n",
      "Epoch 3 Step 1505/1563 Loss: 1.480 | Acc: 46.464% (22392/48192)\n",
      "Epoch 3 Step 1506/1563 Loss: 1.480 | Acc: 46.469% (22409/48224)\n",
      "Epoch 3 Step 1507/1563 Loss: 1.480 | Acc: 46.477% (22428/48256)\n",
      "Epoch 3 Step 1508/1563 Loss: 1.480 | Acc: 46.475% (22442/48288)\n",
      "Epoch 3 Step 1509/1563 Loss: 1.480 | Acc: 46.471% (22455/48320)\n",
      "Epoch 3 Step 1510/1563 Loss: 1.480 | Acc: 46.480% (22474/48352)\n",
      "Epoch 3 Step 1511/1563 Loss: 1.480 | Acc: 46.491% (22494/48384)\n",
      "Epoch 3 Step 1512/1563 Loss: 1.480 | Acc: 46.489% (22508/48416)\n",
      "Epoch 3 Step 1513/1563 Loss: 1.480 | Acc: 46.493% (22525/48448)\n",
      "Epoch 3 Step 1514/1563 Loss: 1.480 | Acc: 46.502% (22544/48480)\n",
      "Epoch 3 Step 1515/1563 Loss: 1.480 | Acc: 46.504% (22560/48512)\n",
      "Epoch 3 Step 1516/1563 Loss: 1.480 | Acc: 46.500% (22573/48544)\n",
      "Epoch 3 Step 1517/1563 Loss: 1.480 | Acc: 46.496% (22586/48576)\n",
      "Epoch 3 Step 1518/1563 Loss: 1.480 | Acc: 46.499% (22602/48608)\n",
      "Epoch 3 Step 1519/1563 Loss: 1.479 | Acc: 46.509% (22622/48640)\n",
      "Epoch 3 Step 1520/1563 Loss: 1.480 | Acc: 46.501% (22633/48672)\n",
      "Epoch 3 Step 1521/1563 Loss: 1.479 | Acc: 46.505% (22650/48704)\n",
      "Epoch 3 Step 1522/1563 Loss: 1.479 | Acc: 46.506% (22665/48736)\n",
      "Epoch 3 Step 1523/1563 Loss: 1.479 | Acc: 46.516% (22685/48768)\n",
      "Epoch 3 Step 1524/1563 Loss: 1.479 | Acc: 46.520% (22702/48800)\n",
      "Epoch 3 Step 1525/1563 Loss: 1.479 | Acc: 46.519% (22716/48832)\n",
      "Epoch 3 Step 1526/1563 Loss: 1.479 | Acc: 46.513% (22728/48864)\n",
      "Epoch 3 Step 1527/1563 Loss: 1.480 | Acc: 46.511% (22742/48896)\n",
      "Epoch 3 Step 1528/1563 Loss: 1.479 | Acc: 46.515% (22759/48928)\n",
      "Epoch 3 Step 1529/1563 Loss: 1.480 | Acc: 46.505% (22769/48960)\n",
      "Epoch 3 Step 1530/1563 Loss: 1.480 | Acc: 46.508% (22785/48992)\n",
      "Epoch 3 Step 1531/1563 Loss: 1.480 | Acc: 46.508% (22800/49024)\n",
      "Epoch 3 Step 1532/1563 Loss: 1.479 | Acc: 46.510% (22816/49056)\n",
      "Epoch 3 Step 1533/1563 Loss: 1.480 | Acc: 46.504% (22828/49088)\n",
      "Epoch 3 Step 1534/1563 Loss: 1.480 | Acc: 46.504% (22843/49120)\n",
      "Epoch 3 Step 1535/1563 Loss: 1.480 | Acc: 46.505% (22858/49152)\n",
      "Epoch 3 Step 1536/1563 Loss: 1.480 | Acc: 46.505% (22873/49184)\n",
      "Epoch 3 Step 1537/1563 Loss: 1.480 | Acc: 46.501% (22886/49216)\n",
      "Epoch 3 Step 1538/1563 Loss: 1.480 | Acc: 46.499% (22900/49248)\n",
      "Epoch 3 Step 1539/1563 Loss: 1.480 | Acc: 46.506% (22918/49280)\n",
      "Epoch 3 Step 1540/1563 Loss: 1.480 | Acc: 46.506% (22933/49312)\n",
      "Epoch 3 Step 1541/1563 Loss: 1.479 | Acc: 46.510% (22950/49344)\n",
      "Epoch 3 Step 1542/1563 Loss: 1.479 | Acc: 46.500% (22960/49376)\n",
      "Epoch 3 Step 1543/1563 Loss: 1.479 | Acc: 46.499% (22974/49408)\n",
      "Epoch 3 Step 1544/1563 Loss: 1.479 | Acc: 46.501% (22990/49440)\n",
      "Epoch 3 Step 1545/1563 Loss: 1.479 | Acc: 46.507% (23008/49472)\n",
      "Epoch 3 Step 1546/1563 Loss: 1.479 | Acc: 46.501% (23020/49504)\n",
      "Epoch 3 Step 1547/1563 Loss: 1.479 | Acc: 46.508% (23038/49536)\n",
      "Epoch 3 Step 1548/1563 Loss: 1.479 | Acc: 46.518% (23058/49568)\n",
      "Epoch 3 Step 1549/1563 Loss: 1.479 | Acc: 46.516% (23072/49600)\n",
      "Epoch 3 Step 1550/1563 Loss: 1.479 | Acc: 46.514% (23086/49632)\n",
      "Epoch 3 Step 1551/1563 Loss: 1.479 | Acc: 46.513% (23100/49664)\n",
      "Epoch 3 Step 1552/1563 Loss: 1.479 | Acc: 46.517% (23117/49696)\n",
      "Epoch 3 Step 1553/1563 Loss: 1.479 | Acc: 46.517% (23132/49728)\n",
      "Epoch 3 Step 1554/1563 Loss: 1.479 | Acc: 46.521% (23149/49760)\n",
      "Epoch 3 Step 1555/1563 Loss: 1.479 | Acc: 46.518% (23162/49792)\n",
      "Epoch 3 Step 1556/1563 Loss: 1.479 | Acc: 46.520% (23178/49824)\n",
      "Epoch 3 Step 1557/1563 Loss: 1.479 | Acc: 46.526% (23196/49856)\n",
      "Epoch 3 Step 1558/1563 Loss: 1.479 | Acc: 46.520% (23208/49888)\n",
      "Epoch 3 Step 1559/1563 Loss: 1.480 | Acc: 46.514% (23220/49920)\n",
      "Epoch 3 Step 1560/1563 Loss: 1.480 | Acc: 46.511% (23233/49952)\n",
      "Epoch 3 Step 1561/1563 Loss: 1.480 | Acc: 46.511% (23248/49984)\n",
      "Epoch 3 Step 1562/1563 Loss: 1.480 | Acc: 46.506% (23253/50000)\n",
      "Epoch 3 Step 0/313 Test Loss: 1.274 | Test Acc: 53.125% (17/32)\n",
      "Epoch 3 Step 1/313 Test Loss: 1.447 | Test Acc: 43.750% (28/64)\n",
      "Epoch 3 Step 2/313 Test Loss: 1.423 | Test Acc: 48.958% (47/96)\n",
      "Epoch 3 Step 3/313 Test Loss: 1.402 | Test Acc: 50.000% (64/128)\n",
      "Epoch 3 Step 4/313 Test Loss: 1.405 | Test Acc: 50.625% (81/160)\n",
      "Epoch 3 Step 5/313 Test Loss: 1.418 | Test Acc: 49.479% (95/192)\n",
      "Epoch 3 Step 6/313 Test Loss: 1.479 | Test Acc: 47.768% (107/224)\n",
      "Epoch 3 Step 7/313 Test Loss: 1.482 | Test Acc: 48.047% (123/256)\n",
      "Epoch 3 Step 8/313 Test Loss: 1.472 | Test Acc: 48.264% (139/288)\n",
      "Epoch 3 Step 9/313 Test Loss: 1.445 | Test Acc: 48.438% (155/320)\n",
      "Epoch 3 Step 10/313 Test Loss: 1.435 | Test Acc: 47.443% (167/352)\n",
      "Epoch 3 Step 11/313 Test Loss: 1.457 | Test Acc: 46.615% (179/384)\n",
      "Epoch 3 Step 12/313 Test Loss: 1.455 | Test Acc: 46.154% (192/416)\n",
      "Epoch 3 Step 13/313 Test Loss: 1.459 | Test Acc: 45.759% (205/448)\n",
      "Epoch 3 Step 14/313 Test Loss: 1.460 | Test Acc: 45.625% (219/480)\n",
      "Epoch 3 Step 15/313 Test Loss: 1.447 | Test Acc: 46.094% (236/512)\n",
      "Epoch 3 Step 16/313 Test Loss: 1.440 | Test Acc: 45.772% (249/544)\n",
      "Epoch 3 Step 17/313 Test Loss: 1.427 | Test Acc: 46.007% (265/576)\n",
      "Epoch 3 Step 18/313 Test Loss: 1.429 | Test Acc: 46.875% (285/608)\n",
      "Epoch 3 Step 19/313 Test Loss: 1.412 | Test Acc: 47.500% (304/640)\n",
      "Epoch 3 Step 20/313 Test Loss: 1.404 | Test Acc: 47.768% (321/672)\n",
      "Epoch 3 Step 21/313 Test Loss: 1.417 | Test Acc: 47.017% (331/704)\n",
      "Epoch 3 Step 22/313 Test Loss: 1.413 | Test Acc: 47.283% (348/736)\n",
      "Epoch 3 Step 23/313 Test Loss: 1.411 | Test Acc: 47.526% (365/768)\n",
      "Epoch 3 Step 24/313 Test Loss: 1.413 | Test Acc: 47.500% (380/800)\n",
      "Epoch 3 Step 25/313 Test Loss: 1.404 | Test Acc: 48.438% (403/832)\n",
      "Epoch 3 Step 26/313 Test Loss: 1.401 | Test Acc: 48.611% (420/864)\n",
      "Epoch 3 Step 27/313 Test Loss: 1.392 | Test Acc: 49.107% (440/896)\n",
      "Epoch 3 Step 28/313 Test Loss: 1.392 | Test Acc: 48.707% (452/928)\n",
      "Epoch 3 Step 29/313 Test Loss: 1.382 | Test Acc: 48.854% (469/960)\n",
      "Epoch 3 Step 30/313 Test Loss: 1.375 | Test Acc: 49.294% (489/992)\n",
      "Epoch 3 Step 31/313 Test Loss: 1.366 | Test Acc: 49.512% (507/1024)\n",
      "Epoch 3 Step 32/313 Test Loss: 1.374 | Test Acc: 49.527% (523/1056)\n",
      "Epoch 3 Step 33/313 Test Loss: 1.371 | Test Acc: 49.724% (541/1088)\n",
      "Epoch 3 Step 34/313 Test Loss: 1.360 | Test Acc: 50.268% (563/1120)\n",
      "Epoch 3 Step 35/313 Test Loss: 1.362 | Test Acc: 50.174% (578/1152)\n",
      "Epoch 3 Step 36/313 Test Loss: 1.361 | Test Acc: 50.338% (596/1184)\n",
      "Epoch 3 Step 37/313 Test Loss: 1.362 | Test Acc: 50.576% (615/1216)\n",
      "Epoch 3 Step 38/313 Test Loss: 1.369 | Test Acc: 50.481% (630/1248)\n",
      "Epoch 3 Step 39/313 Test Loss: 1.371 | Test Acc: 50.312% (644/1280)\n",
      "Epoch 3 Step 40/313 Test Loss: 1.375 | Test Acc: 49.924% (655/1312)\n",
      "Epoch 3 Step 41/313 Test Loss: 1.377 | Test Acc: 49.777% (669/1344)\n",
      "Epoch 3 Step 42/313 Test Loss: 1.370 | Test Acc: 50.000% (688/1376)\n",
      "Epoch 3 Step 43/313 Test Loss: 1.377 | Test Acc: 49.787% (701/1408)\n",
      "Epoch 3 Step 44/313 Test Loss: 1.382 | Test Acc: 49.583% (714/1440)\n",
      "Epoch 3 Step 45/313 Test Loss: 1.379 | Test Acc: 49.592% (730/1472)\n",
      "Epoch 3 Step 46/313 Test Loss: 1.378 | Test Acc: 49.601% (746/1504)\n",
      "Epoch 3 Step 47/313 Test Loss: 1.377 | Test Acc: 49.609% (762/1536)\n",
      "Epoch 3 Step 48/313 Test Loss: 1.372 | Test Acc: 49.809% (781/1568)\n",
      "Epoch 3 Step 49/313 Test Loss: 1.375 | Test Acc: 49.812% (797/1600)\n",
      "Epoch 3 Step 50/313 Test Loss: 1.382 | Test Acc: 49.755% (812/1632)\n",
      "Epoch 3 Step 51/313 Test Loss: 1.380 | Test Acc: 49.820% (829/1664)\n",
      "Epoch 3 Step 52/313 Test Loss: 1.377 | Test Acc: 50.000% (848/1696)\n",
      "Epoch 3 Step 53/313 Test Loss: 1.381 | Test Acc: 49.884% (862/1728)\n",
      "Epoch 3 Step 54/313 Test Loss: 1.382 | Test Acc: 49.773% (876/1760)\n",
      "Epoch 3 Step 55/313 Test Loss: 1.380 | Test Acc: 49.721% (891/1792)\n",
      "Epoch 3 Step 56/313 Test Loss: 1.384 | Test Acc: 49.397% (901/1824)\n",
      "Epoch 3 Step 57/313 Test Loss: 1.389 | Test Acc: 49.353% (916/1856)\n",
      "Epoch 3 Step 58/313 Test Loss: 1.387 | Test Acc: 49.470% (934/1888)\n",
      "Epoch 3 Step 59/313 Test Loss: 1.390 | Test Acc: 49.427% (949/1920)\n",
      "Epoch 3 Step 60/313 Test Loss: 1.390 | Test Acc: 49.436% (965/1952)\n",
      "Epoch 3 Step 61/313 Test Loss: 1.392 | Test Acc: 49.546% (983/1984)\n",
      "Epoch 3 Step 62/313 Test Loss: 1.394 | Test Acc: 49.454% (997/2016)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 63/313 Test Loss: 1.393 | Test Acc: 49.414% (1012/2048)\n",
      "Epoch 3 Step 64/313 Test Loss: 1.391 | Test Acc: 49.375% (1027/2080)\n",
      "Epoch 3 Step 65/313 Test Loss: 1.389 | Test Acc: 49.479% (1045/2112)\n",
      "Epoch 3 Step 66/313 Test Loss: 1.390 | Test Acc: 49.534% (1062/2144)\n",
      "Epoch 3 Step 67/313 Test Loss: 1.394 | Test Acc: 49.357% (1074/2176)\n",
      "Epoch 3 Step 68/313 Test Loss: 1.395 | Test Acc: 49.411% (1091/2208)\n",
      "Epoch 3 Step 69/313 Test Loss: 1.392 | Test Acc: 49.554% (1110/2240)\n",
      "Epoch 3 Step 70/313 Test Loss: 1.393 | Test Acc: 49.692% (1129/2272)\n",
      "Epoch 3 Step 71/313 Test Loss: 1.394 | Test Acc: 49.653% (1144/2304)\n",
      "Epoch 3 Step 72/313 Test Loss: 1.398 | Test Acc: 49.572% (1158/2336)\n",
      "Epoch 3 Step 73/313 Test Loss: 1.397 | Test Acc: 49.662% (1176/2368)\n",
      "Epoch 3 Step 74/313 Test Loss: 1.397 | Test Acc: 49.750% (1194/2400)\n",
      "Epoch 3 Step 75/313 Test Loss: 1.397 | Test Acc: 49.712% (1209/2432)\n",
      "Epoch 3 Step 76/313 Test Loss: 1.397 | Test Acc: 49.716% (1225/2464)\n",
      "Epoch 3 Step 77/313 Test Loss: 1.395 | Test Acc: 49.840% (1244/2496)\n",
      "Epoch 3 Step 78/313 Test Loss: 1.398 | Test Acc: 49.802% (1259/2528)\n",
      "Epoch 3 Step 79/313 Test Loss: 1.402 | Test Acc: 49.766% (1274/2560)\n",
      "Epoch 3 Step 80/313 Test Loss: 1.403 | Test Acc: 49.653% (1287/2592)\n",
      "Epoch 3 Step 81/313 Test Loss: 1.402 | Test Acc: 49.657% (1303/2624)\n",
      "Epoch 3 Step 82/313 Test Loss: 1.404 | Test Acc: 49.661% (1319/2656)\n",
      "Epoch 3 Step 83/313 Test Loss: 1.401 | Test Acc: 49.814% (1339/2688)\n",
      "Epoch 3 Step 84/313 Test Loss: 1.401 | Test Acc: 49.853% (1356/2720)\n",
      "Epoch 3 Step 85/313 Test Loss: 1.402 | Test Acc: 49.746% (1369/2752)\n",
      "Epoch 3 Step 86/313 Test Loss: 1.402 | Test Acc: 49.749% (1385/2784)\n",
      "Epoch 3 Step 87/313 Test Loss: 1.401 | Test Acc: 49.787% (1402/2816)\n",
      "Epoch 3 Step 88/313 Test Loss: 1.403 | Test Acc: 49.789% (1418/2848)\n",
      "Epoch 3 Step 89/313 Test Loss: 1.402 | Test Acc: 49.722% (1432/2880)\n",
      "Epoch 3 Step 90/313 Test Loss: 1.403 | Test Acc: 49.725% (1448/2912)\n",
      "Epoch 3 Step 91/313 Test Loss: 1.399 | Test Acc: 49.898% (1469/2944)\n",
      "Epoch 3 Step 92/313 Test Loss: 1.400 | Test Acc: 49.832% (1483/2976)\n",
      "Epoch 3 Step 93/313 Test Loss: 1.399 | Test Acc: 49.867% (1500/3008)\n",
      "Epoch 3 Step 94/313 Test Loss: 1.399 | Test Acc: 49.901% (1517/3040)\n",
      "Epoch 3 Step 95/313 Test Loss: 1.399 | Test Acc: 49.870% (1532/3072)\n",
      "Epoch 3 Step 96/313 Test Loss: 1.398 | Test Acc: 49.774% (1545/3104)\n",
      "Epoch 3 Step 97/313 Test Loss: 1.399 | Test Acc: 49.617% (1556/3136)\n",
      "Epoch 3 Step 98/313 Test Loss: 1.402 | Test Acc: 49.590% (1571/3168)\n",
      "Epoch 3 Step 99/313 Test Loss: 1.403 | Test Acc: 49.531% (1585/3200)\n",
      "Epoch 3 Step 100/313 Test Loss: 1.406 | Test Acc: 49.412% (1597/3232)\n",
      "Epoch 3 Step 101/313 Test Loss: 1.403 | Test Acc: 49.540% (1617/3264)\n",
      "Epoch 3 Step 102/313 Test Loss: 1.402 | Test Acc: 49.545% (1633/3296)\n",
      "Epoch 3 Step 103/313 Test Loss: 1.402 | Test Acc: 49.579% (1650/3328)\n",
      "Epoch 3 Step 104/313 Test Loss: 1.402 | Test Acc: 49.613% (1667/3360)\n",
      "Epoch 3 Step 105/313 Test Loss: 1.399 | Test Acc: 49.764% (1688/3392)\n",
      "Epoch 3 Step 106/313 Test Loss: 1.400 | Test Acc: 49.708% (1702/3424)\n",
      "Epoch 3 Step 107/313 Test Loss: 1.400 | Test Acc: 49.769% (1720/3456)\n",
      "Epoch 3 Step 108/313 Test Loss: 1.396 | Test Acc: 50.029% (1745/3488)\n",
      "Epoch 3 Step 109/313 Test Loss: 1.397 | Test Acc: 49.886% (1756/3520)\n",
      "Epoch 3 Step 110/313 Test Loss: 1.396 | Test Acc: 49.916% (1773/3552)\n",
      "Epoch 3 Step 111/313 Test Loss: 1.395 | Test Acc: 50.000% (1792/3584)\n",
      "Epoch 3 Step 112/313 Test Loss: 1.395 | Test Acc: 50.028% (1809/3616)\n",
      "Epoch 3 Step 113/313 Test Loss: 1.394 | Test Acc: 49.918% (1821/3648)\n",
      "Epoch 3 Step 114/313 Test Loss: 1.393 | Test Acc: 49.973% (1839/3680)\n",
      "Epoch 3 Step 115/313 Test Loss: 1.392 | Test Acc: 50.027% (1857/3712)\n",
      "Epoch 3 Step 116/313 Test Loss: 1.390 | Test Acc: 50.080% (1875/3744)\n",
      "Epoch 3 Step 117/313 Test Loss: 1.391 | Test Acc: 50.079% (1891/3776)\n",
      "Epoch 3 Step 118/313 Test Loss: 1.391 | Test Acc: 50.079% (1907/3808)\n",
      "Epoch 3 Step 119/313 Test Loss: 1.388 | Test Acc: 50.156% (1926/3840)\n",
      "Epoch 3 Step 120/313 Test Loss: 1.386 | Test Acc: 50.207% (1944/3872)\n",
      "Epoch 3 Step 121/313 Test Loss: 1.385 | Test Acc: 50.282% (1963/3904)\n",
      "Epoch 3 Step 122/313 Test Loss: 1.386 | Test Acc: 50.229% (1977/3936)\n",
      "Epoch 3 Step 123/313 Test Loss: 1.385 | Test Acc: 50.277% (1995/3968)\n",
      "Epoch 3 Step 124/313 Test Loss: 1.388 | Test Acc: 50.200% (2008/4000)\n",
      "Epoch 3 Step 125/313 Test Loss: 1.388 | Test Acc: 50.248% (2026/4032)\n",
      "Epoch 3 Step 126/313 Test Loss: 1.390 | Test Acc: 50.172% (2039/4064)\n",
      "Epoch 3 Step 127/313 Test Loss: 1.387 | Test Acc: 50.269% (2059/4096)\n",
      "Epoch 3 Step 128/313 Test Loss: 1.388 | Test Acc: 50.266% (2075/4128)\n",
      "Epoch 3 Step 129/313 Test Loss: 1.388 | Test Acc: 50.312% (2093/4160)\n",
      "Epoch 3 Step 130/313 Test Loss: 1.386 | Test Acc: 50.406% (2113/4192)\n",
      "Epoch 3 Step 131/313 Test Loss: 1.386 | Test Acc: 50.450% (2131/4224)\n",
      "Epoch 3 Step 132/313 Test Loss: 1.385 | Test Acc: 50.423% (2146/4256)\n",
      "Epoch 3 Step 133/313 Test Loss: 1.384 | Test Acc: 50.420% (2162/4288)\n",
      "Epoch 3 Step 134/313 Test Loss: 1.386 | Test Acc: 50.347% (2175/4320)\n",
      "Epoch 3 Step 135/313 Test Loss: 1.383 | Test Acc: 50.437% (2195/4352)\n",
      "Epoch 3 Step 136/313 Test Loss: 1.382 | Test Acc: 50.479% (2213/4384)\n",
      "Epoch 3 Step 137/313 Test Loss: 1.382 | Test Acc: 50.476% (2229/4416)\n",
      "Epoch 3 Step 138/313 Test Loss: 1.380 | Test Acc: 50.450% (2244/4448)\n",
      "Epoch 3 Step 139/313 Test Loss: 1.380 | Test Acc: 50.424% (2259/4480)\n",
      "Epoch 3 Step 140/313 Test Loss: 1.380 | Test Acc: 50.488% (2278/4512)\n",
      "Epoch 3 Step 141/313 Test Loss: 1.379 | Test Acc: 50.506% (2295/4544)\n",
      "Epoch 3 Step 142/313 Test Loss: 1.380 | Test Acc: 50.481% (2310/4576)\n",
      "Epoch 3 Step 143/313 Test Loss: 1.383 | Test Acc: 50.347% (2320/4608)\n",
      "Epoch 3 Step 144/313 Test Loss: 1.383 | Test Acc: 50.409% (2339/4640)\n",
      "Epoch 3 Step 145/313 Test Loss: 1.381 | Test Acc: 50.535% (2361/4672)\n",
      "Epoch 3 Step 146/313 Test Loss: 1.382 | Test Acc: 50.510% (2376/4704)\n",
      "Epoch 3 Step 147/313 Test Loss: 1.381 | Test Acc: 50.528% (2393/4736)\n",
      "Epoch 3 Step 148/313 Test Loss: 1.382 | Test Acc: 50.524% (2409/4768)\n",
      "Epoch 3 Step 149/313 Test Loss: 1.383 | Test Acc: 50.521% (2425/4800)\n",
      "Epoch 3 Step 150/313 Test Loss: 1.383 | Test Acc: 50.435% (2437/4832)\n",
      "Epoch 3 Step 151/313 Test Loss: 1.381 | Test Acc: 50.514% (2457/4864)\n",
      "Epoch 3 Step 152/313 Test Loss: 1.380 | Test Acc: 50.551% (2475/4896)\n",
      "Epoch 3 Step 153/313 Test Loss: 1.379 | Test Acc: 50.649% (2496/4928)\n",
      "Epoch 3 Step 154/313 Test Loss: 1.379 | Test Acc: 50.665% (2513/4960)\n",
      "Epoch 3 Step 155/313 Test Loss: 1.379 | Test Acc: 50.621% (2527/4992)\n",
      "Epoch 3 Step 156/313 Test Loss: 1.379 | Test Acc: 50.637% (2544/5024)\n",
      "Epoch 3 Step 157/313 Test Loss: 1.378 | Test Acc: 50.613% (2559/5056)\n",
      "Epoch 3 Step 158/313 Test Loss: 1.379 | Test Acc: 50.590% (2574/5088)\n",
      "Epoch 3 Step 159/313 Test Loss: 1.381 | Test Acc: 50.547% (2588/5120)\n",
      "Epoch 3 Step 160/313 Test Loss: 1.380 | Test Acc: 50.582% (2606/5152)\n",
      "Epoch 3 Step 161/313 Test Loss: 1.380 | Test Acc: 50.617% (2624/5184)\n",
      "Epoch 3 Step 162/313 Test Loss: 1.380 | Test Acc: 50.671% (2643/5216)\n",
      "Epoch 3 Step 163/313 Test Loss: 1.379 | Test Acc: 50.724% (2662/5248)\n",
      "Epoch 3 Step 164/313 Test Loss: 1.379 | Test Acc: 50.644% (2674/5280)\n",
      "Epoch 3 Step 165/313 Test Loss: 1.379 | Test Acc: 50.640% (2690/5312)\n",
      "Epoch 3 Step 166/313 Test Loss: 1.381 | Test Acc: 50.599% (2704/5344)\n",
      "Epoch 3 Step 167/313 Test Loss: 1.381 | Test Acc: 50.632% (2722/5376)\n",
      "Epoch 3 Step 168/313 Test Loss: 1.382 | Test Acc: 50.629% (2738/5408)\n",
      "Epoch 3 Step 169/313 Test Loss: 1.381 | Test Acc: 50.680% (2757/5440)\n",
      "Epoch 3 Step 170/313 Test Loss: 1.381 | Test Acc: 50.676% (2773/5472)\n",
      "Epoch 3 Step 171/313 Test Loss: 1.381 | Test Acc: 50.709% (2791/5504)\n",
      "Epoch 3 Step 172/313 Test Loss: 1.381 | Test Acc: 50.723% (2808/5536)\n",
      "Epoch 3 Step 173/313 Test Loss: 1.382 | Test Acc: 50.682% (2822/5568)\n",
      "Epoch 3 Step 174/313 Test Loss: 1.382 | Test Acc: 50.696% (2839/5600)\n",
      "Epoch 3 Step 175/313 Test Loss: 1.384 | Test Acc: 50.568% (2848/5632)\n",
      "Epoch 3 Step 176/313 Test Loss: 1.385 | Test Acc: 50.477% (2859/5664)\n",
      "Epoch 3 Step 177/313 Test Loss: 1.383 | Test Acc: 50.562% (2880/5696)\n",
      "Epoch 3 Step 178/313 Test Loss: 1.381 | Test Acc: 50.663% (2902/5728)\n",
      "Epoch 3 Step 179/313 Test Loss: 1.382 | Test Acc: 50.642% (2917/5760)\n",
      "Epoch 3 Step 180/313 Test Loss: 1.379 | Test Acc: 50.691% (2936/5792)\n",
      "Epoch 3 Step 181/313 Test Loss: 1.379 | Test Acc: 50.687% (2952/5824)\n",
      "Epoch 3 Step 182/313 Test Loss: 1.382 | Test Acc: 50.598% (2963/5856)\n",
      "Epoch 3 Step 183/313 Test Loss: 1.381 | Test Acc: 50.628% (2981/5888)\n",
      "Epoch 3 Step 184/313 Test Loss: 1.383 | Test Acc: 50.557% (2993/5920)\n",
      "Epoch 3 Step 185/313 Test Loss: 1.384 | Test Acc: 50.538% (3008/5952)\n",
      "Epoch 3 Step 186/313 Test Loss: 1.383 | Test Acc: 50.568% (3026/5984)\n",
      "Epoch 3 Step 187/313 Test Loss: 1.383 | Test Acc: 50.582% (3043/6016)\n",
      "Epoch 3 Step 188/313 Test Loss: 1.382 | Test Acc: 50.612% (3061/6048)\n",
      "Epoch 3 Step 189/313 Test Loss: 1.382 | Test Acc: 50.576% (3075/6080)\n",
      "Epoch 3 Step 190/313 Test Loss: 1.382 | Test Acc: 50.540% (3089/6112)\n",
      "Epoch 3 Step 191/313 Test Loss: 1.381 | Test Acc: 50.570% (3107/6144)\n",
      "Epoch 3 Step 192/313 Test Loss: 1.381 | Test Acc: 50.551% (3122/6176)\n",
      "Epoch 3 Step 193/313 Test Loss: 1.381 | Test Acc: 50.580% (3140/6208)\n",
      "Epoch 3 Step 194/313 Test Loss: 1.381 | Test Acc: 50.593% (3157/6240)\n",
      "Epoch 3 Step 195/313 Test Loss: 1.382 | Test Acc: 50.542% (3170/6272)\n",
      "Epoch 3 Step 196/313 Test Loss: 1.384 | Test Acc: 50.523% (3185/6304)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Step 197/313 Test Loss: 1.384 | Test Acc: 50.521% (3201/6336)\n",
      "Epoch 3 Step 198/313 Test Loss: 1.382 | Test Acc: 50.628% (3224/6368)\n",
      "Epoch 3 Step 199/313 Test Loss: 1.383 | Test Acc: 50.547% (3235/6400)\n",
      "Epoch 3 Step 200/313 Test Loss: 1.383 | Test Acc: 50.560% (3252/6432)\n",
      "Epoch 3 Step 201/313 Test Loss: 1.383 | Test Acc: 50.541% (3267/6464)\n",
      "Epoch 3 Step 202/313 Test Loss: 1.385 | Test Acc: 50.523% (3282/6496)\n",
      "Epoch 3 Step 203/313 Test Loss: 1.385 | Test Acc: 50.475% (3295/6528)\n",
      "Epoch 3 Step 204/313 Test Loss: 1.387 | Test Acc: 50.473% (3311/6560)\n",
      "Epoch 3 Step 205/313 Test Loss: 1.387 | Test Acc: 50.455% (3326/6592)\n",
      "Epoch 3 Step 206/313 Test Loss: 1.386 | Test Acc: 50.468% (3343/6624)\n",
      "Epoch 3 Step 207/313 Test Loss: 1.385 | Test Acc: 50.511% (3362/6656)\n",
      "Epoch 3 Step 208/313 Test Loss: 1.385 | Test Acc: 50.493% (3377/6688)\n",
      "Epoch 3 Step 209/313 Test Loss: 1.385 | Test Acc: 50.491% (3393/6720)\n",
      "Epoch 3 Step 210/313 Test Loss: 1.384 | Test Acc: 50.548% (3413/6752)\n",
      "Epoch 3 Step 211/313 Test Loss: 1.384 | Test Acc: 50.531% (3428/6784)\n",
      "Epoch 3 Step 212/313 Test Loss: 1.383 | Test Acc: 50.587% (3448/6816)\n",
      "Epoch 3 Step 213/313 Test Loss: 1.382 | Test Acc: 50.555% (3462/6848)\n",
      "Epoch 3 Step 214/313 Test Loss: 1.385 | Test Acc: 50.465% (3472/6880)\n",
      "Epoch 3 Step 215/313 Test Loss: 1.385 | Test Acc: 50.463% (3488/6912)\n",
      "Epoch 3 Step 216/313 Test Loss: 1.385 | Test Acc: 50.490% (3506/6944)\n",
      "Epoch 3 Step 217/313 Test Loss: 1.386 | Test Acc: 50.473% (3521/6976)\n",
      "Epoch 3 Step 218/313 Test Loss: 1.387 | Test Acc: 50.385% (3531/7008)\n",
      "Epoch 3 Step 219/313 Test Loss: 1.387 | Test Acc: 50.369% (3546/7040)\n",
      "Epoch 3 Step 220/313 Test Loss: 1.388 | Test Acc: 50.311% (3558/7072)\n",
      "Epoch 3 Step 221/313 Test Loss: 1.387 | Test Acc: 50.324% (3575/7104)\n",
      "Epoch 3 Step 222/313 Test Loss: 1.388 | Test Acc: 50.280% (3588/7136)\n",
      "Epoch 3 Step 223/313 Test Loss: 1.388 | Test Acc: 50.265% (3603/7168)\n",
      "Epoch 3 Step 224/313 Test Loss: 1.389 | Test Acc: 50.222% (3616/7200)\n",
      "Epoch 3 Step 225/313 Test Loss: 1.390 | Test Acc: 50.207% (3631/7232)\n",
      "Epoch 3 Step 226/313 Test Loss: 1.390 | Test Acc: 50.193% (3646/7264)\n",
      "Epoch 3 Step 227/313 Test Loss: 1.390 | Test Acc: 50.178% (3661/7296)\n",
      "Epoch 3 Step 228/313 Test Loss: 1.389 | Test Acc: 50.232% (3681/7328)\n",
      "Epoch 3 Step 229/313 Test Loss: 1.389 | Test Acc: 50.272% (3700/7360)\n",
      "Epoch 3 Step 230/313 Test Loss: 1.389 | Test Acc: 50.271% (3716/7392)\n",
      "Epoch 3 Step 231/313 Test Loss: 1.390 | Test Acc: 50.175% (3725/7424)\n",
      "Epoch 3 Step 232/313 Test Loss: 1.390 | Test Acc: 50.161% (3740/7456)\n",
      "Epoch 3 Step 233/313 Test Loss: 1.389 | Test Acc: 50.200% (3759/7488)\n",
      "Epoch 3 Step 234/313 Test Loss: 1.389 | Test Acc: 50.186% (3774/7520)\n",
      "Epoch 3 Step 235/313 Test Loss: 1.390 | Test Acc: 50.199% (3791/7552)\n",
      "Epoch 3 Step 236/313 Test Loss: 1.390 | Test Acc: 50.185% (3806/7584)\n",
      "Epoch 3 Step 237/313 Test Loss: 1.392 | Test Acc: 50.092% (3815/7616)\n",
      "Epoch 3 Step 238/313 Test Loss: 1.391 | Test Acc: 50.105% (3832/7648)\n",
      "Epoch 3 Step 239/313 Test Loss: 1.391 | Test Acc: 50.182% (3854/7680)\n",
      "Epoch 3 Step 240/313 Test Loss: 1.390 | Test Acc: 50.195% (3871/7712)\n",
      "Epoch 3 Step 241/313 Test Loss: 1.390 | Test Acc: 50.155% (3884/7744)\n",
      "Epoch 3 Step 242/313 Test Loss: 1.390 | Test Acc: 50.167% (3901/7776)\n",
      "Epoch 3 Step 243/313 Test Loss: 1.389 | Test Acc: 50.218% (3921/7808)\n",
      "Epoch 3 Step 244/313 Test Loss: 1.388 | Test Acc: 50.204% (3936/7840)\n",
      "Epoch 3 Step 245/313 Test Loss: 1.388 | Test Acc: 50.216% (3953/7872)\n",
      "Epoch 3 Step 246/313 Test Loss: 1.388 | Test Acc: 50.228% (3970/7904)\n",
      "Epoch 3 Step 247/313 Test Loss: 1.388 | Test Acc: 50.189% (3983/7936)\n",
      "Epoch 3 Step 248/313 Test Loss: 1.390 | Test Acc: 50.151% (3996/7968)\n",
      "Epoch 3 Step 249/313 Test Loss: 1.390 | Test Acc: 50.212% (4017/8000)\n",
      "Epoch 3 Step 250/313 Test Loss: 1.390 | Test Acc: 50.237% (4035/8032)\n",
      "Epoch 3 Step 251/313 Test Loss: 1.391 | Test Acc: 50.198% (4048/8064)\n",
      "Epoch 3 Step 252/313 Test Loss: 1.391 | Test Acc: 50.235% (4067/8096)\n",
      "Epoch 3 Step 253/313 Test Loss: 1.391 | Test Acc: 50.246% (4084/8128)\n",
      "Epoch 3 Step 254/313 Test Loss: 1.391 | Test Acc: 50.233% (4099/8160)\n",
      "Epoch 3 Step 255/313 Test Loss: 1.391 | Test Acc: 50.220% (4114/8192)\n",
      "Epoch 3 Step 256/313 Test Loss: 1.393 | Test Acc: 50.195% (4128/8224)\n",
      "Epoch 3 Step 257/313 Test Loss: 1.392 | Test Acc: 50.242% (4148/8256)\n",
      "Epoch 3 Step 258/313 Test Loss: 1.393 | Test Acc: 50.169% (4158/8288)\n",
      "Epoch 3 Step 259/313 Test Loss: 1.395 | Test Acc: 50.072% (4166/8320)\n",
      "Epoch 3 Step 260/313 Test Loss: 1.396 | Test Acc: 50.048% (4180/8352)\n",
      "Epoch 3 Step 261/313 Test Loss: 1.396 | Test Acc: 50.060% (4197/8384)\n",
      "Epoch 3 Step 262/313 Test Loss: 1.396 | Test Acc: 50.012% (4209/8416)\n",
      "Epoch 3 Step 263/313 Test Loss: 1.396 | Test Acc: 49.988% (4223/8448)\n",
      "Epoch 3 Step 264/313 Test Loss: 1.397 | Test Acc: 50.000% (4240/8480)\n",
      "Epoch 3 Step 265/313 Test Loss: 1.397 | Test Acc: 49.965% (4253/8512)\n",
      "Epoch 3 Step 266/313 Test Loss: 1.397 | Test Acc: 49.953% (4268/8544)\n",
      "Epoch 3 Step 267/313 Test Loss: 1.396 | Test Acc: 49.977% (4286/8576)\n",
      "Epoch 3 Step 268/313 Test Loss: 1.397 | Test Acc: 49.942% (4299/8608)\n",
      "Epoch 3 Step 269/313 Test Loss: 1.397 | Test Acc: 49.931% (4314/8640)\n",
      "Epoch 3 Step 270/313 Test Loss: 1.398 | Test Acc: 49.896% (4327/8672)\n",
      "Epoch 3 Step 271/313 Test Loss: 1.398 | Test Acc: 49.931% (4346/8704)\n",
      "Epoch 3 Step 272/313 Test Loss: 1.397 | Test Acc: 49.943% (4363/8736)\n",
      "Epoch 3 Step 273/313 Test Loss: 1.398 | Test Acc: 49.943% (4379/8768)\n",
      "Epoch 3 Step 274/313 Test Loss: 1.398 | Test Acc: 49.943% (4395/8800)\n",
      "Epoch 3 Step 275/313 Test Loss: 1.399 | Test Acc: 49.943% (4411/8832)\n",
      "Epoch 3 Step 276/313 Test Loss: 1.398 | Test Acc: 49.966% (4429/8864)\n",
      "Epoch 3 Step 277/313 Test Loss: 1.397 | Test Acc: 50.000% (4448/8896)\n",
      "Epoch 3 Step 278/313 Test Loss: 1.397 | Test Acc: 50.056% (4469/8928)\n",
      "Epoch 3 Step 279/313 Test Loss: 1.398 | Test Acc: 49.989% (4479/8960)\n",
      "Epoch 3 Step 280/313 Test Loss: 1.399 | Test Acc: 49.967% (4493/8992)\n",
      "Epoch 3 Step 281/313 Test Loss: 1.398 | Test Acc: 50.022% (4514/9024)\n",
      "Epoch 3 Step 282/313 Test Loss: 1.398 | Test Acc: 50.000% (4528/9056)\n",
      "Epoch 3 Step 283/313 Test Loss: 1.397 | Test Acc: 50.000% (4544/9088)\n",
      "Epoch 3 Step 284/313 Test Loss: 1.397 | Test Acc: 50.022% (4562/9120)\n",
      "Epoch 3 Step 285/313 Test Loss: 1.398 | Test Acc: 50.033% (4579/9152)\n",
      "Epoch 3 Step 286/313 Test Loss: 1.397 | Test Acc: 50.087% (4600/9184)\n",
      "Epoch 3 Step 287/313 Test Loss: 1.396 | Test Acc: 50.119% (4619/9216)\n",
      "Epoch 3 Step 288/313 Test Loss: 1.395 | Test Acc: 50.141% (4637/9248)\n",
      "Epoch 3 Step 289/313 Test Loss: 1.395 | Test Acc: 50.172% (4656/9280)\n",
      "Epoch 3 Step 290/313 Test Loss: 1.396 | Test Acc: 50.129% (4668/9312)\n",
      "Epoch 3 Step 291/313 Test Loss: 1.396 | Test Acc: 50.128% (4684/9344)\n",
      "Epoch 3 Step 292/313 Test Loss: 1.396 | Test Acc: 50.149% (4702/9376)\n",
      "Epoch 3 Step 293/313 Test Loss: 1.396 | Test Acc: 50.117% (4715/9408)\n",
      "Epoch 3 Step 294/313 Test Loss: 1.396 | Test Acc: 50.138% (4733/9440)\n",
      "Epoch 3 Step 295/313 Test Loss: 1.396 | Test Acc: 50.169% (4752/9472)\n",
      "Epoch 3 Step 296/313 Test Loss: 1.395 | Test Acc: 50.200% (4771/9504)\n",
      "Epoch 3 Step 297/313 Test Loss: 1.396 | Test Acc: 50.199% (4787/9536)\n",
      "Epoch 3 Step 298/313 Test Loss: 1.396 | Test Acc: 50.240% (4807/9568)\n",
      "Epoch 3 Step 299/313 Test Loss: 1.394 | Test Acc: 50.260% (4825/9600)\n",
      "Epoch 3 Step 300/313 Test Loss: 1.395 | Test Acc: 50.228% (4838/9632)\n",
      "Epoch 3 Step 301/313 Test Loss: 1.396 | Test Acc: 50.197% (4851/9664)\n",
      "Epoch 3 Step 302/313 Test Loss: 1.396 | Test Acc: 50.196% (4867/9696)\n",
      "Epoch 3 Step 303/313 Test Loss: 1.395 | Test Acc: 50.216% (4885/9728)\n",
      "Epoch 3 Step 304/313 Test Loss: 1.396 | Test Acc: 50.195% (4899/9760)\n",
      "Epoch 3 Step 305/313 Test Loss: 1.395 | Test Acc: 50.214% (4917/9792)\n",
      "Epoch 3 Step 306/313 Test Loss: 1.396 | Test Acc: 50.183% (4930/9824)\n",
      "Epoch 3 Step 307/313 Test Loss: 1.396 | Test Acc: 50.193% (4947/9856)\n",
      "Epoch 3 Step 308/313 Test Loss: 1.397 | Test Acc: 50.162% (4960/9888)\n",
      "Epoch 3 Step 309/313 Test Loss: 1.396 | Test Acc: 50.171% (4977/9920)\n",
      "Epoch 3 Step 310/313 Test Loss: 1.397 | Test Acc: 50.131% (4989/9952)\n",
      "Epoch 3 Step 311/313 Test Loss: 1.396 | Test Acc: 50.110% (5003/9984)\n",
      "Epoch 3 Step 312/313 Test Loss: 1.396 | Test Acc: 50.120% (5012/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 4\n",
      "Epoch 4 Step 0/1563 Loss: 1.707 | Acc: 31.250% (10/32)\n",
      "Epoch 4 Step 1/1563 Loss: 1.603 | Acc: 40.625% (26/64)\n",
      "Epoch 4 Step 2/1563 Loss: 1.504 | Acc: 45.833% (44/96)\n",
      "Epoch 4 Step 3/1563 Loss: 1.443 | Acc: 48.438% (62/128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 4/1563 Loss: 1.483 | Acc: 46.250% (74/160)\n",
      "Epoch 4 Step 5/1563 Loss: 1.515 | Acc: 45.312% (87/192)\n",
      "Epoch 4 Step 6/1563 Loss: 1.496 | Acc: 45.089% (101/224)\n",
      "Epoch 4 Step 7/1563 Loss: 1.477 | Acc: 43.750% (112/256)\n",
      "Epoch 4 Step 8/1563 Loss: 1.467 | Acc: 44.097% (127/288)\n",
      "Epoch 4 Step 9/1563 Loss: 1.458 | Acc: 43.750% (140/320)\n",
      "Epoch 4 Step 10/1563 Loss: 1.491 | Acc: 43.750% (154/352)\n",
      "Epoch 4 Step 11/1563 Loss: 1.508 | Acc: 43.750% (168/384)\n",
      "Epoch 4 Step 12/1563 Loss: 1.473 | Acc: 44.952% (187/416)\n",
      "Epoch 4 Step 13/1563 Loss: 1.473 | Acc: 45.312% (203/448)\n",
      "Epoch 4 Step 14/1563 Loss: 1.473 | Acc: 45.625% (219/480)\n",
      "Epoch 4 Step 15/1563 Loss: 1.447 | Acc: 46.680% (239/512)\n",
      "Epoch 4 Step 16/1563 Loss: 1.440 | Acc: 47.059% (256/544)\n",
      "Epoch 4 Step 17/1563 Loss: 1.445 | Acc: 47.396% (273/576)\n",
      "Epoch 4 Step 18/1563 Loss: 1.443 | Acc: 47.533% (289/608)\n",
      "Epoch 4 Step 19/1563 Loss: 1.443 | Acc: 47.656% (305/640)\n",
      "Epoch 4 Step 20/1563 Loss: 1.431 | Acc: 47.917% (322/672)\n",
      "Epoch 4 Step 21/1563 Loss: 1.431 | Acc: 48.722% (343/704)\n",
      "Epoch 4 Step 22/1563 Loss: 1.419 | Acc: 49.185% (362/736)\n",
      "Epoch 4 Step 23/1563 Loss: 1.434 | Acc: 48.698% (374/768)\n",
      "Epoch 4 Step 24/1563 Loss: 1.432 | Acc: 48.500% (388/800)\n",
      "Epoch 4 Step 25/1563 Loss: 1.434 | Acc: 48.438% (403/832)\n",
      "Epoch 4 Step 26/1563 Loss: 1.430 | Acc: 48.495% (419/864)\n",
      "Epoch 4 Step 27/1563 Loss: 1.424 | Acc: 48.438% (434/896)\n",
      "Epoch 4 Step 28/1563 Loss: 1.429 | Acc: 47.953% (445/928)\n",
      "Epoch 4 Step 29/1563 Loss: 1.429 | Acc: 48.021% (461/960)\n",
      "Epoch 4 Step 30/1563 Loss: 1.425 | Acc: 48.286% (479/992)\n",
      "Epoch 4 Step 31/1563 Loss: 1.421 | Acc: 48.438% (496/1024)\n",
      "Epoch 4 Step 32/1563 Loss: 1.421 | Acc: 48.769% (515/1056)\n",
      "Epoch 4 Step 33/1563 Loss: 1.426 | Acc: 48.989% (533/1088)\n",
      "Epoch 4 Step 34/1563 Loss: 1.435 | Acc: 48.482% (543/1120)\n",
      "Epoch 4 Step 35/1563 Loss: 1.438 | Acc: 48.264% (556/1152)\n",
      "Epoch 4 Step 36/1563 Loss: 1.437 | Acc: 48.480% (574/1184)\n",
      "Epoch 4 Step 37/1563 Loss: 1.435 | Acc: 48.438% (589/1216)\n",
      "Epoch 4 Step 38/1563 Loss: 1.441 | Acc: 47.917% (598/1248)\n",
      "Epoch 4 Step 39/1563 Loss: 1.434 | Acc: 48.047% (615/1280)\n",
      "Epoch 4 Step 40/1563 Loss: 1.439 | Acc: 48.018% (630/1312)\n",
      "Epoch 4 Step 41/1563 Loss: 1.441 | Acc: 47.842% (643/1344)\n",
      "Epoch 4 Step 42/1563 Loss: 1.445 | Acc: 47.820% (658/1376)\n",
      "Epoch 4 Step 43/1563 Loss: 1.446 | Acc: 47.656% (671/1408)\n",
      "Epoch 4 Step 44/1563 Loss: 1.443 | Acc: 47.778% (688/1440)\n",
      "Epoch 4 Step 45/1563 Loss: 1.448 | Acc: 47.418% (698/1472)\n",
      "Epoch 4 Step 46/1563 Loss: 1.447 | Acc: 47.407% (713/1504)\n",
      "Epoch 4 Step 47/1563 Loss: 1.456 | Acc: 47.005% (722/1536)\n",
      "Epoch 4 Step 48/1563 Loss: 1.460 | Acc: 46.875% (735/1568)\n",
      "Epoch 4 Step 49/1563 Loss: 1.462 | Acc: 46.938% (751/1600)\n",
      "Epoch 4 Step 50/1563 Loss: 1.463 | Acc: 46.875% (765/1632)\n",
      "Epoch 4 Step 51/1563 Loss: 1.471 | Acc: 46.454% (773/1664)\n",
      "Epoch 4 Step 52/1563 Loss: 1.475 | Acc: 46.344% (786/1696)\n",
      "Epoch 4 Step 53/1563 Loss: 1.474 | Acc: 46.470% (803/1728)\n",
      "Epoch 4 Step 54/1563 Loss: 1.474 | Acc: 46.420% (817/1760)\n",
      "Epoch 4 Step 55/1563 Loss: 1.474 | Acc: 46.373% (831/1792)\n",
      "Epoch 4 Step 56/1563 Loss: 1.473 | Acc: 46.327% (845/1824)\n",
      "Epoch 4 Step 57/1563 Loss: 1.472 | Acc: 46.282% (859/1856)\n",
      "Epoch 4 Step 58/1563 Loss: 1.470 | Acc: 46.398% (876/1888)\n",
      "Epoch 4 Step 59/1563 Loss: 1.470 | Acc: 46.458% (892/1920)\n",
      "Epoch 4 Step 60/1563 Loss: 1.473 | Acc: 46.311% (904/1952)\n",
      "Epoch 4 Step 61/1563 Loss: 1.475 | Acc: 46.169% (916/1984)\n",
      "Epoch 4 Step 62/1563 Loss: 1.476 | Acc: 45.933% (926/2016)\n",
      "Epoch 4 Step 63/1563 Loss: 1.474 | Acc: 46.094% (944/2048)\n",
      "Epoch 4 Step 64/1563 Loss: 1.475 | Acc: 46.106% (959/2080)\n",
      "Epoch 4 Step 65/1563 Loss: 1.474 | Acc: 46.165% (975/2112)\n",
      "Epoch 4 Step 66/1563 Loss: 1.470 | Acc: 46.175% (990/2144)\n",
      "Epoch 4 Step 67/1563 Loss: 1.470 | Acc: 46.002% (1001/2176)\n",
      "Epoch 4 Step 68/1563 Loss: 1.469 | Acc: 46.060% (1017/2208)\n",
      "Epoch 4 Step 69/1563 Loss: 1.470 | Acc: 45.982% (1030/2240)\n",
      "Epoch 4 Step 70/1563 Loss: 1.477 | Acc: 45.731% (1039/2272)\n",
      "Epoch 4 Step 71/1563 Loss: 1.475 | Acc: 45.833% (1056/2304)\n",
      "Epoch 4 Step 72/1563 Loss: 1.470 | Acc: 45.976% (1074/2336)\n",
      "Epoch 4 Step 73/1563 Loss: 1.472 | Acc: 45.904% (1087/2368)\n",
      "Epoch 4 Step 74/1563 Loss: 1.468 | Acc: 46.333% (1112/2400)\n",
      "Epoch 4 Step 75/1563 Loss: 1.473 | Acc: 46.094% (1121/2432)\n",
      "Epoch 4 Step 76/1563 Loss: 1.469 | Acc: 46.307% (1141/2464)\n",
      "Epoch 4 Step 77/1563 Loss: 1.470 | Acc: 46.314% (1156/2496)\n",
      "Epoch 4 Step 78/1563 Loss: 1.469 | Acc: 46.400% (1173/2528)\n",
      "Epoch 4 Step 79/1563 Loss: 1.468 | Acc: 46.406% (1188/2560)\n",
      "Epoch 4 Step 80/1563 Loss: 1.468 | Acc: 46.412% (1203/2592)\n",
      "Epoch 4 Step 81/1563 Loss: 1.466 | Acc: 46.418% (1218/2624)\n",
      "Epoch 4 Step 82/1563 Loss: 1.467 | Acc: 46.386% (1232/2656)\n",
      "Epoch 4 Step 83/1563 Loss: 1.471 | Acc: 46.205% (1242/2688)\n",
      "Epoch 4 Step 84/1563 Loss: 1.469 | Acc: 46.213% (1257/2720)\n",
      "Epoch 4 Step 85/1563 Loss: 1.466 | Acc: 46.366% (1276/2752)\n",
      "Epoch 4 Step 86/1563 Loss: 1.466 | Acc: 46.300% (1289/2784)\n",
      "Epoch 4 Step 87/1563 Loss: 1.466 | Acc: 46.271% (1303/2816)\n",
      "Epoch 4 Step 88/1563 Loss: 1.464 | Acc: 46.208% (1316/2848)\n",
      "Epoch 4 Step 89/1563 Loss: 1.462 | Acc: 46.250% (1332/2880)\n",
      "Epoch 4 Step 90/1563 Loss: 1.464 | Acc: 46.154% (1344/2912)\n",
      "Epoch 4 Step 91/1563 Loss: 1.461 | Acc: 46.264% (1362/2944)\n",
      "Epoch 4 Step 92/1563 Loss: 1.463 | Acc: 46.237% (1376/2976)\n",
      "Epoch 4 Step 93/1563 Loss: 1.463 | Acc: 46.144% (1388/3008)\n",
      "Epoch 4 Step 94/1563 Loss: 1.461 | Acc: 46.217% (1405/3040)\n",
      "Epoch 4 Step 95/1563 Loss: 1.458 | Acc: 46.387% (1425/3072)\n",
      "Epoch 4 Step 96/1563 Loss: 1.458 | Acc: 46.424% (1441/3104)\n",
      "Epoch 4 Step 97/1563 Loss: 1.456 | Acc: 46.492% (1458/3136)\n",
      "Epoch 4 Step 98/1563 Loss: 1.453 | Acc: 46.591% (1476/3168)\n",
      "Epoch 4 Step 99/1563 Loss: 1.453 | Acc: 46.594% (1491/3200)\n",
      "Epoch 4 Step 100/1563 Loss: 1.452 | Acc: 46.627% (1507/3232)\n",
      "Epoch 4 Step 101/1563 Loss: 1.451 | Acc: 46.661% (1523/3264)\n",
      "Epoch 4 Step 102/1563 Loss: 1.449 | Acc: 46.693% (1539/3296)\n",
      "Epoch 4 Step 103/1563 Loss: 1.450 | Acc: 46.725% (1555/3328)\n",
      "Epoch 4 Step 104/1563 Loss: 1.446 | Acc: 46.845% (1574/3360)\n",
      "Epoch 4 Step 105/1563 Loss: 1.445 | Acc: 46.875% (1590/3392)\n",
      "Epoch 4 Step 106/1563 Loss: 1.443 | Acc: 46.933% (1607/3424)\n",
      "Epoch 4 Step 107/1563 Loss: 1.442 | Acc: 46.962% (1623/3456)\n",
      "Epoch 4 Step 108/1563 Loss: 1.444 | Acc: 46.932% (1637/3488)\n",
      "Epoch 4 Step 109/1563 Loss: 1.442 | Acc: 46.960% (1653/3520)\n",
      "Epoch 4 Step 110/1563 Loss: 1.441 | Acc: 46.959% (1668/3552)\n",
      "Epoch 4 Step 111/1563 Loss: 1.442 | Acc: 46.959% (1683/3584)\n",
      "Epoch 4 Step 112/1563 Loss: 1.445 | Acc: 46.875% (1695/3616)\n",
      "Epoch 4 Step 113/1563 Loss: 1.447 | Acc: 46.848% (1709/3648)\n",
      "Epoch 4 Step 114/1563 Loss: 1.449 | Acc: 46.875% (1725/3680)\n",
      "Epoch 4 Step 115/1563 Loss: 1.451 | Acc: 46.740% (1735/3712)\n",
      "Epoch 4 Step 116/1563 Loss: 1.451 | Acc: 46.822% (1753/3744)\n",
      "Epoch 4 Step 117/1563 Loss: 1.454 | Acc: 46.716% (1764/3776)\n",
      "Epoch 4 Step 118/1563 Loss: 1.455 | Acc: 46.665% (1777/3808)\n",
      "Epoch 4 Step 119/1563 Loss: 1.458 | Acc: 46.615% (1790/3840)\n",
      "Epoch 4 Step 120/1563 Loss: 1.458 | Acc: 46.617% (1805/3872)\n",
      "Epoch 4 Step 121/1563 Loss: 1.459 | Acc: 46.619% (1820/3904)\n",
      "Epoch 4 Step 122/1563 Loss: 1.462 | Acc: 46.570% (1833/3936)\n",
      "Epoch 4 Step 123/1563 Loss: 1.462 | Acc: 46.673% (1852/3968)\n",
      "Epoch 4 Step 124/1563 Loss: 1.460 | Acc: 46.775% (1871/4000)\n",
      "Epoch 4 Step 125/1563 Loss: 1.461 | Acc: 46.801% (1887/4032)\n",
      "Epoch 4 Step 126/1563 Loss: 1.461 | Acc: 46.801% (1902/4064)\n",
      "Epoch 4 Step 127/1563 Loss: 1.461 | Acc: 46.753% (1915/4096)\n",
      "Epoch 4 Step 128/1563 Loss: 1.462 | Acc: 46.657% (1926/4128)\n",
      "Epoch 4 Step 129/1563 Loss: 1.461 | Acc: 46.707% (1943/4160)\n",
      "Epoch 4 Step 130/1563 Loss: 1.461 | Acc: 46.684% (1957/4192)\n",
      "Epoch 4 Step 131/1563 Loss: 1.459 | Acc: 46.804% (1977/4224)\n",
      "Epoch 4 Step 132/1563 Loss: 1.458 | Acc: 46.734% (1989/4256)\n",
      "Epoch 4 Step 133/1563 Loss: 1.458 | Acc: 46.782% (2006/4288)\n",
      "Epoch 4 Step 134/1563 Loss: 1.458 | Acc: 46.806% (2022/4320)\n",
      "Epoch 4 Step 135/1563 Loss: 1.458 | Acc: 46.760% (2035/4352)\n",
      "Epoch 4 Step 136/1563 Loss: 1.456 | Acc: 46.852% (2054/4384)\n",
      "Epoch 4 Step 137/1563 Loss: 1.455 | Acc: 46.898% (2071/4416)\n",
      "Epoch 4 Step 138/1563 Loss: 1.455 | Acc: 46.875% (2085/4448)\n",
      "Epoch 4 Step 139/1563 Loss: 1.457 | Acc: 46.786% (2096/4480)\n",
      "Epoch 4 Step 140/1563 Loss: 1.457 | Acc: 46.742% (2109/4512)\n",
      "Epoch 4 Step 141/1563 Loss: 1.455 | Acc: 46.765% (2125/4544)\n",
      "Epoch 4 Step 142/1563 Loss: 1.454 | Acc: 46.831% (2143/4576)\n",
      "Epoch 4 Step 143/1563 Loss: 1.454 | Acc: 46.810% (2157/4608)\n",
      "Epoch 4 Step 144/1563 Loss: 1.452 | Acc: 46.940% (2178/4640)\n",
      "Epoch 4 Step 145/1563 Loss: 1.452 | Acc: 46.961% (2194/4672)\n",
      "Epoch 4 Step 146/1563 Loss: 1.453 | Acc: 46.896% (2206/4704)\n",
      "Epoch 4 Step 147/1563 Loss: 1.454 | Acc: 46.875% (2220/4736)\n",
      "Epoch 4 Step 148/1563 Loss: 1.453 | Acc: 46.938% (2238/4768)\n",
      "Epoch 4 Step 149/1563 Loss: 1.454 | Acc: 46.938% (2253/4800)\n",
      "Epoch 4 Step 150/1563 Loss: 1.453 | Acc: 46.978% (2270/4832)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 151/1563 Loss: 1.456 | Acc: 46.875% (2280/4864)\n",
      "Epoch 4 Step 152/1563 Loss: 1.458 | Acc: 46.855% (2294/4896)\n",
      "Epoch 4 Step 153/1563 Loss: 1.458 | Acc: 46.875% (2310/4928)\n",
      "Epoch 4 Step 154/1563 Loss: 1.457 | Acc: 46.935% (2328/4960)\n",
      "Epoch 4 Step 155/1563 Loss: 1.458 | Acc: 46.935% (2343/4992)\n",
      "Epoch 4 Step 156/1563 Loss: 1.459 | Acc: 46.975% (2360/5024)\n",
      "Epoch 4 Step 157/1563 Loss: 1.458 | Acc: 47.033% (2378/5056)\n",
      "Epoch 4 Step 158/1563 Loss: 1.459 | Acc: 47.052% (2394/5088)\n",
      "Epoch 4 Step 159/1563 Loss: 1.460 | Acc: 47.031% (2408/5120)\n",
      "Epoch 4 Step 160/1563 Loss: 1.461 | Acc: 47.011% (2422/5152)\n",
      "Epoch 4 Step 161/1563 Loss: 1.462 | Acc: 46.952% (2434/5184)\n",
      "Epoch 4 Step 162/1563 Loss: 1.462 | Acc: 46.913% (2447/5216)\n",
      "Epoch 4 Step 163/1563 Loss: 1.462 | Acc: 46.951% (2464/5248)\n",
      "Epoch 4 Step 164/1563 Loss: 1.461 | Acc: 46.951% (2479/5280)\n",
      "Epoch 4 Step 165/1563 Loss: 1.461 | Acc: 46.969% (2495/5312)\n",
      "Epoch 4 Step 166/1563 Loss: 1.458 | Acc: 47.100% (2517/5344)\n",
      "Epoch 4 Step 167/1563 Loss: 1.458 | Acc: 47.042% (2529/5376)\n",
      "Epoch 4 Step 168/1563 Loss: 1.459 | Acc: 47.023% (2543/5408)\n",
      "Epoch 4 Step 169/1563 Loss: 1.459 | Acc: 47.040% (2559/5440)\n",
      "Epoch 4 Step 170/1563 Loss: 1.458 | Acc: 47.076% (2576/5472)\n",
      "Epoch 4 Step 171/1563 Loss: 1.456 | Acc: 47.148% (2595/5504)\n",
      "Epoch 4 Step 172/1563 Loss: 1.455 | Acc: 47.182% (2612/5536)\n",
      "Epoch 4 Step 173/1563 Loss: 1.456 | Acc: 47.126% (2624/5568)\n",
      "Epoch 4 Step 174/1563 Loss: 1.455 | Acc: 47.179% (2642/5600)\n",
      "Epoch 4 Step 175/1563 Loss: 1.453 | Acc: 47.212% (2659/5632)\n",
      "Epoch 4 Step 176/1563 Loss: 1.452 | Acc: 47.316% (2680/5664)\n",
      "Epoch 4 Step 177/1563 Loss: 1.453 | Acc: 47.331% (2696/5696)\n",
      "Epoch 4 Step 178/1563 Loss: 1.452 | Acc: 47.346% (2712/5728)\n",
      "Epoch 4 Step 179/1563 Loss: 1.452 | Acc: 47.344% (2727/5760)\n",
      "Epoch 4 Step 180/1563 Loss: 1.450 | Acc: 47.410% (2746/5792)\n",
      "Epoch 4 Step 181/1563 Loss: 1.451 | Acc: 47.339% (2757/5824)\n",
      "Epoch 4 Step 182/1563 Loss: 1.451 | Acc: 47.336% (2772/5856)\n",
      "Epoch 4 Step 183/1563 Loss: 1.451 | Acc: 47.300% (2785/5888)\n",
      "Epoch 4 Step 184/1563 Loss: 1.454 | Acc: 47.230% (2796/5920)\n",
      "Epoch 4 Step 185/1563 Loss: 1.454 | Acc: 47.211% (2810/5952)\n",
      "Epoch 4 Step 186/1563 Loss: 1.454 | Acc: 47.176% (2823/5984)\n",
      "Epoch 4 Step 187/1563 Loss: 1.453 | Acc: 47.241% (2842/6016)\n",
      "Epoch 4 Step 188/1563 Loss: 1.452 | Acc: 47.305% (2861/6048)\n",
      "Epoch 4 Step 189/1563 Loss: 1.452 | Acc: 47.286% (2875/6080)\n",
      "Epoch 4 Step 190/1563 Loss: 1.453 | Acc: 47.268% (2889/6112)\n",
      "Epoch 4 Step 191/1563 Loss: 1.453 | Acc: 47.282% (2905/6144)\n",
      "Epoch 4 Step 192/1563 Loss: 1.453 | Acc: 47.280% (2920/6176)\n",
      "Epoch 4 Step 193/1563 Loss: 1.452 | Acc: 47.294% (2936/6208)\n",
      "Epoch 4 Step 194/1563 Loss: 1.452 | Acc: 47.340% (2954/6240)\n",
      "Epoch 4 Step 195/1563 Loss: 1.452 | Acc: 47.353% (2970/6272)\n",
      "Epoch 4 Step 196/1563 Loss: 1.452 | Acc: 47.398% (2988/6304)\n",
      "Epoch 4 Step 197/1563 Loss: 1.452 | Acc: 47.396% (3003/6336)\n",
      "Epoch 4 Step 198/1563 Loss: 1.452 | Acc: 47.393% (3018/6368)\n",
      "Epoch 4 Step 199/1563 Loss: 1.450 | Acc: 47.500% (3040/6400)\n",
      "Epoch 4 Step 200/1563 Loss: 1.450 | Acc: 47.512% (3056/6432)\n",
      "Epoch 4 Step 201/1563 Loss: 1.451 | Acc: 47.494% (3070/6464)\n",
      "Epoch 4 Step 202/1563 Loss: 1.450 | Acc: 47.522% (3087/6496)\n",
      "Epoch 4 Step 203/1563 Loss: 1.451 | Acc: 47.518% (3102/6528)\n",
      "Epoch 4 Step 204/1563 Loss: 1.449 | Acc: 47.591% (3122/6560)\n",
      "Epoch 4 Step 205/1563 Loss: 1.449 | Acc: 47.618% (3139/6592)\n",
      "Epoch 4 Step 206/1563 Loss: 1.449 | Acc: 47.600% (3153/6624)\n",
      "Epoch 4 Step 207/1563 Loss: 1.448 | Acc: 47.641% (3171/6656)\n",
      "Epoch 4 Step 208/1563 Loss: 1.449 | Acc: 47.608% (3184/6688)\n",
      "Epoch 4 Step 209/1563 Loss: 1.449 | Acc: 47.664% (3203/6720)\n",
      "Epoch 4 Step 210/1563 Loss: 1.449 | Acc: 47.616% (3215/6752)\n",
      "Epoch 4 Step 211/1563 Loss: 1.449 | Acc: 47.612% (3230/6784)\n",
      "Epoch 4 Step 212/1563 Loss: 1.448 | Acc: 47.638% (3247/6816)\n",
      "Epoch 4 Step 213/1563 Loss: 1.447 | Acc: 47.766% (3271/6848)\n",
      "Epoch 4 Step 214/1563 Loss: 1.447 | Acc: 47.791% (3288/6880)\n",
      "Epoch 4 Step 215/1563 Loss: 1.448 | Acc: 47.815% (3305/6912)\n",
      "Epoch 4 Step 216/1563 Loss: 1.447 | Acc: 47.854% (3323/6944)\n",
      "Epoch 4 Step 217/1563 Loss: 1.448 | Acc: 47.850% (3338/6976)\n",
      "Epoch 4 Step 218/1563 Loss: 1.449 | Acc: 47.860% (3354/7008)\n",
      "Epoch 4 Step 219/1563 Loss: 1.449 | Acc: 47.812% (3366/7040)\n",
      "Epoch 4 Step 220/1563 Loss: 1.450 | Acc: 47.822% (3382/7072)\n",
      "Epoch 4 Step 221/1563 Loss: 1.450 | Acc: 47.776% (3394/7104)\n",
      "Epoch 4 Step 222/1563 Loss: 1.450 | Acc: 47.786% (3410/7136)\n",
      "Epoch 4 Step 223/1563 Loss: 1.449 | Acc: 47.810% (3427/7168)\n",
      "Epoch 4 Step 224/1563 Loss: 1.448 | Acc: 47.889% (3448/7200)\n",
      "Epoch 4 Step 225/1563 Loss: 1.448 | Acc: 47.884% (3463/7232)\n",
      "Epoch 4 Step 226/1563 Loss: 1.450 | Acc: 47.797% (3472/7264)\n",
      "Epoch 4 Step 227/1563 Loss: 1.450 | Acc: 47.821% (3489/7296)\n",
      "Epoch 4 Step 228/1563 Loss: 1.450 | Acc: 47.803% (3503/7328)\n",
      "Epoch 4 Step 229/1563 Loss: 1.449 | Acc: 47.826% (3520/7360)\n",
      "Epoch 4 Step 230/1563 Loss: 1.449 | Acc: 47.835% (3536/7392)\n",
      "Epoch 4 Step 231/1563 Loss: 1.449 | Acc: 47.791% (3548/7424)\n",
      "Epoch 4 Step 232/1563 Loss: 1.449 | Acc: 47.800% (3564/7456)\n",
      "Epoch 4 Step 233/1563 Loss: 1.447 | Acc: 47.863% (3584/7488)\n",
      "Epoch 4 Step 234/1563 Loss: 1.447 | Acc: 47.872% (3600/7520)\n",
      "Epoch 4 Step 235/1563 Loss: 1.448 | Acc: 47.868% (3615/7552)\n",
      "Epoch 4 Step 236/1563 Loss: 1.448 | Acc: 47.811% (3626/7584)\n",
      "Epoch 4 Step 237/1563 Loss: 1.448 | Acc: 47.873% (3646/7616)\n",
      "Epoch 4 Step 238/1563 Loss: 1.447 | Acc: 47.882% (3662/7648)\n",
      "Epoch 4 Step 239/1563 Loss: 1.448 | Acc: 47.852% (3675/7680)\n",
      "Epoch 4 Step 240/1563 Loss: 1.447 | Acc: 47.822% (3688/7712)\n",
      "Epoch 4 Step 241/1563 Loss: 1.447 | Acc: 47.818% (3703/7744)\n",
      "Epoch 4 Step 242/1563 Loss: 1.447 | Acc: 47.801% (3717/7776)\n",
      "Epoch 4 Step 243/1563 Loss: 1.448 | Acc: 47.772% (3730/7808)\n",
      "Epoch 4 Step 244/1563 Loss: 1.449 | Acc: 47.742% (3743/7840)\n",
      "Epoch 4 Step 245/1563 Loss: 1.449 | Acc: 47.726% (3757/7872)\n",
      "Epoch 4 Step 246/1563 Loss: 1.449 | Acc: 47.748% (3774/7904)\n",
      "Epoch 4 Step 247/1563 Loss: 1.448 | Acc: 47.782% (3792/7936)\n",
      "Epoch 4 Step 248/1563 Loss: 1.447 | Acc: 47.816% (3810/7968)\n",
      "Epoch 4 Step 249/1563 Loss: 1.447 | Acc: 47.837% (3827/8000)\n",
      "Epoch 4 Step 250/1563 Loss: 1.447 | Acc: 47.809% (3840/8032)\n",
      "Epoch 4 Step 251/1563 Loss: 1.447 | Acc: 47.780% (3853/8064)\n",
      "Epoch 4 Step 252/1563 Loss: 1.446 | Acc: 47.789% (3869/8096)\n",
      "Epoch 4 Step 253/1563 Loss: 1.447 | Acc: 47.761% (3882/8128)\n",
      "Epoch 4 Step 254/1563 Loss: 1.446 | Acc: 47.806% (3901/8160)\n",
      "Epoch 4 Step 255/1563 Loss: 1.446 | Acc: 47.815% (3917/8192)\n",
      "Epoch 4 Step 256/1563 Loss: 1.446 | Acc: 47.787% (3930/8224)\n",
      "Epoch 4 Step 257/1563 Loss: 1.444 | Acc: 47.880% (3953/8256)\n",
      "Epoch 4 Step 258/1563 Loss: 1.445 | Acc: 47.876% (3968/8288)\n",
      "Epoch 4 Step 259/1563 Loss: 1.445 | Acc: 47.885% (3984/8320)\n",
      "Epoch 4 Step 260/1563 Loss: 1.445 | Acc: 47.893% (4000/8352)\n",
      "Epoch 4 Step 261/1563 Loss: 1.445 | Acc: 47.913% (4017/8384)\n",
      "Epoch 4 Step 262/1563 Loss: 1.445 | Acc: 47.897% (4031/8416)\n",
      "Epoch 4 Step 263/1563 Loss: 1.444 | Acc: 47.940% (4050/8448)\n",
      "Epoch 4 Step 264/1563 Loss: 1.444 | Acc: 47.972% (4068/8480)\n",
      "Epoch 4 Step 265/1563 Loss: 1.443 | Acc: 47.979% (4084/8512)\n",
      "Epoch 4 Step 266/1563 Loss: 1.442 | Acc: 48.034% (4104/8544)\n",
      "Epoch 4 Step 267/1563 Loss: 1.442 | Acc: 47.994% (4116/8576)\n",
      "Epoch 4 Step 268/1563 Loss: 1.441 | Acc: 48.025% (4134/8608)\n",
      "Epoch 4 Step 269/1563 Loss: 1.441 | Acc: 48.021% (4149/8640)\n",
      "Epoch 4 Step 270/1563 Loss: 1.441 | Acc: 48.028% (4165/8672)\n",
      "Epoch 4 Step 271/1563 Loss: 1.441 | Acc: 48.047% (4182/8704)\n",
      "Epoch 4 Step 272/1563 Loss: 1.441 | Acc: 48.043% (4197/8736)\n",
      "Epoch 4 Step 273/1563 Loss: 1.441 | Acc: 48.050% (4213/8768)\n",
      "Epoch 4 Step 274/1563 Loss: 1.441 | Acc: 48.011% (4225/8800)\n",
      "Epoch 4 Step 275/1563 Loss: 1.441 | Acc: 48.030% (4242/8832)\n",
      "Epoch 4 Step 276/1563 Loss: 1.442 | Acc: 47.992% (4254/8864)\n",
      "Epoch 4 Step 277/1563 Loss: 1.442 | Acc: 47.999% (4270/8896)\n",
      "Epoch 4 Step 278/1563 Loss: 1.442 | Acc: 48.017% (4287/8928)\n",
      "Epoch 4 Step 279/1563 Loss: 1.442 | Acc: 48.025% (4303/8960)\n",
      "Epoch 4 Step 280/1563 Loss: 1.442 | Acc: 48.054% (4321/8992)\n",
      "Epoch 4 Step 281/1563 Loss: 1.442 | Acc: 48.050% (4336/9024)\n",
      "Epoch 4 Step 282/1563 Loss: 1.442 | Acc: 48.057% (4352/9056)\n",
      "Epoch 4 Step 283/1563 Loss: 1.441 | Acc: 48.063% (4368/9088)\n",
      "Epoch 4 Step 284/1563 Loss: 1.443 | Acc: 48.015% (4379/9120)\n",
      "Epoch 4 Step 285/1563 Loss: 1.443 | Acc: 47.990% (4392/9152)\n",
      "Epoch 4 Step 286/1563 Loss: 1.443 | Acc: 47.997% (4408/9184)\n",
      "Epoch 4 Step 287/1563 Loss: 1.443 | Acc: 47.971% (4421/9216)\n",
      "Epoch 4 Step 288/1563 Loss: 1.443 | Acc: 47.946% (4434/9248)\n",
      "Epoch 4 Step 289/1563 Loss: 1.444 | Acc: 47.909% (4446/9280)\n",
      "Epoch 4 Step 290/1563 Loss: 1.444 | Acc: 47.906% (4461/9312)\n",
      "Epoch 4 Step 291/1563 Loss: 1.444 | Acc: 47.902% (4476/9344)\n",
      "Epoch 4 Step 292/1563 Loss: 1.445 | Acc: 47.910% (4492/9376)\n",
      "Epoch 4 Step 293/1563 Loss: 1.446 | Acc: 47.874% (4504/9408)\n",
      "Epoch 4 Step 294/1563 Loss: 1.445 | Acc: 47.903% (4522/9440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 295/1563 Loss: 1.445 | Acc: 47.867% (4534/9472)\n",
      "Epoch 4 Step 296/1563 Loss: 1.446 | Acc: 47.854% (4548/9504)\n",
      "Epoch 4 Step 297/1563 Loss: 1.446 | Acc: 47.829% (4561/9536)\n",
      "Epoch 4 Step 298/1563 Loss: 1.446 | Acc: 47.816% (4575/9568)\n",
      "Epoch 4 Step 299/1563 Loss: 1.445 | Acc: 47.833% (4592/9600)\n",
      "Epoch 4 Step 300/1563 Loss: 1.446 | Acc: 47.799% (4604/9632)\n",
      "Epoch 4 Step 301/1563 Loss: 1.447 | Acc: 47.724% (4612/9664)\n",
      "Epoch 4 Step 302/1563 Loss: 1.447 | Acc: 47.741% (4629/9696)\n",
      "Epoch 4 Step 303/1563 Loss: 1.446 | Acc: 47.790% (4649/9728)\n",
      "Epoch 4 Step 304/1563 Loss: 1.445 | Acc: 47.818% (4667/9760)\n",
      "Epoch 4 Step 305/1563 Loss: 1.444 | Acc: 47.886% (4689/9792)\n",
      "Epoch 4 Step 306/1563 Loss: 1.444 | Acc: 47.934% (4709/9824)\n",
      "Epoch 4 Step 307/1563 Loss: 1.444 | Acc: 47.920% (4723/9856)\n",
      "Epoch 4 Step 308/1563 Loss: 1.443 | Acc: 47.937% (4740/9888)\n",
      "Epoch 4 Step 309/1563 Loss: 1.443 | Acc: 47.933% (4755/9920)\n",
      "Epoch 4 Step 310/1563 Loss: 1.444 | Acc: 47.870% (4764/9952)\n",
      "Epoch 4 Step 311/1563 Loss: 1.444 | Acc: 47.897% (4782/9984)\n",
      "Epoch 4 Step 312/1563 Loss: 1.445 | Acc: 47.863% (4794/10016)\n",
      "Epoch 4 Step 313/1563 Loss: 1.445 | Acc: 47.870% (4810/10048)\n",
      "Epoch 4 Step 314/1563 Loss: 1.446 | Acc: 47.877% (4826/10080)\n",
      "Epoch 4 Step 315/1563 Loss: 1.445 | Acc: 47.894% (4843/10112)\n",
      "Epoch 4 Step 316/1563 Loss: 1.445 | Acc: 47.910% (4860/10144)\n",
      "Epoch 4 Step 317/1563 Loss: 1.445 | Acc: 47.917% (4876/10176)\n",
      "Epoch 4 Step 318/1563 Loss: 1.444 | Acc: 47.913% (4891/10208)\n",
      "Epoch 4 Step 319/1563 Loss: 1.445 | Acc: 47.881% (4903/10240)\n",
      "Epoch 4 Step 320/1563 Loss: 1.446 | Acc: 47.829% (4913/10272)\n",
      "Epoch 4 Step 321/1563 Loss: 1.446 | Acc: 47.865% (4932/10304)\n",
      "Epoch 4 Step 322/1563 Loss: 1.446 | Acc: 47.852% (4946/10336)\n",
      "Epoch 4 Step 323/1563 Loss: 1.446 | Acc: 47.840% (4960/10368)\n",
      "Epoch 4 Step 324/1563 Loss: 1.445 | Acc: 47.846% (4976/10400)\n",
      "Epoch 4 Step 325/1563 Loss: 1.446 | Acc: 47.853% (4992/10432)\n",
      "Epoch 4 Step 326/1563 Loss: 1.445 | Acc: 47.878% (5010/10464)\n",
      "Epoch 4 Step 327/1563 Loss: 1.445 | Acc: 47.913% (5029/10496)\n",
      "Epoch 4 Step 328/1563 Loss: 1.445 | Acc: 47.910% (5044/10528)\n",
      "Epoch 4 Step 329/1563 Loss: 1.444 | Acc: 47.955% (5064/10560)\n",
      "Epoch 4 Step 330/1563 Loss: 1.444 | Acc: 47.942% (5078/10592)\n",
      "Epoch 4 Step 331/1563 Loss: 1.445 | Acc: 47.892% (5088/10624)\n",
      "Epoch 4 Step 332/1563 Loss: 1.445 | Acc: 47.907% (5105/10656)\n",
      "Epoch 4 Step 333/1563 Loss: 1.446 | Acc: 47.914% (5121/10688)\n",
      "Epoch 4 Step 334/1563 Loss: 1.445 | Acc: 47.901% (5135/10720)\n",
      "Epoch 4 Step 335/1563 Loss: 1.445 | Acc: 47.879% (5148/10752)\n",
      "Epoch 4 Step 336/1563 Loss: 1.445 | Acc: 47.904% (5166/10784)\n",
      "Epoch 4 Step 337/1563 Loss: 1.445 | Acc: 47.911% (5182/10816)\n",
      "Epoch 4 Step 338/1563 Loss: 1.445 | Acc: 47.917% (5198/10848)\n",
      "Epoch 4 Step 339/1563 Loss: 1.444 | Acc: 47.932% (5215/10880)\n",
      "Epoch 4 Step 340/1563 Loss: 1.446 | Acc: 47.865% (5223/10912)\n",
      "Epoch 4 Step 341/1563 Loss: 1.446 | Acc: 47.880% (5240/10944)\n",
      "Epoch 4 Step 342/1563 Loss: 1.447 | Acc: 47.859% (5253/10976)\n",
      "Epoch 4 Step 343/1563 Loss: 1.447 | Acc: 47.829% (5265/11008)\n",
      "Epoch 4 Step 344/1563 Loss: 1.446 | Acc: 47.853% (5283/11040)\n",
      "Epoch 4 Step 345/1563 Loss: 1.447 | Acc: 47.859% (5299/11072)\n",
      "Epoch 4 Step 346/1563 Loss: 1.447 | Acc: 47.839% (5312/11104)\n",
      "Epoch 4 Step 347/1563 Loss: 1.448 | Acc: 47.818% (5325/11136)\n",
      "Epoch 4 Step 348/1563 Loss: 1.448 | Acc: 47.842% (5343/11168)\n",
      "Epoch 4 Step 349/1563 Loss: 1.448 | Acc: 47.830% (5357/11200)\n",
      "Epoch 4 Step 350/1563 Loss: 1.448 | Acc: 47.845% (5374/11232)\n",
      "Epoch 4 Step 351/1563 Loss: 1.448 | Acc: 47.816% (5386/11264)\n",
      "Epoch 4 Step 352/1563 Loss: 1.448 | Acc: 47.822% (5402/11296)\n",
      "Epoch 4 Step 353/1563 Loss: 1.448 | Acc: 47.820% (5417/11328)\n",
      "Epoch 4 Step 354/1563 Loss: 1.448 | Acc: 47.799% (5430/11360)\n",
      "Epoch 4 Step 355/1563 Loss: 1.447 | Acc: 47.832% (5449/11392)\n",
      "Epoch 4 Step 356/1563 Loss: 1.447 | Acc: 47.838% (5465/11424)\n",
      "Epoch 4 Step 357/1563 Loss: 1.448 | Acc: 47.792% (5475/11456)\n",
      "Epoch 4 Step 358/1563 Loss: 1.448 | Acc: 47.815% (5493/11488)\n",
      "Epoch 4 Step 359/1563 Loss: 1.448 | Acc: 47.839% (5511/11520)\n",
      "Epoch 4 Step 360/1563 Loss: 1.448 | Acc: 47.819% (5524/11552)\n",
      "Epoch 4 Step 361/1563 Loss: 1.448 | Acc: 47.825% (5540/11584)\n",
      "Epoch 4 Step 362/1563 Loss: 1.447 | Acc: 47.891% (5563/11616)\n",
      "Epoch 4 Step 363/1563 Loss: 1.447 | Acc: 47.879% (5577/11648)\n",
      "Epoch 4 Step 364/1563 Loss: 1.448 | Acc: 47.868% (5591/11680)\n",
      "Epoch 4 Step 365/1563 Loss: 1.448 | Acc: 47.874% (5607/11712)\n",
      "Epoch 4 Step 366/1563 Loss: 1.448 | Acc: 47.854% (5620/11744)\n",
      "Epoch 4 Step 367/1563 Loss: 1.448 | Acc: 47.886% (5639/11776)\n",
      "Epoch 4 Step 368/1563 Loss: 1.448 | Acc: 47.883% (5654/11808)\n",
      "Epoch 4 Step 369/1563 Loss: 1.448 | Acc: 47.897% (5671/11840)\n",
      "Epoch 4 Step 370/1563 Loss: 1.447 | Acc: 47.911% (5688/11872)\n",
      "Epoch 4 Step 371/1563 Loss: 1.447 | Acc: 47.933% (5706/11904)\n",
      "Epoch 4 Step 372/1563 Loss: 1.446 | Acc: 47.939% (5722/11936)\n",
      "Epoch 4 Step 373/1563 Loss: 1.446 | Acc: 47.936% (5737/11968)\n",
      "Epoch 4 Step 374/1563 Loss: 1.445 | Acc: 47.983% (5758/12000)\n",
      "Epoch 4 Step 375/1563 Loss: 1.445 | Acc: 47.989% (5774/12032)\n",
      "Epoch 4 Step 376/1563 Loss: 1.446 | Acc: 47.994% (5790/12064)\n",
      "Epoch 4 Step 377/1563 Loss: 1.445 | Acc: 47.999% (5806/12096)\n",
      "Epoch 4 Step 378/1563 Loss: 1.445 | Acc: 47.996% (5821/12128)\n",
      "Epoch 4 Step 379/1563 Loss: 1.447 | Acc: 47.977% (5834/12160)\n",
      "Epoch 4 Step 380/1563 Loss: 1.446 | Acc: 47.999% (5852/12192)\n",
      "Epoch 4 Step 381/1563 Loss: 1.446 | Acc: 47.988% (5866/12224)\n",
      "Epoch 4 Step 382/1563 Loss: 1.445 | Acc: 47.985% (5881/12256)\n",
      "Epoch 4 Step 383/1563 Loss: 1.445 | Acc: 47.982% (5896/12288)\n",
      "Epoch 4 Step 384/1563 Loss: 1.446 | Acc: 47.922% (5904/12320)\n",
      "Epoch 4 Step 385/1563 Loss: 1.446 | Acc: 47.927% (5920/12352)\n",
      "Epoch 4 Step 386/1563 Loss: 1.446 | Acc: 47.917% (5934/12384)\n",
      "Epoch 4 Step 387/1563 Loss: 1.447 | Acc: 47.882% (5945/12416)\n",
      "Epoch 4 Step 388/1563 Loss: 1.447 | Acc: 47.879% (5960/12448)\n",
      "Epoch 4 Step 389/1563 Loss: 1.448 | Acc: 47.837% (5970/12480)\n",
      "Epoch 4 Step 390/1563 Loss: 1.447 | Acc: 47.850% (5987/12512)\n",
      "Epoch 4 Step 391/1563 Loss: 1.447 | Acc: 47.848% (6002/12544)\n",
      "Epoch 4 Step 392/1563 Loss: 1.446 | Acc: 47.893% (6023/12576)\n",
      "Epoch 4 Step 393/1563 Loss: 1.446 | Acc: 47.906% (6040/12608)\n",
      "Epoch 4 Step 394/1563 Loss: 1.446 | Acc: 47.896% (6054/12640)\n",
      "Epoch 4 Step 395/1563 Loss: 1.446 | Acc: 47.861% (6065/12672)\n",
      "Epoch 4 Step 396/1563 Loss: 1.446 | Acc: 47.875% (6082/12704)\n",
      "Epoch 4 Step 397/1563 Loss: 1.445 | Acc: 47.896% (6100/12736)\n",
      "Epoch 4 Step 398/1563 Loss: 1.446 | Acc: 47.870% (6112/12768)\n",
      "Epoch 4 Step 399/1563 Loss: 1.446 | Acc: 47.875% (6128/12800)\n",
      "Epoch 4 Step 400/1563 Loss: 1.445 | Acc: 47.911% (6148/12832)\n",
      "Epoch 4 Step 401/1563 Loss: 1.445 | Acc: 47.901% (6162/12864)\n",
      "Epoch 4 Step 402/1563 Loss: 1.446 | Acc: 47.899% (6177/12896)\n",
      "Epoch 4 Step 403/1563 Loss: 1.446 | Acc: 47.912% (6194/12928)\n",
      "Epoch 4 Step 404/1563 Loss: 1.445 | Acc: 47.932% (6212/12960)\n",
      "Epoch 4 Step 405/1563 Loss: 1.446 | Acc: 47.929% (6227/12992)\n",
      "Epoch 4 Step 406/1563 Loss: 1.446 | Acc: 47.958% (6246/13024)\n",
      "Epoch 4 Step 407/1563 Loss: 1.445 | Acc: 47.978% (6264/13056)\n",
      "Epoch 4 Step 408/1563 Loss: 1.445 | Acc: 47.975% (6279/13088)\n",
      "Epoch 4 Step 409/1563 Loss: 1.445 | Acc: 47.995% (6297/13120)\n",
      "Epoch 4 Step 410/1563 Loss: 1.444 | Acc: 47.977% (6310/13152)\n",
      "Epoch 4 Step 411/1563 Loss: 1.444 | Acc: 47.990% (6327/13184)\n",
      "Epoch 4 Step 412/1563 Loss: 1.443 | Acc: 48.033% (6348/13216)\n",
      "Epoch 4 Step 413/1563 Loss: 1.442 | Acc: 48.090% (6371/13248)\n",
      "Epoch 4 Step 414/1563 Loss: 1.441 | Acc: 48.133% (6392/13280)\n",
      "Epoch 4 Step 415/1563 Loss: 1.442 | Acc: 48.114% (6405/13312)\n",
      "Epoch 4 Step 416/1563 Loss: 1.441 | Acc: 48.156% (6426/13344)\n",
      "Epoch 4 Step 417/1563 Loss: 1.441 | Acc: 48.168% (6443/13376)\n",
      "Epoch 4 Step 418/1563 Loss: 1.442 | Acc: 48.158% (6457/13408)\n",
      "Epoch 4 Step 419/1563 Loss: 1.442 | Acc: 48.155% (6472/13440)\n",
      "Epoch 4 Step 420/1563 Loss: 1.441 | Acc: 48.174% (6490/13472)\n",
      "Epoch 4 Step 421/1563 Loss: 1.442 | Acc: 48.141% (6501/13504)\n",
      "Epoch 4 Step 422/1563 Loss: 1.442 | Acc: 48.131% (6515/13536)\n",
      "Epoch 4 Step 423/1563 Loss: 1.442 | Acc: 48.121% (6529/13568)\n",
      "Epoch 4 Step 424/1563 Loss: 1.441 | Acc: 48.154% (6549/13600)\n",
      "Epoch 4 Step 425/1563 Loss: 1.442 | Acc: 48.129% (6561/13632)\n",
      "Epoch 4 Step 426/1563 Loss: 1.443 | Acc: 48.105% (6573/13664)\n",
      "Epoch 4 Step 427/1563 Loss: 1.443 | Acc: 48.072% (6584/13696)\n",
      "Epoch 4 Step 428/1563 Loss: 1.443 | Acc: 48.062% (6598/13728)\n",
      "Epoch 4 Step 429/1563 Loss: 1.444 | Acc: 48.081% (6616/13760)\n",
      "Epoch 4 Step 430/1563 Loss: 1.443 | Acc: 48.108% (6635/13792)\n",
      "Epoch 4 Step 431/1563 Loss: 1.443 | Acc: 48.155% (6657/13824)\n",
      "Epoch 4 Step 432/1563 Loss: 1.443 | Acc: 48.138% (6670/13856)\n",
      "Epoch 4 Step 433/1563 Loss: 1.444 | Acc: 48.121% (6683/13888)\n",
      "Epoch 4 Step 434/1563 Loss: 1.444 | Acc: 48.089% (6694/13920)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 435/1563 Loss: 1.444 | Acc: 48.101% (6711/13952)\n",
      "Epoch 4 Step 436/1563 Loss: 1.444 | Acc: 48.091% (6725/13984)\n",
      "Epoch 4 Step 437/1563 Loss: 1.444 | Acc: 48.081% (6739/14016)\n",
      "Epoch 4 Step 438/1563 Loss: 1.444 | Acc: 48.085% (6755/14048)\n",
      "Epoch 4 Step 439/1563 Loss: 1.444 | Acc: 48.075% (6769/14080)\n",
      "Epoch 4 Step 440/1563 Loss: 1.444 | Acc: 48.108% (6789/14112)\n",
      "Epoch 4 Step 441/1563 Loss: 1.444 | Acc: 48.084% (6801/14144)\n",
      "Epoch 4 Step 442/1563 Loss: 1.444 | Acc: 48.046% (6811/14176)\n",
      "Epoch 4 Step 443/1563 Loss: 1.445 | Acc: 48.029% (6824/14208)\n",
      "Epoch 4 Step 444/1563 Loss: 1.446 | Acc: 48.006% (6836/14240)\n",
      "Epoch 4 Step 445/1563 Loss: 1.446 | Acc: 47.975% (6847/14272)\n",
      "Epoch 4 Step 446/1563 Loss: 1.447 | Acc: 47.959% (6860/14304)\n",
      "Epoch 4 Step 447/1563 Loss: 1.446 | Acc: 47.977% (6878/14336)\n",
      "Epoch 4 Step 448/1563 Loss: 1.446 | Acc: 47.982% (6894/14368)\n",
      "Epoch 4 Step 449/1563 Loss: 1.446 | Acc: 47.986% (6910/14400)\n",
      "Epoch 4 Step 450/1563 Loss: 1.446 | Acc: 47.970% (6923/14432)\n",
      "Epoch 4 Step 451/1563 Loss: 1.445 | Acc: 47.995% (6942/14464)\n",
      "Epoch 4 Step 452/1563 Loss: 1.446 | Acc: 47.958% (6952/14496)\n",
      "Epoch 4 Step 453/1563 Loss: 1.446 | Acc: 47.956% (6967/14528)\n",
      "Epoch 4 Step 454/1563 Loss: 1.446 | Acc: 47.933% (6979/14560)\n",
      "Epoch 4 Step 455/1563 Loss: 1.446 | Acc: 47.930% (6994/14592)\n",
      "Epoch 4 Step 456/1563 Loss: 1.446 | Acc: 47.942% (7011/14624)\n",
      "Epoch 4 Step 457/1563 Loss: 1.446 | Acc: 47.939% (7026/14656)\n",
      "Epoch 4 Step 458/1563 Loss: 1.446 | Acc: 47.971% (7046/14688)\n",
      "Epoch 4 Step 459/1563 Loss: 1.446 | Acc: 47.969% (7061/14720)\n",
      "Epoch 4 Step 460/1563 Loss: 1.446 | Acc: 47.946% (7073/14752)\n",
      "Epoch 4 Step 461/1563 Loss: 1.445 | Acc: 47.944% (7088/14784)\n",
      "Epoch 4 Step 462/1563 Loss: 1.445 | Acc: 47.975% (7108/14816)\n",
      "Epoch 4 Step 463/1563 Loss: 1.445 | Acc: 47.966% (7122/14848)\n",
      "Epoch 4 Step 464/1563 Loss: 1.445 | Acc: 47.991% (7141/14880)\n",
      "Epoch 4 Step 465/1563 Loss: 1.445 | Acc: 47.975% (7154/14912)\n",
      "Epoch 4 Step 466/1563 Loss: 1.445 | Acc: 47.972% (7169/14944)\n",
      "Epoch 4 Step 467/1563 Loss: 1.445 | Acc: 47.990% (7187/14976)\n",
      "Epoch 4 Step 468/1563 Loss: 1.445 | Acc: 47.988% (7202/15008)\n",
      "Epoch 4 Step 469/1563 Loss: 1.445 | Acc: 47.979% (7216/15040)\n",
      "Epoch 4 Step 470/1563 Loss: 1.444 | Acc: 48.003% (7235/15072)\n",
      "Epoch 4 Step 471/1563 Loss: 1.444 | Acc: 47.987% (7248/15104)\n",
      "Epoch 4 Step 472/1563 Loss: 1.444 | Acc: 47.985% (7263/15136)\n",
      "Epoch 4 Step 473/1563 Loss: 1.444 | Acc: 48.009% (7282/15168)\n",
      "Epoch 4 Step 474/1563 Loss: 1.445 | Acc: 47.987% (7294/15200)\n",
      "Epoch 4 Step 475/1563 Loss: 1.444 | Acc: 48.037% (7317/15232)\n",
      "Epoch 4 Step 476/1563 Loss: 1.445 | Acc: 48.015% (7329/15264)\n",
      "Epoch 4 Step 477/1563 Loss: 1.445 | Acc: 47.993% (7341/15296)\n",
      "Epoch 4 Step 478/1563 Loss: 1.446 | Acc: 47.958% (7351/15328)\n",
      "Epoch 4 Step 479/1563 Loss: 1.446 | Acc: 47.956% (7366/15360)\n",
      "Epoch 4 Step 480/1563 Loss: 1.447 | Acc: 47.953% (7381/15392)\n",
      "Epoch 4 Step 481/1563 Loss: 1.446 | Acc: 47.977% (7400/15424)\n",
      "Epoch 4 Step 482/1563 Loss: 1.446 | Acc: 48.001% (7419/15456)\n",
      "Epoch 4 Step 483/1563 Loss: 1.445 | Acc: 48.018% (7437/15488)\n",
      "Epoch 4 Step 484/1563 Loss: 1.446 | Acc: 48.015% (7452/15520)\n",
      "Epoch 4 Step 485/1563 Loss: 1.445 | Acc: 48.020% (7468/15552)\n",
      "Epoch 4 Step 486/1563 Loss: 1.445 | Acc: 48.043% (7487/15584)\n",
      "Epoch 4 Step 487/1563 Loss: 1.445 | Acc: 48.047% (7503/15616)\n",
      "Epoch 4 Step 488/1563 Loss: 1.445 | Acc: 48.025% (7515/15648)\n",
      "Epoch 4 Step 489/1563 Loss: 1.445 | Acc: 48.029% (7531/15680)\n",
      "Epoch 4 Step 490/1563 Loss: 1.445 | Acc: 48.033% (7547/15712)\n",
      "Epoch 4 Step 491/1563 Loss: 1.445 | Acc: 48.063% (7567/15744)\n",
      "Epoch 4 Step 492/1563 Loss: 1.445 | Acc: 48.079% (7585/15776)\n",
      "Epoch 4 Step 493/1563 Loss: 1.445 | Acc: 48.064% (7598/15808)\n",
      "Epoch 4 Step 494/1563 Loss: 1.445 | Acc: 48.043% (7610/15840)\n",
      "Epoch 4 Step 495/1563 Loss: 1.445 | Acc: 48.047% (7626/15872)\n",
      "Epoch 4 Step 496/1563 Loss: 1.445 | Acc: 48.051% (7642/15904)\n",
      "Epoch 4 Step 497/1563 Loss: 1.445 | Acc: 48.055% (7658/15936)\n",
      "Epoch 4 Step 498/1563 Loss: 1.446 | Acc: 48.046% (7672/15968)\n",
      "Epoch 4 Step 499/1563 Loss: 1.445 | Acc: 48.075% (7692/16000)\n",
      "Epoch 4 Step 500/1563 Loss: 1.446 | Acc: 48.048% (7703/16032)\n",
      "Epoch 4 Step 501/1563 Loss: 1.445 | Acc: 48.064% (7721/16064)\n",
      "Epoch 4 Step 502/1563 Loss: 1.445 | Acc: 48.105% (7743/16096)\n",
      "Epoch 4 Step 503/1563 Loss: 1.445 | Acc: 48.109% (7759/16128)\n",
      "Epoch 4 Step 504/1563 Loss: 1.445 | Acc: 48.069% (7768/16160)\n",
      "Epoch 4 Step 505/1563 Loss: 1.445 | Acc: 48.079% (7785/16192)\n",
      "Epoch 4 Step 506/1563 Loss: 1.445 | Acc: 48.065% (7798/16224)\n",
      "Epoch 4 Step 507/1563 Loss: 1.445 | Acc: 48.056% (7812/16256)\n",
      "Epoch 4 Step 508/1563 Loss: 1.445 | Acc: 48.048% (7826/16288)\n",
      "Epoch 4 Step 509/1563 Loss: 1.445 | Acc: 48.033% (7839/16320)\n",
      "Epoch 4 Step 510/1563 Loss: 1.445 | Acc: 48.019% (7852/16352)\n",
      "Epoch 4 Step 511/1563 Loss: 1.445 | Acc: 48.016% (7867/16384)\n",
      "Epoch 4 Step 512/1563 Loss: 1.446 | Acc: 48.014% (7882/16416)\n",
      "Epoch 4 Step 513/1563 Loss: 1.446 | Acc: 48.018% (7898/16448)\n",
      "Epoch 4 Step 514/1563 Loss: 1.446 | Acc: 47.992% (7909/16480)\n",
      "Epoch 4 Step 515/1563 Loss: 1.446 | Acc: 47.989% (7924/16512)\n",
      "Epoch 4 Step 516/1563 Loss: 1.447 | Acc: 47.963% (7935/16544)\n",
      "Epoch 4 Step 517/1563 Loss: 1.446 | Acc: 47.991% (7955/16576)\n",
      "Epoch 4 Step 518/1563 Loss: 1.447 | Acc: 47.977% (7968/16608)\n",
      "Epoch 4 Step 519/1563 Loss: 1.447 | Acc: 47.963% (7981/16640)\n",
      "Epoch 4 Step 520/1563 Loss: 1.447 | Acc: 47.991% (8001/16672)\n",
      "Epoch 4 Step 521/1563 Loss: 1.447 | Acc: 47.983% (8015/16704)\n",
      "Epoch 4 Step 522/1563 Loss: 1.447 | Acc: 47.986% (8031/16736)\n",
      "Epoch 4 Step 523/1563 Loss: 1.446 | Acc: 47.990% (8047/16768)\n",
      "Epoch 4 Step 524/1563 Loss: 1.447 | Acc: 47.976% (8060/16800)\n",
      "Epoch 4 Step 525/1563 Loss: 1.447 | Acc: 47.950% (8071/16832)\n",
      "Epoch 4 Step 526/1563 Loss: 1.447 | Acc: 47.948% (8086/16864)\n",
      "Epoch 4 Step 527/1563 Loss: 1.447 | Acc: 47.952% (8102/16896)\n",
      "Epoch 4 Step 528/1563 Loss: 1.447 | Acc: 47.932% (8114/16928)\n",
      "Epoch 4 Step 529/1563 Loss: 1.447 | Acc: 47.936% (8130/16960)\n",
      "Epoch 4 Step 530/1563 Loss: 1.447 | Acc: 47.946% (8147/16992)\n",
      "Epoch 4 Step 531/1563 Loss: 1.446 | Acc: 47.997% (8171/17024)\n",
      "Epoch 4 Step 532/1563 Loss: 1.447 | Acc: 47.989% (8185/17056)\n",
      "Epoch 4 Step 533/1563 Loss: 1.446 | Acc: 48.016% (8205/17088)\n",
      "Epoch 4 Step 534/1563 Loss: 1.446 | Acc: 48.008% (8219/17120)\n",
      "Epoch 4 Step 535/1563 Loss: 1.446 | Acc: 48.006% (8234/17152)\n",
      "Epoch 4 Step 536/1563 Loss: 1.447 | Acc: 48.010% (8250/17184)\n",
      "Epoch 4 Step 537/1563 Loss: 1.446 | Acc: 48.025% (8268/17216)\n",
      "Epoch 4 Step 538/1563 Loss: 1.447 | Acc: 48.011% (8281/17248)\n",
      "Epoch 4 Step 539/1563 Loss: 1.447 | Acc: 47.986% (8292/17280)\n",
      "Epoch 4 Step 540/1563 Loss: 1.447 | Acc: 47.978% (8306/17312)\n",
      "Epoch 4 Step 541/1563 Loss: 1.447 | Acc: 47.999% (8325/17344)\n",
      "Epoch 4 Step 542/1563 Loss: 1.446 | Acc: 48.020% (8344/17376)\n",
      "Epoch 4 Step 543/1563 Loss: 1.446 | Acc: 48.024% (8360/17408)\n",
      "Epoch 4 Step 544/1563 Loss: 1.447 | Acc: 47.999% (8371/17440)\n",
      "Epoch 4 Step 545/1563 Loss: 1.447 | Acc: 47.997% (8386/17472)\n",
      "Epoch 4 Step 546/1563 Loss: 1.447 | Acc: 48.000% (8402/17504)\n",
      "Epoch 4 Step 547/1563 Loss: 1.447 | Acc: 47.987% (8415/17536)\n",
      "Epoch 4 Step 548/1563 Loss: 1.447 | Acc: 47.979% (8429/17568)\n",
      "Epoch 4 Step 549/1563 Loss: 1.447 | Acc: 47.994% (8447/17600)\n",
      "Epoch 4 Step 550/1563 Loss: 1.446 | Acc: 48.009% (8465/17632)\n",
      "Epoch 4 Step 551/1563 Loss: 1.446 | Acc: 48.019% (8482/17664)\n",
      "Epoch 4 Step 552/1563 Loss: 1.446 | Acc: 48.011% (8496/17696)\n",
      "Epoch 4 Step 553/1563 Loss: 1.445 | Acc: 48.026% (8514/17728)\n",
      "Epoch 4 Step 554/1563 Loss: 1.445 | Acc: 48.035% (8531/17760)\n",
      "Epoch 4 Step 555/1563 Loss: 1.445 | Acc: 48.044% (8548/17792)\n",
      "Epoch 4 Step 556/1563 Loss: 1.445 | Acc: 48.048% (8564/17824)\n",
      "Epoch 4 Step 557/1563 Loss: 1.445 | Acc: 48.057% (8581/17856)\n",
      "Epoch 4 Step 558/1563 Loss: 1.446 | Acc: 48.038% (8593/17888)\n",
      "Epoch 4 Step 559/1563 Loss: 1.446 | Acc: 48.013% (8604/17920)\n",
      "Epoch 4 Step 560/1563 Loss: 1.446 | Acc: 48.011% (8619/17952)\n",
      "Epoch 4 Step 561/1563 Loss: 1.446 | Acc: 48.015% (8635/17984)\n",
      "Epoch 4 Step 562/1563 Loss: 1.446 | Acc: 48.013% (8650/18016)\n",
      "Epoch 4 Step 563/1563 Loss: 1.446 | Acc: 48.016% (8666/18048)\n",
      "Epoch 4 Step 564/1563 Loss: 1.446 | Acc: 48.031% (8684/18080)\n",
      "Epoch 4 Step 565/1563 Loss: 1.446 | Acc: 48.018% (8697/18112)\n",
      "Epoch 4 Step 566/1563 Loss: 1.446 | Acc: 47.999% (8709/18144)\n",
      "Epoch 4 Step 567/1563 Loss: 1.446 | Acc: 48.019% (8728/18176)\n",
      "Epoch 4 Step 568/1563 Loss: 1.446 | Acc: 48.006% (8741/18208)\n",
      "Epoch 4 Step 569/1563 Loss: 1.446 | Acc: 47.993% (8754/18240)\n",
      "Epoch 4 Step 570/1563 Loss: 1.445 | Acc: 47.997% (8770/18272)\n",
      "Epoch 4 Step 571/1563 Loss: 1.445 | Acc: 48.017% (8789/18304)\n",
      "Epoch 4 Step 572/1563 Loss: 1.445 | Acc: 48.037% (8808/18336)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 573/1563 Loss: 1.445 | Acc: 48.029% (8822/18368)\n",
      "Epoch 4 Step 574/1563 Loss: 1.445 | Acc: 48.011% (8834/18400)\n",
      "Epoch 4 Step 575/1563 Loss: 1.445 | Acc: 47.987% (8845/18432)\n",
      "Epoch 4 Step 576/1563 Loss: 1.445 | Acc: 47.991% (8861/18464)\n",
      "Epoch 4 Step 577/1563 Loss: 1.444 | Acc: 47.994% (8877/18496)\n",
      "Epoch 4 Step 578/1563 Loss: 1.444 | Acc: 47.998% (8893/18528)\n",
      "Epoch 4 Step 579/1563 Loss: 1.444 | Acc: 47.985% (8906/18560)\n",
      "Epoch 4 Step 580/1563 Loss: 1.445 | Acc: 47.972% (8919/18592)\n",
      "Epoch 4 Step 581/1563 Loss: 1.445 | Acc: 47.944% (8929/18624)\n",
      "Epoch 4 Step 582/1563 Loss: 1.444 | Acc: 47.947% (8945/18656)\n",
      "Epoch 4 Step 583/1563 Loss: 1.445 | Acc: 47.935% (8958/18688)\n",
      "Epoch 4 Step 584/1563 Loss: 1.444 | Acc: 47.949% (8976/18720)\n",
      "Epoch 4 Step 585/1563 Loss: 1.444 | Acc: 47.952% (8992/18752)\n",
      "Epoch 4 Step 586/1563 Loss: 1.444 | Acc: 47.950% (9007/18784)\n",
      "Epoch 4 Step 587/1563 Loss: 1.444 | Acc: 47.943% (9021/18816)\n",
      "Epoch 4 Step 588/1563 Loss: 1.444 | Acc: 47.957% (9039/18848)\n",
      "Epoch 4 Step 589/1563 Loss: 1.443 | Acc: 47.966% (9056/18880)\n",
      "Epoch 4 Step 590/1563 Loss: 1.443 | Acc: 47.985% (9075/18912)\n",
      "Epoch 4 Step 591/1563 Loss: 1.443 | Acc: 47.989% (9091/18944)\n",
      "Epoch 4 Step 592/1563 Loss: 1.444 | Acc: 47.966% (9102/18976)\n",
      "Epoch 4 Step 593/1563 Loss: 1.444 | Acc: 47.959% (9116/19008)\n",
      "Epoch 4 Step 594/1563 Loss: 1.444 | Acc: 47.978% (9135/19040)\n",
      "Epoch 4 Step 595/1563 Loss: 1.444 | Acc: 47.981% (9151/19072)\n",
      "Epoch 4 Step 596/1563 Loss: 1.444 | Acc: 47.969% (9164/19104)\n",
      "Epoch 4 Step 597/1563 Loss: 1.444 | Acc: 47.972% (9180/19136)\n",
      "Epoch 4 Step 598/1563 Loss: 1.444 | Acc: 47.986% (9198/19168)\n",
      "Epoch 4 Step 599/1563 Loss: 1.444 | Acc: 48.000% (9216/19200)\n",
      "Epoch 4 Step 600/1563 Loss: 1.443 | Acc: 48.009% (9233/19232)\n",
      "Epoch 4 Step 601/1563 Loss: 1.443 | Acc: 48.022% (9251/19264)\n",
      "Epoch 4 Step 602/1563 Loss: 1.443 | Acc: 48.031% (9268/19296)\n",
      "Epoch 4 Step 603/1563 Loss: 1.443 | Acc: 48.008% (9279/19328)\n",
      "Epoch 4 Step 604/1563 Loss: 1.443 | Acc: 48.017% (9296/19360)\n",
      "Epoch 4 Step 605/1563 Loss: 1.443 | Acc: 48.025% (9313/19392)\n",
      "Epoch 4 Step 606/1563 Loss: 1.443 | Acc: 48.039% (9331/19424)\n",
      "Epoch 4 Step 607/1563 Loss: 1.443 | Acc: 48.031% (9345/19456)\n",
      "Epoch 4 Step 608/1563 Loss: 1.443 | Acc: 48.019% (9358/19488)\n",
      "Epoch 4 Step 609/1563 Loss: 1.443 | Acc: 48.023% (9374/19520)\n",
      "Epoch 4 Step 610/1563 Loss: 1.443 | Acc: 48.016% (9388/19552)\n",
      "Epoch 4 Step 611/1563 Loss: 1.444 | Acc: 48.009% (9402/19584)\n",
      "Epoch 4 Step 612/1563 Loss: 1.444 | Acc: 48.002% (9416/19616)\n",
      "Epoch 4 Step 613/1563 Loss: 1.444 | Acc: 48.000% (9431/19648)\n",
      "Epoch 4 Step 614/1563 Loss: 1.444 | Acc: 48.008% (9448/19680)\n",
      "Epoch 4 Step 615/1563 Loss: 1.444 | Acc: 48.006% (9463/19712)\n",
      "Epoch 4 Step 616/1563 Loss: 1.444 | Acc: 47.989% (9475/19744)\n",
      "Epoch 4 Step 617/1563 Loss: 1.443 | Acc: 48.008% (9494/19776)\n",
      "Epoch 4 Step 618/1563 Loss: 1.443 | Acc: 48.031% (9514/19808)\n",
      "Epoch 4 Step 619/1563 Loss: 1.443 | Acc: 48.019% (9527/19840)\n",
      "Epoch 4 Step 620/1563 Loss: 1.443 | Acc: 48.017% (9542/19872)\n",
      "Epoch 4 Step 621/1563 Loss: 1.443 | Acc: 48.020% (9558/19904)\n",
      "Epoch 4 Step 622/1563 Loss: 1.443 | Acc: 48.014% (9572/19936)\n",
      "Epoch 4 Step 623/1563 Loss: 1.443 | Acc: 48.017% (9588/19968)\n",
      "Epoch 4 Step 624/1563 Loss: 1.443 | Acc: 48.035% (9607/20000)\n",
      "Epoch 4 Step 625/1563 Loss: 1.443 | Acc: 48.033% (9622/20032)\n",
      "Epoch 4 Step 626/1563 Loss: 1.443 | Acc: 48.036% (9638/20064)\n",
      "Epoch 4 Step 627/1563 Loss: 1.444 | Acc: 48.010% (9648/20096)\n",
      "Epoch 4 Step 628/1563 Loss: 1.444 | Acc: 48.003% (9662/20128)\n",
      "Epoch 4 Step 629/1563 Loss: 1.444 | Acc: 48.001% (9677/20160)\n",
      "Epoch 4 Step 630/1563 Loss: 1.444 | Acc: 47.989% (9690/20192)\n",
      "Epoch 4 Step 631/1563 Loss: 1.444 | Acc: 47.983% (9704/20224)\n",
      "Epoch 4 Step 632/1563 Loss: 1.444 | Acc: 47.976% (9718/20256)\n",
      "Epoch 4 Step 633/1563 Loss: 1.445 | Acc: 47.954% (9729/20288)\n",
      "Epoch 4 Step 634/1563 Loss: 1.445 | Acc: 47.958% (9745/20320)\n",
      "Epoch 4 Step 635/1563 Loss: 1.445 | Acc: 47.961% (9761/20352)\n",
      "Epoch 4 Step 636/1563 Loss: 1.445 | Acc: 47.959% (9776/20384)\n",
      "Epoch 4 Step 637/1563 Loss: 1.445 | Acc: 47.948% (9789/20416)\n",
      "Epoch 4 Step 638/1563 Loss: 1.446 | Acc: 47.926% (9800/20448)\n",
      "Epoch 4 Step 639/1563 Loss: 1.445 | Acc: 47.920% (9814/20480)\n",
      "Epoch 4 Step 640/1563 Loss: 1.445 | Acc: 47.938% (9833/20512)\n",
      "Epoch 4 Step 641/1563 Loss: 1.445 | Acc: 47.941% (9849/20544)\n",
      "Epoch 4 Step 642/1563 Loss: 1.445 | Acc: 47.939% (9864/20576)\n",
      "Epoch 4 Step 643/1563 Loss: 1.444 | Acc: 47.952% (9882/20608)\n",
      "Epoch 4 Step 644/1563 Loss: 1.444 | Acc: 47.960% (9899/20640)\n",
      "Epoch 4 Step 645/1563 Loss: 1.444 | Acc: 47.959% (9914/20672)\n",
      "Epoch 4 Step 646/1563 Loss: 1.444 | Acc: 47.952% (9928/20704)\n",
      "Epoch 4 Step 647/1563 Loss: 1.444 | Acc: 47.955% (9944/20736)\n",
      "Epoch 4 Step 648/1563 Loss: 1.444 | Acc: 47.963% (9961/20768)\n",
      "Epoch 4 Step 649/1563 Loss: 1.444 | Acc: 47.981% (9980/20800)\n",
      "Epoch 4 Step 650/1563 Loss: 1.444 | Acc: 47.969% (9993/20832)\n",
      "Epoch 4 Step 651/1563 Loss: 1.444 | Acc: 47.973% (10009/20864)\n",
      "Epoch 4 Step 652/1563 Loss: 1.444 | Acc: 47.985% (10027/20896)\n",
      "Epoch 4 Step 653/1563 Loss: 1.444 | Acc: 47.979% (10041/20928)\n",
      "Epoch 4 Step 654/1563 Loss: 1.444 | Acc: 47.982% (10057/20960)\n",
      "Epoch 4 Step 655/1563 Loss: 1.444 | Acc: 47.980% (10072/20992)\n",
      "Epoch 4 Step 656/1563 Loss: 1.444 | Acc: 47.974% (10086/21024)\n",
      "Epoch 4 Step 657/1563 Loss: 1.444 | Acc: 47.972% (10101/21056)\n",
      "Epoch 4 Step 658/1563 Loss: 1.444 | Acc: 47.970% (10116/21088)\n",
      "Epoch 4 Step 659/1563 Loss: 1.444 | Acc: 47.983% (10134/21120)\n",
      "Epoch 4 Step 660/1563 Loss: 1.444 | Acc: 47.991% (10151/21152)\n",
      "Epoch 4 Step 661/1563 Loss: 1.444 | Acc: 47.989% (10166/21184)\n",
      "Epoch 4 Step 662/1563 Loss: 1.443 | Acc: 47.987% (10181/21216)\n",
      "Epoch 4 Step 663/1563 Loss: 1.443 | Acc: 47.995% (10198/21248)\n",
      "Epoch 4 Step 664/1563 Loss: 1.443 | Acc: 47.993% (10213/21280)\n",
      "Epoch 4 Step 665/1563 Loss: 1.443 | Acc: 48.006% (10231/21312)\n",
      "Epoch 4 Step 666/1563 Loss: 1.443 | Acc: 48.018% (10249/21344)\n",
      "Epoch 4 Step 667/1563 Loss: 1.443 | Acc: 47.998% (10260/21376)\n",
      "Epoch 4 Step 668/1563 Loss: 1.443 | Acc: 47.991% (10274/21408)\n",
      "Epoch 4 Step 669/1563 Loss: 1.443 | Acc: 47.990% (10289/21440)\n",
      "Epoch 4 Step 670/1563 Loss: 1.443 | Acc: 47.974% (10301/21472)\n",
      "Epoch 4 Step 671/1563 Loss: 1.443 | Acc: 47.982% (10318/21504)\n",
      "Epoch 4 Step 672/1563 Loss: 1.443 | Acc: 47.999% (10337/21536)\n",
      "Epoch 4 Step 673/1563 Loss: 1.444 | Acc: 47.983% (10349/21568)\n",
      "Epoch 4 Step 674/1563 Loss: 1.444 | Acc: 47.981% (10364/21600)\n",
      "Epoch 4 Step 675/1563 Loss: 1.444 | Acc: 47.971% (10377/21632)\n",
      "Epoch 4 Step 676/1563 Loss: 1.444 | Acc: 47.960% (10390/21664)\n",
      "Epoch 4 Step 677/1563 Loss: 1.445 | Acc: 47.935% (10400/21696)\n",
      "Epoch 4 Step 678/1563 Loss: 1.445 | Acc: 47.947% (10418/21728)\n",
      "Epoch 4 Step 679/1563 Loss: 1.444 | Acc: 47.946% (10433/21760)\n",
      "Epoch 4 Step 680/1563 Loss: 1.445 | Acc: 47.935% (10446/21792)\n",
      "Epoch 4 Step 681/1563 Loss: 1.445 | Acc: 47.943% (10463/21824)\n",
      "Epoch 4 Step 682/1563 Loss: 1.445 | Acc: 47.941% (10478/21856)\n",
      "Epoch 4 Step 683/1563 Loss: 1.444 | Acc: 47.962% (10498/21888)\n",
      "Epoch 4 Step 684/1563 Loss: 1.444 | Acc: 47.965% (10514/21920)\n",
      "Epoch 4 Step 685/1563 Loss: 1.445 | Acc: 47.946% (10525/21952)\n",
      "Epoch 4 Step 686/1563 Loss: 1.444 | Acc: 47.967% (10545/21984)\n",
      "Epoch 4 Step 687/1563 Loss: 1.444 | Acc: 47.974% (10562/22016)\n",
      "Epoch 4 Step 688/1563 Loss: 1.444 | Acc: 47.991% (10581/22048)\n",
      "Epoch 4 Step 689/1563 Loss: 1.444 | Acc: 48.007% (10600/22080)\n",
      "Epoch 4 Step 690/1563 Loss: 1.444 | Acc: 48.001% (10614/22112)\n",
      "Epoch 4 Step 691/1563 Loss: 1.444 | Acc: 48.013% (10632/22144)\n",
      "Epoch 4 Step 692/1563 Loss: 1.443 | Acc: 48.029% (10651/22176)\n",
      "Epoch 4 Step 693/1563 Loss: 1.443 | Acc: 48.041% (10669/22208)\n",
      "Epoch 4 Step 694/1563 Loss: 1.444 | Acc: 48.035% (10683/22240)\n",
      "Epoch 4 Step 695/1563 Loss: 1.444 | Acc: 48.038% (10699/22272)\n",
      "Epoch 4 Step 696/1563 Loss: 1.443 | Acc: 48.045% (10716/22304)\n",
      "Epoch 4 Step 697/1563 Loss: 1.443 | Acc: 48.035% (10729/22336)\n",
      "Epoch 4 Step 698/1563 Loss: 1.443 | Acc: 48.033% (10744/22368)\n",
      "Epoch 4 Step 699/1563 Loss: 1.444 | Acc: 48.018% (10756/22400)\n",
      "Epoch 4 Step 700/1563 Loss: 1.444 | Acc: 48.021% (10772/22432)\n",
      "Epoch 4 Step 701/1563 Loss: 1.444 | Acc: 48.015% (10786/22464)\n",
      "Epoch 4 Step 702/1563 Loss: 1.444 | Acc: 48.022% (10803/22496)\n",
      "Epoch 4 Step 703/1563 Loss: 1.443 | Acc: 48.034% (10821/22528)\n",
      "Epoch 4 Step 704/1563 Loss: 1.443 | Acc: 48.054% (10841/22560)\n",
      "Epoch 4 Step 705/1563 Loss: 1.443 | Acc: 48.044% (10854/22592)\n",
      "Epoch 4 Step 706/1563 Loss: 1.443 | Acc: 48.029% (10866/22624)\n",
      "Epoch 4 Step 707/1563 Loss: 1.443 | Acc: 48.045% (10885/22656)\n",
      "Epoch 4 Step 708/1563 Loss: 1.443 | Acc: 48.034% (10898/22688)\n",
      "Epoch 4 Step 709/1563 Loss: 1.443 | Acc: 48.028% (10912/22720)\n",
      "Epoch 4 Step 710/1563 Loss: 1.443 | Acc: 48.018% (10925/22752)\n",
      "Epoch 4 Step 711/1563 Loss: 1.443 | Acc: 48.021% (10941/22784)\n",
      "Epoch 4 Step 712/1563 Loss: 1.444 | Acc: 48.010% (10954/22816)\n",
      "Epoch 4 Step 713/1563 Loss: 1.444 | Acc: 48.026% (10973/22848)\n",
      "Epoch 4 Step 714/1563 Loss: 1.443 | Acc: 48.042% (10992/22880)\n",
      "Epoch 4 Step 715/1563 Loss: 1.443 | Acc: 48.040% (11007/22912)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 716/1563 Loss: 1.443 | Acc: 48.039% (11022/22944)\n",
      "Epoch 4 Step 717/1563 Loss: 1.444 | Acc: 48.024% (11034/22976)\n",
      "Epoch 4 Step 718/1563 Loss: 1.444 | Acc: 48.005% (11045/23008)\n",
      "Epoch 4 Step 719/1563 Loss: 1.444 | Acc: 47.990% (11057/23040)\n",
      "Epoch 4 Step 720/1563 Loss: 1.444 | Acc: 47.993% (11073/23072)\n",
      "Epoch 4 Step 721/1563 Loss: 1.444 | Acc: 48.000% (11090/23104)\n",
      "Epoch 4 Step 722/1563 Loss: 1.444 | Acc: 47.994% (11104/23136)\n",
      "Epoch 4 Step 723/1563 Loss: 1.444 | Acc: 48.019% (11125/23168)\n",
      "Epoch 4 Step 724/1563 Loss: 1.444 | Acc: 48.026% (11142/23200)\n",
      "Epoch 4 Step 725/1563 Loss: 1.444 | Acc: 48.011% (11154/23232)\n",
      "Epoch 4 Step 726/1563 Loss: 1.444 | Acc: 48.014% (11170/23264)\n",
      "Epoch 4 Step 727/1563 Loss: 1.444 | Acc: 48.000% (11182/23296)\n",
      "Epoch 4 Step 728/1563 Loss: 1.444 | Acc: 48.007% (11199/23328)\n",
      "Epoch 4 Step 729/1563 Loss: 1.444 | Acc: 47.992% (11211/23360)\n",
      "Epoch 4 Step 730/1563 Loss: 1.444 | Acc: 48.004% (11229/23392)\n",
      "Epoch 4 Step 731/1563 Loss: 1.444 | Acc: 48.019% (11248/23424)\n",
      "Epoch 4 Step 732/1563 Loss: 1.443 | Acc: 48.018% (11263/23456)\n",
      "Epoch 4 Step 733/1563 Loss: 1.444 | Acc: 47.999% (11274/23488)\n",
      "Epoch 4 Step 734/1563 Loss: 1.444 | Acc: 47.989% (11287/23520)\n",
      "Epoch 4 Step 735/1563 Loss: 1.444 | Acc: 47.983% (11301/23552)\n",
      "Epoch 4 Step 736/1563 Loss: 1.444 | Acc: 47.969% (11313/23584)\n",
      "Epoch 4 Step 737/1563 Loss: 1.444 | Acc: 47.972% (11329/23616)\n",
      "Epoch 4 Step 738/1563 Loss: 1.443 | Acc: 47.974% (11345/23648)\n",
      "Epoch 4 Step 739/1563 Loss: 1.443 | Acc: 47.990% (11364/23680)\n",
      "Epoch 4 Step 740/1563 Loss: 1.443 | Acc: 47.984% (11378/23712)\n",
      "Epoch 4 Step 741/1563 Loss: 1.443 | Acc: 47.978% (11392/23744)\n",
      "Epoch 4 Step 742/1563 Loss: 1.443 | Acc: 47.964% (11404/23776)\n",
      "Epoch 4 Step 743/1563 Loss: 1.443 | Acc: 47.967% (11420/23808)\n",
      "Epoch 4 Step 744/1563 Loss: 1.444 | Acc: 47.991% (11441/23840)\n",
      "Epoch 4 Step 745/1563 Loss: 1.444 | Acc: 47.998% (11458/23872)\n",
      "Epoch 4 Step 746/1563 Loss: 1.444 | Acc: 47.996% (11473/23904)\n",
      "Epoch 4 Step 747/1563 Loss: 1.444 | Acc: 47.999% (11489/23936)\n",
      "Epoch 4 Step 748/1563 Loss: 1.444 | Acc: 47.981% (11500/23968)\n",
      "Epoch 4 Step 749/1563 Loss: 1.444 | Acc: 47.983% (11516/24000)\n",
      "Epoch 4 Step 750/1563 Loss: 1.444 | Acc: 47.982% (11531/24032)\n",
      "Epoch 4 Step 751/1563 Loss: 1.444 | Acc: 47.997% (11550/24064)\n",
      "Epoch 4 Step 752/1563 Loss: 1.444 | Acc: 47.996% (11565/24096)\n",
      "Epoch 4 Step 753/1563 Loss: 1.445 | Acc: 47.982% (11577/24128)\n",
      "Epoch 4 Step 754/1563 Loss: 1.444 | Acc: 47.993% (11595/24160)\n",
      "Epoch 4 Step 755/1563 Loss: 1.444 | Acc: 47.999% (11612/24192)\n",
      "Epoch 4 Step 756/1563 Loss: 1.444 | Acc: 48.006% (11629/24224)\n",
      "Epoch 4 Step 757/1563 Loss: 1.444 | Acc: 48.000% (11643/24256)\n",
      "Epoch 4 Step 758/1563 Loss: 1.444 | Acc: 47.995% (11657/24288)\n",
      "Epoch 4 Step 759/1563 Loss: 1.444 | Acc: 47.989% (11671/24320)\n",
      "Epoch 4 Step 760/1563 Loss: 1.444 | Acc: 48.012% (11692/24352)\n",
      "Epoch 4 Step 761/1563 Loss: 1.444 | Acc: 48.023% (11710/24384)\n",
      "Epoch 4 Step 762/1563 Loss: 1.444 | Acc: 48.010% (11722/24416)\n",
      "Epoch 4 Step 763/1563 Loss: 1.444 | Acc: 47.992% (11733/24448)\n",
      "Epoch 4 Step 764/1563 Loss: 1.445 | Acc: 47.978% (11745/24480)\n",
      "Epoch 4 Step 765/1563 Loss: 1.444 | Acc: 48.001% (11766/24512)\n",
      "Epoch 4 Step 766/1563 Loss: 1.444 | Acc: 48.008% (11783/24544)\n",
      "Epoch 4 Step 767/1563 Loss: 1.444 | Acc: 48.002% (11797/24576)\n",
      "Epoch 4 Step 768/1563 Loss: 1.444 | Acc: 48.017% (11816/24608)\n",
      "Epoch 4 Step 769/1563 Loss: 1.444 | Acc: 48.036% (11836/24640)\n",
      "Epoch 4 Step 770/1563 Loss: 1.444 | Acc: 48.042% (11853/24672)\n",
      "Epoch 4 Step 771/1563 Loss: 1.444 | Acc: 48.025% (11864/24704)\n",
      "Epoch 4 Step 772/1563 Loss: 1.444 | Acc: 48.007% (11875/24736)\n",
      "Epoch 4 Step 773/1563 Loss: 1.444 | Acc: 48.018% (11893/24768)\n",
      "Epoch 4 Step 774/1563 Loss: 1.444 | Acc: 48.000% (11904/24800)\n",
      "Epoch 4 Step 775/1563 Loss: 1.444 | Acc: 47.978% (11914/24832)\n",
      "Epoch 4 Step 776/1563 Loss: 1.444 | Acc: 47.989% (11932/24864)\n",
      "Epoch 4 Step 777/1563 Loss: 1.444 | Acc: 47.984% (11946/24896)\n",
      "Epoch 4 Step 778/1563 Loss: 1.444 | Acc: 47.970% (11958/24928)\n",
      "Epoch 4 Step 779/1563 Loss: 1.444 | Acc: 47.981% (11976/24960)\n",
      "Epoch 4 Step 780/1563 Loss: 1.443 | Acc: 47.983% (11992/24992)\n",
      "Epoch 4 Step 781/1563 Loss: 1.444 | Acc: 47.958% (12001/25024)\n",
      "Epoch 4 Step 782/1563 Loss: 1.444 | Acc: 47.957% (12016/25056)\n",
      "Epoch 4 Step 783/1563 Loss: 1.444 | Acc: 47.931% (12025/25088)\n",
      "Epoch 4 Step 784/1563 Loss: 1.445 | Acc: 47.926% (12039/25120)\n",
      "Epoch 4 Step 785/1563 Loss: 1.445 | Acc: 47.929% (12055/25152)\n",
      "Epoch 4 Step 786/1563 Loss: 1.445 | Acc: 47.915% (12067/25184)\n",
      "Epoch 4 Step 787/1563 Loss: 1.445 | Acc: 47.910% (12081/25216)\n",
      "Epoch 4 Step 788/1563 Loss: 1.445 | Acc: 47.921% (12099/25248)\n",
      "Epoch 4 Step 789/1563 Loss: 1.445 | Acc: 47.931% (12117/25280)\n",
      "Epoch 4 Step 790/1563 Loss: 1.445 | Acc: 47.946% (12136/25312)\n",
      "Epoch 4 Step 791/1563 Loss: 1.445 | Acc: 47.956% (12154/25344)\n",
      "Epoch 4 Step 792/1563 Loss: 1.445 | Acc: 47.951% (12168/25376)\n",
      "Epoch 4 Step 793/1563 Loss: 1.445 | Acc: 47.957% (12185/25408)\n",
      "Epoch 4 Step 794/1563 Loss: 1.445 | Acc: 47.944% (12197/25440)\n",
      "Epoch 4 Step 795/1563 Loss: 1.445 | Acc: 47.943% (12212/25472)\n",
      "Epoch 4 Step 796/1563 Loss: 1.445 | Acc: 47.945% (12228/25504)\n",
      "Epoch 4 Step 797/1563 Loss: 1.445 | Acc: 47.932% (12240/25536)\n",
      "Epoch 4 Step 798/1563 Loss: 1.446 | Acc: 47.919% (12252/25568)\n",
      "Epoch 4 Step 799/1563 Loss: 1.446 | Acc: 47.934% (12271/25600)\n",
      "Epoch 4 Step 800/1563 Loss: 1.446 | Acc: 47.948% (12290/25632)\n",
      "Epoch 4 Step 801/1563 Loss: 1.446 | Acc: 47.935% (12302/25664)\n",
      "Epoch 4 Step 802/1563 Loss: 1.446 | Acc: 47.934% (12317/25696)\n",
      "Epoch 4 Step 803/1563 Loss: 1.446 | Acc: 47.924% (12330/25728)\n",
      "Epoch 4 Step 804/1563 Loss: 1.446 | Acc: 47.911% (12342/25760)\n",
      "Epoch 4 Step 805/1563 Loss: 1.446 | Acc: 47.914% (12358/25792)\n",
      "Epoch 4 Step 806/1563 Loss: 1.446 | Acc: 47.921% (12375/25824)\n",
      "Epoch 4 Step 807/1563 Loss: 1.446 | Acc: 47.927% (12392/25856)\n",
      "Epoch 4 Step 808/1563 Loss: 1.446 | Acc: 47.918% (12405/25888)\n",
      "Epoch 4 Step 809/1563 Loss: 1.446 | Acc: 47.917% (12420/25920)\n",
      "Epoch 4 Step 810/1563 Loss: 1.445 | Acc: 47.931% (12439/25952)\n",
      "Epoch 4 Step 811/1563 Loss: 1.446 | Acc: 47.914% (12450/25984)\n",
      "Epoch 4 Step 812/1563 Loss: 1.446 | Acc: 47.913% (12465/26016)\n",
      "Epoch 4 Step 813/1563 Loss: 1.446 | Acc: 47.900% (12477/26048)\n",
      "Epoch 4 Step 814/1563 Loss: 1.446 | Acc: 47.899% (12492/26080)\n",
      "Epoch 4 Step 815/1563 Loss: 1.446 | Acc: 47.901% (12508/26112)\n",
      "Epoch 4 Step 816/1563 Loss: 1.446 | Acc: 47.892% (12521/26144)\n",
      "Epoch 4 Step 817/1563 Loss: 1.446 | Acc: 47.884% (12534/26176)\n",
      "Epoch 4 Step 818/1563 Loss: 1.446 | Acc: 47.894% (12552/26208)\n",
      "Epoch 4 Step 819/1563 Loss: 1.447 | Acc: 47.877% (12563/26240)\n",
      "Epoch 4 Step 820/1563 Loss: 1.447 | Acc: 47.876% (12578/26272)\n",
      "Epoch 4 Step 821/1563 Loss: 1.447 | Acc: 47.882% (12595/26304)\n",
      "Epoch 4 Step 822/1563 Loss: 1.447 | Acc: 47.866% (12606/26336)\n",
      "Epoch 4 Step 823/1563 Loss: 1.447 | Acc: 47.861% (12620/26368)\n",
      "Epoch 4 Step 824/1563 Loss: 1.447 | Acc: 47.860% (12635/26400)\n",
      "Epoch 4 Step 825/1563 Loss: 1.447 | Acc: 47.866% (12652/26432)\n",
      "Epoch 4 Step 826/1563 Loss: 1.447 | Acc: 47.873% (12669/26464)\n",
      "Epoch 4 Step 827/1563 Loss: 1.447 | Acc: 47.879% (12686/26496)\n",
      "Epoch 4 Step 828/1563 Loss: 1.447 | Acc: 47.893% (12705/26528)\n",
      "Epoch 4 Step 829/1563 Loss: 1.447 | Acc: 47.895% (12721/26560)\n",
      "Epoch 4 Step 830/1563 Loss: 1.447 | Acc: 47.898% (12737/26592)\n",
      "Epoch 4 Step 831/1563 Loss: 1.447 | Acc: 47.904% (12754/26624)\n",
      "Epoch 4 Step 832/1563 Loss: 1.446 | Acc: 47.910% (12771/26656)\n",
      "Epoch 4 Step 833/1563 Loss: 1.446 | Acc: 47.920% (12789/26688)\n",
      "Epoch 4 Step 834/1563 Loss: 1.446 | Acc: 47.934% (12808/26720)\n",
      "Epoch 4 Step 835/1563 Loss: 1.446 | Acc: 47.933% (12823/26752)\n",
      "Epoch 4 Step 836/1563 Loss: 1.446 | Acc: 47.917% (12834/26784)\n",
      "Epoch 4 Step 837/1563 Loss: 1.446 | Acc: 47.919% (12850/26816)\n",
      "Epoch 4 Step 838/1563 Loss: 1.446 | Acc: 47.922% (12866/26848)\n",
      "Epoch 4 Step 839/1563 Loss: 1.447 | Acc: 47.917% (12880/26880)\n",
      "Epoch 4 Step 840/1563 Loss: 1.447 | Acc: 47.912% (12894/26912)\n",
      "Epoch 4 Step 841/1563 Loss: 1.447 | Acc: 47.907% (12908/26944)\n",
      "Epoch 4 Step 842/1563 Loss: 1.447 | Acc: 47.906% (12923/26976)\n",
      "Epoch 4 Step 843/1563 Loss: 1.447 | Acc: 47.908% (12939/27008)\n",
      "Epoch 4 Step 844/1563 Loss: 1.447 | Acc: 47.918% (12957/27040)\n",
      "Epoch 4 Step 845/1563 Loss: 1.447 | Acc: 47.920% (12973/27072)\n",
      "Epoch 4 Step 846/1563 Loss: 1.447 | Acc: 47.915% (12987/27104)\n",
      "Epoch 4 Step 847/1563 Loss: 1.447 | Acc: 47.925% (13005/27136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 848/1563 Loss: 1.446 | Acc: 47.950% (13027/27168)\n",
      "Epoch 4 Step 849/1563 Loss: 1.446 | Acc: 47.974% (13049/27200)\n",
      "Epoch 4 Step 850/1563 Loss: 1.446 | Acc: 47.973% (13064/27232)\n",
      "Epoch 4 Step 851/1563 Loss: 1.446 | Acc: 47.975% (13080/27264)\n",
      "Epoch 4 Step 852/1563 Loss: 1.446 | Acc: 48.000% (13102/27296)\n",
      "Epoch 4 Step 853/1563 Loss: 1.445 | Acc: 47.998% (13117/27328)\n",
      "Epoch 4 Step 854/1563 Loss: 1.445 | Acc: 48.004% (13134/27360)\n",
      "Epoch 4 Step 855/1563 Loss: 1.445 | Acc: 48.007% (13150/27392)\n",
      "Epoch 4 Step 856/1563 Loss: 1.445 | Acc: 48.013% (13167/27424)\n",
      "Epoch 4 Step 857/1563 Loss: 1.445 | Acc: 48.019% (13184/27456)\n",
      "Epoch 4 Step 858/1563 Loss: 1.445 | Acc: 48.039% (13205/27488)\n",
      "Epoch 4 Step 859/1563 Loss: 1.445 | Acc: 48.049% (13223/27520)\n",
      "Epoch 4 Step 860/1563 Loss: 1.445 | Acc: 48.047% (13238/27552)\n",
      "Epoch 4 Step 861/1563 Loss: 1.445 | Acc: 48.050% (13254/27584)\n",
      "Epoch 4 Step 862/1563 Loss: 1.445 | Acc: 48.045% (13268/27616)\n",
      "Epoch 4 Step 863/1563 Loss: 1.444 | Acc: 48.050% (13285/27648)\n",
      "Epoch 4 Step 864/1563 Loss: 1.444 | Acc: 48.049% (13300/27680)\n",
      "Epoch 4 Step 865/1563 Loss: 1.444 | Acc: 48.059% (13318/27712)\n",
      "Epoch 4 Step 866/1563 Loss: 1.444 | Acc: 48.043% (13329/27744)\n",
      "Epoch 4 Step 867/1563 Loss: 1.444 | Acc: 48.056% (13348/27776)\n",
      "Epoch 4 Step 868/1563 Loss: 1.444 | Acc: 48.051% (13362/27808)\n",
      "Epoch 4 Step 869/1563 Loss: 1.444 | Acc: 48.068% (13382/27840)\n",
      "Epoch 4 Step 870/1563 Loss: 1.444 | Acc: 48.073% (13399/27872)\n",
      "Epoch 4 Step 871/1563 Loss: 1.444 | Acc: 48.068% (13413/27904)\n",
      "Epoch 4 Step 872/1563 Loss: 1.444 | Acc: 48.067% (13428/27936)\n",
      "Epoch 4 Step 873/1563 Loss: 1.444 | Acc: 48.069% (13444/27968)\n",
      "Epoch 4 Step 874/1563 Loss: 1.444 | Acc: 48.068% (13459/28000)\n",
      "Epoch 4 Step 875/1563 Loss: 1.444 | Acc: 48.088% (13480/28032)\n",
      "Epoch 4 Step 876/1563 Loss: 1.444 | Acc: 48.094% (13497/28064)\n",
      "Epoch 4 Step 877/1563 Loss: 1.444 | Acc: 48.096% (13513/28096)\n",
      "Epoch 4 Step 878/1563 Loss: 1.444 | Acc: 48.094% (13528/28128)\n",
      "Epoch 4 Step 879/1563 Loss: 1.444 | Acc: 48.082% (13540/28160)\n",
      "Epoch 4 Step 880/1563 Loss: 1.444 | Acc: 48.085% (13556/28192)\n",
      "Epoch 4 Step 881/1563 Loss: 1.444 | Acc: 48.090% (13573/28224)\n",
      "Epoch 4 Step 882/1563 Loss: 1.444 | Acc: 48.092% (13589/28256)\n",
      "Epoch 4 Step 883/1563 Loss: 1.444 | Acc: 48.073% (13599/28288)\n",
      "Epoch 4 Step 884/1563 Loss: 1.444 | Acc: 48.090% (13619/28320)\n",
      "Epoch 4 Step 885/1563 Loss: 1.444 | Acc: 48.095% (13636/28352)\n",
      "Epoch 4 Step 886/1563 Loss: 1.444 | Acc: 48.083% (13648/28384)\n",
      "Epoch 4 Step 887/1563 Loss: 1.444 | Acc: 48.096% (13667/28416)\n",
      "Epoch 4 Step 888/1563 Loss: 1.444 | Acc: 48.098% (13683/28448)\n",
      "Epoch 4 Step 889/1563 Loss: 1.444 | Acc: 48.093% (13697/28480)\n",
      "Epoch 4 Step 890/1563 Loss: 1.444 | Acc: 48.085% (13710/28512)\n",
      "Epoch 4 Step 891/1563 Loss: 1.444 | Acc: 48.094% (13728/28544)\n",
      "Epoch 4 Step 892/1563 Loss: 1.444 | Acc: 48.096% (13744/28576)\n",
      "Epoch 4 Step 893/1563 Loss: 1.444 | Acc: 48.081% (13755/28608)\n",
      "Epoch 4 Step 894/1563 Loss: 1.444 | Acc: 48.090% (13773/28640)\n",
      "Epoch 4 Step 895/1563 Loss: 1.444 | Acc: 48.078% (13785/28672)\n",
      "Epoch 4 Step 896/1563 Loss: 1.444 | Acc: 48.080% (13801/28704)\n",
      "Epoch 4 Step 897/1563 Loss: 1.444 | Acc: 48.065% (13812/28736)\n",
      "Epoch 4 Step 898/1563 Loss: 1.444 | Acc: 48.085% (13833/28768)\n",
      "Epoch 4 Step 899/1563 Loss: 1.444 | Acc: 48.097% (13852/28800)\n",
      "Epoch 4 Step 900/1563 Loss: 1.444 | Acc: 48.103% (13869/28832)\n",
      "Epoch 4 Step 901/1563 Loss: 1.444 | Acc: 48.105% (13885/28864)\n",
      "Epoch 4 Step 902/1563 Loss: 1.444 | Acc: 48.100% (13899/28896)\n",
      "Epoch 4 Step 903/1563 Loss: 1.444 | Acc: 48.109% (13917/28928)\n",
      "Epoch 4 Step 904/1563 Loss: 1.444 | Acc: 48.101% (13930/28960)\n",
      "Epoch 4 Step 905/1563 Loss: 1.444 | Acc: 48.096% (13944/28992)\n",
      "Epoch 4 Step 906/1563 Loss: 1.444 | Acc: 48.095% (13959/29024)\n",
      "Epoch 4 Step 907/1563 Loss: 1.444 | Acc: 48.104% (13977/29056)\n",
      "Epoch 4 Step 908/1563 Loss: 1.444 | Acc: 48.102% (13992/29088)\n",
      "Epoch 4 Step 909/1563 Loss: 1.444 | Acc: 48.104% (14008/29120)\n",
      "Epoch 4 Step 910/1563 Loss: 1.444 | Acc: 48.110% (14025/29152)\n",
      "Epoch 4 Step 911/1563 Loss: 1.445 | Acc: 48.102% (14038/29184)\n",
      "Epoch 4 Step 912/1563 Loss: 1.444 | Acc: 48.131% (14062/29216)\n",
      "Epoch 4 Step 913/1563 Loss: 1.444 | Acc: 48.133% (14078/29248)\n",
      "Epoch 4 Step 914/1563 Loss: 1.444 | Acc: 48.135% (14094/29280)\n",
      "Epoch 4 Step 915/1563 Loss: 1.444 | Acc: 48.137% (14110/29312)\n",
      "Epoch 4 Step 916/1563 Loss: 1.443 | Acc: 48.143% (14127/29344)\n",
      "Epoch 4 Step 917/1563 Loss: 1.443 | Acc: 48.131% (14139/29376)\n",
      "Epoch 4 Step 918/1563 Loss: 1.443 | Acc: 48.126% (14153/29408)\n",
      "Epoch 4 Step 919/1563 Loss: 1.443 | Acc: 48.132% (14170/29440)\n",
      "Epoch 4 Step 920/1563 Loss: 1.443 | Acc: 48.137% (14187/29472)\n",
      "Epoch 4 Step 921/1563 Loss: 1.443 | Acc: 48.136% (14202/29504)\n",
      "Epoch 4 Step 922/1563 Loss: 1.443 | Acc: 48.131% (14216/29536)\n",
      "Epoch 4 Step 923/1563 Loss: 1.443 | Acc: 48.150% (14237/29568)\n",
      "Epoch 4 Step 924/1563 Loss: 1.442 | Acc: 48.166% (14257/29600)\n",
      "Epoch 4 Step 925/1563 Loss: 1.443 | Acc: 48.151% (14268/29632)\n",
      "Epoch 4 Step 926/1563 Loss: 1.443 | Acc: 48.146% (14282/29664)\n",
      "Epoch 4 Step 927/1563 Loss: 1.443 | Acc: 48.138% (14295/29696)\n",
      "Epoch 4 Step 928/1563 Loss: 1.443 | Acc: 48.150% (14314/29728)\n",
      "Epoch 4 Step 929/1563 Loss: 1.443 | Acc: 48.159% (14332/29760)\n",
      "Epoch 4 Step 930/1563 Loss: 1.443 | Acc: 48.161% (14348/29792)\n",
      "Epoch 4 Step 931/1563 Loss: 1.443 | Acc: 48.136% (14356/29824)\n",
      "Epoch 4 Step 932/1563 Loss: 1.443 | Acc: 48.138% (14372/29856)\n",
      "Epoch 4 Step 933/1563 Loss: 1.443 | Acc: 48.163% (14395/29888)\n",
      "Epoch 4 Step 934/1563 Loss: 1.443 | Acc: 48.158% (14409/29920)\n",
      "Epoch 4 Step 935/1563 Loss: 1.443 | Acc: 48.157% (14424/29952)\n",
      "Epoch 4 Step 936/1563 Loss: 1.443 | Acc: 48.162% (14441/29984)\n",
      "Epoch 4 Step 937/1563 Loss: 1.443 | Acc: 48.171% (14459/30016)\n",
      "Epoch 4 Step 938/1563 Loss: 1.443 | Acc: 48.160% (14471/30048)\n",
      "Epoch 4 Step 939/1563 Loss: 1.443 | Acc: 48.162% (14487/30080)\n",
      "Epoch 4 Step 940/1563 Loss: 1.443 | Acc: 48.164% (14503/30112)\n",
      "Epoch 4 Step 941/1563 Loss: 1.443 | Acc: 48.162% (14518/30144)\n",
      "Epoch 4 Step 942/1563 Loss: 1.443 | Acc: 48.167% (14535/30176)\n",
      "Epoch 4 Step 943/1563 Loss: 1.443 | Acc: 48.169% (14551/30208)\n",
      "Epoch 4 Step 944/1563 Loss: 1.442 | Acc: 48.161% (14564/30240)\n",
      "Epoch 4 Step 945/1563 Loss: 1.442 | Acc: 48.167% (14581/30272)\n",
      "Epoch 4 Step 946/1563 Loss: 1.442 | Acc: 48.169% (14597/30304)\n",
      "Epoch 4 Step 947/1563 Loss: 1.443 | Acc: 48.167% (14612/30336)\n",
      "Epoch 4 Step 948/1563 Loss: 1.443 | Acc: 48.169% (14628/30368)\n",
      "Epoch 4 Step 949/1563 Loss: 1.442 | Acc: 48.174% (14645/30400)\n",
      "Epoch 4 Step 950/1563 Loss: 1.442 | Acc: 48.173% (14660/30432)\n",
      "Epoch 4 Step 951/1563 Loss: 1.442 | Acc: 48.181% (14678/30464)\n",
      "Epoch 4 Step 952/1563 Loss: 1.442 | Acc: 48.180% (14693/30496)\n",
      "Epoch 4 Step 953/1563 Loss: 1.442 | Acc: 48.185% (14710/30528)\n",
      "Epoch 4 Step 954/1563 Loss: 1.442 | Acc: 48.194% (14728/30560)\n",
      "Epoch 4 Step 955/1563 Loss: 1.442 | Acc: 48.192% (14743/30592)\n",
      "Epoch 4 Step 956/1563 Loss: 1.442 | Acc: 48.171% (14752/30624)\n",
      "Epoch 4 Step 957/1563 Loss: 1.442 | Acc: 48.173% (14768/30656)\n",
      "Epoch 4 Step 958/1563 Loss: 1.442 | Acc: 48.175% (14784/30688)\n",
      "Epoch 4 Step 959/1563 Loss: 1.442 | Acc: 48.177% (14800/30720)\n",
      "Epoch 4 Step 960/1563 Loss: 1.442 | Acc: 48.166% (14812/30752)\n",
      "Epoch 4 Step 961/1563 Loss: 1.442 | Acc: 48.168% (14828/30784)\n",
      "Epoch 4 Step 962/1563 Loss: 1.442 | Acc: 48.173% (14845/30816)\n",
      "Epoch 4 Step 963/1563 Loss: 1.442 | Acc: 48.175% (14861/30848)\n",
      "Epoch 4 Step 964/1563 Loss: 1.441 | Acc: 48.190% (14881/30880)\n",
      "Epoch 4 Step 965/1563 Loss: 1.441 | Acc: 48.195% (14898/30912)\n",
      "Epoch 4 Step 966/1563 Loss: 1.441 | Acc: 48.194% (14913/30944)\n",
      "Epoch 4 Step 967/1563 Loss: 1.441 | Acc: 48.166% (14920/30976)\n",
      "Epoch 4 Step 968/1563 Loss: 1.441 | Acc: 48.168% (14936/31008)\n",
      "Epoch 4 Step 969/1563 Loss: 1.441 | Acc: 48.167% (14951/31040)\n",
      "Epoch 4 Step 970/1563 Loss: 1.441 | Acc: 48.175% (14969/31072)\n",
      "Epoch 4 Step 971/1563 Loss: 1.441 | Acc: 48.180% (14986/31104)\n",
      "Epoch 4 Step 972/1563 Loss: 1.441 | Acc: 48.179% (15001/31136)\n",
      "Epoch 4 Step 973/1563 Loss: 1.441 | Acc: 48.171% (15014/31168)\n",
      "Epoch 4 Step 974/1563 Loss: 1.441 | Acc: 48.183% (15033/31200)\n",
      "Epoch 4 Step 975/1563 Loss: 1.441 | Acc: 48.181% (15048/31232)\n",
      "Epoch 4 Step 976/1563 Loss: 1.441 | Acc: 48.180% (15063/31264)\n",
      "Epoch 4 Step 977/1563 Loss: 1.441 | Acc: 48.175% (15077/31296)\n",
      "Epoch 4 Step 978/1563 Loss: 1.441 | Acc: 48.161% (15088/31328)\n",
      "Epoch 4 Step 979/1563 Loss: 1.441 | Acc: 48.170% (15106/31360)\n",
      "Epoch 4 Step 980/1563 Loss: 1.441 | Acc: 48.168% (15121/31392)\n",
      "Epoch 4 Step 981/1563 Loss: 1.441 | Acc: 48.186% (15142/31424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 982/1563 Loss: 1.441 | Acc: 48.185% (15157/31456)\n",
      "Epoch 4 Step 983/1563 Loss: 1.441 | Acc: 48.177% (15170/31488)\n",
      "Epoch 4 Step 984/1563 Loss: 1.441 | Acc: 48.182% (15187/31520)\n",
      "Epoch 4 Step 985/1563 Loss: 1.440 | Acc: 48.190% (15205/31552)\n",
      "Epoch 4 Step 986/1563 Loss: 1.441 | Acc: 48.192% (15221/31584)\n",
      "Epoch 4 Step 987/1563 Loss: 1.441 | Acc: 48.178% (15232/31616)\n",
      "Epoch 4 Step 988/1563 Loss: 1.441 | Acc: 48.189% (15251/31648)\n",
      "Epoch 4 Step 989/1563 Loss: 1.441 | Acc: 48.179% (15263/31680)\n",
      "Epoch 4 Step 990/1563 Loss: 1.440 | Acc: 48.190% (15282/31712)\n",
      "Epoch 4 Step 991/1563 Loss: 1.440 | Acc: 48.195% (15299/31744)\n",
      "Epoch 4 Step 992/1563 Loss: 1.440 | Acc: 48.190% (15313/31776)\n",
      "Epoch 4 Step 993/1563 Loss: 1.440 | Acc: 48.195% (15330/31808)\n",
      "Epoch 4 Step 994/1563 Loss: 1.440 | Acc: 48.191% (15344/31840)\n",
      "Epoch 4 Step 995/1563 Loss: 1.441 | Acc: 48.180% (15356/31872)\n",
      "Epoch 4 Step 996/1563 Loss: 1.441 | Acc: 48.185% (15373/31904)\n",
      "Epoch 4 Step 997/1563 Loss: 1.440 | Acc: 48.200% (15393/31936)\n",
      "Epoch 4 Step 998/1563 Loss: 1.440 | Acc: 48.195% (15407/31968)\n",
      "Epoch 4 Step 999/1563 Loss: 1.440 | Acc: 48.197% (15423/32000)\n",
      "Epoch 4 Step 1000/1563 Loss: 1.440 | Acc: 48.186% (15435/32032)\n",
      "Epoch 4 Step 1001/1563 Loss: 1.440 | Acc: 48.207% (15457/32064)\n",
      "Epoch 4 Step 1002/1563 Loss: 1.440 | Acc: 48.205% (15472/32096)\n",
      "Epoch 4 Step 1003/1563 Loss: 1.440 | Acc: 48.207% (15488/32128)\n",
      "Epoch 4 Step 1004/1563 Loss: 1.441 | Acc: 48.203% (15502/32160)\n",
      "Epoch 4 Step 1005/1563 Loss: 1.441 | Acc: 48.189% (15513/32192)\n",
      "Epoch 4 Step 1006/1563 Loss: 1.441 | Acc: 48.191% (15529/32224)\n",
      "Epoch 4 Step 1007/1563 Loss: 1.441 | Acc: 48.196% (15546/32256)\n",
      "Epoch 4 Step 1008/1563 Loss: 1.441 | Acc: 48.197% (15562/32288)\n",
      "Epoch 4 Step 1009/1563 Loss: 1.442 | Acc: 48.190% (15575/32320)\n",
      "Epoch 4 Step 1010/1563 Loss: 1.442 | Acc: 48.192% (15591/32352)\n",
      "Epoch 4 Step 1011/1563 Loss: 1.442 | Acc: 48.184% (15604/32384)\n",
      "Epoch 4 Step 1012/1563 Loss: 1.442 | Acc: 48.183% (15619/32416)\n",
      "Epoch 4 Step 1013/1563 Loss: 1.442 | Acc: 48.185% (15635/32448)\n",
      "Epoch 4 Step 1014/1563 Loss: 1.442 | Acc: 48.171% (15646/32480)\n",
      "Epoch 4 Step 1015/1563 Loss: 1.442 | Acc: 48.167% (15660/32512)\n",
      "Epoch 4 Step 1016/1563 Loss: 1.442 | Acc: 48.162% (15674/32544)\n",
      "Epoch 4 Step 1017/1563 Loss: 1.442 | Acc: 48.164% (15690/32576)\n",
      "Epoch 4 Step 1018/1563 Loss: 1.442 | Acc: 48.157% (15703/32608)\n",
      "Epoch 4 Step 1019/1563 Loss: 1.442 | Acc: 48.159% (15719/32640)\n",
      "Epoch 4 Step 1020/1563 Loss: 1.442 | Acc: 48.148% (15731/32672)\n",
      "Epoch 4 Step 1021/1563 Loss: 1.442 | Acc: 48.147% (15746/32704)\n",
      "Epoch 4 Step 1022/1563 Loss: 1.442 | Acc: 48.146% (15761/32736)\n",
      "Epoch 4 Step 1023/1563 Loss: 1.442 | Acc: 48.154% (15779/32768)\n",
      "Epoch 4 Step 1024/1563 Loss: 1.442 | Acc: 48.152% (15794/32800)\n",
      "Epoch 4 Step 1025/1563 Loss: 1.442 | Acc: 48.163% (15813/32832)\n",
      "Epoch 4 Step 1026/1563 Loss: 1.442 | Acc: 48.159% (15827/32864)\n",
      "Epoch 4 Step 1027/1563 Loss: 1.442 | Acc: 48.158% (15842/32896)\n",
      "Epoch 4 Step 1028/1563 Loss: 1.442 | Acc: 48.163% (15859/32928)\n",
      "Epoch 4 Step 1029/1563 Loss: 1.442 | Acc: 48.177% (15879/32960)\n",
      "Epoch 4 Step 1030/1563 Loss: 1.442 | Acc: 48.181% (15896/32992)\n",
      "Epoch 4 Step 1031/1563 Loss: 1.442 | Acc: 48.189% (15914/33024)\n",
      "Epoch 4 Step 1032/1563 Loss: 1.442 | Acc: 48.179% (15926/33056)\n",
      "Epoch 4 Step 1033/1563 Loss: 1.441 | Acc: 48.178% (15941/33088)\n",
      "Epoch 4 Step 1034/1563 Loss: 1.442 | Acc: 48.173% (15955/33120)\n",
      "Epoch 4 Step 1035/1563 Loss: 1.442 | Acc: 48.157% (15965/33152)\n",
      "Epoch 4 Step 1036/1563 Loss: 1.442 | Acc: 48.165% (15983/33184)\n",
      "Epoch 4 Step 1037/1563 Loss: 1.442 | Acc: 48.155% (15995/33216)\n",
      "Epoch 4 Step 1038/1563 Loss: 1.442 | Acc: 48.156% (16011/33248)\n",
      "Epoch 4 Step 1039/1563 Loss: 1.442 | Acc: 48.143% (16022/33280)\n",
      "Epoch 4 Step 1040/1563 Loss: 1.442 | Acc: 48.154% (16041/33312)\n",
      "Epoch 4 Step 1041/1563 Loss: 1.442 | Acc: 48.144% (16053/33344)\n",
      "Epoch 4 Step 1042/1563 Loss: 1.442 | Acc: 48.133% (16065/33376)\n",
      "Epoch 4 Step 1043/1563 Loss: 1.442 | Acc: 48.120% (16076/33408)\n",
      "Epoch 4 Step 1044/1563 Loss: 1.443 | Acc: 48.116% (16090/33440)\n",
      "Epoch 4 Step 1045/1563 Loss: 1.443 | Acc: 48.106% (16102/33472)\n",
      "Epoch 4 Step 1046/1563 Loss: 1.443 | Acc: 48.090% (16112/33504)\n",
      "Epoch 4 Step 1047/1563 Loss: 1.443 | Acc: 48.092% (16128/33536)\n",
      "Epoch 4 Step 1048/1563 Loss: 1.443 | Acc: 48.090% (16143/33568)\n",
      "Epoch 4 Step 1049/1563 Loss: 1.443 | Acc: 48.083% (16156/33600)\n",
      "Epoch 4 Step 1050/1563 Loss: 1.443 | Acc: 48.091% (16174/33632)\n",
      "Epoch 4 Step 1051/1563 Loss: 1.443 | Acc: 48.090% (16189/33664)\n",
      "Epoch 4 Step 1052/1563 Loss: 1.443 | Acc: 48.101% (16208/33696)\n",
      "Epoch 4 Step 1053/1563 Loss: 1.443 | Acc: 48.082% (16217/33728)\n",
      "Epoch 4 Step 1054/1563 Loss: 1.443 | Acc: 48.063% (16226/33760)\n",
      "Epoch 4 Step 1055/1563 Loss: 1.443 | Acc: 48.059% (16240/33792)\n",
      "Epoch 4 Step 1056/1563 Loss: 1.443 | Acc: 48.066% (16258/33824)\n",
      "Epoch 4 Step 1057/1563 Loss: 1.443 | Acc: 48.080% (16278/33856)\n",
      "Epoch 4 Step 1058/1563 Loss: 1.443 | Acc: 48.061% (16287/33888)\n",
      "Epoch 4 Step 1059/1563 Loss: 1.443 | Acc: 48.063% (16303/33920)\n",
      "Epoch 4 Step 1060/1563 Loss: 1.444 | Acc: 48.059% (16317/33952)\n",
      "Epoch 4 Step 1061/1563 Loss: 1.443 | Acc: 48.067% (16335/33984)\n",
      "Epoch 4 Step 1062/1563 Loss: 1.443 | Acc: 48.060% (16348/34016)\n",
      "Epoch 4 Step 1063/1563 Loss: 1.443 | Acc: 48.059% (16363/34048)\n",
      "Epoch 4 Step 1064/1563 Loss: 1.444 | Acc: 48.037% (16371/34080)\n",
      "Epoch 4 Step 1065/1563 Loss: 1.443 | Acc: 48.045% (16389/34112)\n",
      "Epoch 4 Step 1066/1563 Loss: 1.444 | Acc: 48.026% (16398/34144)\n",
      "Epoch 4 Step 1067/1563 Loss: 1.444 | Acc: 48.031% (16415/34176)\n",
      "Epoch 4 Step 1068/1563 Loss: 1.444 | Acc: 48.024% (16428/34208)\n",
      "Epoch 4 Step 1069/1563 Loss: 1.444 | Acc: 48.023% (16443/34240)\n",
      "Epoch 4 Step 1070/1563 Loss: 1.444 | Acc: 48.013% (16455/34272)\n",
      "Epoch 4 Step 1071/1563 Loss: 1.444 | Acc: 48.021% (16473/34304)\n",
      "Epoch 4 Step 1072/1563 Loss: 1.444 | Acc: 48.025% (16490/34336)\n",
      "Epoch 4 Step 1073/1563 Loss: 1.444 | Acc: 48.024% (16505/34368)\n",
      "Epoch 4 Step 1074/1563 Loss: 1.444 | Acc: 48.026% (16521/34400)\n",
      "Epoch 4 Step 1075/1563 Loss: 1.444 | Acc: 48.025% (16536/34432)\n",
      "Epoch 4 Step 1076/1563 Loss: 1.443 | Acc: 48.027% (16552/34464)\n",
      "Epoch 4 Step 1077/1563 Loss: 1.444 | Acc: 48.023% (16566/34496)\n",
      "Epoch 4 Step 1078/1563 Loss: 1.443 | Acc: 48.031% (16584/34528)\n",
      "Epoch 4 Step 1079/1563 Loss: 1.444 | Acc: 48.032% (16600/34560)\n",
      "Epoch 4 Step 1080/1563 Loss: 1.444 | Acc: 48.034% (16616/34592)\n",
      "Epoch 4 Step 1081/1563 Loss: 1.444 | Acc: 48.030% (16630/34624)\n",
      "Epoch 4 Step 1082/1563 Loss: 1.444 | Acc: 48.035% (16647/34656)\n",
      "Epoch 4 Step 1083/1563 Loss: 1.443 | Acc: 48.031% (16661/34688)\n",
      "Epoch 4 Step 1084/1563 Loss: 1.443 | Acc: 48.030% (16676/34720)\n",
      "Epoch 4 Step 1085/1563 Loss: 1.444 | Acc: 48.026% (16690/34752)\n",
      "Epoch 4 Step 1086/1563 Loss: 1.444 | Acc: 48.022% (16704/34784)\n",
      "Epoch 4 Step 1087/1563 Loss: 1.443 | Acc: 48.024% (16720/34816)\n",
      "Epoch 4 Step 1088/1563 Loss: 1.443 | Acc: 48.011% (16731/34848)\n",
      "Epoch 4 Step 1089/1563 Loss: 1.443 | Acc: 48.025% (16751/34880)\n",
      "Epoch 4 Step 1090/1563 Loss: 1.443 | Acc: 48.029% (16768/34912)\n",
      "Epoch 4 Step 1091/1563 Loss: 1.443 | Acc: 48.025% (16782/34944)\n",
      "Epoch 4 Step 1092/1563 Loss: 1.444 | Acc: 48.013% (16793/34976)\n",
      "Epoch 4 Step 1093/1563 Loss: 1.444 | Acc: 48.009% (16807/35008)\n",
      "Epoch 4 Step 1094/1563 Loss: 1.444 | Acc: 47.997% (16818/35040)\n",
      "Epoch 4 Step 1095/1563 Loss: 1.444 | Acc: 47.990% (16831/35072)\n",
      "Epoch 4 Step 1096/1563 Loss: 1.444 | Acc: 47.989% (16846/35104)\n",
      "Epoch 4 Step 1097/1563 Loss: 1.444 | Acc: 47.985% (16860/35136)\n",
      "Epoch 4 Step 1098/1563 Loss: 1.444 | Acc: 47.975% (16872/35168)\n",
      "Epoch 4 Step 1099/1563 Loss: 1.444 | Acc: 47.983% (16890/35200)\n",
      "Epoch 4 Step 1100/1563 Loss: 1.444 | Acc: 47.988% (16907/35232)\n",
      "Epoch 4 Step 1101/1563 Loss: 1.444 | Acc: 47.992% (16924/35264)\n",
      "Epoch 4 Step 1102/1563 Loss: 1.444 | Acc: 47.994% (16940/35296)\n",
      "Epoch 4 Step 1103/1563 Loss: 1.444 | Acc: 47.996% (16956/35328)\n",
      "Epoch 4 Step 1104/1563 Loss: 1.444 | Acc: 47.998% (16972/35360)\n",
      "Epoch 4 Step 1105/1563 Loss: 1.444 | Acc: 47.997% (16987/35392)\n",
      "Epoch 4 Step 1106/1563 Loss: 1.444 | Acc: 47.993% (17001/35424)\n",
      "Epoch 4 Step 1107/1563 Loss: 1.444 | Acc: 47.995% (17017/35456)\n",
      "Epoch 4 Step 1108/1563 Loss: 1.444 | Acc: 47.999% (17034/35488)\n",
      "Epoch 4 Step 1109/1563 Loss: 1.444 | Acc: 48.004% (17051/35520)\n",
      "Epoch 4 Step 1110/1563 Loss: 1.444 | Acc: 47.989% (17061/35552)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 1111/1563 Loss: 1.444 | Acc: 47.985% (17075/35584)\n",
      "Epoch 4 Step 1112/1563 Loss: 1.444 | Acc: 47.984% (17090/35616)\n",
      "Epoch 4 Step 1113/1563 Loss: 1.444 | Acc: 47.972% (17101/35648)\n",
      "Epoch 4 Step 1114/1563 Loss: 1.444 | Acc: 47.974% (17117/35680)\n",
      "Epoch 4 Step 1115/1563 Loss: 1.444 | Acc: 47.975% (17133/35712)\n",
      "Epoch 4 Step 1116/1563 Loss: 1.444 | Acc: 47.977% (17149/35744)\n",
      "Epoch 4 Step 1117/1563 Loss: 1.444 | Acc: 47.990% (17169/35776)\n",
      "Epoch 4 Step 1118/1563 Loss: 1.444 | Acc: 47.989% (17184/35808)\n",
      "Epoch 4 Step 1119/1563 Loss: 1.444 | Acc: 47.991% (17200/35840)\n",
      "Epoch 4 Step 1120/1563 Loss: 1.444 | Acc: 47.996% (17217/35872)\n",
      "Epoch 4 Step 1121/1563 Loss: 1.444 | Acc: 47.997% (17233/35904)\n",
      "Epoch 4 Step 1122/1563 Loss: 1.444 | Acc: 47.985% (17244/35936)\n",
      "Epoch 4 Step 1123/1563 Loss: 1.444 | Acc: 47.990% (17261/35968)\n",
      "Epoch 4 Step 1124/1563 Loss: 1.444 | Acc: 47.989% (17276/36000)\n",
      "Epoch 4 Step 1125/1563 Loss: 1.444 | Acc: 47.988% (17291/36032)\n",
      "Epoch 4 Step 1126/1563 Loss: 1.444 | Acc: 48.009% (17314/36064)\n",
      "Epoch 4 Step 1127/1563 Loss: 1.444 | Acc: 48.011% (17330/36096)\n",
      "Epoch 4 Step 1128/1563 Loss: 1.444 | Acc: 48.007% (17344/36128)\n",
      "Epoch 4 Step 1129/1563 Loss: 1.444 | Acc: 48.017% (17363/36160)\n",
      "Epoch 4 Step 1130/1563 Loss: 1.444 | Acc: 48.019% (17379/36192)\n",
      "Epoch 4 Step 1131/1563 Loss: 1.444 | Acc: 48.032% (17399/36224)\n",
      "Epoch 4 Step 1132/1563 Loss: 1.444 | Acc: 48.028% (17413/36256)\n",
      "Epoch 4 Step 1133/1563 Loss: 1.444 | Acc: 48.016% (17424/36288)\n",
      "Epoch 4 Step 1134/1563 Loss: 1.444 | Acc: 48.009% (17437/36320)\n",
      "Epoch 4 Step 1135/1563 Loss: 1.444 | Acc: 48.008% (17452/36352)\n",
      "Epoch 4 Step 1136/1563 Loss: 1.444 | Acc: 48.002% (17465/36384)\n",
      "Epoch 4 Step 1137/1563 Loss: 1.444 | Acc: 48.001% (17480/36416)\n",
      "Epoch 4 Step 1138/1563 Loss: 1.444 | Acc: 48.008% (17498/36448)\n",
      "Epoch 4 Step 1139/1563 Loss: 1.444 | Acc: 48.013% (17515/36480)\n",
      "Epoch 4 Step 1140/1563 Loss: 1.444 | Acc: 48.017% (17532/36512)\n",
      "Epoch 4 Step 1141/1563 Loss: 1.444 | Acc: 48.011% (17545/36544)\n",
      "Epoch 4 Step 1142/1563 Loss: 1.444 | Acc: 48.004% (17558/36576)\n",
      "Epoch 4 Step 1143/1563 Loss: 1.445 | Acc: 47.990% (17568/36608)\n",
      "Epoch 4 Step 1144/1563 Loss: 1.445 | Acc: 47.975% (17578/36640)\n",
      "Epoch 4 Step 1145/1563 Loss: 1.445 | Acc: 47.977% (17594/36672)\n",
      "Epoch 4 Step 1146/1563 Loss: 1.445 | Acc: 47.965% (17605/36704)\n",
      "Epoch 4 Step 1147/1563 Loss: 1.445 | Acc: 47.953% (17616/36736)\n",
      "Epoch 4 Step 1148/1563 Loss: 1.445 | Acc: 47.947% (17629/36768)\n",
      "Epoch 4 Step 1149/1563 Loss: 1.445 | Acc: 47.938% (17641/36800)\n",
      "Epoch 4 Step 1150/1563 Loss: 1.445 | Acc: 47.947% (17660/36832)\n",
      "Epoch 4 Step 1151/1563 Loss: 1.445 | Acc: 47.944% (17674/36864)\n",
      "Epoch 4 Step 1152/1563 Loss: 1.445 | Acc: 47.946% (17690/36896)\n",
      "Epoch 4 Step 1153/1563 Loss: 1.445 | Acc: 47.945% (17705/36928)\n",
      "Epoch 4 Step 1154/1563 Loss: 1.445 | Acc: 47.944% (17720/36960)\n",
      "Epoch 4 Step 1155/1563 Loss: 1.445 | Acc: 47.951% (17738/36992)\n",
      "Epoch 4 Step 1156/1563 Loss: 1.445 | Acc: 47.958% (17756/37024)\n",
      "Epoch 4 Step 1157/1563 Loss: 1.445 | Acc: 47.960% (17772/37056)\n",
      "Epoch 4 Step 1158/1563 Loss: 1.445 | Acc: 47.967% (17790/37088)\n",
      "Epoch 4 Step 1159/1563 Loss: 1.445 | Acc: 47.969% (17806/37120)\n",
      "Epoch 4 Step 1160/1563 Loss: 1.445 | Acc: 47.973% (17823/37152)\n",
      "Epoch 4 Step 1161/1563 Loss: 1.445 | Acc: 47.972% (17838/37184)\n",
      "Epoch 4 Step 1162/1563 Loss: 1.444 | Acc: 47.982% (17857/37216)\n",
      "Epoch 4 Step 1163/1563 Loss: 1.444 | Acc: 47.978% (17871/37248)\n",
      "Epoch 4 Step 1164/1563 Loss: 1.444 | Acc: 47.988% (17890/37280)\n",
      "Epoch 4 Step 1165/1563 Loss: 1.444 | Acc: 47.995% (17908/37312)\n",
      "Epoch 4 Step 1166/1563 Loss: 1.444 | Acc: 48.002% (17926/37344)\n",
      "Epoch 4 Step 1167/1563 Loss: 1.444 | Acc: 47.988% (17936/37376)\n",
      "Epoch 4 Step 1168/1563 Loss: 1.445 | Acc: 47.982% (17949/37408)\n",
      "Epoch 4 Step 1169/1563 Loss: 1.445 | Acc: 47.989% (17967/37440)\n",
      "Epoch 4 Step 1170/1563 Loss: 1.445 | Acc: 47.980% (17979/37472)\n",
      "Epoch 4 Step 1171/1563 Loss: 1.445 | Acc: 47.976% (17993/37504)\n",
      "Epoch 4 Step 1172/1563 Loss: 1.445 | Acc: 47.957% (18001/37536)\n",
      "Epoch 4 Step 1173/1563 Loss: 1.445 | Acc: 47.956% (18016/37568)\n",
      "Epoch 4 Step 1174/1563 Loss: 1.445 | Acc: 47.957% (18032/37600)\n",
      "Epoch 4 Step 1175/1563 Loss: 1.445 | Acc: 47.964% (18050/37632)\n",
      "Epoch 4 Step 1176/1563 Loss: 1.445 | Acc: 47.969% (18067/37664)\n",
      "Epoch 4 Step 1177/1563 Loss: 1.445 | Acc: 47.963% (18080/37696)\n",
      "Epoch 4 Step 1178/1563 Loss: 1.445 | Acc: 47.956% (18093/37728)\n",
      "Epoch 4 Step 1179/1563 Loss: 1.445 | Acc: 47.948% (18105/37760)\n",
      "Epoch 4 Step 1180/1563 Loss: 1.445 | Acc: 47.960% (18125/37792)\n",
      "Epoch 4 Step 1181/1563 Loss: 1.445 | Acc: 47.970% (18144/37824)\n",
      "Epoch 4 Step 1182/1563 Loss: 1.445 | Acc: 47.958% (18155/37856)\n",
      "Epoch 4 Step 1183/1563 Loss: 1.445 | Acc: 47.968% (18174/37888)\n",
      "Epoch 4 Step 1184/1563 Loss: 1.445 | Acc: 47.961% (18187/37920)\n",
      "Epoch 4 Step 1185/1563 Loss: 1.445 | Acc: 47.961% (18202/37952)\n",
      "Epoch 4 Step 1186/1563 Loss: 1.445 | Acc: 47.973% (18222/37984)\n",
      "Epoch 4 Step 1187/1563 Loss: 1.445 | Acc: 47.961% (18233/38016)\n",
      "Epoch 4 Step 1188/1563 Loss: 1.445 | Acc: 47.976% (18254/38048)\n",
      "Epoch 4 Step 1189/1563 Loss: 1.445 | Acc: 47.975% (18269/38080)\n",
      "Epoch 4 Step 1190/1563 Loss: 1.445 | Acc: 47.961% (18279/38112)\n",
      "Epoch 4 Step 1191/1563 Loss: 1.444 | Acc: 47.971% (18298/38144)\n",
      "Epoch 4 Step 1192/1563 Loss: 1.445 | Acc: 47.965% (18311/38176)\n",
      "Epoch 4 Step 1193/1563 Loss: 1.445 | Acc: 47.964% (18326/38208)\n",
      "Epoch 4 Step 1194/1563 Loss: 1.445 | Acc: 47.965% (18342/38240)\n",
      "Epoch 4 Step 1195/1563 Loss: 1.445 | Acc: 47.967% (18358/38272)\n",
      "Epoch 4 Step 1196/1563 Loss: 1.445 | Acc: 47.971% (18375/38304)\n",
      "Epoch 4 Step 1197/1563 Loss: 1.445 | Acc: 47.976% (18392/38336)\n",
      "Epoch 4 Step 1198/1563 Loss: 1.445 | Acc: 47.980% (18409/38368)\n",
      "Epoch 4 Step 1199/1563 Loss: 1.445 | Acc: 47.971% (18421/38400)\n",
      "Epoch 4 Step 1200/1563 Loss: 1.445 | Acc: 47.968% (18435/38432)\n",
      "Epoch 4 Step 1201/1563 Loss: 1.444 | Acc: 47.972% (18452/38464)\n",
      "Epoch 4 Step 1202/1563 Loss: 1.444 | Acc: 47.971% (18467/38496)\n",
      "Epoch 4 Step 1203/1563 Loss: 1.444 | Acc: 47.968% (18481/38528)\n",
      "Epoch 4 Step 1204/1563 Loss: 1.444 | Acc: 47.967% (18496/38560)\n",
      "Epoch 4 Step 1205/1563 Loss: 1.445 | Acc: 47.966% (18511/38592)\n",
      "Epoch 4 Step 1206/1563 Loss: 1.444 | Acc: 47.978% (18531/38624)\n",
      "Epoch 4 Step 1207/1563 Loss: 1.444 | Acc: 47.982% (18548/38656)\n",
      "Epoch 4 Step 1208/1563 Loss: 1.444 | Acc: 47.981% (18563/38688)\n",
      "Epoch 4 Step 1209/1563 Loss: 1.444 | Acc: 47.986% (18580/38720)\n",
      "Epoch 4 Step 1210/1563 Loss: 1.444 | Acc: 47.990% (18597/38752)\n",
      "Epoch 4 Step 1211/1563 Loss: 1.444 | Acc: 47.989% (18612/38784)\n",
      "Epoch 4 Step 1212/1563 Loss: 1.444 | Acc: 47.983% (18625/38816)\n",
      "Epoch 4 Step 1213/1563 Loss: 1.444 | Acc: 47.982% (18640/38848)\n",
      "Epoch 4 Step 1214/1563 Loss: 1.444 | Acc: 47.978% (18654/38880)\n",
      "Epoch 4 Step 1215/1563 Loss: 1.444 | Acc: 47.980% (18670/38912)\n",
      "Epoch 4 Step 1216/1563 Loss: 1.444 | Acc: 47.984% (18687/38944)\n",
      "Epoch 4 Step 1217/1563 Loss: 1.444 | Acc: 47.991% (18705/38976)\n",
      "Epoch 4 Step 1218/1563 Loss: 1.444 | Acc: 47.977% (18715/39008)\n",
      "Epoch 4 Step 1219/1563 Loss: 1.444 | Acc: 47.971% (18728/39040)\n",
      "Epoch 4 Step 1220/1563 Loss: 1.444 | Acc: 47.973% (18744/39072)\n",
      "Epoch 4 Step 1221/1563 Loss: 1.444 | Acc: 47.982% (18763/39104)\n",
      "Epoch 4 Step 1222/1563 Loss: 1.444 | Acc: 47.976% (18776/39136)\n",
      "Epoch 4 Step 1223/1563 Loss: 1.444 | Acc: 47.973% (18790/39168)\n",
      "Epoch 4 Step 1224/1563 Loss: 1.444 | Acc: 47.972% (18805/39200)\n",
      "Epoch 4 Step 1225/1563 Loss: 1.444 | Acc: 47.971% (18820/39232)\n",
      "Epoch 4 Step 1226/1563 Loss: 1.444 | Acc: 47.968% (18834/39264)\n",
      "Epoch 4 Step 1227/1563 Loss: 1.444 | Acc: 47.962% (18847/39296)\n",
      "Epoch 4 Step 1228/1563 Loss: 1.444 | Acc: 47.973% (18867/39328)\n",
      "Epoch 4 Step 1229/1563 Loss: 1.444 | Acc: 47.970% (18881/39360)\n",
      "Epoch 4 Step 1230/1563 Loss: 1.444 | Acc: 47.972% (18897/39392)\n",
      "Epoch 4 Step 1231/1563 Loss: 1.444 | Acc: 47.971% (18912/39424)\n",
      "Epoch 4 Step 1232/1563 Loss: 1.444 | Acc: 47.965% (18925/39456)\n",
      "Epoch 4 Step 1233/1563 Loss: 1.444 | Acc: 47.972% (18943/39488)\n",
      "Epoch 4 Step 1234/1563 Loss: 1.444 | Acc: 47.973% (18959/39520)\n",
      "Epoch 4 Step 1235/1563 Loss: 1.444 | Acc: 47.980% (18977/39552)\n",
      "Epoch 4 Step 1236/1563 Loss: 1.444 | Acc: 47.982% (18993/39584)\n",
      "Epoch 4 Step 1237/1563 Loss: 1.444 | Acc: 47.976% (19006/39616)\n",
      "Epoch 4 Step 1238/1563 Loss: 1.444 | Acc: 47.985% (19025/39648)\n",
      "Epoch 4 Step 1239/1563 Loss: 1.444 | Acc: 47.994% (19044/39680)\n",
      "Epoch 4 Step 1240/1563 Loss: 1.444 | Acc: 47.983% (19055/39712)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 1241/1563 Loss: 1.444 | Acc: 47.980% (19069/39744)\n",
      "Epoch 4 Step 1242/1563 Loss: 1.444 | Acc: 47.984% (19086/39776)\n",
      "Epoch 4 Step 1243/1563 Loss: 1.444 | Acc: 47.973% (19097/39808)\n",
      "Epoch 4 Step 1244/1563 Loss: 1.444 | Acc: 47.999% (19123/39840)\n",
      "Epoch 4 Step 1245/1563 Loss: 1.444 | Acc: 47.999% (19138/39872)\n",
      "Epoch 4 Step 1246/1563 Loss: 1.443 | Acc: 47.990% (19150/39904)\n",
      "Epoch 4 Step 1247/1563 Loss: 1.444 | Acc: 47.984% (19163/39936)\n",
      "Epoch 4 Step 1248/1563 Loss: 1.444 | Acc: 47.988% (19180/39968)\n",
      "Epoch 4 Step 1249/1563 Loss: 1.443 | Acc: 47.990% (19196/40000)\n",
      "Epoch 4 Step 1250/1563 Loss: 1.443 | Acc: 48.004% (19217/40032)\n",
      "Epoch 4 Step 1251/1563 Loss: 1.443 | Acc: 48.006% (19233/40064)\n",
      "Epoch 4 Step 1252/1563 Loss: 1.443 | Acc: 48.010% (19250/40096)\n",
      "Epoch 4 Step 1253/1563 Loss: 1.443 | Acc: 48.011% (19266/40128)\n",
      "Epoch 4 Step 1254/1563 Loss: 1.443 | Acc: 48.013% (19282/40160)\n",
      "Epoch 4 Step 1255/1563 Loss: 1.443 | Acc: 48.017% (19299/40192)\n",
      "Epoch 4 Step 1256/1563 Loss: 1.442 | Acc: 48.019% (19315/40224)\n",
      "Epoch 4 Step 1257/1563 Loss: 1.443 | Acc: 48.015% (19329/40256)\n",
      "Epoch 4 Step 1258/1563 Loss: 1.443 | Acc: 48.022% (19347/40288)\n",
      "Epoch 4 Step 1259/1563 Loss: 1.443 | Acc: 48.023% (19363/40320)\n",
      "Epoch 4 Step 1260/1563 Loss: 1.443 | Acc: 48.025% (19379/40352)\n",
      "Epoch 4 Step 1261/1563 Loss: 1.442 | Acc: 48.036% (19399/40384)\n",
      "Epoch 4 Step 1262/1563 Loss: 1.442 | Acc: 48.050% (19420/40416)\n",
      "Epoch 4 Step 1263/1563 Loss: 1.442 | Acc: 48.062% (19440/40448)\n",
      "Epoch 4 Step 1264/1563 Loss: 1.442 | Acc: 48.073% (19460/40480)\n",
      "Epoch 4 Step 1265/1563 Loss: 1.442 | Acc: 48.075% (19476/40512)\n",
      "Epoch 4 Step 1266/1563 Loss: 1.442 | Acc: 48.069% (19489/40544)\n",
      "Epoch 4 Step 1267/1563 Loss: 1.442 | Acc: 48.075% (19507/40576)\n",
      "Epoch 4 Step 1268/1563 Loss: 1.442 | Acc: 48.087% (19527/40608)\n",
      "Epoch 4 Step 1269/1563 Loss: 1.442 | Acc: 48.095% (19546/40640)\n",
      "Epoch 4 Step 1270/1563 Loss: 1.441 | Acc: 48.112% (19568/40672)\n",
      "Epoch 4 Step 1271/1563 Loss: 1.441 | Acc: 48.116% (19585/40704)\n",
      "Epoch 4 Step 1272/1563 Loss: 1.441 | Acc: 48.125% (19604/40736)\n",
      "Epoch 4 Step 1273/1563 Loss: 1.441 | Acc: 48.138% (19625/40768)\n",
      "Epoch 4 Step 1274/1563 Loss: 1.441 | Acc: 48.140% (19641/40800)\n",
      "Epoch 4 Step 1275/1563 Loss: 1.441 | Acc: 48.141% (19657/40832)\n",
      "Epoch 4 Step 1276/1563 Loss: 1.441 | Acc: 48.130% (19668/40864)\n",
      "Epoch 4 Step 1277/1563 Loss: 1.441 | Acc: 48.134% (19685/40896)\n",
      "Epoch 4 Step 1278/1563 Loss: 1.441 | Acc: 48.128% (19698/40928)\n",
      "Epoch 4 Step 1279/1563 Loss: 1.441 | Acc: 48.127% (19713/40960)\n",
      "Epoch 4 Step 1280/1563 Loss: 1.442 | Acc: 48.114% (19723/40992)\n",
      "Epoch 4 Step 1281/1563 Loss: 1.442 | Acc: 48.111% (19737/41024)\n",
      "Epoch 4 Step 1282/1563 Loss: 1.442 | Acc: 48.115% (19754/41056)\n",
      "Epoch 4 Step 1283/1563 Loss: 1.441 | Acc: 48.128% (19775/41088)\n",
      "Epoch 4 Step 1284/1563 Loss: 1.442 | Acc: 48.123% (19788/41120)\n",
      "Epoch 4 Step 1285/1563 Loss: 1.442 | Acc: 48.122% (19803/41152)\n",
      "Epoch 4 Step 1286/1563 Loss: 1.442 | Acc: 48.116% (19816/41184)\n",
      "Epoch 4 Step 1287/1563 Loss: 1.442 | Acc: 48.110% (19829/41216)\n",
      "Epoch 4 Step 1288/1563 Loss: 1.442 | Acc: 48.104% (19842/41248)\n",
      "Epoch 4 Step 1289/1563 Loss: 1.442 | Acc: 48.103% (19857/41280)\n",
      "Epoch 4 Step 1290/1563 Loss: 1.442 | Acc: 48.102% (19872/41312)\n",
      "Epoch 4 Step 1291/1563 Loss: 1.442 | Acc: 48.101% (19887/41344)\n",
      "Epoch 4 Step 1292/1563 Loss: 1.442 | Acc: 48.105% (19904/41376)\n",
      "Epoch 4 Step 1293/1563 Loss: 1.442 | Acc: 48.102% (19918/41408)\n",
      "Epoch 4 Step 1294/1563 Loss: 1.442 | Acc: 48.111% (19937/41440)\n",
      "Epoch 4 Step 1295/1563 Loss: 1.442 | Acc: 48.102% (19949/41472)\n",
      "Epoch 4 Step 1296/1563 Loss: 1.442 | Acc: 48.101% (19964/41504)\n",
      "Epoch 4 Step 1297/1563 Loss: 1.442 | Acc: 48.108% (19982/41536)\n",
      "Epoch 4 Step 1298/1563 Loss: 1.442 | Acc: 48.102% (19995/41568)\n",
      "Epoch 4 Step 1299/1563 Loss: 1.442 | Acc: 48.106% (20012/41600)\n",
      "Epoch 4 Step 1300/1563 Loss: 1.442 | Acc: 48.095% (20023/41632)\n",
      "Epoch 4 Step 1301/1563 Loss: 1.442 | Acc: 48.101% (20041/41664)\n",
      "Epoch 4 Step 1302/1563 Loss: 1.442 | Acc: 48.105% (20058/41696)\n",
      "Epoch 4 Step 1303/1563 Loss: 1.442 | Acc: 48.107% (20074/41728)\n",
      "Epoch 4 Step 1304/1563 Loss: 1.442 | Acc: 48.108% (20090/41760)\n",
      "Epoch 4 Step 1305/1563 Loss: 1.442 | Acc: 48.100% (20102/41792)\n",
      "Epoch 4 Step 1306/1563 Loss: 1.442 | Acc: 48.092% (20114/41824)\n",
      "Epoch 4 Step 1307/1563 Loss: 1.442 | Acc: 48.093% (20130/41856)\n",
      "Epoch 4 Step 1308/1563 Loss: 1.442 | Acc: 48.085% (20142/41888)\n",
      "Epoch 4 Step 1309/1563 Loss: 1.442 | Acc: 48.080% (20155/41920)\n",
      "Epoch 4 Step 1310/1563 Loss: 1.443 | Acc: 48.076% (20169/41952)\n",
      "Epoch 4 Step 1311/1563 Loss: 1.443 | Acc: 48.075% (20184/41984)\n",
      "Epoch 4 Step 1312/1563 Loss: 1.443 | Acc: 48.063% (20194/42016)\n",
      "Epoch 4 Step 1313/1563 Loss: 1.443 | Acc: 48.055% (20206/42048)\n",
      "Epoch 4 Step 1314/1563 Loss: 1.443 | Acc: 48.070% (20228/42080)\n",
      "Epoch 4 Step 1315/1563 Loss: 1.442 | Acc: 48.086% (20250/42112)\n",
      "Epoch 4 Step 1316/1563 Loss: 1.442 | Acc: 48.085% (20265/42144)\n",
      "Epoch 4 Step 1317/1563 Loss: 1.442 | Acc: 48.079% (20278/42176)\n",
      "Epoch 4 Step 1318/1563 Loss: 1.442 | Acc: 48.062% (20286/42208)\n",
      "Epoch 4 Step 1319/1563 Loss: 1.442 | Acc: 48.063% (20302/42240)\n",
      "Epoch 4 Step 1320/1563 Loss: 1.442 | Acc: 48.070% (20320/42272)\n",
      "Epoch 4 Step 1321/1563 Loss: 1.442 | Acc: 48.069% (20335/42304)\n",
      "Epoch 4 Step 1322/1563 Loss: 1.442 | Acc: 48.061% (20347/42336)\n",
      "Epoch 4 Step 1323/1563 Loss: 1.442 | Acc: 48.069% (20366/42368)\n",
      "Epoch 4 Step 1324/1563 Loss: 1.442 | Acc: 48.071% (20382/42400)\n",
      "Epoch 4 Step 1325/1563 Loss: 1.442 | Acc: 48.067% (20396/42432)\n",
      "Epoch 4 Step 1326/1563 Loss: 1.442 | Acc: 48.081% (20417/42464)\n",
      "Epoch 4 Step 1327/1563 Loss: 1.441 | Acc: 48.085% (20434/42496)\n",
      "Epoch 4 Step 1328/1563 Loss: 1.441 | Acc: 48.086% (20450/42528)\n",
      "Epoch 4 Step 1329/1563 Loss: 1.442 | Acc: 48.085% (20465/42560)\n",
      "Epoch 4 Step 1330/1563 Loss: 1.441 | Acc: 48.086% (20481/42592)\n",
      "Epoch 4 Step 1331/1563 Loss: 1.441 | Acc: 48.090% (20498/42624)\n",
      "Epoch 4 Step 1332/1563 Loss: 1.442 | Acc: 48.078% (20508/42656)\n",
      "Epoch 4 Step 1333/1563 Loss: 1.442 | Acc: 48.077% (20523/42688)\n",
      "Epoch 4 Step 1334/1563 Loss: 1.442 | Acc: 48.057% (20530/42720)\n",
      "Epoch 4 Step 1335/1563 Loss: 1.442 | Acc: 48.063% (20548/42752)\n",
      "Epoch 4 Step 1336/1563 Loss: 1.442 | Acc: 48.048% (20557/42784)\n",
      "Epoch 4 Step 1337/1563 Loss: 1.442 | Acc: 48.054% (20575/42816)\n",
      "Epoch 4 Step 1338/1563 Loss: 1.442 | Acc: 48.054% (20590/42848)\n",
      "Epoch 4 Step 1339/1563 Loss: 1.442 | Acc: 48.050% (20604/42880)\n",
      "Epoch 4 Step 1340/1563 Loss: 1.442 | Acc: 48.054% (20621/42912)\n",
      "Epoch 4 Step 1341/1563 Loss: 1.442 | Acc: 48.058% (20638/42944)\n",
      "Epoch 4 Step 1342/1563 Loss: 1.442 | Acc: 48.048% (20649/42976)\n",
      "Epoch 4 Step 1343/1563 Loss: 1.442 | Acc: 48.056% (20668/43008)\n",
      "Epoch 4 Step 1344/1563 Loss: 1.442 | Acc: 48.074% (20691/43040)\n",
      "Epoch 4 Step 1345/1563 Loss: 1.442 | Acc: 48.075% (20707/43072)\n",
      "Epoch 4 Step 1346/1563 Loss: 1.442 | Acc: 48.074% (20722/43104)\n",
      "Epoch 4 Step 1347/1563 Loss: 1.442 | Acc: 48.053% (20728/43136)\n",
      "Epoch 4 Step 1348/1563 Loss: 1.442 | Acc: 48.061% (20747/43168)\n",
      "Epoch 4 Step 1349/1563 Loss: 1.442 | Acc: 48.062% (20763/43200)\n",
      "Epoch 4 Step 1350/1563 Loss: 1.442 | Acc: 48.069% (20781/43232)\n",
      "Epoch 4 Step 1351/1563 Loss: 1.442 | Acc: 48.065% (20795/43264)\n",
      "Epoch 4 Step 1352/1563 Loss: 1.442 | Acc: 48.067% (20811/43296)\n",
      "Epoch 4 Step 1353/1563 Loss: 1.442 | Acc: 48.059% (20823/43328)\n",
      "Epoch 4 Step 1354/1563 Loss: 1.442 | Acc: 48.067% (20842/43360)\n",
      "Epoch 4 Step 1355/1563 Loss: 1.442 | Acc: 48.062% (20855/43392)\n",
      "Epoch 4 Step 1356/1563 Loss: 1.442 | Acc: 48.063% (20871/43424)\n",
      "Epoch 4 Step 1357/1563 Loss: 1.442 | Acc: 48.065% (20887/43456)\n",
      "Epoch 4 Step 1358/1563 Loss: 1.442 | Acc: 48.062% (20901/43488)\n",
      "Epoch 4 Step 1359/1563 Loss: 1.442 | Acc: 48.054% (20913/43520)\n",
      "Epoch 4 Step 1360/1563 Loss: 1.442 | Acc: 48.048% (20926/43552)\n",
      "Epoch 4 Step 1361/1563 Loss: 1.442 | Acc: 48.050% (20942/43584)\n",
      "Epoch 4 Step 1362/1563 Loss: 1.442 | Acc: 48.053% (20959/43616)\n",
      "Epoch 4 Step 1363/1563 Loss: 1.442 | Acc: 48.064% (20979/43648)\n",
      "Epoch 4 Step 1364/1563 Loss: 1.442 | Acc: 48.061% (20993/43680)\n",
      "Epoch 4 Step 1365/1563 Loss: 1.442 | Acc: 48.051% (21004/43712)\n",
      "Epoch 4 Step 1366/1563 Loss: 1.442 | Acc: 48.045% (21017/43744)\n",
      "Epoch 4 Step 1367/1563 Loss: 1.443 | Acc: 48.040% (21030/43776)\n",
      "Epoch 4 Step 1368/1563 Loss: 1.442 | Acc: 48.051% (21050/43808)\n",
      "Epoch 4 Step 1369/1563 Loss: 1.443 | Acc: 48.052% (21066/43840)\n",
      "Epoch 4 Step 1370/1563 Loss: 1.443 | Acc: 48.047% (21079/43872)\n",
      "Epoch 4 Step 1371/1563 Loss: 1.443 | Acc: 48.055% (21098/43904)\n",
      "Epoch 4 Step 1372/1563 Loss: 1.443 | Acc: 48.047% (21110/43936)\n",
      "Epoch 4 Step 1373/1563 Loss: 1.443 | Acc: 48.053% (21128/43968)\n",
      "Epoch 4 Step 1374/1563 Loss: 1.443 | Acc: 48.043% (21139/44000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 1375/1563 Loss: 1.443 | Acc: 48.040% (21153/44032)\n",
      "Epoch 4 Step 1376/1563 Loss: 1.443 | Acc: 48.032% (21165/44064)\n",
      "Epoch 4 Step 1377/1563 Loss: 1.443 | Acc: 48.032% (21180/44096)\n",
      "Epoch 4 Step 1378/1563 Loss: 1.443 | Acc: 48.026% (21193/44128)\n",
      "Epoch 4 Step 1379/1563 Loss: 1.443 | Acc: 48.034% (21212/44160)\n",
      "Epoch 4 Step 1380/1563 Loss: 1.443 | Acc: 48.036% (21228/44192)\n",
      "Epoch 4 Step 1381/1563 Loss: 1.443 | Acc: 48.030% (21241/44224)\n",
      "Epoch 4 Step 1382/1563 Loss: 1.443 | Acc: 48.025% (21254/44256)\n",
      "Epoch 4 Step 1383/1563 Loss: 1.443 | Acc: 48.031% (21272/44288)\n",
      "Epoch 4 Step 1384/1563 Loss: 1.443 | Acc: 48.032% (21288/44320)\n",
      "Epoch 4 Step 1385/1563 Loss: 1.443 | Acc: 48.025% (21300/44352)\n",
      "Epoch 4 Step 1386/1563 Loss: 1.443 | Acc: 48.040% (21322/44384)\n",
      "Epoch 4 Step 1387/1563 Loss: 1.443 | Acc: 48.037% (21336/44416)\n",
      "Epoch 4 Step 1388/1563 Loss: 1.443 | Acc: 48.040% (21353/44448)\n",
      "Epoch 4 Step 1389/1563 Loss: 1.443 | Acc: 48.049% (21372/44480)\n",
      "Epoch 4 Step 1390/1563 Loss: 1.442 | Acc: 48.057% (21391/44512)\n",
      "Epoch 4 Step 1391/1563 Loss: 1.443 | Acc: 48.049% (21403/44544)\n",
      "Epoch 4 Step 1392/1563 Loss: 1.443 | Acc: 48.048% (21418/44576)\n",
      "Epoch 4 Step 1393/1563 Loss: 1.443 | Acc: 48.041% (21430/44608)\n",
      "Epoch 4 Step 1394/1563 Loss: 1.443 | Acc: 48.042% (21446/44640)\n",
      "Epoch 4 Step 1395/1563 Loss: 1.442 | Acc: 48.052% (21466/44672)\n",
      "Epoch 4 Step 1396/1563 Loss: 1.442 | Acc: 48.063% (21486/44704)\n",
      "Epoch 4 Step 1397/1563 Loss: 1.442 | Acc: 48.060% (21500/44736)\n",
      "Epoch 4 Step 1398/1563 Loss: 1.442 | Acc: 48.057% (21514/44768)\n",
      "Epoch 4 Step 1399/1563 Loss: 1.442 | Acc: 48.062% (21532/44800)\n",
      "Epoch 4 Step 1400/1563 Loss: 1.442 | Acc: 48.066% (21549/44832)\n",
      "Epoch 4 Step 1401/1563 Loss: 1.442 | Acc: 48.065% (21564/44864)\n",
      "Epoch 4 Step 1402/1563 Loss: 1.442 | Acc: 48.064% (21579/44896)\n",
      "Epoch 4 Step 1403/1563 Loss: 1.442 | Acc: 48.066% (21595/44928)\n",
      "Epoch 4 Step 1404/1563 Loss: 1.442 | Acc: 48.056% (21606/44960)\n",
      "Epoch 4 Step 1405/1563 Loss: 1.442 | Acc: 48.057% (21622/44992)\n",
      "Epoch 4 Step 1406/1563 Loss: 1.442 | Acc: 48.063% (21640/45024)\n",
      "Epoch 4 Step 1407/1563 Loss: 1.442 | Acc: 48.067% (21657/45056)\n",
      "Epoch 4 Step 1408/1563 Loss: 1.442 | Acc: 48.066% (21672/45088)\n",
      "Epoch 4 Step 1409/1563 Loss: 1.442 | Acc: 48.063% (21686/45120)\n",
      "Epoch 4 Step 1410/1563 Loss: 1.442 | Acc: 48.058% (21699/45152)\n",
      "Epoch 4 Step 1411/1563 Loss: 1.442 | Acc: 48.063% (21717/45184)\n",
      "Epoch 4 Step 1412/1563 Loss: 1.443 | Acc: 48.060% (21731/45216)\n",
      "Epoch 4 Step 1413/1563 Loss: 1.442 | Acc: 48.064% (21748/45248)\n",
      "Epoch 4 Step 1414/1563 Loss: 1.442 | Acc: 48.074% (21768/45280)\n",
      "Epoch 4 Step 1415/1563 Loss: 1.442 | Acc: 48.073% (21783/45312)\n",
      "Epoch 4 Step 1416/1563 Loss: 1.442 | Acc: 48.073% (21798/45344)\n",
      "Epoch 4 Step 1417/1563 Loss: 1.442 | Acc: 48.074% (21814/45376)\n",
      "Epoch 4 Step 1418/1563 Loss: 1.442 | Acc: 48.071% (21828/45408)\n",
      "Epoch 4 Step 1419/1563 Loss: 1.442 | Acc: 48.070% (21843/45440)\n",
      "Epoch 4 Step 1420/1563 Loss: 1.442 | Acc: 48.076% (21861/45472)\n",
      "Epoch 4 Step 1421/1563 Loss: 1.442 | Acc: 48.073% (21875/45504)\n",
      "Epoch 4 Step 1422/1563 Loss: 1.442 | Acc: 48.067% (21888/45536)\n",
      "Epoch 4 Step 1423/1563 Loss: 1.442 | Acc: 48.071% (21905/45568)\n",
      "Epoch 4 Step 1424/1563 Loss: 1.442 | Acc: 48.075% (21922/45600)\n",
      "Epoch 4 Step 1425/1563 Loss: 1.442 | Acc: 48.067% (21934/45632)\n",
      "Epoch 4 Step 1426/1563 Loss: 1.442 | Acc: 48.073% (21952/45664)\n",
      "Epoch 4 Step 1427/1563 Loss: 1.442 | Acc: 48.070% (21966/45696)\n",
      "Epoch 4 Step 1428/1563 Loss: 1.442 | Acc: 48.062% (21978/45728)\n",
      "Epoch 4 Step 1429/1563 Loss: 1.442 | Acc: 48.075% (21999/45760)\n",
      "Epoch 4 Step 1430/1563 Loss: 1.442 | Acc: 48.072% (22013/45792)\n",
      "Epoch 4 Step 1431/1563 Loss: 1.442 | Acc: 48.064% (22025/45824)\n",
      "Epoch 4 Step 1432/1563 Loss: 1.442 | Acc: 48.066% (22041/45856)\n",
      "Epoch 4 Step 1433/1563 Loss: 1.442 | Acc: 48.063% (22055/45888)\n",
      "Epoch 4 Step 1434/1563 Loss: 1.443 | Acc: 48.064% (22071/45920)\n",
      "Epoch 4 Step 1435/1563 Loss: 1.443 | Acc: 48.072% (22090/45952)\n",
      "Epoch 4 Step 1436/1563 Loss: 1.443 | Acc: 48.073% (22106/45984)\n",
      "Epoch 4 Step 1437/1563 Loss: 1.443 | Acc: 48.070% (22120/46016)\n",
      "Epoch 4 Step 1438/1563 Loss: 1.443 | Acc: 48.067% (22134/46048)\n",
      "Epoch 4 Step 1439/1563 Loss: 1.443 | Acc: 48.071% (22151/46080)\n",
      "Epoch 4 Step 1440/1563 Loss: 1.443 | Acc: 48.059% (22161/46112)\n",
      "Epoch 4 Step 1441/1563 Loss: 1.443 | Acc: 48.054% (22174/46144)\n",
      "Epoch 4 Step 1442/1563 Loss: 1.443 | Acc: 48.053% (22189/46176)\n",
      "Epoch 4 Step 1443/1563 Loss: 1.443 | Acc: 48.054% (22205/46208)\n",
      "Epoch 4 Step 1444/1563 Loss: 1.443 | Acc: 48.045% (22216/46240)\n",
      "Epoch 4 Step 1445/1563 Loss: 1.443 | Acc: 48.044% (22231/46272)\n",
      "Epoch 4 Step 1446/1563 Loss: 1.443 | Acc: 48.041% (22245/46304)\n",
      "Epoch 4 Step 1447/1563 Loss: 1.443 | Acc: 48.034% (22257/46336)\n",
      "Epoch 4 Step 1448/1563 Loss: 1.443 | Acc: 48.037% (22274/46368)\n",
      "Epoch 4 Step 1449/1563 Loss: 1.443 | Acc: 48.045% (22293/46400)\n",
      "Epoch 4 Step 1450/1563 Loss: 1.443 | Acc: 48.040% (22306/46432)\n",
      "Epoch 4 Step 1451/1563 Loss: 1.443 | Acc: 48.050% (22326/46464)\n",
      "Epoch 4 Step 1452/1563 Loss: 1.443 | Acc: 48.051% (22342/46496)\n",
      "Epoch 4 Step 1453/1563 Loss: 1.443 | Acc: 48.048% (22356/46528)\n",
      "Epoch 4 Step 1454/1563 Loss: 1.443 | Acc: 48.043% (22369/46560)\n",
      "Epoch 4 Step 1455/1563 Loss: 1.443 | Acc: 48.049% (22387/46592)\n",
      "Epoch 4 Step 1456/1563 Loss: 1.443 | Acc: 48.050% (22403/46624)\n",
      "Epoch 4 Step 1457/1563 Loss: 1.443 | Acc: 48.054% (22420/46656)\n",
      "Epoch 4 Step 1458/1563 Loss: 1.443 | Acc: 48.059% (22438/46688)\n",
      "Epoch 4 Step 1459/1563 Loss: 1.443 | Acc: 48.065% (22456/46720)\n",
      "Epoch 4 Step 1460/1563 Loss: 1.443 | Acc: 48.073% (22475/46752)\n",
      "Epoch 4 Step 1461/1563 Loss: 1.443 | Acc: 48.081% (22494/46784)\n",
      "Epoch 4 Step 1462/1563 Loss: 1.443 | Acc: 48.078% (22508/46816)\n",
      "Epoch 4 Step 1463/1563 Loss: 1.443 | Acc: 48.079% (22524/46848)\n",
      "Epoch 4 Step 1464/1563 Loss: 1.443 | Acc: 48.067% (22534/46880)\n",
      "Epoch 4 Step 1465/1563 Loss: 1.443 | Acc: 48.067% (22549/46912)\n",
      "Epoch 4 Step 1466/1563 Loss: 1.443 | Acc: 48.068% (22565/46944)\n",
      "Epoch 4 Step 1467/1563 Loss: 1.443 | Acc: 48.069% (22581/46976)\n",
      "Epoch 4 Step 1468/1563 Loss: 1.443 | Acc: 48.062% (22593/47008)\n",
      "Epoch 4 Step 1469/1563 Loss: 1.443 | Acc: 48.063% (22609/47040)\n",
      "Epoch 4 Step 1470/1563 Loss: 1.443 | Acc: 48.065% (22625/47072)\n",
      "Epoch 4 Step 1471/1563 Loss: 1.443 | Acc: 48.055% (22636/47104)\n",
      "Epoch 4 Step 1472/1563 Loss: 1.443 | Acc: 48.057% (22652/47136)\n",
      "Epoch 4 Step 1473/1563 Loss: 1.443 | Acc: 48.050% (22664/47168)\n",
      "Epoch 4 Step 1474/1563 Loss: 1.443 | Acc: 48.051% (22680/47200)\n",
      "Epoch 4 Step 1475/1563 Loss: 1.443 | Acc: 48.050% (22695/47232)\n",
      "Epoch 4 Step 1476/1563 Loss: 1.443 | Acc: 48.045% (22708/47264)\n",
      "Epoch 4 Step 1477/1563 Loss: 1.443 | Acc: 48.042% (22722/47296)\n",
      "Epoch 4 Step 1478/1563 Loss: 1.443 | Acc: 48.041% (22737/47328)\n",
      "Epoch 4 Step 1479/1563 Loss: 1.443 | Acc: 48.038% (22751/47360)\n",
      "Epoch 4 Step 1480/1563 Loss: 1.443 | Acc: 48.046% (22770/47392)\n",
      "Epoch 4 Step 1481/1563 Loss: 1.443 | Acc: 48.050% (22787/47424)\n",
      "Epoch 4 Step 1482/1563 Loss: 1.443 | Acc: 48.051% (22803/47456)\n",
      "Epoch 4 Step 1483/1563 Loss: 1.443 | Acc: 48.050% (22818/47488)\n",
      "Epoch 4 Step 1484/1563 Loss: 1.443 | Acc: 48.047% (22832/47520)\n",
      "Epoch 4 Step 1485/1563 Loss: 1.444 | Acc: 48.038% (22843/47552)\n",
      "Epoch 4 Step 1486/1563 Loss: 1.444 | Acc: 48.035% (22857/47584)\n",
      "Epoch 4 Step 1487/1563 Loss: 1.444 | Acc: 48.026% (22868/47616)\n",
      "Epoch 4 Step 1488/1563 Loss: 1.444 | Acc: 48.013% (22877/47648)\n",
      "Epoch 4 Step 1489/1563 Loss: 1.444 | Acc: 48.010% (22891/47680)\n",
      "Epoch 4 Step 1490/1563 Loss: 1.445 | Acc: 48.005% (22904/47712)\n",
      "Epoch 4 Step 1491/1563 Loss: 1.444 | Acc: 48.008% (22921/47744)\n",
      "Epoch 4 Step 1492/1563 Loss: 1.444 | Acc: 48.022% (22943/47776)\n",
      "Epoch 4 Step 1493/1563 Loss: 1.444 | Acc: 48.025% (22960/47808)\n",
      "Epoch 4 Step 1494/1563 Loss: 1.444 | Acc: 48.025% (22975/47840)\n",
      "Epoch 4 Step 1495/1563 Loss: 1.444 | Acc: 48.020% (22988/47872)\n",
      "Epoch 4 Step 1496/1563 Loss: 1.444 | Acc: 48.021% (23004/47904)\n",
      "Epoch 4 Step 1497/1563 Loss: 1.444 | Acc: 48.033% (23025/47936)\n",
      "Epoch 4 Step 1498/1563 Loss: 1.444 | Acc: 48.040% (23044/47968)\n",
      "Epoch 4 Step 1499/1563 Loss: 1.444 | Acc: 48.052% (23065/48000)\n",
      "Epoch 4 Step 1500/1563 Loss: 1.444 | Acc: 48.047% (23078/48032)\n",
      "Epoch 4 Step 1501/1563 Loss: 1.444 | Acc: 48.051% (23095/48064)\n",
      "Epoch 4 Step 1502/1563 Loss: 1.444 | Acc: 48.046% (23108/48096)\n",
      "Epoch 4 Step 1503/1563 Loss: 1.444 | Acc: 48.049% (23125/48128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 1504/1563 Loss: 1.444 | Acc: 48.042% (23137/48160)\n",
      "Epoch 4 Step 1505/1563 Loss: 1.444 | Acc: 48.041% (23152/48192)\n",
      "Epoch 4 Step 1506/1563 Loss: 1.444 | Acc: 48.049% (23171/48224)\n",
      "Epoch 4 Step 1507/1563 Loss: 1.444 | Acc: 48.067% (23195/48256)\n",
      "Epoch 4 Step 1508/1563 Loss: 1.444 | Acc: 48.068% (23211/48288)\n",
      "Epoch 4 Step 1509/1563 Loss: 1.444 | Acc: 48.061% (23223/48320)\n",
      "Epoch 4 Step 1510/1563 Loss: 1.444 | Acc: 48.054% (23235/48352)\n",
      "Epoch 4 Step 1511/1563 Loss: 1.444 | Acc: 48.055% (23251/48384)\n",
      "Epoch 4 Step 1512/1563 Loss: 1.444 | Acc: 48.052% (23265/48416)\n",
      "Epoch 4 Step 1513/1563 Loss: 1.444 | Acc: 48.056% (23282/48448)\n",
      "Epoch 4 Step 1514/1563 Loss: 1.444 | Acc: 48.047% (23293/48480)\n",
      "Epoch 4 Step 1515/1563 Loss: 1.444 | Acc: 48.042% (23306/48512)\n",
      "Epoch 4 Step 1516/1563 Loss: 1.444 | Acc: 48.037% (23319/48544)\n",
      "Epoch 4 Step 1517/1563 Loss: 1.444 | Acc: 48.040% (23336/48576)\n",
      "Epoch 4 Step 1518/1563 Loss: 1.444 | Acc: 48.044% (23353/48608)\n",
      "Epoch 4 Step 1519/1563 Loss: 1.444 | Acc: 48.045% (23369/48640)\n",
      "Epoch 4 Step 1520/1563 Loss: 1.444 | Acc: 48.044% (23384/48672)\n",
      "Epoch 4 Step 1521/1563 Loss: 1.444 | Acc: 48.037% (23396/48704)\n",
      "Epoch 4 Step 1522/1563 Loss: 1.444 | Acc: 48.040% (23413/48736)\n",
      "Epoch 4 Step 1523/1563 Loss: 1.444 | Acc: 48.029% (23423/48768)\n",
      "Epoch 4 Step 1524/1563 Loss: 1.444 | Acc: 48.037% (23442/48800)\n",
      "Epoch 4 Step 1525/1563 Loss: 1.444 | Acc: 48.046% (23462/48832)\n",
      "Epoch 4 Step 1526/1563 Loss: 1.444 | Acc: 48.039% (23474/48864)\n",
      "Epoch 4 Step 1527/1563 Loss: 1.444 | Acc: 48.041% (23490/48896)\n",
      "Epoch 4 Step 1528/1563 Loss: 1.444 | Acc: 48.042% (23506/48928)\n",
      "Epoch 4 Step 1529/1563 Loss: 1.444 | Acc: 48.035% (23518/48960)\n",
      "Epoch 4 Step 1530/1563 Loss: 1.444 | Acc: 48.028% (23530/48992)\n",
      "Epoch 4 Step 1531/1563 Loss: 1.444 | Acc: 48.027% (23545/49024)\n",
      "Epoch 4 Step 1532/1563 Loss: 1.444 | Acc: 48.031% (23562/49056)\n",
      "Epoch 4 Step 1533/1563 Loss: 1.444 | Acc: 48.022% (23573/49088)\n",
      "Epoch 4 Step 1534/1563 Loss: 1.444 | Acc: 48.029% (23592/49120)\n",
      "Epoch 4 Step 1535/1563 Loss: 1.444 | Acc: 48.029% (23607/49152)\n",
      "Epoch 4 Step 1536/1563 Loss: 1.444 | Acc: 48.020% (23618/49184)\n",
      "Epoch 4 Step 1537/1563 Loss: 1.444 | Acc: 48.027% (23637/49216)\n",
      "Epoch 4 Step 1538/1563 Loss: 1.445 | Acc: 48.018% (23648/49248)\n",
      "Epoch 4 Step 1539/1563 Loss: 1.445 | Acc: 48.013% (23661/49280)\n",
      "Epoch 4 Step 1540/1563 Loss: 1.445 | Acc: 48.023% (23681/49312)\n",
      "Epoch 4 Step 1541/1563 Loss: 1.444 | Acc: 48.026% (23698/49344)\n",
      "Epoch 4 Step 1542/1563 Loss: 1.444 | Acc: 48.033% (23717/49376)\n",
      "Epoch 4 Step 1543/1563 Loss: 1.444 | Acc: 48.037% (23734/49408)\n",
      "Epoch 4 Step 1544/1563 Loss: 1.444 | Acc: 48.046% (23754/49440)\n",
      "Epoch 4 Step 1545/1563 Loss: 1.444 | Acc: 48.045% (23769/49472)\n",
      "Epoch 4 Step 1546/1563 Loss: 1.444 | Acc: 48.051% (23787/49504)\n",
      "Epoch 4 Step 1547/1563 Loss: 1.444 | Acc: 48.054% (23804/49536)\n",
      "Epoch 4 Step 1548/1563 Loss: 1.444 | Acc: 48.049% (23817/49568)\n",
      "Epoch 4 Step 1549/1563 Loss: 1.444 | Acc: 48.044% (23830/49600)\n",
      "Epoch 4 Step 1550/1563 Loss: 1.444 | Acc: 48.038% (23842/49632)\n",
      "Epoch 4 Step 1551/1563 Loss: 1.444 | Acc: 48.041% (23859/49664)\n",
      "Epoch 4 Step 1552/1563 Loss: 1.444 | Acc: 48.036% (23872/49696)\n",
      "Epoch 4 Step 1553/1563 Loss: 1.444 | Acc: 48.029% (23884/49728)\n",
      "Epoch 4 Step 1554/1563 Loss: 1.444 | Acc: 48.027% (23898/49760)\n",
      "Epoch 4 Step 1555/1563 Loss: 1.444 | Acc: 48.030% (23915/49792)\n",
      "Epoch 4 Step 1556/1563 Loss: 1.444 | Acc: 48.031% (23931/49824)\n",
      "Epoch 4 Step 1557/1563 Loss: 1.444 | Acc: 48.028% (23945/49856)\n",
      "Epoch 4 Step 1558/1563 Loss: 1.444 | Acc: 48.046% (23969/49888)\n",
      "Epoch 4 Step 1559/1563 Loss: 1.444 | Acc: 48.041% (23982/49920)\n",
      "Epoch 4 Step 1560/1563 Loss: 1.444 | Acc: 48.046% (24000/49952)\n",
      "Epoch 4 Step 1561/1563 Loss: 1.444 | Acc: 48.045% (24015/49984)\n",
      "Epoch 4 Step 1562/1563 Loss: 1.444 | Acc: 48.048% (24024/50000)\n",
      "Epoch 4 Step 0/313 Test Loss: 1.174 | Test Acc: 46.875% (15/32)\n",
      "Epoch 4 Step 1/313 Test Loss: 1.301 | Test Acc: 46.875% (30/64)\n",
      "Epoch 4 Step 2/313 Test Loss: 1.288 | Test Acc: 52.083% (50/96)\n",
      "Epoch 4 Step 3/313 Test Loss: 1.288 | Test Acc: 53.125% (68/128)\n",
      "Epoch 4 Step 4/313 Test Loss: 1.329 | Test Acc: 53.125% (85/160)\n",
      "Epoch 4 Step 5/313 Test Loss: 1.336 | Test Acc: 52.604% (101/192)\n",
      "Epoch 4 Step 6/313 Test Loss: 1.394 | Test Acc: 50.000% (112/224)\n",
      "Epoch 4 Step 7/313 Test Loss: 1.399 | Test Acc: 50.391% (129/256)\n",
      "Epoch 4 Step 8/313 Test Loss: 1.411 | Test Acc: 48.958% (141/288)\n",
      "Epoch 4 Step 9/313 Test Loss: 1.388 | Test Acc: 49.688% (159/320)\n",
      "Epoch 4 Step 10/313 Test Loss: 1.370 | Test Acc: 49.716% (175/352)\n",
      "Epoch 4 Step 11/313 Test Loss: 1.385 | Test Acc: 48.958% (188/384)\n",
      "Epoch 4 Step 12/313 Test Loss: 1.371 | Test Acc: 49.760% (207/416)\n",
      "Epoch 4 Step 13/313 Test Loss: 1.374 | Test Acc: 49.107% (220/448)\n",
      "Epoch 4 Step 14/313 Test Loss: 1.373 | Test Acc: 48.958% (235/480)\n",
      "Epoch 4 Step 15/313 Test Loss: 1.367 | Test Acc: 49.023% (251/512)\n",
      "Epoch 4 Step 16/313 Test Loss: 1.357 | Test Acc: 49.081% (267/544)\n",
      "Epoch 4 Step 17/313 Test Loss: 1.348 | Test Acc: 49.653% (286/576)\n",
      "Epoch 4 Step 18/313 Test Loss: 1.346 | Test Acc: 50.329% (306/608)\n",
      "Epoch 4 Step 19/313 Test Loss: 1.329 | Test Acc: 50.938% (326/640)\n",
      "Epoch 4 Step 20/313 Test Loss: 1.323 | Test Acc: 50.893% (342/672)\n",
      "Epoch 4 Step 21/313 Test Loss: 1.341 | Test Acc: 49.858% (351/704)\n",
      "Epoch 4 Step 22/313 Test Loss: 1.335 | Test Acc: 50.000% (368/736)\n",
      "Epoch 4 Step 23/313 Test Loss: 1.334 | Test Acc: 50.260% (386/768)\n",
      "Epoch 4 Step 24/313 Test Loss: 1.337 | Test Acc: 50.000% (400/800)\n",
      "Epoch 4 Step 25/313 Test Loss: 1.333 | Test Acc: 50.120% (417/832)\n",
      "Epoch 4 Step 26/313 Test Loss: 1.333 | Test Acc: 50.231% (434/864)\n",
      "Epoch 4 Step 27/313 Test Loss: 1.325 | Test Acc: 50.670% (454/896)\n",
      "Epoch 4 Step 28/313 Test Loss: 1.325 | Test Acc: 50.970% (473/928)\n",
      "Epoch 4 Step 29/313 Test Loss: 1.314 | Test Acc: 51.250% (492/960)\n",
      "Epoch 4 Step 30/313 Test Loss: 1.305 | Test Acc: 51.714% (513/992)\n",
      "Epoch 4 Step 31/313 Test Loss: 1.296 | Test Acc: 52.051% (533/1024)\n",
      "Epoch 4 Step 32/313 Test Loss: 1.304 | Test Acc: 51.799% (547/1056)\n",
      "Epoch 4 Step 33/313 Test Loss: 1.301 | Test Acc: 52.022% (566/1088)\n",
      "Epoch 4 Step 34/313 Test Loss: 1.293 | Test Acc: 52.500% (588/1120)\n",
      "Epoch 4 Step 35/313 Test Loss: 1.301 | Test Acc: 52.083% (600/1152)\n",
      "Epoch 4 Step 36/313 Test Loss: 1.298 | Test Acc: 52.027% (616/1184)\n",
      "Epoch 4 Step 37/313 Test Loss: 1.300 | Test Acc: 52.138% (634/1216)\n",
      "Epoch 4 Step 38/313 Test Loss: 1.308 | Test Acc: 52.003% (649/1248)\n",
      "Epoch 4 Step 39/313 Test Loss: 1.309 | Test Acc: 52.031% (666/1280)\n",
      "Epoch 4 Step 40/313 Test Loss: 1.308 | Test Acc: 51.753% (679/1312)\n",
      "Epoch 4 Step 41/313 Test Loss: 1.312 | Test Acc: 51.562% (693/1344)\n",
      "Epoch 4 Step 42/313 Test Loss: 1.307 | Test Acc: 51.599% (710/1376)\n",
      "Epoch 4 Step 43/313 Test Loss: 1.314 | Test Acc: 51.278% (722/1408)\n",
      "Epoch 4 Step 44/313 Test Loss: 1.318 | Test Acc: 50.972% (734/1440)\n",
      "Epoch 4 Step 45/313 Test Loss: 1.315 | Test Acc: 51.087% (752/1472)\n",
      "Epoch 4 Step 46/313 Test Loss: 1.314 | Test Acc: 51.064% (768/1504)\n",
      "Epoch 4 Step 47/313 Test Loss: 1.313 | Test Acc: 51.237% (787/1536)\n",
      "Epoch 4 Step 48/313 Test Loss: 1.310 | Test Acc: 51.276% (804/1568)\n",
      "Epoch 4 Step 49/313 Test Loss: 1.316 | Test Acc: 51.062% (817/1600)\n",
      "Epoch 4 Step 50/313 Test Loss: 1.326 | Test Acc: 50.735% (828/1632)\n",
      "Epoch 4 Step 51/313 Test Loss: 1.322 | Test Acc: 51.022% (849/1664)\n",
      "Epoch 4 Step 52/313 Test Loss: 1.321 | Test Acc: 51.120% (867/1696)\n",
      "Epoch 4 Step 53/313 Test Loss: 1.324 | Test Acc: 51.215% (885/1728)\n",
      "Epoch 4 Step 54/313 Test Loss: 1.326 | Test Acc: 51.080% (899/1760)\n",
      "Epoch 4 Step 55/313 Test Loss: 1.323 | Test Acc: 51.060% (915/1792)\n",
      "Epoch 4 Step 56/313 Test Loss: 1.323 | Test Acc: 50.987% (930/1824)\n",
      "Epoch 4 Step 57/313 Test Loss: 1.326 | Test Acc: 51.131% (949/1856)\n",
      "Epoch 4 Step 58/313 Test Loss: 1.327 | Test Acc: 51.059% (964/1888)\n",
      "Epoch 4 Step 59/313 Test Loss: 1.331 | Test Acc: 51.042% (980/1920)\n",
      "Epoch 4 Step 60/313 Test Loss: 1.332 | Test Acc: 50.871% (993/1952)\n",
      "Epoch 4 Step 61/313 Test Loss: 1.332 | Test Acc: 51.008% (1012/1984)\n",
      "Epoch 4 Step 62/313 Test Loss: 1.335 | Test Acc: 50.893% (1026/2016)\n",
      "Epoch 4 Step 63/313 Test Loss: 1.335 | Test Acc: 50.830% (1041/2048)\n",
      "Epoch 4 Step 64/313 Test Loss: 1.332 | Test Acc: 50.817% (1057/2080)\n",
      "Epoch 4 Step 65/313 Test Loss: 1.330 | Test Acc: 50.947% (1076/2112)\n",
      "Epoch 4 Step 66/313 Test Loss: 1.330 | Test Acc: 50.979% (1093/2144)\n",
      "Epoch 4 Step 67/313 Test Loss: 1.335 | Test Acc: 50.781% (1105/2176)\n",
      "Epoch 4 Step 68/313 Test Loss: 1.336 | Test Acc: 50.815% (1122/2208)\n",
      "Epoch 4 Step 69/313 Test Loss: 1.335 | Test Acc: 50.938% (1141/2240)\n",
      "Epoch 4 Step 70/313 Test Loss: 1.335 | Test Acc: 51.012% (1159/2272)\n",
      "Epoch 4 Step 71/313 Test Loss: 1.337 | Test Acc: 50.955% (1174/2304)\n",
      "Epoch 4 Step 72/313 Test Loss: 1.342 | Test Acc: 50.942% (1190/2336)\n",
      "Epoch 4 Step 73/313 Test Loss: 1.341 | Test Acc: 51.014% (1208/2368)\n",
      "Epoch 4 Step 74/313 Test Loss: 1.340 | Test Acc: 51.125% (1227/2400)\n",
      "Epoch 4 Step 75/313 Test Loss: 1.340 | Test Acc: 51.192% (1245/2432)\n",
      "Epoch 4 Step 76/313 Test Loss: 1.341 | Test Acc: 51.177% (1261/2464)\n",
      "Epoch 4 Step 77/313 Test Loss: 1.340 | Test Acc: 51.282% (1280/2496)\n",
      "Epoch 4 Step 78/313 Test Loss: 1.343 | Test Acc: 51.226% (1295/2528)\n",
      "Epoch 4 Step 79/313 Test Loss: 1.346 | Test Acc: 51.172% (1310/2560)\n",
      "Epoch 4 Step 80/313 Test Loss: 1.349 | Test Acc: 51.042% (1323/2592)\n",
      "Epoch 4 Step 81/313 Test Loss: 1.347 | Test Acc: 51.067% (1340/2624)\n",
      "Epoch 4 Step 82/313 Test Loss: 1.348 | Test Acc: 50.979% (1354/2656)\n",
      "Epoch 4 Step 83/313 Test Loss: 1.347 | Test Acc: 51.079% (1373/2688)\n",
      "Epoch 4 Step 84/313 Test Loss: 1.348 | Test Acc: 51.029% (1388/2720)\n",
      "Epoch 4 Step 85/313 Test Loss: 1.351 | Test Acc: 50.945% (1402/2752)\n",
      "Epoch 4 Step 86/313 Test Loss: 1.352 | Test Acc: 50.970% (1419/2784)\n",
      "Epoch 4 Step 87/313 Test Loss: 1.352 | Test Acc: 50.888% (1433/2816)\n",
      "Epoch 4 Step 88/313 Test Loss: 1.353 | Test Acc: 50.843% (1448/2848)\n",
      "Epoch 4 Step 89/313 Test Loss: 1.353 | Test Acc: 50.764% (1462/2880)\n",
      "Epoch 4 Step 90/313 Test Loss: 1.354 | Test Acc: 50.721% (1477/2912)\n",
      "Epoch 4 Step 91/313 Test Loss: 1.351 | Test Acc: 50.849% (1497/2944)\n",
      "Epoch 4 Step 92/313 Test Loss: 1.351 | Test Acc: 50.840% (1513/2976)\n",
      "Epoch 4 Step 93/313 Test Loss: 1.351 | Test Acc: 50.831% (1529/3008)\n",
      "Epoch 4 Step 94/313 Test Loss: 1.351 | Test Acc: 50.954% (1549/3040)\n",
      "Epoch 4 Step 95/313 Test Loss: 1.351 | Test Acc: 50.944% (1565/3072)\n",
      "Epoch 4 Step 96/313 Test Loss: 1.350 | Test Acc: 50.870% (1579/3104)\n",
      "Epoch 4 Step 97/313 Test Loss: 1.349 | Test Acc: 50.925% (1597/3136)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 98/313 Test Loss: 1.351 | Test Acc: 50.947% (1614/3168)\n",
      "Epoch 4 Step 99/313 Test Loss: 1.352 | Test Acc: 50.969% (1631/3200)\n",
      "Epoch 4 Step 100/313 Test Loss: 1.354 | Test Acc: 50.928% (1646/3232)\n",
      "Epoch 4 Step 101/313 Test Loss: 1.352 | Test Acc: 51.072% (1667/3264)\n",
      "Epoch 4 Step 102/313 Test Loss: 1.351 | Test Acc: 51.214% (1688/3296)\n",
      "Epoch 4 Step 103/313 Test Loss: 1.352 | Test Acc: 51.172% (1703/3328)\n",
      "Epoch 4 Step 104/313 Test Loss: 1.353 | Test Acc: 51.220% (1721/3360)\n",
      "Epoch 4 Step 105/313 Test Loss: 1.350 | Test Acc: 51.356% (1742/3392)\n",
      "Epoch 4 Step 106/313 Test Loss: 1.351 | Test Acc: 51.285% (1756/3424)\n",
      "Epoch 4 Step 107/313 Test Loss: 1.350 | Test Acc: 51.273% (1772/3456)\n",
      "Epoch 4 Step 108/313 Test Loss: 1.348 | Test Acc: 51.376% (1792/3488)\n",
      "Epoch 4 Step 109/313 Test Loss: 1.350 | Test Acc: 51.307% (1806/3520)\n",
      "Epoch 4 Step 110/313 Test Loss: 1.349 | Test Acc: 51.464% (1828/3552)\n",
      "Epoch 4 Step 111/313 Test Loss: 1.348 | Test Acc: 51.535% (1847/3584)\n",
      "Epoch 4 Step 112/313 Test Loss: 1.348 | Test Acc: 51.604% (1866/3616)\n",
      "Epoch 4 Step 113/313 Test Loss: 1.348 | Test Acc: 51.645% (1884/3648)\n",
      "Epoch 4 Step 114/313 Test Loss: 1.346 | Test Acc: 51.712% (1903/3680)\n",
      "Epoch 4 Step 115/313 Test Loss: 1.345 | Test Acc: 51.751% (1921/3712)\n",
      "Epoch 4 Step 116/313 Test Loss: 1.345 | Test Acc: 51.790% (1939/3744)\n",
      "Epoch 4 Step 117/313 Test Loss: 1.346 | Test Acc: 51.695% (1952/3776)\n",
      "Epoch 4 Step 118/313 Test Loss: 1.346 | Test Acc: 51.786% (1972/3808)\n",
      "Epoch 4 Step 119/313 Test Loss: 1.344 | Test Acc: 51.797% (1989/3840)\n",
      "Epoch 4 Step 120/313 Test Loss: 1.342 | Test Acc: 51.808% (2006/3872)\n",
      "Epoch 4 Step 121/313 Test Loss: 1.340 | Test Acc: 51.793% (2022/3904)\n",
      "Epoch 4 Step 122/313 Test Loss: 1.341 | Test Acc: 51.778% (2038/3936)\n",
      "Epoch 4 Step 123/313 Test Loss: 1.339 | Test Acc: 51.764% (2054/3968)\n",
      "Epoch 4 Step 124/313 Test Loss: 1.341 | Test Acc: 51.775% (2071/4000)\n",
      "Epoch 4 Step 125/313 Test Loss: 1.340 | Test Acc: 51.910% (2093/4032)\n",
      "Epoch 4 Step 126/313 Test Loss: 1.342 | Test Acc: 51.870% (2108/4064)\n",
      "Epoch 4 Step 127/313 Test Loss: 1.339 | Test Acc: 51.904% (2126/4096)\n",
      "Epoch 4 Step 128/313 Test Loss: 1.341 | Test Acc: 51.793% (2138/4128)\n",
      "Epoch 4 Step 129/313 Test Loss: 1.340 | Test Acc: 51.851% (2157/4160)\n",
      "Epoch 4 Step 130/313 Test Loss: 1.338 | Test Acc: 51.956% (2178/4192)\n",
      "Epoch 4 Step 131/313 Test Loss: 1.338 | Test Acc: 51.894% (2192/4224)\n",
      "Epoch 4 Step 132/313 Test Loss: 1.339 | Test Acc: 51.856% (2207/4256)\n",
      "Epoch 4 Step 133/313 Test Loss: 1.338 | Test Acc: 51.889% (2225/4288)\n",
      "Epoch 4 Step 134/313 Test Loss: 1.340 | Test Acc: 51.852% (2240/4320)\n",
      "Epoch 4 Step 135/313 Test Loss: 1.337 | Test Acc: 51.907% (2259/4352)\n",
      "Epoch 4 Step 136/313 Test Loss: 1.336 | Test Acc: 52.007% (2280/4384)\n",
      "Epoch 4 Step 137/313 Test Loss: 1.336 | Test Acc: 52.061% (2299/4416)\n",
      "Epoch 4 Step 138/313 Test Loss: 1.335 | Test Acc: 52.091% (2317/4448)\n",
      "Epoch 4 Step 139/313 Test Loss: 1.334 | Test Acc: 52.098% (2334/4480)\n",
      "Epoch 4 Step 140/313 Test Loss: 1.334 | Test Acc: 52.105% (2351/4512)\n",
      "Epoch 4 Step 141/313 Test Loss: 1.334 | Test Acc: 52.069% (2366/4544)\n",
      "Epoch 4 Step 142/313 Test Loss: 1.335 | Test Acc: 52.054% (2382/4576)\n",
      "Epoch 4 Step 143/313 Test Loss: 1.338 | Test Acc: 51.931% (2393/4608)\n",
      "Epoch 4 Step 144/313 Test Loss: 1.337 | Test Acc: 51.983% (2412/4640)\n",
      "Epoch 4 Step 145/313 Test Loss: 1.336 | Test Acc: 52.055% (2432/4672)\n",
      "Epoch 4 Step 146/313 Test Loss: 1.337 | Test Acc: 51.998% (2446/4704)\n",
      "Epoch 4 Step 147/313 Test Loss: 1.336 | Test Acc: 52.027% (2464/4736)\n",
      "Epoch 4 Step 148/313 Test Loss: 1.337 | Test Acc: 51.992% (2479/4768)\n",
      "Epoch 4 Step 149/313 Test Loss: 1.337 | Test Acc: 51.938% (2493/4800)\n",
      "Epoch 4 Step 150/313 Test Loss: 1.338 | Test Acc: 51.925% (2509/4832)\n",
      "Epoch 4 Step 151/313 Test Loss: 1.336 | Test Acc: 52.056% (2532/4864)\n",
      "Epoch 4 Step 152/313 Test Loss: 1.336 | Test Acc: 52.002% (2546/4896)\n",
      "Epoch 4 Step 153/313 Test Loss: 1.335 | Test Acc: 52.090% (2567/4928)\n",
      "Epoch 4 Step 154/313 Test Loss: 1.334 | Test Acc: 52.077% (2583/4960)\n",
      "Epoch 4 Step 155/313 Test Loss: 1.334 | Test Acc: 52.063% (2599/4992)\n",
      "Epoch 4 Step 156/313 Test Loss: 1.334 | Test Acc: 52.110% (2618/5024)\n",
      "Epoch 4 Step 157/313 Test Loss: 1.333 | Test Acc: 52.156% (2637/5056)\n",
      "Epoch 4 Step 158/313 Test Loss: 1.334 | Test Acc: 52.083% (2650/5088)\n",
      "Epoch 4 Step 159/313 Test Loss: 1.336 | Test Acc: 51.973% (2661/5120)\n",
      "Epoch 4 Step 160/313 Test Loss: 1.337 | Test Acc: 51.980% (2678/5152)\n",
      "Epoch 4 Step 161/313 Test Loss: 1.336 | Test Acc: 52.083% (2700/5184)\n",
      "Epoch 4 Step 162/313 Test Loss: 1.336 | Test Acc: 52.071% (2716/5216)\n",
      "Epoch 4 Step 163/313 Test Loss: 1.336 | Test Acc: 52.077% (2733/5248)\n",
      "Epoch 4 Step 164/313 Test Loss: 1.337 | Test Acc: 52.027% (2747/5280)\n",
      "Epoch 4 Step 165/313 Test Loss: 1.337 | Test Acc: 51.995% (2762/5312)\n",
      "Epoch 4 Step 166/313 Test Loss: 1.338 | Test Acc: 51.984% (2778/5344)\n",
      "Epoch 4 Step 167/313 Test Loss: 1.338 | Test Acc: 51.990% (2795/5376)\n",
      "Epoch 4 Step 168/313 Test Loss: 1.338 | Test Acc: 51.979% (2811/5408)\n",
      "Epoch 4 Step 169/313 Test Loss: 1.338 | Test Acc: 51.985% (2828/5440)\n",
      "Epoch 4 Step 170/313 Test Loss: 1.337 | Test Acc: 52.010% (2846/5472)\n",
      "Epoch 4 Step 171/313 Test Loss: 1.338 | Test Acc: 51.999% (2862/5504)\n",
      "Epoch 4 Step 172/313 Test Loss: 1.339 | Test Acc: 51.951% (2876/5536)\n",
      "Epoch 4 Step 173/313 Test Loss: 1.339 | Test Acc: 51.904% (2890/5568)\n",
      "Epoch 4 Step 174/313 Test Loss: 1.339 | Test Acc: 51.875% (2905/5600)\n",
      "Epoch 4 Step 175/313 Test Loss: 1.341 | Test Acc: 51.829% (2919/5632)\n",
      "Epoch 4 Step 176/313 Test Loss: 1.342 | Test Acc: 51.713% (2929/5664)\n",
      "Epoch 4 Step 177/313 Test Loss: 1.341 | Test Acc: 51.791% (2950/5696)\n",
      "Epoch 4 Step 178/313 Test Loss: 1.340 | Test Acc: 51.816% (2968/5728)\n",
      "Epoch 4 Step 179/313 Test Loss: 1.340 | Test Acc: 51.753% (2981/5760)\n",
      "Epoch 4 Step 180/313 Test Loss: 1.338 | Test Acc: 51.865% (3004/5792)\n",
      "Epoch 4 Step 181/313 Test Loss: 1.338 | Test Acc: 51.820% (3018/5824)\n",
      "Epoch 4 Step 182/313 Test Loss: 1.340 | Test Acc: 51.759% (3031/5856)\n",
      "Epoch 4 Step 183/313 Test Loss: 1.340 | Test Acc: 51.800% (3050/5888)\n",
      "Epoch 4 Step 184/313 Test Loss: 1.342 | Test Acc: 51.723% (3062/5920)\n",
      "Epoch 4 Step 185/313 Test Loss: 1.342 | Test Acc: 51.680% (3076/5952)\n",
      "Epoch 4 Step 186/313 Test Loss: 1.342 | Test Acc: 51.654% (3091/5984)\n",
      "Epoch 4 Step 187/313 Test Loss: 1.342 | Test Acc: 51.679% (3109/6016)\n",
      "Epoch 4 Step 188/313 Test Loss: 1.341 | Test Acc: 51.653% (3124/6048)\n",
      "Epoch 4 Step 189/313 Test Loss: 1.342 | Test Acc: 51.595% (3137/6080)\n",
      "Epoch 4 Step 190/313 Test Loss: 1.341 | Test Acc: 51.620% (3155/6112)\n",
      "Epoch 4 Step 191/313 Test Loss: 1.341 | Test Acc: 51.611% (3171/6144)\n",
      "Epoch 4 Step 192/313 Test Loss: 1.342 | Test Acc: 51.603% (3187/6176)\n",
      "Epoch 4 Step 193/313 Test Loss: 1.342 | Test Acc: 51.627% (3205/6208)\n",
      "Epoch 4 Step 194/313 Test Loss: 1.342 | Test Acc: 51.635% (3222/6240)\n",
      "Epoch 4 Step 195/313 Test Loss: 1.344 | Test Acc: 51.547% (3233/6272)\n",
      "Epoch 4 Step 196/313 Test Loss: 1.345 | Test Acc: 51.507% (3247/6304)\n",
      "Epoch 4 Step 197/313 Test Loss: 1.344 | Test Acc: 51.515% (3264/6336)\n",
      "Epoch 4 Step 198/313 Test Loss: 1.342 | Test Acc: 51.617% (3287/6368)\n",
      "Epoch 4 Step 199/313 Test Loss: 1.343 | Test Acc: 51.594% (3302/6400)\n",
      "Epoch 4 Step 200/313 Test Loss: 1.343 | Test Acc: 51.632% (3321/6432)\n",
      "Epoch 4 Step 201/313 Test Loss: 1.344 | Test Acc: 51.624% (3337/6464)\n",
      "Epoch 4 Step 202/313 Test Loss: 1.345 | Test Acc: 51.632% (3354/6496)\n",
      "Epoch 4 Step 203/313 Test Loss: 1.345 | Test Acc: 51.608% (3369/6528)\n",
      "Epoch 4 Step 204/313 Test Loss: 1.346 | Test Acc: 51.540% (3381/6560)\n",
      "Epoch 4 Step 205/313 Test Loss: 1.347 | Test Acc: 51.471% (3393/6592)\n",
      "Epoch 4 Step 206/313 Test Loss: 1.346 | Test Acc: 51.510% (3412/6624)\n",
      "Epoch 4 Step 207/313 Test Loss: 1.345 | Test Acc: 51.547% (3431/6656)\n",
      "Epoch 4 Step 208/313 Test Loss: 1.345 | Test Acc: 51.540% (3447/6688)\n",
      "Epoch 4 Step 209/313 Test Loss: 1.345 | Test Acc: 51.518% (3462/6720)\n",
      "Epoch 4 Step 210/313 Test Loss: 1.345 | Test Acc: 51.555% (3481/6752)\n",
      "Epoch 4 Step 211/313 Test Loss: 1.345 | Test Acc: 51.518% (3495/6784)\n",
      "Epoch 4 Step 212/313 Test Loss: 1.344 | Test Acc: 51.585% (3516/6816)\n",
      "Epoch 4 Step 213/313 Test Loss: 1.344 | Test Acc: 51.548% (3530/6848)\n",
      "Epoch 4 Step 214/313 Test Loss: 1.346 | Test Acc: 51.468% (3541/6880)\n",
      "Epoch 4 Step 215/313 Test Loss: 1.345 | Test Acc: 51.519% (3561/6912)\n",
      "Epoch 4 Step 216/313 Test Loss: 1.345 | Test Acc: 51.555% (3580/6944)\n",
      "Epoch 4 Step 217/313 Test Loss: 1.346 | Test Acc: 51.519% (3594/6976)\n",
      "Epoch 4 Step 218/313 Test Loss: 1.348 | Test Acc: 51.441% (3605/7008)\n",
      "Epoch 4 Step 219/313 Test Loss: 1.347 | Test Acc: 51.435% (3621/7040)\n",
      "Epoch 4 Step 220/313 Test Loss: 1.348 | Test Acc: 51.414% (3636/7072)\n",
      "Epoch 4 Step 221/313 Test Loss: 1.348 | Test Acc: 51.394% (3651/7104)\n",
      "Epoch 4 Step 222/313 Test Loss: 1.349 | Test Acc: 51.401% (3668/7136)\n",
      "Epoch 4 Step 223/313 Test Loss: 1.349 | Test Acc: 51.409% (3685/7168)\n",
      "Epoch 4 Step 224/313 Test Loss: 1.349 | Test Acc: 51.389% (3700/7200)\n",
      "Epoch 4 Step 225/313 Test Loss: 1.350 | Test Acc: 51.369% (3715/7232)\n",
      "Epoch 4 Step 226/313 Test Loss: 1.351 | Test Acc: 51.349% (3730/7264)\n",
      "Epoch 4 Step 227/313 Test Loss: 1.350 | Test Acc: 51.329% (3745/7296)\n",
      "Epoch 4 Step 228/313 Test Loss: 1.350 | Test Acc: 51.365% (3764/7328)\n",
      "Epoch 4 Step 229/313 Test Loss: 1.348 | Test Acc: 51.440% (3786/7360)\n",
      "Epoch 4 Step 230/313 Test Loss: 1.348 | Test Acc: 51.448% (3803/7392)\n",
      "Epoch 4 Step 231/313 Test Loss: 1.349 | Test Acc: 51.374% (3814/7424)\n",
      "Epoch 4 Step 232/313 Test Loss: 1.349 | Test Acc: 51.368% (3830/7456)\n",
      "Epoch 4 Step 233/313 Test Loss: 1.348 | Test Acc: 51.402% (3849/7488)\n",
      "Epoch 4 Step 234/313 Test Loss: 1.347 | Test Acc: 51.410% (3866/7520)\n",
      "Epoch 4 Step 235/313 Test Loss: 1.348 | Test Acc: 51.417% (3883/7552)\n",
      "Epoch 4 Step 236/313 Test Loss: 1.348 | Test Acc: 51.371% (3896/7584)\n",
      "Epoch 4 Step 237/313 Test Loss: 1.350 | Test Acc: 51.300% (3907/7616)\n",
      "Epoch 4 Step 238/313 Test Loss: 1.350 | Test Acc: 51.268% (3921/7648)\n",
      "Epoch 4 Step 239/313 Test Loss: 1.350 | Test Acc: 51.276% (3938/7680)\n",
      "Epoch 4 Step 240/313 Test Loss: 1.348 | Test Acc: 51.349% (3960/7712)\n",
      "Epoch 4 Step 241/313 Test Loss: 1.348 | Test Acc: 51.330% (3975/7744)\n",
      "Epoch 4 Step 242/313 Test Loss: 1.348 | Test Acc: 51.325% (3991/7776)\n",
      "Epoch 4 Step 243/313 Test Loss: 1.348 | Test Acc: 51.332% (4008/7808)\n",
      "Epoch 4 Step 244/313 Test Loss: 1.348 | Test Acc: 51.314% (4023/7840)\n",
      "Epoch 4 Step 245/313 Test Loss: 1.348 | Test Acc: 51.308% (4039/7872)\n",
      "Epoch 4 Step 246/313 Test Loss: 1.348 | Test Acc: 51.354% (4059/7904)\n",
      "Epoch 4 Step 247/313 Test Loss: 1.349 | Test Acc: 51.298% (4071/7936)\n",
      "Epoch 4 Step 248/313 Test Loss: 1.350 | Test Acc: 51.280% (4086/7968)\n",
      "Epoch 4 Step 249/313 Test Loss: 1.350 | Test Acc: 51.325% (4106/8000)\n",
      "Epoch 4 Step 250/313 Test Loss: 1.351 | Test Acc: 51.307% (4121/8032)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Step 251/313 Test Loss: 1.352 | Test Acc: 51.277% (4135/8064)\n",
      "Epoch 4 Step 252/313 Test Loss: 1.352 | Test Acc: 51.309% (4154/8096)\n",
      "Epoch 4 Step 253/313 Test Loss: 1.352 | Test Acc: 51.316% (4171/8128)\n",
      "Epoch 4 Step 254/313 Test Loss: 1.353 | Test Acc: 51.311% (4187/8160)\n",
      "Epoch 4 Step 255/313 Test Loss: 1.352 | Test Acc: 51.331% (4205/8192)\n",
      "Epoch 4 Step 256/313 Test Loss: 1.353 | Test Acc: 51.301% (4219/8224)\n",
      "Epoch 4 Step 257/313 Test Loss: 1.352 | Test Acc: 51.332% (4238/8256)\n",
      "Epoch 4 Step 258/313 Test Loss: 1.353 | Test Acc: 51.291% (4251/8288)\n",
      "Epoch 4 Step 259/313 Test Loss: 1.354 | Test Acc: 51.250% (4264/8320)\n",
      "Epoch 4 Step 260/313 Test Loss: 1.355 | Test Acc: 51.257% (4281/8352)\n",
      "Epoch 4 Step 261/313 Test Loss: 1.354 | Test Acc: 51.276% (4299/8384)\n",
      "Epoch 4 Step 262/313 Test Loss: 1.354 | Test Acc: 51.248% (4313/8416)\n",
      "Epoch 4 Step 263/313 Test Loss: 1.354 | Test Acc: 51.231% (4328/8448)\n",
      "Epoch 4 Step 264/313 Test Loss: 1.355 | Test Acc: 51.238% (4345/8480)\n",
      "Epoch 4 Step 265/313 Test Loss: 1.354 | Test Acc: 51.245% (4362/8512)\n",
      "Epoch 4 Step 266/313 Test Loss: 1.354 | Test Acc: 51.241% (4378/8544)\n",
      "Epoch 4 Step 267/313 Test Loss: 1.354 | Test Acc: 51.248% (4395/8576)\n",
      "Epoch 4 Step 268/313 Test Loss: 1.354 | Test Acc: 51.231% (4410/8608)\n",
      "Epoch 4 Step 269/313 Test Loss: 1.354 | Test Acc: 51.238% (4427/8640)\n",
      "Epoch 4 Step 270/313 Test Loss: 1.355 | Test Acc: 51.188% (4439/8672)\n",
      "Epoch 4 Step 271/313 Test Loss: 1.354 | Test Acc: 51.195% (4456/8704)\n",
      "Epoch 4 Step 272/313 Test Loss: 1.353 | Test Acc: 51.259% (4478/8736)\n",
      "Epoch 4 Step 273/313 Test Loss: 1.353 | Test Acc: 51.232% (4492/8768)\n",
      "Epoch 4 Step 274/313 Test Loss: 1.353 | Test Acc: 51.239% (4509/8800)\n",
      "Epoch 4 Step 275/313 Test Loss: 1.353 | Test Acc: 51.223% (4524/8832)\n",
      "Epoch 4 Step 276/313 Test Loss: 1.353 | Test Acc: 51.252% (4543/8864)\n",
      "Epoch 4 Step 277/313 Test Loss: 1.352 | Test Acc: 51.281% (4562/8896)\n",
      "Epoch 4 Step 278/313 Test Loss: 1.351 | Test Acc: 51.322% (4582/8928)\n",
      "Epoch 4 Step 279/313 Test Loss: 1.352 | Test Acc: 51.261% (4593/8960)\n",
      "Epoch 4 Step 280/313 Test Loss: 1.352 | Test Acc: 51.234% (4607/8992)\n",
      "Epoch 4 Step 281/313 Test Loss: 1.352 | Test Acc: 51.263% (4626/9024)\n",
      "Epoch 4 Step 282/313 Test Loss: 1.352 | Test Acc: 51.248% (4641/9056)\n",
      "Epoch 4 Step 283/313 Test Loss: 1.352 | Test Acc: 51.276% (4660/9088)\n",
      "Epoch 4 Step 284/313 Test Loss: 1.351 | Test Acc: 51.283% (4677/9120)\n",
      "Epoch 4 Step 285/313 Test Loss: 1.352 | Test Acc: 51.267% (4692/9152)\n",
      "Epoch 4 Step 286/313 Test Loss: 1.350 | Test Acc: 51.361% (4717/9184)\n",
      "Epoch 4 Step 287/313 Test Loss: 1.349 | Test Acc: 51.421% (4739/9216)\n",
      "Epoch 4 Step 288/313 Test Loss: 1.349 | Test Acc: 51.460% (4759/9248)\n",
      "Epoch 4 Step 289/313 Test Loss: 1.349 | Test Acc: 51.487% (4778/9280)\n",
      "Epoch 4 Step 290/313 Test Loss: 1.350 | Test Acc: 51.439% (4790/9312)\n",
      "Epoch 4 Step 291/313 Test Loss: 1.350 | Test Acc: 51.466% (4809/9344)\n",
      "Epoch 4 Step 292/313 Test Loss: 1.350 | Test Acc: 51.451% (4824/9376)\n",
      "Epoch 4 Step 293/313 Test Loss: 1.351 | Test Acc: 51.392% (4835/9408)\n",
      "Epoch 4 Step 294/313 Test Loss: 1.351 | Test Acc: 51.409% (4853/9440)\n",
      "Epoch 4 Step 295/313 Test Loss: 1.351 | Test Acc: 51.436% (4872/9472)\n",
      "Epoch 4 Step 296/313 Test Loss: 1.350 | Test Acc: 51.463% (4891/9504)\n",
      "Epoch 4 Step 297/313 Test Loss: 1.351 | Test Acc: 51.447% (4906/9536)\n",
      "Epoch 4 Step 298/313 Test Loss: 1.350 | Test Acc: 51.484% (4926/9568)\n",
      "Epoch 4 Step 299/313 Test Loss: 1.350 | Test Acc: 51.500% (4944/9600)\n",
      "Epoch 4 Step 300/313 Test Loss: 1.350 | Test Acc: 51.474% (4958/9632)\n",
      "Epoch 4 Step 301/313 Test Loss: 1.351 | Test Acc: 51.438% (4971/9664)\n",
      "Epoch 4 Step 302/313 Test Loss: 1.351 | Test Acc: 51.434% (4987/9696)\n",
      "Epoch 4 Step 303/313 Test Loss: 1.350 | Test Acc: 51.480% (5008/9728)\n",
      "Epoch 4 Step 304/313 Test Loss: 1.351 | Test Acc: 51.465% (5023/9760)\n",
      "Epoch 4 Step 305/313 Test Loss: 1.351 | Test Acc: 51.481% (5041/9792)\n",
      "Epoch 4 Step 306/313 Test Loss: 1.351 | Test Acc: 51.456% (5055/9824)\n",
      "Epoch 4 Step 307/313 Test Loss: 1.352 | Test Acc: 51.431% (5069/9856)\n",
      "Epoch 4 Step 308/313 Test Loss: 1.353 | Test Acc: 51.426% (5085/9888)\n",
      "Epoch 4 Step 309/313 Test Loss: 1.352 | Test Acc: 51.462% (5105/9920)\n",
      "Epoch 4 Step 310/313 Test Loss: 1.352 | Test Acc: 51.437% (5119/9952)\n",
      "Epoch 4 Step 311/313 Test Loss: 1.352 | Test Acc: 51.442% (5136/9984)\n",
      "Epoch 4 Step 312/313 Test Loss: 1.352 | Test Acc: 51.430% (5143/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 5\n",
      "Epoch 5 Step 0/1563 Loss: 1.197 | Acc: 46.875% (15/32)\n",
      "Epoch 5 Step 1/1563 Loss: 1.320 | Acc: 45.312% (29/64)\n",
      "Epoch 5 Step 2/1563 Loss: 1.364 | Acc: 47.917% (46/96)\n",
      "Epoch 5 Step 3/1563 Loss: 1.450 | Acc: 47.656% (61/128)\n",
      "Epoch 5 Step 4/1563 Loss: 1.397 | Acc: 47.500% (76/160)\n",
      "Epoch 5 Step 5/1563 Loss: 1.407 | Acc: 46.875% (90/192)\n",
      "Epoch 5 Step 6/1563 Loss: 1.385 | Acc: 48.214% (108/224)\n",
      "Epoch 5 Step 7/1563 Loss: 1.395 | Acc: 48.047% (123/256)\n",
      "Epoch 5 Step 8/1563 Loss: 1.395 | Acc: 48.958% (141/288)\n",
      "Epoch 5 Step 9/1563 Loss: 1.377 | Acc: 49.062% (157/320)\n",
      "Epoch 5 Step 10/1563 Loss: 1.367 | Acc: 49.432% (174/352)\n",
      "Epoch 5 Step 11/1563 Loss: 1.366 | Acc: 49.479% (190/384)\n",
      "Epoch 5 Step 12/1563 Loss: 1.386 | Acc: 48.317% (201/416)\n",
      "Epoch 5 Step 13/1563 Loss: 1.414 | Acc: 47.545% (213/448)\n",
      "Epoch 5 Step 14/1563 Loss: 1.405 | Acc: 48.333% (232/480)\n",
      "Epoch 5 Step 15/1563 Loss: 1.396 | Acc: 48.242% (247/512)\n",
      "Epoch 5 Step 16/1563 Loss: 1.401 | Acc: 47.978% (261/544)\n",
      "Epoch 5 Step 17/1563 Loss: 1.409 | Acc: 48.090% (277/576)\n",
      "Epoch 5 Step 18/1563 Loss: 1.407 | Acc: 48.026% (292/608)\n",
      "Epoch 5 Step 19/1563 Loss: 1.397 | Acc: 48.750% (312/640)\n",
      "Epoch 5 Step 20/1563 Loss: 1.384 | Acc: 49.405% (332/672)\n",
      "Epoch 5 Step 21/1563 Loss: 1.390 | Acc: 49.432% (348/704)\n",
      "Epoch 5 Step 22/1563 Loss: 1.384 | Acc: 49.457% (364/736)\n",
      "Epoch 5 Step 23/1563 Loss: 1.380 | Acc: 49.479% (380/768)\n",
      "Epoch 5 Step 24/1563 Loss: 1.374 | Acc: 49.750% (398/800)\n",
      "Epoch 5 Step 25/1563 Loss: 1.374 | Acc: 49.760% (414/832)\n",
      "Epoch 5 Step 26/1563 Loss: 1.367 | Acc: 50.000% (432/864)\n",
      "Epoch 5 Step 27/1563 Loss: 1.371 | Acc: 49.554% (444/896)\n",
      "Epoch 5 Step 28/1563 Loss: 1.370 | Acc: 49.784% (462/928)\n",
      "Epoch 5 Step 29/1563 Loss: 1.370 | Acc: 49.688% (477/960)\n",
      "Epoch 5 Step 30/1563 Loss: 1.372 | Acc: 49.798% (494/992)\n",
      "Epoch 5 Step 31/1563 Loss: 1.378 | Acc: 49.609% (508/1024)\n",
      "Epoch 5 Step 32/1563 Loss: 1.383 | Acc: 49.148% (519/1056)\n",
      "Epoch 5 Step 33/1563 Loss: 1.380 | Acc: 49.173% (535/1088)\n",
      "Epoch 5 Step 34/1563 Loss: 1.388 | Acc: 48.750% (546/1120)\n",
      "Epoch 5 Step 35/1563 Loss: 1.391 | Acc: 48.611% (560/1152)\n",
      "Epoch 5 Step 36/1563 Loss: 1.386 | Acc: 48.902% (579/1184)\n",
      "Epoch 5 Step 37/1563 Loss: 1.379 | Acc: 49.013% (596/1216)\n",
      "Epoch 5 Step 38/1563 Loss: 1.385 | Acc: 48.878% (610/1248)\n",
      "Epoch 5 Step 39/1563 Loss: 1.384 | Acc: 49.062% (628/1280)\n",
      "Epoch 5 Step 40/1563 Loss: 1.379 | Acc: 49.543% (650/1312)\n",
      "Epoch 5 Step 41/1563 Loss: 1.385 | Acc: 49.479% (665/1344)\n",
      "Epoch 5 Step 42/1563 Loss: 1.389 | Acc: 49.419% (680/1376)\n",
      "Epoch 5 Step 43/1563 Loss: 1.387 | Acc: 49.645% (699/1408)\n",
      "Epoch 5 Step 44/1563 Loss: 1.387 | Acc: 49.444% (712/1440)\n",
      "Epoch 5 Step 45/1563 Loss: 1.387 | Acc: 49.660% (731/1472)\n",
      "Epoch 5 Step 46/1563 Loss: 1.381 | Acc: 49.867% (750/1504)\n",
      "Epoch 5 Step 47/1563 Loss: 1.383 | Acc: 49.805% (765/1536)\n",
      "Epoch 5 Step 48/1563 Loss: 1.387 | Acc: 49.872% (782/1568)\n",
      "Epoch 5 Step 49/1563 Loss: 1.388 | Acc: 49.812% (797/1600)\n",
      "Epoch 5 Step 50/1563 Loss: 1.394 | Acc: 49.510% (808/1632)\n",
      "Epoch 5 Step 51/1563 Loss: 1.390 | Acc: 49.880% (830/1664)\n",
      "Epoch 5 Step 52/1563 Loss: 1.401 | Acc: 49.410% (838/1696)\n",
      "Epoch 5 Step 53/1563 Loss: 1.410 | Acc: 49.132% (849/1728)\n",
      "Epoch 5 Step 54/1563 Loss: 1.411 | Acc: 49.091% (864/1760)\n",
      "Epoch 5 Step 55/1563 Loss: 1.410 | Acc: 48.828% (875/1792)\n",
      "Epoch 5 Step 56/1563 Loss: 1.405 | Acc: 48.794% (890/1824)\n",
      "Epoch 5 Step 57/1563 Loss: 1.407 | Acc: 48.869% (907/1856)\n",
      "Epoch 5 Step 58/1563 Loss: 1.409 | Acc: 48.782% (921/1888)\n",
      "Epoch 5 Step 59/1563 Loss: 1.400 | Acc: 48.958% (940/1920)\n",
      "Epoch 5 Step 60/1563 Loss: 1.400 | Acc: 48.822% (953/1952)\n",
      "Epoch 5 Step 61/1563 Loss: 1.403 | Acc: 48.841% (969/1984)\n",
      "Epoch 5 Step 62/1563 Loss: 1.406 | Acc: 48.909% (986/2016)\n",
      "Epoch 5 Step 63/1563 Loss: 1.401 | Acc: 48.975% (1003/2048)\n",
      "Epoch 5 Step 64/1563 Loss: 1.402 | Acc: 49.038% (1020/2080)\n",
      "Epoch 5 Step 65/1563 Loss: 1.405 | Acc: 48.911% (1033/2112)\n",
      "Epoch 5 Step 66/1563 Loss: 1.408 | Acc: 48.927% (1049/2144)\n",
      "Epoch 5 Step 67/1563 Loss: 1.410 | Acc: 48.851% (1063/2176)\n",
      "Epoch 5 Step 68/1563 Loss: 1.411 | Acc: 48.687% (1075/2208)\n",
      "Epoch 5 Step 69/1563 Loss: 1.414 | Acc: 48.616% (1089/2240)\n",
      "Epoch 5 Step 70/1563 Loss: 1.413 | Acc: 48.768% (1108/2272)\n",
      "Epoch 5 Step 71/1563 Loss: 1.416 | Acc: 48.741% (1123/2304)\n",
      "Epoch 5 Step 72/1563 Loss: 1.411 | Acc: 48.887% (1142/2336)\n",
      "Epoch 5 Step 73/1563 Loss: 1.409 | Acc: 48.986% (1160/2368)\n",
      "Epoch 5 Step 74/1563 Loss: 1.411 | Acc: 48.917% (1174/2400)\n",
      "Epoch 5 Step 75/1563 Loss: 1.412 | Acc: 48.890% (1189/2432)\n",
      "Epoch 5 Step 76/1563 Loss: 1.416 | Acc: 48.620% (1198/2464)\n",
      "Epoch 5 Step 77/1563 Loss: 1.421 | Acc: 48.397% (1208/2496)\n",
      "Epoch 5 Step 78/1563 Loss: 1.420 | Acc: 48.378% (1223/2528)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 79/1563 Loss: 1.418 | Acc: 48.594% (1244/2560)\n",
      "Epoch 5 Step 80/1563 Loss: 1.414 | Acc: 48.765% (1264/2592)\n",
      "Epoch 5 Step 81/1563 Loss: 1.414 | Acc: 48.704% (1278/2624)\n",
      "Epoch 5 Step 82/1563 Loss: 1.415 | Acc: 48.607% (1291/2656)\n",
      "Epoch 5 Step 83/1563 Loss: 1.415 | Acc: 48.698% (1309/2688)\n",
      "Epoch 5 Step 84/1563 Loss: 1.418 | Acc: 48.713% (1325/2720)\n",
      "Epoch 5 Step 85/1563 Loss: 1.417 | Acc: 48.583% (1337/2752)\n",
      "Epoch 5 Step 86/1563 Loss: 1.419 | Acc: 48.707% (1356/2784)\n",
      "Epoch 5 Step 87/1563 Loss: 1.421 | Acc: 48.615% (1369/2816)\n",
      "Epoch 5 Step 88/1563 Loss: 1.422 | Acc: 48.525% (1382/2848)\n",
      "Epoch 5 Step 89/1563 Loss: 1.422 | Acc: 48.611% (1400/2880)\n",
      "Epoch 5 Step 90/1563 Loss: 1.420 | Acc: 48.626% (1416/2912)\n",
      "Epoch 5 Step 91/1563 Loss: 1.423 | Acc: 48.675% (1433/2944)\n",
      "Epoch 5 Step 92/1563 Loss: 1.422 | Acc: 48.723% (1450/2976)\n",
      "Epoch 5 Step 93/1563 Loss: 1.423 | Acc: 48.637% (1463/3008)\n",
      "Epoch 5 Step 94/1563 Loss: 1.421 | Acc: 48.750% (1482/3040)\n",
      "Epoch 5 Step 95/1563 Loss: 1.418 | Acc: 48.828% (1500/3072)\n",
      "Epoch 5 Step 96/1563 Loss: 1.418 | Acc: 48.872% (1517/3104)\n",
      "Epoch 5 Step 97/1563 Loss: 1.419 | Acc: 48.852% (1532/3136)\n",
      "Epoch 5 Step 98/1563 Loss: 1.418 | Acc: 48.769% (1545/3168)\n",
      "Epoch 5 Step 99/1563 Loss: 1.418 | Acc: 48.750% (1560/3200)\n",
      "Epoch 5 Step 100/1563 Loss: 1.420 | Acc: 48.731% (1575/3232)\n",
      "Epoch 5 Step 101/1563 Loss: 1.421 | Acc: 48.652% (1588/3264)\n",
      "Epoch 5 Step 102/1563 Loss: 1.419 | Acc: 48.726% (1606/3296)\n",
      "Epoch 5 Step 103/1563 Loss: 1.419 | Acc: 48.738% (1622/3328)\n",
      "Epoch 5 Step 104/1563 Loss: 1.420 | Acc: 48.720% (1637/3360)\n",
      "Epoch 5 Step 105/1563 Loss: 1.419 | Acc: 48.791% (1655/3392)\n",
      "Epoch 5 Step 106/1563 Loss: 1.420 | Acc: 48.715% (1668/3424)\n",
      "Epoch 5 Step 107/1563 Loss: 1.424 | Acc: 48.582% (1679/3456)\n",
      "Epoch 5 Step 108/1563 Loss: 1.423 | Acc: 48.595% (1695/3488)\n",
      "Epoch 5 Step 109/1563 Loss: 1.423 | Acc: 48.636% (1712/3520)\n",
      "Epoch 5 Step 110/1563 Loss: 1.421 | Acc: 48.705% (1730/3552)\n",
      "Epoch 5 Step 111/1563 Loss: 1.420 | Acc: 48.717% (1746/3584)\n",
      "Epoch 5 Step 112/1563 Loss: 1.417 | Acc: 48.811% (1765/3616)\n",
      "Epoch 5 Step 113/1563 Loss: 1.417 | Acc: 48.849% (1782/3648)\n",
      "Epoch 5 Step 114/1563 Loss: 1.419 | Acc: 48.641% (1790/3680)\n",
      "Epoch 5 Step 115/1563 Loss: 1.418 | Acc: 48.680% (1807/3712)\n",
      "Epoch 5 Step 116/1563 Loss: 1.417 | Acc: 48.718% (1824/3744)\n",
      "Epoch 5 Step 117/1563 Loss: 1.415 | Acc: 48.729% (1840/3776)\n",
      "Epoch 5 Step 118/1563 Loss: 1.415 | Acc: 48.792% (1858/3808)\n",
      "Epoch 5 Step 119/1563 Loss: 1.415 | Acc: 48.724% (1871/3840)\n",
      "Epoch 5 Step 120/1563 Loss: 1.416 | Acc: 48.657% (1884/3872)\n",
      "Epoch 5 Step 121/1563 Loss: 1.415 | Acc: 48.642% (1899/3904)\n",
      "Epoch 5 Step 122/1563 Loss: 1.415 | Acc: 48.679% (1916/3936)\n",
      "Epoch 5 Step 123/1563 Loss: 1.415 | Acc: 48.589% (1928/3968)\n",
      "Epoch 5 Step 124/1563 Loss: 1.415 | Acc: 48.625% (1945/4000)\n",
      "Epoch 5 Step 125/1563 Loss: 1.414 | Acc: 48.661% (1962/4032)\n",
      "Epoch 5 Step 126/1563 Loss: 1.414 | Acc: 48.671% (1978/4064)\n",
      "Epoch 5 Step 127/1563 Loss: 1.417 | Acc: 48.560% (1989/4096)\n",
      "Epoch 5 Step 128/1563 Loss: 1.414 | Acc: 48.643% (2008/4128)\n",
      "Epoch 5 Step 129/1563 Loss: 1.415 | Acc: 48.654% (2024/4160)\n",
      "Epoch 5 Step 130/1563 Loss: 1.415 | Acc: 48.736% (2043/4192)\n",
      "Epoch 5 Step 131/1563 Loss: 1.416 | Acc: 48.722% (2058/4224)\n",
      "Epoch 5 Step 132/1563 Loss: 1.419 | Acc: 48.708% (2073/4256)\n",
      "Epoch 5 Step 133/1563 Loss: 1.419 | Acc: 48.694% (2088/4288)\n",
      "Epoch 5 Step 134/1563 Loss: 1.421 | Acc: 48.704% (2104/4320)\n",
      "Epoch 5 Step 135/1563 Loss: 1.421 | Acc: 48.667% (2118/4352)\n",
      "Epoch 5 Step 136/1563 Loss: 1.424 | Acc: 48.517% (2127/4384)\n",
      "Epoch 5 Step 137/1563 Loss: 1.426 | Acc: 48.438% (2139/4416)\n",
      "Epoch 5 Step 138/1563 Loss: 1.427 | Acc: 48.471% (2156/4448)\n",
      "Epoch 5 Step 139/1563 Loss: 1.427 | Acc: 48.504% (2173/4480)\n",
      "Epoch 5 Step 140/1563 Loss: 1.428 | Acc: 48.559% (2191/4512)\n",
      "Epoch 5 Step 141/1563 Loss: 1.426 | Acc: 48.614% (2209/4544)\n",
      "Epoch 5 Step 142/1563 Loss: 1.426 | Acc: 48.601% (2224/4576)\n",
      "Epoch 5 Step 143/1563 Loss: 1.426 | Acc: 48.589% (2239/4608)\n",
      "Epoch 5 Step 144/1563 Loss: 1.425 | Acc: 48.621% (2256/4640)\n",
      "Epoch 5 Step 145/1563 Loss: 1.425 | Acc: 48.673% (2274/4672)\n",
      "Epoch 5 Step 146/1563 Loss: 1.426 | Acc: 48.639% (2288/4704)\n",
      "Epoch 5 Step 147/1563 Loss: 1.426 | Acc: 48.649% (2304/4736)\n",
      "Epoch 5 Step 148/1563 Loss: 1.426 | Acc: 48.700% (2322/4768)\n",
      "Epoch 5 Step 149/1563 Loss: 1.425 | Acc: 48.688% (2337/4800)\n",
      "Epoch 5 Step 150/1563 Loss: 1.425 | Acc: 48.717% (2354/4832)\n",
      "Epoch 5 Step 151/1563 Loss: 1.426 | Acc: 48.684% (2368/4864)\n",
      "Epoch 5 Step 152/1563 Loss: 1.424 | Acc: 48.672% (2383/4896)\n",
      "Epoch 5 Step 153/1563 Loss: 1.426 | Acc: 48.620% (2396/4928)\n",
      "Epoch 5 Step 154/1563 Loss: 1.425 | Acc: 48.649% (2413/4960)\n",
      "Epoch 5 Step 155/1563 Loss: 1.424 | Acc: 48.638% (2428/4992)\n",
      "Epoch 5 Step 156/1563 Loss: 1.421 | Acc: 48.826% (2453/5024)\n",
      "Epoch 5 Step 157/1563 Loss: 1.420 | Acc: 48.873% (2471/5056)\n",
      "Epoch 5 Step 158/1563 Loss: 1.419 | Acc: 48.840% (2485/5088)\n",
      "Epoch 5 Step 159/1563 Loss: 1.419 | Acc: 48.828% (2500/5120)\n",
      "Epoch 5 Step 160/1563 Loss: 1.418 | Acc: 48.894% (2519/5152)\n",
      "Epoch 5 Step 161/1563 Loss: 1.418 | Acc: 48.939% (2537/5184)\n",
      "Epoch 5 Step 162/1563 Loss: 1.417 | Acc: 48.946% (2553/5216)\n",
      "Epoch 5 Step 163/1563 Loss: 1.418 | Acc: 48.895% (2566/5248)\n",
      "Epoch 5 Step 164/1563 Loss: 1.419 | Acc: 48.920% (2583/5280)\n",
      "Epoch 5 Step 165/1563 Loss: 1.420 | Acc: 48.852% (2595/5312)\n",
      "Epoch 5 Step 166/1563 Loss: 1.418 | Acc: 48.877% (2612/5344)\n",
      "Epoch 5 Step 167/1563 Loss: 1.416 | Acc: 48.977% (2633/5376)\n",
      "Epoch 5 Step 168/1563 Loss: 1.416 | Acc: 48.928% (2646/5408)\n",
      "Epoch 5 Step 169/1563 Loss: 1.416 | Acc: 48.952% (2663/5440)\n",
      "Epoch 5 Step 170/1563 Loss: 1.415 | Acc: 49.013% (2682/5472)\n",
      "Epoch 5 Step 171/1563 Loss: 1.413 | Acc: 49.073% (2701/5504)\n",
      "Epoch 5 Step 172/1563 Loss: 1.413 | Acc: 49.097% (2718/5536)\n",
      "Epoch 5 Step 173/1563 Loss: 1.412 | Acc: 49.084% (2733/5568)\n",
      "Epoch 5 Step 174/1563 Loss: 1.412 | Acc: 49.071% (2748/5600)\n",
      "Epoch 5 Step 175/1563 Loss: 1.412 | Acc: 49.094% (2765/5632)\n",
      "Epoch 5 Step 176/1563 Loss: 1.411 | Acc: 49.100% (2781/5664)\n",
      "Epoch 5 Step 177/1563 Loss: 1.410 | Acc: 49.192% (2802/5696)\n",
      "Epoch 5 Step 178/1563 Loss: 1.410 | Acc: 49.127% (2814/5728)\n",
      "Epoch 5 Step 179/1563 Loss: 1.409 | Acc: 49.219% (2835/5760)\n",
      "Epoch 5 Step 180/1563 Loss: 1.408 | Acc: 49.240% (2852/5792)\n",
      "Epoch 5 Step 181/1563 Loss: 1.407 | Acc: 49.279% (2870/5824)\n",
      "Epoch 5 Step 182/1563 Loss: 1.407 | Acc: 49.283% (2886/5856)\n",
      "Epoch 5 Step 183/1563 Loss: 1.406 | Acc: 49.287% (2902/5888)\n",
      "Epoch 5 Step 184/1563 Loss: 1.407 | Acc: 49.240% (2915/5920)\n",
      "Epoch 5 Step 185/1563 Loss: 1.406 | Acc: 49.261% (2932/5952)\n",
      "Epoch 5 Step 186/1563 Loss: 1.406 | Acc: 49.281% (2949/5984)\n",
      "Epoch 5 Step 187/1563 Loss: 1.403 | Acc: 49.402% (2972/6016)\n",
      "Epoch 5 Step 188/1563 Loss: 1.405 | Acc: 49.388% (2987/6048)\n",
      "Epoch 5 Step 189/1563 Loss: 1.405 | Acc: 49.359% (3001/6080)\n",
      "Epoch 5 Step 190/1563 Loss: 1.403 | Acc: 49.411% (3020/6112)\n",
      "Epoch 5 Step 191/1563 Loss: 1.405 | Acc: 49.430% (3037/6144)\n",
      "Epoch 5 Step 192/1563 Loss: 1.405 | Acc: 49.385% (3050/6176)\n",
      "Epoch 5 Step 193/1563 Loss: 1.404 | Acc: 49.420% (3068/6208)\n",
      "Epoch 5 Step 194/1563 Loss: 1.404 | Acc: 49.423% (3084/6240)\n",
      "Epoch 5 Step 195/1563 Loss: 1.403 | Acc: 49.474% (3103/6272)\n",
      "Epoch 5 Step 196/1563 Loss: 1.404 | Acc: 49.492% (3120/6304)\n",
      "Epoch 5 Step 197/1563 Loss: 1.404 | Acc: 49.511% (3137/6336)\n",
      "Epoch 5 Step 198/1563 Loss: 1.404 | Acc: 49.513% (3153/6368)\n",
      "Epoch 5 Step 199/1563 Loss: 1.404 | Acc: 49.469% (3166/6400)\n",
      "Epoch 5 Step 200/1563 Loss: 1.404 | Acc: 49.487% (3183/6432)\n",
      "Epoch 5 Step 201/1563 Loss: 1.404 | Acc: 49.520% (3201/6464)\n",
      "Epoch 5 Step 202/1563 Loss: 1.405 | Acc: 49.430% (3211/6496)\n",
      "Epoch 5 Step 203/1563 Loss: 1.406 | Acc: 49.387% (3224/6528)\n",
      "Epoch 5 Step 204/1563 Loss: 1.407 | Acc: 49.375% (3239/6560)\n",
      "Epoch 5 Step 205/1563 Loss: 1.407 | Acc: 49.348% (3253/6592)\n",
      "Epoch 5 Step 206/1563 Loss: 1.406 | Acc: 49.321% (3267/6624)\n",
      "Epoch 5 Step 207/1563 Loss: 1.405 | Acc: 49.414% (3289/6656)\n",
      "Epoch 5 Step 208/1563 Loss: 1.407 | Acc: 49.342% (3300/6688)\n",
      "Epoch 5 Step 209/1563 Loss: 1.406 | Acc: 49.375% (3318/6720)\n",
      "Epoch 5 Step 210/1563 Loss: 1.404 | Acc: 49.422% (3337/6752)\n",
      "Epoch 5 Step 211/1563 Loss: 1.404 | Acc: 49.440% (3354/6784)\n",
      "Epoch 5 Step 212/1563 Loss: 1.404 | Acc: 49.472% (3372/6816)\n",
      "Epoch 5 Step 213/1563 Loss: 1.404 | Acc: 49.416% (3384/6848)\n",
      "Epoch 5 Step 214/1563 Loss: 1.404 | Acc: 49.448% (3402/6880)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 215/1563 Loss: 1.404 | Acc: 49.436% (3417/6912)\n",
      "Epoch 5 Step 216/1563 Loss: 1.403 | Acc: 49.424% (3432/6944)\n",
      "Epoch 5 Step 217/1563 Loss: 1.403 | Acc: 49.427% (3448/6976)\n",
      "Epoch 5 Step 218/1563 Loss: 1.402 | Acc: 49.443% (3465/7008)\n",
      "Epoch 5 Step 219/1563 Loss: 1.403 | Acc: 49.418% (3479/7040)\n",
      "Epoch 5 Step 220/1563 Loss: 1.402 | Acc: 49.420% (3495/7072)\n",
      "Epoch 5 Step 221/1563 Loss: 1.402 | Acc: 49.409% (3510/7104)\n",
      "Epoch 5 Step 222/1563 Loss: 1.402 | Acc: 49.453% (3529/7136)\n",
      "Epoch 5 Step 223/1563 Loss: 1.400 | Acc: 49.512% (3549/7168)\n",
      "Epoch 5 Step 224/1563 Loss: 1.401 | Acc: 49.458% (3561/7200)\n",
      "Epoch 5 Step 225/1563 Loss: 1.402 | Acc: 49.433% (3575/7232)\n",
      "Epoch 5 Step 226/1563 Loss: 1.402 | Acc: 49.353% (3585/7264)\n",
      "Epoch 5 Step 227/1563 Loss: 1.402 | Acc: 49.370% (3602/7296)\n",
      "Epoch 5 Step 228/1563 Loss: 1.402 | Acc: 49.400% (3620/7328)\n",
      "Epoch 5 Step 229/1563 Loss: 1.402 | Acc: 49.402% (3636/7360)\n",
      "Epoch 5 Step 230/1563 Loss: 1.401 | Acc: 49.391% (3651/7392)\n",
      "Epoch 5 Step 231/1563 Loss: 1.402 | Acc: 49.394% (3667/7424)\n",
      "Epoch 5 Step 232/1563 Loss: 1.403 | Acc: 49.329% (3678/7456)\n",
      "Epoch 5 Step 233/1563 Loss: 1.402 | Acc: 49.359% (3696/7488)\n",
      "Epoch 5 Step 234/1563 Loss: 1.401 | Acc: 49.415% (3716/7520)\n",
      "Epoch 5 Step 235/1563 Loss: 1.401 | Acc: 49.457% (3735/7552)\n",
      "Epoch 5 Step 236/1563 Loss: 1.402 | Acc: 49.459% (3751/7584)\n",
      "Epoch 5 Step 237/1563 Loss: 1.401 | Acc: 49.475% (3768/7616)\n",
      "Epoch 5 Step 238/1563 Loss: 1.402 | Acc: 49.438% (3781/7648)\n",
      "Epoch 5 Step 239/1563 Loss: 1.403 | Acc: 49.440% (3797/7680)\n",
      "Epoch 5 Step 240/1563 Loss: 1.402 | Acc: 49.468% (3815/7712)\n",
      "Epoch 5 Step 241/1563 Loss: 1.401 | Acc: 49.522% (3835/7744)\n",
      "Epoch 5 Step 242/1563 Loss: 1.402 | Acc: 49.447% (3845/7776)\n",
      "Epoch 5 Step 243/1563 Loss: 1.402 | Acc: 49.488% (3864/7808)\n",
      "Epoch 5 Step 244/1563 Loss: 1.403 | Acc: 49.426% (3875/7840)\n",
      "Epoch 5 Step 245/1563 Loss: 1.403 | Acc: 49.416% (3890/7872)\n",
      "Epoch 5 Step 246/1563 Loss: 1.405 | Acc: 49.367% (3902/7904)\n",
      "Epoch 5 Step 247/1563 Loss: 1.404 | Acc: 49.383% (3919/7936)\n",
      "Epoch 5 Step 248/1563 Loss: 1.404 | Acc: 49.360% (3933/7968)\n",
      "Epoch 5 Step 249/1563 Loss: 1.405 | Acc: 49.362% (3949/8000)\n",
      "Epoch 5 Step 250/1563 Loss: 1.405 | Acc: 49.353% (3964/8032)\n",
      "Epoch 5 Step 251/1563 Loss: 1.404 | Acc: 49.392% (3983/8064)\n",
      "Epoch 5 Step 252/1563 Loss: 1.404 | Acc: 49.382% (3998/8096)\n",
      "Epoch 5 Step 253/1563 Loss: 1.405 | Acc: 49.360% (4012/8128)\n",
      "Epoch 5 Step 254/1563 Loss: 1.406 | Acc: 49.412% (4032/8160)\n",
      "Epoch 5 Step 255/1563 Loss: 1.405 | Acc: 49.463% (4052/8192)\n",
      "Epoch 5 Step 256/1563 Loss: 1.405 | Acc: 49.489% (4070/8224)\n",
      "Epoch 5 Step 257/1563 Loss: 1.406 | Acc: 49.443% (4082/8256)\n",
      "Epoch 5 Step 258/1563 Loss: 1.405 | Acc: 49.493% (4102/8288)\n",
      "Epoch 5 Step 259/1563 Loss: 1.404 | Acc: 49.507% (4119/8320)\n",
      "Epoch 5 Step 260/1563 Loss: 1.404 | Acc: 49.545% (4138/8352)\n",
      "Epoch 5 Step 261/1563 Loss: 1.403 | Acc: 49.583% (4157/8384)\n",
      "Epoch 5 Step 262/1563 Loss: 1.403 | Acc: 49.525% (4168/8416)\n",
      "Epoch 5 Step 263/1563 Loss: 1.405 | Acc: 49.444% (4177/8448)\n",
      "Epoch 5 Step 264/1563 Loss: 1.404 | Acc: 49.410% (4190/8480)\n",
      "Epoch 5 Step 265/1563 Loss: 1.405 | Acc: 49.436% (4208/8512)\n",
      "Epoch 5 Step 266/1563 Loss: 1.407 | Acc: 49.368% (4218/8544)\n",
      "Epoch 5 Step 267/1563 Loss: 1.408 | Acc: 49.277% (4226/8576)\n",
      "Epoch 5 Step 268/1563 Loss: 1.408 | Acc: 49.280% (4242/8608)\n",
      "Epoch 5 Step 269/1563 Loss: 1.409 | Acc: 49.236% (4254/8640)\n",
      "Epoch 5 Step 270/1563 Loss: 1.408 | Acc: 49.262% (4272/8672)\n",
      "Epoch 5 Step 271/1563 Loss: 1.407 | Acc: 49.311% (4292/8704)\n",
      "Epoch 5 Step 272/1563 Loss: 1.407 | Acc: 49.325% (4309/8736)\n",
      "Epoch 5 Step 273/1563 Loss: 1.406 | Acc: 49.373% (4329/8768)\n",
      "Epoch 5 Step 274/1563 Loss: 1.406 | Acc: 49.432% (4350/8800)\n",
      "Epoch 5 Step 275/1563 Loss: 1.406 | Acc: 49.389% (4362/8832)\n",
      "Epoch 5 Step 276/1563 Loss: 1.406 | Acc: 49.447% (4383/8864)\n",
      "Epoch 5 Step 277/1563 Loss: 1.406 | Acc: 49.427% (4397/8896)\n",
      "Epoch 5 Step 278/1563 Loss: 1.406 | Acc: 49.429% (4413/8928)\n",
      "Epoch 5 Step 279/1563 Loss: 1.406 | Acc: 49.442% (4430/8960)\n",
      "Epoch 5 Step 280/1563 Loss: 1.406 | Acc: 49.455% (4447/8992)\n",
      "Epoch 5 Step 281/1563 Loss: 1.407 | Acc: 49.457% (4463/9024)\n",
      "Epoch 5 Step 282/1563 Loss: 1.407 | Acc: 49.448% (4478/9056)\n",
      "Epoch 5 Step 283/1563 Loss: 1.406 | Acc: 49.494% (4498/9088)\n",
      "Epoch 5 Step 284/1563 Loss: 1.407 | Acc: 49.441% (4509/9120)\n",
      "Epoch 5 Step 285/1563 Loss: 1.408 | Acc: 49.443% (4525/9152)\n",
      "Epoch 5 Step 286/1563 Loss: 1.408 | Acc: 49.434% (4540/9184)\n",
      "Epoch 5 Step 287/1563 Loss: 1.408 | Acc: 49.392% (4552/9216)\n",
      "Epoch 5 Step 288/1563 Loss: 1.409 | Acc: 49.373% (4566/9248)\n",
      "Epoch 5 Step 289/1563 Loss: 1.410 | Acc: 49.300% (4575/9280)\n",
      "Epoch 5 Step 290/1563 Loss: 1.411 | Acc: 49.270% (4588/9312)\n",
      "Epoch 5 Step 291/1563 Loss: 1.412 | Acc: 49.240% (4601/9344)\n",
      "Epoch 5 Step 292/1563 Loss: 1.411 | Acc: 49.253% (4618/9376)\n",
      "Epoch 5 Step 293/1563 Loss: 1.412 | Acc: 49.235% (4632/9408)\n",
      "Epoch 5 Step 294/1563 Loss: 1.412 | Acc: 49.206% (4645/9440)\n",
      "Epoch 5 Step 295/1563 Loss: 1.413 | Acc: 49.177% (4658/9472)\n",
      "Epoch 5 Step 296/1563 Loss: 1.413 | Acc: 49.158% (4672/9504)\n",
      "Epoch 5 Step 297/1563 Loss: 1.413 | Acc: 49.151% (4687/9536)\n",
      "Epoch 5 Step 298/1563 Loss: 1.413 | Acc: 49.133% (4701/9568)\n",
      "Epoch 5 Step 299/1563 Loss: 1.414 | Acc: 49.146% (4718/9600)\n",
      "Epoch 5 Step 300/1563 Loss: 1.413 | Acc: 49.159% (4735/9632)\n",
      "Epoch 5 Step 301/1563 Loss: 1.413 | Acc: 49.183% (4753/9664)\n",
      "Epoch 5 Step 302/1563 Loss: 1.413 | Acc: 49.175% (4768/9696)\n",
      "Epoch 5 Step 303/1563 Loss: 1.412 | Acc: 49.188% (4785/9728)\n",
      "Epoch 5 Step 304/1563 Loss: 1.414 | Acc: 49.139% (4796/9760)\n",
      "Epoch 5 Step 305/1563 Loss: 1.413 | Acc: 49.203% (4818/9792)\n",
      "Epoch 5 Step 306/1563 Loss: 1.412 | Acc: 49.206% (4834/9824)\n",
      "Epoch 5 Step 307/1563 Loss: 1.413 | Acc: 49.178% (4847/9856)\n",
      "Epoch 5 Step 308/1563 Loss: 1.413 | Acc: 49.171% (4862/9888)\n",
      "Epoch 5 Step 309/1563 Loss: 1.413 | Acc: 49.163% (4877/9920)\n",
      "Epoch 5 Step 310/1563 Loss: 1.413 | Acc: 49.166% (4893/9952)\n",
      "Epoch 5 Step 311/1563 Loss: 1.412 | Acc: 49.159% (4908/9984)\n",
      "Epoch 5 Step 312/1563 Loss: 1.412 | Acc: 49.161% (4924/10016)\n",
      "Epoch 5 Step 313/1563 Loss: 1.413 | Acc: 49.134% (4937/10048)\n",
      "Epoch 5 Step 314/1563 Loss: 1.413 | Acc: 49.097% (4949/10080)\n",
      "Epoch 5 Step 315/1563 Loss: 1.414 | Acc: 49.080% (4963/10112)\n",
      "Epoch 5 Step 316/1563 Loss: 1.414 | Acc: 49.083% (4979/10144)\n",
      "Epoch 5 Step 317/1563 Loss: 1.414 | Acc: 49.037% (4990/10176)\n",
      "Epoch 5 Step 318/1563 Loss: 1.414 | Acc: 49.011% (5003/10208)\n",
      "Epoch 5 Step 319/1563 Loss: 1.414 | Acc: 49.023% (5020/10240)\n",
      "Epoch 5 Step 320/1563 Loss: 1.415 | Acc: 49.007% (5034/10272)\n",
      "Epoch 5 Step 321/1563 Loss: 1.414 | Acc: 49.020% (5051/10304)\n",
      "Epoch 5 Step 322/1563 Loss: 1.413 | Acc: 49.052% (5070/10336)\n",
      "Epoch 5 Step 323/1563 Loss: 1.413 | Acc: 49.055% (5086/10368)\n",
      "Epoch 5 Step 324/1563 Loss: 1.414 | Acc: 49.048% (5101/10400)\n",
      "Epoch 5 Step 325/1563 Loss: 1.413 | Acc: 49.061% (5118/10432)\n",
      "Epoch 5 Step 326/1563 Loss: 1.413 | Acc: 49.063% (5134/10464)\n",
      "Epoch 5 Step 327/1563 Loss: 1.413 | Acc: 49.076% (5151/10496)\n",
      "Epoch 5 Step 328/1563 Loss: 1.412 | Acc: 49.117% (5171/10528)\n",
      "Epoch 5 Step 329/1563 Loss: 1.412 | Acc: 49.100% (5185/10560)\n",
      "Epoch 5 Step 330/1563 Loss: 1.412 | Acc: 49.122% (5203/10592)\n",
      "Epoch 5 Step 331/1563 Loss: 1.412 | Acc: 49.096% (5216/10624)\n",
      "Epoch 5 Step 332/1563 Loss: 1.412 | Acc: 49.071% (5229/10656)\n",
      "Epoch 5 Step 333/1563 Loss: 1.414 | Acc: 49.018% (5239/10688)\n",
      "Epoch 5 Step 334/1563 Loss: 1.414 | Acc: 49.058% (5259/10720)\n",
      "Epoch 5 Step 335/1563 Loss: 1.414 | Acc: 49.061% (5275/10752)\n",
      "Epoch 5 Step 336/1563 Loss: 1.415 | Acc: 49.063% (5291/10784)\n",
      "Epoch 5 Step 337/1563 Loss: 1.415 | Acc: 49.038% (5304/10816)\n",
      "Epoch 5 Step 338/1563 Loss: 1.415 | Acc: 49.004% (5316/10848)\n",
      "Epoch 5 Step 339/1563 Loss: 1.415 | Acc: 48.998% (5331/10880)\n",
      "Epoch 5 Step 340/1563 Loss: 1.414 | Acc: 49.010% (5348/10912)\n",
      "Epoch 5 Step 341/1563 Loss: 1.415 | Acc: 49.013% (5364/10944)\n",
      "Epoch 5 Step 342/1563 Loss: 1.414 | Acc: 49.007% (5379/10976)\n",
      "Epoch 5 Step 343/1563 Loss: 1.415 | Acc: 49.010% (5395/11008)\n",
      "Epoch 5 Step 344/1563 Loss: 1.414 | Acc: 49.058% (5416/11040)\n",
      "Epoch 5 Step 345/1563 Loss: 1.414 | Acc: 49.079% (5434/11072)\n",
      "Epoch 5 Step 346/1563 Loss: 1.414 | Acc: 49.090% (5451/11104)\n",
      "Epoch 5 Step 347/1563 Loss: 1.414 | Acc: 49.102% (5468/11136)\n",
      "Epoch 5 Step 348/1563 Loss: 1.414 | Acc: 49.087% (5482/11168)\n",
      "Epoch 5 Step 349/1563 Loss: 1.413 | Acc: 49.107% (5500/11200)\n",
      "Epoch 5 Step 350/1563 Loss: 1.414 | Acc: 49.101% (5515/11232)\n",
      "Epoch 5 Step 351/1563 Loss: 1.414 | Acc: 49.094% (5530/11264)\n",
      "Epoch 5 Step 352/1563 Loss: 1.416 | Acc: 49.088% (5545/11296)\n",
      "Epoch 5 Step 353/1563 Loss: 1.416 | Acc: 49.091% (5561/11328)\n",
      "Epoch 5 Step 354/1563 Loss: 1.416 | Acc: 49.102% (5578/11360)\n",
      "Epoch 5 Step 355/1563 Loss: 1.417 | Acc: 49.087% (5592/11392)\n",
      "Epoch 5 Step 356/1563 Loss: 1.417 | Acc: 49.081% (5607/11424)\n",
      "Epoch 5 Step 357/1563 Loss: 1.417 | Acc: 49.083% (5623/11456)\n",
      "Epoch 5 Step 358/1563 Loss: 1.417 | Acc: 49.121% (5643/11488)\n",
      "Epoch 5 Step 359/1563 Loss: 1.417 | Acc: 49.132% (5660/11520)\n",
      "Epoch 5 Step 360/1563 Loss: 1.417 | Acc: 49.134% (5676/11552)\n",
      "Epoch 5 Step 361/1563 Loss: 1.417 | Acc: 49.119% (5690/11584)\n",
      "Epoch 5 Step 362/1563 Loss: 1.417 | Acc: 49.113% (5705/11616)\n",
      "Epoch 5 Step 363/1563 Loss: 1.416 | Acc: 49.124% (5722/11648)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 364/1563 Loss: 1.417 | Acc: 49.092% (5734/11680)\n",
      "Epoch 5 Step 365/1563 Loss: 1.416 | Acc: 49.095% (5750/11712)\n",
      "Epoch 5 Step 366/1563 Loss: 1.417 | Acc: 49.080% (5764/11744)\n",
      "Epoch 5 Step 367/1563 Loss: 1.417 | Acc: 49.066% (5778/11776)\n",
      "Epoch 5 Step 368/1563 Loss: 1.417 | Acc: 49.051% (5792/11808)\n",
      "Epoch 5 Step 369/1563 Loss: 1.417 | Acc: 49.046% (5807/11840)\n",
      "Epoch 5 Step 370/1563 Loss: 1.416 | Acc: 49.073% (5826/11872)\n",
      "Epoch 5 Step 371/1563 Loss: 1.416 | Acc: 49.084% (5843/11904)\n",
      "Epoch 5 Step 372/1563 Loss: 1.416 | Acc: 49.078% (5858/11936)\n",
      "Epoch 5 Step 373/1563 Loss: 1.416 | Acc: 49.089% (5875/11968)\n",
      "Epoch 5 Step 374/1563 Loss: 1.416 | Acc: 49.100% (5892/12000)\n",
      "Epoch 5 Step 375/1563 Loss: 1.416 | Acc: 49.094% (5907/12032)\n",
      "Epoch 5 Step 376/1563 Loss: 1.416 | Acc: 49.055% (5918/12064)\n",
      "Epoch 5 Step 377/1563 Loss: 1.417 | Acc: 48.991% (5926/12096)\n",
      "Epoch 5 Step 378/1563 Loss: 1.418 | Acc: 48.986% (5941/12128)\n",
      "Epoch 5 Step 379/1563 Loss: 1.418 | Acc: 48.947% (5952/12160)\n",
      "Epoch 5 Step 380/1563 Loss: 1.418 | Acc: 48.942% (5967/12192)\n",
      "Epoch 5 Step 381/1563 Loss: 1.419 | Acc: 48.928% (5981/12224)\n",
      "Epoch 5 Step 382/1563 Loss: 1.419 | Acc: 48.898% (5993/12256)\n",
      "Epoch 5 Step 383/1563 Loss: 1.419 | Acc: 48.885% (6007/12288)\n",
      "Epoch 5 Step 384/1563 Loss: 1.418 | Acc: 48.896% (6024/12320)\n",
      "Epoch 5 Step 385/1563 Loss: 1.418 | Acc: 48.883% (6038/12352)\n",
      "Epoch 5 Step 386/1563 Loss: 1.418 | Acc: 48.878% (6053/12384)\n",
      "Epoch 5 Step 387/1563 Loss: 1.417 | Acc: 48.897% (6071/12416)\n",
      "Epoch 5 Step 388/1563 Loss: 1.417 | Acc: 48.891% (6086/12448)\n",
      "Epoch 5 Step 389/1563 Loss: 1.417 | Acc: 48.926% (6106/12480)\n",
      "Epoch 5 Step 390/1563 Loss: 1.417 | Acc: 48.953% (6125/12512)\n",
      "Epoch 5 Step 391/1563 Loss: 1.417 | Acc: 48.956% (6141/12544)\n",
      "Epoch 5 Step 392/1563 Loss: 1.417 | Acc: 48.950% (6156/12576)\n",
      "Epoch 5 Step 393/1563 Loss: 1.417 | Acc: 48.937% (6170/12608)\n",
      "Epoch 5 Step 394/1563 Loss: 1.417 | Acc: 48.948% (6187/12640)\n",
      "Epoch 5 Step 395/1563 Loss: 1.416 | Acc: 48.998% (6209/12672)\n",
      "Epoch 5 Step 396/1563 Loss: 1.417 | Acc: 48.985% (6223/12704)\n",
      "Epoch 5 Step 397/1563 Loss: 1.417 | Acc: 48.979% (6238/12736)\n",
      "Epoch 5 Step 398/1563 Loss: 1.417 | Acc: 48.974% (6253/12768)\n",
      "Epoch 5 Step 399/1563 Loss: 1.416 | Acc: 48.977% (6269/12800)\n",
      "Epoch 5 Step 400/1563 Loss: 1.418 | Acc: 48.909% (6276/12832)\n",
      "Epoch 5 Step 401/1563 Loss: 1.417 | Acc: 48.935% (6295/12864)\n",
      "Epoch 5 Step 402/1563 Loss: 1.418 | Acc: 48.914% (6308/12896)\n",
      "Epoch 5 Step 403/1563 Loss: 1.418 | Acc: 48.886% (6320/12928)\n",
      "Epoch 5 Step 404/1563 Loss: 1.419 | Acc: 48.866% (6333/12960)\n",
      "Epoch 5 Step 405/1563 Loss: 1.418 | Acc: 48.869% (6349/12992)\n",
      "Epoch 5 Step 406/1563 Loss: 1.418 | Acc: 48.856% (6363/13024)\n",
      "Epoch 5 Step 407/1563 Loss: 1.418 | Acc: 48.828% (6375/13056)\n",
      "Epoch 5 Step 408/1563 Loss: 1.418 | Acc: 48.854% (6394/13088)\n",
      "Epoch 5 Step 409/1563 Loss: 1.419 | Acc: 48.811% (6404/13120)\n",
      "Epoch 5 Step 410/1563 Loss: 1.418 | Acc: 48.806% (6419/13152)\n",
      "Epoch 5 Step 411/1563 Loss: 1.418 | Acc: 48.809% (6435/13184)\n",
      "Epoch 5 Step 412/1563 Loss: 1.417 | Acc: 48.850% (6456/13216)\n",
      "Epoch 5 Step 413/1563 Loss: 1.417 | Acc: 48.860% (6473/13248)\n",
      "Epoch 5 Step 414/1563 Loss: 1.416 | Acc: 48.870% (6490/13280)\n",
      "Epoch 5 Step 415/1563 Loss: 1.416 | Acc: 48.896% (6509/13312)\n",
      "Epoch 5 Step 416/1563 Loss: 1.417 | Acc: 48.883% (6523/13344)\n",
      "Epoch 5 Step 417/1563 Loss: 1.417 | Acc: 48.856% (6535/13376)\n",
      "Epoch 5 Step 418/1563 Loss: 1.417 | Acc: 48.837% (6548/13408)\n",
      "Epoch 5 Step 419/1563 Loss: 1.417 | Acc: 48.839% (6564/13440)\n",
      "Epoch 5 Step 420/1563 Loss: 1.416 | Acc: 48.842% (6580/13472)\n",
      "Epoch 5 Step 421/1563 Loss: 1.417 | Acc: 48.830% (6594/13504)\n",
      "Epoch 5 Step 422/1563 Loss: 1.417 | Acc: 48.855% (6613/13536)\n",
      "Epoch 5 Step 423/1563 Loss: 1.416 | Acc: 48.850% (6628/13568)\n",
      "Epoch 5 Step 424/1563 Loss: 1.416 | Acc: 48.875% (6647/13600)\n",
      "Epoch 5 Step 425/1563 Loss: 1.416 | Acc: 48.878% (6663/13632)\n",
      "Epoch 5 Step 426/1563 Loss: 1.417 | Acc: 48.873% (6678/13664)\n",
      "Epoch 5 Step 427/1563 Loss: 1.417 | Acc: 48.890% (6696/13696)\n",
      "Epoch 5 Step 428/1563 Loss: 1.417 | Acc: 48.893% (6712/13728)\n",
      "Epoch 5 Step 429/1563 Loss: 1.417 | Acc: 48.888% (6727/13760)\n",
      "Epoch 5 Step 430/1563 Loss: 1.417 | Acc: 48.883% (6742/13792)\n",
      "Epoch 5 Step 431/1563 Loss: 1.417 | Acc: 48.872% (6756/13824)\n",
      "Epoch 5 Step 432/1563 Loss: 1.416 | Acc: 48.903% (6776/13856)\n",
      "Epoch 5 Step 433/1563 Loss: 1.416 | Acc: 48.920% (6794/13888)\n",
      "Epoch 5 Step 434/1563 Loss: 1.416 | Acc: 48.937% (6812/13920)\n",
      "Epoch 5 Step 435/1563 Loss: 1.416 | Acc: 48.954% (6830/13952)\n",
      "Epoch 5 Step 436/1563 Loss: 1.417 | Acc: 48.934% (6843/13984)\n",
      "Epoch 5 Step 437/1563 Loss: 1.417 | Acc: 48.923% (6857/14016)\n",
      "Epoch 5 Step 438/1563 Loss: 1.417 | Acc: 48.918% (6872/14048)\n",
      "Epoch 5 Step 439/1563 Loss: 1.417 | Acc: 48.885% (6883/14080)\n",
      "Epoch 5 Step 440/1563 Loss: 1.417 | Acc: 48.880% (6898/14112)\n",
      "Epoch 5 Step 441/1563 Loss: 1.417 | Acc: 48.890% (6915/14144)\n",
      "Epoch 5 Step 442/1563 Loss: 1.417 | Acc: 48.871% (6928/14176)\n",
      "Epoch 5 Step 443/1563 Loss: 1.417 | Acc: 48.846% (6940/14208)\n",
      "Epoch 5 Step 444/1563 Loss: 1.417 | Acc: 48.876% (6960/14240)\n",
      "Epoch 5 Step 445/1563 Loss: 1.417 | Acc: 48.886% (6977/14272)\n",
      "Epoch 5 Step 446/1563 Loss: 1.417 | Acc: 48.916% (6997/14304)\n",
      "Epoch 5 Step 447/1563 Loss: 1.417 | Acc: 48.898% (7010/14336)\n",
      "Epoch 5 Step 448/1563 Loss: 1.417 | Acc: 48.907% (7027/14368)\n",
      "Epoch 5 Step 449/1563 Loss: 1.417 | Acc: 48.931% (7046/14400)\n",
      "Epoch 5 Step 450/1563 Loss: 1.417 | Acc: 48.905% (7058/14432)\n",
      "Epoch 5 Step 451/1563 Loss: 1.417 | Acc: 48.915% (7075/14464)\n",
      "Epoch 5 Step 452/1563 Loss: 1.417 | Acc: 48.945% (7095/14496)\n",
      "Epoch 5 Step 453/1563 Loss: 1.416 | Acc: 48.926% (7108/14528)\n",
      "Epoch 5 Step 454/1563 Loss: 1.416 | Acc: 48.922% (7123/14560)\n",
      "Epoch 5 Step 455/1563 Loss: 1.416 | Acc: 48.945% (7142/14592)\n",
      "Epoch 5 Step 456/1563 Loss: 1.416 | Acc: 48.933% (7156/14624)\n",
      "Epoch 5 Step 457/1563 Loss: 1.416 | Acc: 48.929% (7171/14656)\n",
      "Epoch 5 Step 458/1563 Loss: 1.416 | Acc: 48.938% (7188/14688)\n",
      "Epoch 5 Step 459/1563 Loss: 1.416 | Acc: 48.933% (7203/14720)\n",
      "Epoch 5 Step 460/1563 Loss: 1.416 | Acc: 48.956% (7222/14752)\n",
      "Epoch 5 Step 461/1563 Loss: 1.416 | Acc: 48.958% (7238/14784)\n",
      "Epoch 5 Step 462/1563 Loss: 1.416 | Acc: 48.981% (7257/14816)\n",
      "Epoch 5 Step 463/1563 Loss: 1.417 | Acc: 48.949% (7268/14848)\n",
      "Epoch 5 Step 464/1563 Loss: 1.416 | Acc: 48.965% (7286/14880)\n",
      "Epoch 5 Step 465/1563 Loss: 1.418 | Acc: 48.927% (7296/14912)\n",
      "Epoch 5 Step 466/1563 Loss: 1.417 | Acc: 48.936% (7313/14944)\n",
      "Epoch 5 Step 467/1563 Loss: 1.418 | Acc: 48.925% (7327/14976)\n",
      "Epoch 5 Step 468/1563 Loss: 1.418 | Acc: 48.934% (7344/15008)\n",
      "Epoch 5 Step 469/1563 Loss: 1.418 | Acc: 48.916% (7357/15040)\n",
      "Epoch 5 Step 470/1563 Loss: 1.418 | Acc: 48.912% (7372/15072)\n",
      "Epoch 5 Step 471/1563 Loss: 1.419 | Acc: 48.868% (7381/15104)\n",
      "Epoch 5 Step 472/1563 Loss: 1.419 | Acc: 48.877% (7398/15136)\n",
      "Epoch 5 Step 473/1563 Loss: 1.419 | Acc: 48.873% (7413/15168)\n",
      "Epoch 5 Step 474/1563 Loss: 1.420 | Acc: 48.855% (7426/15200)\n",
      "Epoch 5 Step 475/1563 Loss: 1.419 | Acc: 48.858% (7442/15232)\n",
      "Epoch 5 Step 476/1563 Loss: 1.420 | Acc: 48.834% (7454/15264)\n",
      "Epoch 5 Step 477/1563 Loss: 1.420 | Acc: 48.830% (7469/15296)\n",
      "Epoch 5 Step 478/1563 Loss: 1.421 | Acc: 48.832% (7485/15328)\n",
      "Epoch 5 Step 479/1563 Loss: 1.421 | Acc: 48.835% (7501/15360)\n",
      "Epoch 5 Step 480/1563 Loss: 1.421 | Acc: 48.837% (7517/15392)\n",
      "Epoch 5 Step 481/1563 Loss: 1.421 | Acc: 48.852% (7535/15424)\n",
      "Epoch 5 Step 482/1563 Loss: 1.421 | Acc: 48.861% (7552/15456)\n",
      "Epoch 5 Step 483/1563 Loss: 1.422 | Acc: 48.844% (7565/15488)\n",
      "Epoch 5 Step 484/1563 Loss: 1.422 | Acc: 48.821% (7577/15520)\n",
      "Epoch 5 Step 485/1563 Loss: 1.421 | Acc: 48.855% (7598/15552)\n",
      "Epoch 5 Step 486/1563 Loss: 1.421 | Acc: 48.851% (7613/15584)\n",
      "Epoch 5 Step 487/1563 Loss: 1.421 | Acc: 48.835% (7626/15616)\n",
      "Epoch 5 Step 488/1563 Loss: 1.421 | Acc: 48.818% (7639/15648)\n",
      "Epoch 5 Step 489/1563 Loss: 1.420 | Acc: 48.833% (7657/15680)\n",
      "Epoch 5 Step 490/1563 Loss: 1.419 | Acc: 48.873% (7679/15712)\n",
      "Epoch 5 Step 491/1563 Loss: 1.419 | Acc: 48.869% (7694/15744)\n",
      "Epoch 5 Step 492/1563 Loss: 1.419 | Acc: 48.891% (7713/15776)\n",
      "Epoch 5 Step 493/1563 Loss: 1.419 | Acc: 48.918% (7733/15808)\n",
      "Epoch 5 Step 494/1563 Loss: 1.419 | Acc: 48.895% (7745/15840)\n",
      "Epoch 5 Step 495/1563 Loss: 1.419 | Acc: 48.904% (7762/15872)\n",
      "Epoch 5 Step 496/1563 Loss: 1.419 | Acc: 48.919% (7780/15904)\n",
      "Epoch 5 Step 497/1563 Loss: 1.419 | Acc: 48.902% (7793/15936)\n",
      "Epoch 5 Step 498/1563 Loss: 1.419 | Acc: 48.885% (7806/15968)\n",
      "Epoch 5 Step 499/1563 Loss: 1.418 | Acc: 48.881% (7821/16000)\n",
      "Epoch 5 Step 500/1563 Loss: 1.419 | Acc: 48.852% (7832/16032)\n",
      "Epoch 5 Step 501/1563 Loss: 1.419 | Acc: 48.842% (7846/16064)\n",
      "Epoch 5 Step 502/1563 Loss: 1.418 | Acc: 48.851% (7863/16096)\n",
      "Epoch 5 Step 503/1563 Loss: 1.418 | Acc: 48.859% (7880/16128)\n",
      "Epoch 5 Step 504/1563 Loss: 1.419 | Acc: 48.837% (7892/16160)\n",
      "Epoch 5 Step 505/1563 Loss: 1.419 | Acc: 48.802% (7902/16192)\n",
      "Epoch 5 Step 506/1563 Loss: 1.419 | Acc: 48.810% (7919/16224)\n",
      "Epoch 5 Step 507/1563 Loss: 1.419 | Acc: 48.813% (7935/16256)\n",
      "Epoch 5 Step 508/1563 Loss: 1.420 | Acc: 48.797% (7948/16288)\n",
      "Epoch 5 Step 509/1563 Loss: 1.419 | Acc: 48.793% (7963/16320)\n",
      "Epoch 5 Step 510/1563 Loss: 1.419 | Acc: 48.814% (7982/16352)\n",
      "Epoch 5 Step 511/1563 Loss: 1.419 | Acc: 48.810% (7997/16384)\n",
      "Epoch 5 Step 512/1563 Loss: 1.419 | Acc: 48.830% (8016/16416)\n",
      "Epoch 5 Step 513/1563 Loss: 1.419 | Acc: 48.833% (8032/16448)\n",
      "Epoch 5 Step 514/1563 Loss: 1.419 | Acc: 48.792% (8041/16480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 515/1563 Loss: 1.419 | Acc: 48.795% (8057/16512)\n",
      "Epoch 5 Step 516/1563 Loss: 1.419 | Acc: 48.797% (8073/16544)\n",
      "Epoch 5 Step 517/1563 Loss: 1.419 | Acc: 48.793% (8088/16576)\n",
      "Epoch 5 Step 518/1563 Loss: 1.419 | Acc: 48.820% (8108/16608)\n",
      "Epoch 5 Step 519/1563 Loss: 1.419 | Acc: 48.828% (8125/16640)\n",
      "Epoch 5 Step 520/1563 Loss: 1.419 | Acc: 48.842% (8143/16672)\n",
      "Epoch 5 Step 521/1563 Loss: 1.419 | Acc: 48.845% (8159/16704)\n",
      "Epoch 5 Step 522/1563 Loss: 1.418 | Acc: 48.865% (8178/16736)\n",
      "Epoch 5 Step 523/1563 Loss: 1.418 | Acc: 48.861% (8193/16768)\n",
      "Epoch 5 Step 524/1563 Loss: 1.418 | Acc: 48.875% (8211/16800)\n",
      "Epoch 5 Step 525/1563 Loss: 1.418 | Acc: 48.871% (8226/16832)\n",
      "Epoch 5 Step 526/1563 Loss: 1.418 | Acc: 48.873% (8242/16864)\n",
      "Epoch 5 Step 527/1563 Loss: 1.418 | Acc: 48.864% (8256/16896)\n",
      "Epoch 5 Step 528/1563 Loss: 1.418 | Acc: 48.860% (8271/16928)\n",
      "Epoch 5 Step 529/1563 Loss: 1.418 | Acc: 48.880% (8290/16960)\n",
      "Epoch 5 Step 530/1563 Loss: 1.417 | Acc: 48.899% (8309/16992)\n",
      "Epoch 5 Step 531/1563 Loss: 1.418 | Acc: 48.902% (8325/17024)\n",
      "Epoch 5 Step 532/1563 Loss: 1.417 | Acc: 48.909% (8342/17056)\n",
      "Epoch 5 Step 533/1563 Loss: 1.418 | Acc: 48.923% (8360/17088)\n",
      "Epoch 5 Step 534/1563 Loss: 1.418 | Acc: 48.931% (8377/17120)\n",
      "Epoch 5 Step 535/1563 Loss: 1.418 | Acc: 48.939% (8394/17152)\n",
      "Epoch 5 Step 536/1563 Loss: 1.418 | Acc: 48.900% (8403/17184)\n",
      "Epoch 5 Step 537/1563 Loss: 1.417 | Acc: 48.937% (8425/17216)\n",
      "Epoch 5 Step 538/1563 Loss: 1.417 | Acc: 48.945% (8442/17248)\n",
      "Epoch 5 Step 539/1563 Loss: 1.418 | Acc: 48.924% (8454/17280)\n",
      "Epoch 5 Step 540/1563 Loss: 1.418 | Acc: 48.908% (8467/17312)\n",
      "Epoch 5 Step 541/1563 Loss: 1.418 | Acc: 48.928% (8486/17344)\n",
      "Epoch 5 Step 542/1563 Loss: 1.417 | Acc: 48.953% (8506/17376)\n",
      "Epoch 5 Step 543/1563 Loss: 1.417 | Acc: 48.955% (8522/17408)\n",
      "Epoch 5 Step 544/1563 Loss: 1.417 | Acc: 48.985% (8543/17440)\n",
      "Epoch 5 Step 545/1563 Loss: 1.417 | Acc: 48.970% (8556/17472)\n",
      "Epoch 5 Step 546/1563 Loss: 1.416 | Acc: 48.995% (8576/17504)\n",
      "Epoch 5 Step 547/1563 Loss: 1.416 | Acc: 49.013% (8595/17536)\n",
      "Epoch 5 Step 548/1563 Loss: 1.416 | Acc: 49.049% (8617/17568)\n",
      "Epoch 5 Step 549/1563 Loss: 1.417 | Acc: 49.028% (8629/17600)\n",
      "Epoch 5 Step 550/1563 Loss: 1.417 | Acc: 49.002% (8640/17632)\n",
      "Epoch 5 Step 551/1563 Loss: 1.417 | Acc: 49.009% (8657/17664)\n",
      "Epoch 5 Step 552/1563 Loss: 1.417 | Acc: 49.005% (8672/17696)\n",
      "Epoch 5 Step 553/1563 Loss: 1.417 | Acc: 48.990% (8685/17728)\n",
      "Epoch 5 Step 554/1563 Loss: 1.417 | Acc: 48.998% (8702/17760)\n",
      "Epoch 5 Step 555/1563 Loss: 1.418 | Acc: 48.988% (8716/17792)\n",
      "Epoch 5 Step 556/1563 Loss: 1.418 | Acc: 49.007% (8735/17824)\n",
      "Epoch 5 Step 557/1563 Loss: 1.418 | Acc: 48.975% (8745/17856)\n",
      "Epoch 5 Step 558/1563 Loss: 1.418 | Acc: 48.960% (8758/17888)\n",
      "Epoch 5 Step 559/1563 Loss: 1.418 | Acc: 48.979% (8777/17920)\n",
      "Epoch 5 Step 560/1563 Loss: 1.418 | Acc: 48.986% (8794/17952)\n",
      "Epoch 5 Step 561/1563 Loss: 1.418 | Acc: 48.999% (8812/17984)\n",
      "Epoch 5 Step 562/1563 Loss: 1.417 | Acc: 49.006% (8829/18016)\n",
      "Epoch 5 Step 563/1563 Loss: 1.417 | Acc: 49.025% (8848/18048)\n",
      "Epoch 5 Step 564/1563 Loss: 1.416 | Acc: 49.032% (8865/18080)\n",
      "Epoch 5 Step 565/1563 Loss: 1.416 | Acc: 49.056% (8885/18112)\n",
      "Epoch 5 Step 566/1563 Loss: 1.417 | Acc: 49.063% (8902/18144)\n",
      "Epoch 5 Step 567/1563 Loss: 1.416 | Acc: 49.059% (8917/18176)\n",
      "Epoch 5 Step 568/1563 Loss: 1.417 | Acc: 49.050% (8931/18208)\n",
      "Epoch 5 Step 569/1563 Loss: 1.417 | Acc: 49.024% (8942/18240)\n",
      "Epoch 5 Step 570/1563 Loss: 1.417 | Acc: 49.048% (8962/18272)\n",
      "Epoch 5 Step 571/1563 Loss: 1.417 | Acc: 49.038% (8976/18304)\n",
      "Epoch 5 Step 572/1563 Loss: 1.417 | Acc: 49.051% (8994/18336)\n",
      "Epoch 5 Step 573/1563 Loss: 1.417 | Acc: 49.069% (9013/18368)\n",
      "Epoch 5 Step 574/1563 Loss: 1.417 | Acc: 49.060% (9027/18400)\n",
      "Epoch 5 Step 575/1563 Loss: 1.417 | Acc: 49.072% (9045/18432)\n",
      "Epoch 5 Step 576/1563 Loss: 1.416 | Acc: 49.074% (9061/18464)\n",
      "Epoch 5 Step 577/1563 Loss: 1.416 | Acc: 49.070% (9076/18496)\n",
      "Epoch 5 Step 578/1563 Loss: 1.416 | Acc: 49.082% (9094/18528)\n",
      "Epoch 5 Step 579/1563 Loss: 1.416 | Acc: 49.100% (9113/18560)\n",
      "Epoch 5 Step 580/1563 Loss: 1.416 | Acc: 49.102% (9129/18592)\n",
      "Epoch 5 Step 581/1563 Loss: 1.415 | Acc: 49.109% (9146/18624)\n",
      "Epoch 5 Step 582/1563 Loss: 1.415 | Acc: 49.099% (9160/18656)\n",
      "Epoch 5 Step 583/1563 Loss: 1.416 | Acc: 49.085% (9173/18688)\n",
      "Epoch 5 Step 584/1563 Loss: 1.416 | Acc: 49.065% (9185/18720)\n",
      "Epoch 5 Step 585/1563 Loss: 1.416 | Acc: 49.045% (9197/18752)\n",
      "Epoch 5 Step 586/1563 Loss: 1.416 | Acc: 49.052% (9214/18784)\n",
      "Epoch 5 Step 587/1563 Loss: 1.416 | Acc: 49.033% (9226/18816)\n",
      "Epoch 5 Step 588/1563 Loss: 1.416 | Acc: 49.034% (9242/18848)\n",
      "Epoch 5 Step 589/1563 Loss: 1.416 | Acc: 49.015% (9254/18880)\n",
      "Epoch 5 Step 590/1563 Loss: 1.417 | Acc: 49.001% (9267/18912)\n",
      "Epoch 5 Step 591/1563 Loss: 1.417 | Acc: 48.986% (9280/18944)\n",
      "Epoch 5 Step 592/1563 Loss: 1.418 | Acc: 48.983% (9295/18976)\n",
      "Epoch 5 Step 593/1563 Loss: 1.418 | Acc: 48.974% (9309/19008)\n",
      "Epoch 5 Step 594/1563 Loss: 1.418 | Acc: 48.981% (9326/19040)\n",
      "Epoch 5 Step 595/1563 Loss: 1.418 | Acc: 48.983% (9342/19072)\n",
      "Epoch 5 Step 596/1563 Loss: 1.418 | Acc: 49.000% (9361/19104)\n",
      "Epoch 5 Step 597/1563 Loss: 1.417 | Acc: 49.023% (9381/19136)\n",
      "Epoch 5 Step 598/1563 Loss: 1.417 | Acc: 49.035% (9399/19168)\n",
      "Epoch 5 Step 599/1563 Loss: 1.417 | Acc: 49.042% (9416/19200)\n",
      "Epoch 5 Step 600/1563 Loss: 1.417 | Acc: 49.043% (9432/19232)\n",
      "Epoch 5 Step 601/1563 Loss: 1.417 | Acc: 49.045% (9448/19264)\n",
      "Epoch 5 Step 602/1563 Loss: 1.418 | Acc: 49.041% (9463/19296)\n",
      "Epoch 5 Step 603/1563 Loss: 1.417 | Acc: 49.064% (9483/19328)\n",
      "Epoch 5 Step 604/1563 Loss: 1.417 | Acc: 49.055% (9497/19360)\n",
      "Epoch 5 Step 605/1563 Loss: 1.417 | Acc: 49.067% (9515/19392)\n",
      "Epoch 5 Step 606/1563 Loss: 1.417 | Acc: 49.063% (9530/19424)\n",
      "Epoch 5 Step 607/1563 Loss: 1.417 | Acc: 49.065% (9546/19456)\n",
      "Epoch 5 Step 608/1563 Loss: 1.417 | Acc: 49.056% (9560/19488)\n",
      "Epoch 5 Step 609/1563 Loss: 1.417 | Acc: 49.047% (9574/19520)\n",
      "Epoch 5 Step 610/1563 Loss: 1.417 | Acc: 49.044% (9589/19552)\n",
      "Epoch 5 Step 611/1563 Loss: 1.417 | Acc: 49.050% (9606/19584)\n",
      "Epoch 5 Step 612/1563 Loss: 1.417 | Acc: 49.067% (9625/19616)\n",
      "Epoch 5 Step 613/1563 Loss: 1.417 | Acc: 49.089% (9645/19648)\n",
      "Epoch 5 Step 614/1563 Loss: 1.417 | Acc: 49.085% (9660/19680)\n",
      "Epoch 5 Step 615/1563 Loss: 1.417 | Acc: 49.087% (9676/19712)\n",
      "Epoch 5 Step 616/1563 Loss: 1.417 | Acc: 49.073% (9689/19744)\n",
      "Epoch 5 Step 617/1563 Loss: 1.417 | Acc: 49.085% (9707/19776)\n",
      "Epoch 5 Step 618/1563 Loss: 1.417 | Acc: 49.081% (9722/19808)\n",
      "Epoch 5 Step 619/1563 Loss: 1.417 | Acc: 49.078% (9737/19840)\n",
      "Epoch 5 Step 620/1563 Loss: 1.417 | Acc: 49.074% (9752/19872)\n",
      "Epoch 5 Step 621/1563 Loss: 1.417 | Acc: 49.081% (9769/19904)\n",
      "Epoch 5 Step 622/1563 Loss: 1.417 | Acc: 49.097% (9788/19936)\n",
      "Epoch 5 Step 623/1563 Loss: 1.417 | Acc: 49.094% (9803/19968)\n",
      "Epoch 5 Step 624/1563 Loss: 1.417 | Acc: 49.085% (9817/20000)\n",
      "Epoch 5 Step 625/1563 Loss: 1.417 | Acc: 49.076% (9831/20032)\n",
      "Epoch 5 Step 626/1563 Loss: 1.417 | Acc: 49.073% (9846/20064)\n",
      "Epoch 5 Step 627/1563 Loss: 1.417 | Acc: 49.084% (9864/20096)\n",
      "Epoch 5 Step 628/1563 Loss: 1.417 | Acc: 49.081% (9879/20128)\n",
      "Epoch 5 Step 629/1563 Loss: 1.417 | Acc: 49.077% (9894/20160)\n",
      "Epoch 5 Step 630/1563 Loss: 1.417 | Acc: 49.084% (9911/20192)\n",
      "Epoch 5 Step 631/1563 Loss: 1.417 | Acc: 49.080% (9926/20224)\n",
      "Epoch 5 Step 632/1563 Loss: 1.417 | Acc: 49.082% (9942/20256)\n",
      "Epoch 5 Step 633/1563 Loss: 1.416 | Acc: 49.088% (9959/20288)\n",
      "Epoch 5 Step 634/1563 Loss: 1.417 | Acc: 49.070% (9971/20320)\n",
      "Epoch 5 Step 635/1563 Loss: 1.416 | Acc: 49.076% (9988/20352)\n",
      "Epoch 5 Step 636/1563 Loss: 1.416 | Acc: 49.058% (10000/20384)\n",
      "Epoch 5 Step 637/1563 Loss: 1.416 | Acc: 49.069% (10018/20416)\n",
      "Epoch 5 Step 638/1563 Loss: 1.416 | Acc: 49.081% (10036/20448)\n",
      "Epoch 5 Step 639/1563 Loss: 1.416 | Acc: 49.097% (10055/20480)\n",
      "Epoch 5 Step 640/1563 Loss: 1.417 | Acc: 49.088% (10069/20512)\n",
      "Epoch 5 Step 641/1563 Loss: 1.417 | Acc: 49.090% (10085/20544)\n",
      "Epoch 5 Step 642/1563 Loss: 1.417 | Acc: 49.077% (10098/20576)\n",
      "Epoch 5 Step 643/1563 Loss: 1.417 | Acc: 49.068% (10112/20608)\n",
      "Epoch 5 Step 644/1563 Loss: 1.418 | Acc: 49.060% (10126/20640)\n",
      "Epoch 5 Step 645/1563 Loss: 1.417 | Acc: 49.110% (10152/20672)\n",
      "Epoch 5 Step 646/1563 Loss: 1.417 | Acc: 49.116% (10169/20704)\n",
      "Epoch 5 Step 647/1563 Loss: 1.418 | Acc: 49.093% (10180/20736)\n",
      "Epoch 5 Step 648/1563 Loss: 1.417 | Acc: 49.104% (10198/20768)\n",
      "Epoch 5 Step 649/1563 Loss: 1.417 | Acc: 49.101% (10213/20800)\n",
      "Epoch 5 Step 650/1563 Loss: 1.417 | Acc: 49.078% (10224/20832)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 651/1563 Loss: 1.417 | Acc: 49.080% (10240/20864)\n",
      "Epoch 5 Step 652/1563 Loss: 1.417 | Acc: 49.091% (10258/20896)\n",
      "Epoch 5 Step 653/1563 Loss: 1.417 | Acc: 49.106% (10277/20928)\n",
      "Epoch 5 Step 654/1563 Loss: 1.417 | Acc: 49.108% (10293/20960)\n",
      "Epoch 5 Step 655/1563 Loss: 1.417 | Acc: 49.090% (10305/20992)\n",
      "Epoch 5 Step 656/1563 Loss: 1.417 | Acc: 49.087% (10320/21024)\n",
      "Epoch 5 Step 657/1563 Loss: 1.417 | Acc: 49.083% (10335/21056)\n",
      "Epoch 5 Step 658/1563 Loss: 1.417 | Acc: 49.094% (10353/21088)\n",
      "Epoch 5 Step 659/1563 Loss: 1.417 | Acc: 49.081% (10366/21120)\n",
      "Epoch 5 Step 660/1563 Loss: 1.418 | Acc: 49.059% (10377/21152)\n",
      "Epoch 5 Step 661/1563 Loss: 1.417 | Acc: 49.061% (10393/21184)\n",
      "Epoch 5 Step 662/1563 Loss: 1.418 | Acc: 49.043% (10405/21216)\n",
      "Epoch 5 Step 663/1563 Loss: 1.418 | Acc: 49.045% (10421/21248)\n",
      "Epoch 5 Step 664/1563 Loss: 1.418 | Acc: 49.008% (10429/21280)\n",
      "Epoch 5 Step 665/1563 Loss: 1.418 | Acc: 49.010% (10445/21312)\n",
      "Epoch 5 Step 666/1563 Loss: 1.418 | Acc: 49.011% (10461/21344)\n",
      "Epoch 5 Step 667/1563 Loss: 1.418 | Acc: 49.027% (10480/21376)\n",
      "Epoch 5 Step 668/1563 Loss: 1.417 | Acc: 49.052% (10501/21408)\n",
      "Epoch 5 Step 669/1563 Loss: 1.417 | Acc: 49.058% (10518/21440)\n",
      "Epoch 5 Step 670/1563 Loss: 1.417 | Acc: 49.045% (10531/21472)\n",
      "Epoch 5 Step 671/1563 Loss: 1.417 | Acc: 49.033% (10544/21504)\n",
      "Epoch 5 Step 672/1563 Loss: 1.417 | Acc: 49.034% (10560/21536)\n",
      "Epoch 5 Step 673/1563 Loss: 1.418 | Acc: 49.026% (10574/21568)\n",
      "Epoch 5 Step 674/1563 Loss: 1.418 | Acc: 49.037% (10592/21600)\n",
      "Epoch 5 Step 675/1563 Loss: 1.418 | Acc: 49.020% (10604/21632)\n",
      "Epoch 5 Step 676/1563 Loss: 1.418 | Acc: 49.012% (10618/21664)\n",
      "Epoch 5 Step 677/1563 Loss: 1.419 | Acc: 49.009% (10633/21696)\n",
      "Epoch 5 Step 678/1563 Loss: 1.419 | Acc: 48.992% (10645/21728)\n",
      "Epoch 5 Step 679/1563 Loss: 1.419 | Acc: 49.012% (10665/21760)\n",
      "Epoch 5 Step 680/1563 Loss: 1.419 | Acc: 49.013% (10681/21792)\n",
      "Epoch 5 Step 681/1563 Loss: 1.418 | Acc: 49.038% (10702/21824)\n",
      "Epoch 5 Step 682/1563 Loss: 1.418 | Acc: 49.025% (10715/21856)\n",
      "Epoch 5 Step 683/1563 Loss: 1.418 | Acc: 49.022% (10730/21888)\n",
      "Epoch 5 Step 684/1563 Loss: 1.418 | Acc: 49.028% (10747/21920)\n",
      "Epoch 5 Step 685/1563 Loss: 1.418 | Acc: 49.034% (10764/21952)\n",
      "Epoch 5 Step 686/1563 Loss: 1.418 | Acc: 49.027% (10778/21984)\n",
      "Epoch 5 Step 687/1563 Loss: 1.419 | Acc: 48.996% (10787/22016)\n",
      "Epoch 5 Step 688/1563 Loss: 1.419 | Acc: 48.993% (10802/22048)\n",
      "Epoch 5 Step 689/1563 Loss: 1.419 | Acc: 48.995% (10818/22080)\n",
      "Epoch 5 Step 690/1563 Loss: 1.420 | Acc: 48.982% (10831/22112)\n",
      "Epoch 5 Step 691/1563 Loss: 1.420 | Acc: 48.984% (10847/22144)\n",
      "Epoch 5 Step 692/1563 Loss: 1.420 | Acc: 48.999% (10866/22176)\n",
      "Epoch 5 Step 693/1563 Loss: 1.420 | Acc: 48.996% (10881/22208)\n",
      "Epoch 5 Step 694/1563 Loss: 1.420 | Acc: 48.997% (10897/22240)\n",
      "Epoch 5 Step 695/1563 Loss: 1.420 | Acc: 48.994% (10912/22272)\n",
      "Epoch 5 Step 696/1563 Loss: 1.420 | Acc: 48.991% (10927/22304)\n",
      "Epoch 5 Step 697/1563 Loss: 1.420 | Acc: 49.006% (10946/22336)\n",
      "Epoch 5 Step 698/1563 Loss: 1.420 | Acc: 49.025% (10966/22368)\n",
      "Epoch 5 Step 699/1563 Loss: 1.420 | Acc: 49.018% (10980/22400)\n",
      "Epoch 5 Step 700/1563 Loss: 1.420 | Acc: 49.024% (10997/22432)\n",
      "Epoch 5 Step 701/1563 Loss: 1.420 | Acc: 49.016% (11011/22464)\n",
      "Epoch 5 Step 702/1563 Loss: 1.420 | Acc: 49.009% (11025/22496)\n",
      "Epoch 5 Step 703/1563 Loss: 1.420 | Acc: 49.015% (11042/22528)\n",
      "Epoch 5 Step 704/1563 Loss: 1.420 | Acc: 49.029% (11061/22560)\n",
      "Epoch 5 Step 705/1563 Loss: 1.420 | Acc: 49.035% (11078/22592)\n",
      "Epoch 5 Step 706/1563 Loss: 1.420 | Acc: 49.023% (11091/22624)\n",
      "Epoch 5 Step 707/1563 Loss: 1.420 | Acc: 49.038% (11110/22656)\n",
      "Epoch 5 Step 708/1563 Loss: 1.420 | Acc: 49.030% (11124/22688)\n",
      "Epoch 5 Step 709/1563 Loss: 1.420 | Acc: 49.023% (11138/22720)\n",
      "Epoch 5 Step 710/1563 Loss: 1.420 | Acc: 49.042% (11158/22752)\n",
      "Epoch 5 Step 711/1563 Loss: 1.420 | Acc: 49.039% (11173/22784)\n",
      "Epoch 5 Step 712/1563 Loss: 1.420 | Acc: 49.027% (11186/22816)\n",
      "Epoch 5 Step 713/1563 Loss: 1.420 | Acc: 49.028% (11202/22848)\n",
      "Epoch 5 Step 714/1563 Loss: 1.420 | Acc: 49.034% (11219/22880)\n",
      "Epoch 5 Step 715/1563 Loss: 1.420 | Acc: 49.014% (11230/22912)\n",
      "Epoch 5 Step 716/1563 Loss: 1.420 | Acc: 49.028% (11249/22944)\n",
      "Epoch 5 Step 717/1563 Loss: 1.420 | Acc: 49.047% (11269/22976)\n",
      "Epoch 5 Step 718/1563 Loss: 1.420 | Acc: 49.053% (11286/23008)\n",
      "Epoch 5 Step 719/1563 Loss: 1.419 | Acc: 49.058% (11303/23040)\n",
      "Epoch 5 Step 720/1563 Loss: 1.419 | Acc: 49.090% (11326/23072)\n",
      "Epoch 5 Step 721/1563 Loss: 1.419 | Acc: 49.082% (11340/23104)\n",
      "Epoch 5 Step 722/1563 Loss: 1.419 | Acc: 49.071% (11353/23136)\n",
      "Epoch 5 Step 723/1563 Loss: 1.419 | Acc: 49.089% (11373/23168)\n",
      "Epoch 5 Step 724/1563 Loss: 1.419 | Acc: 49.103% (11392/23200)\n",
      "Epoch 5 Step 725/1563 Loss: 1.419 | Acc: 49.105% (11408/23232)\n",
      "Epoch 5 Step 726/1563 Loss: 1.419 | Acc: 49.106% (11424/23264)\n",
      "Epoch 5 Step 727/1563 Loss: 1.419 | Acc: 49.111% (11441/23296)\n",
      "Epoch 5 Step 728/1563 Loss: 1.419 | Acc: 49.096% (11453/23328)\n",
      "Epoch 5 Step 729/1563 Loss: 1.419 | Acc: 49.118% (11474/23360)\n",
      "Epoch 5 Step 730/1563 Loss: 1.418 | Acc: 49.132% (11493/23392)\n",
      "Epoch 5 Step 731/1563 Loss: 1.418 | Acc: 49.142% (11511/23424)\n",
      "Epoch 5 Step 732/1563 Loss: 1.418 | Acc: 49.135% (11525/23456)\n",
      "Epoch 5 Step 733/1563 Loss: 1.418 | Acc: 49.131% (11540/23488)\n",
      "Epoch 5 Step 734/1563 Loss: 1.418 | Acc: 49.124% (11554/23520)\n",
      "Epoch 5 Step 735/1563 Loss: 1.418 | Acc: 49.121% (11569/23552)\n",
      "Epoch 5 Step 736/1563 Loss: 1.418 | Acc: 49.127% (11586/23584)\n",
      "Epoch 5 Step 737/1563 Loss: 1.418 | Acc: 49.128% (11602/23616)\n",
      "Epoch 5 Step 738/1563 Loss: 1.418 | Acc: 49.116% (11615/23648)\n",
      "Epoch 5 Step 739/1563 Loss: 1.418 | Acc: 49.101% (11627/23680)\n",
      "Epoch 5 Step 740/1563 Loss: 1.418 | Acc: 49.148% (11654/23712)\n",
      "Epoch 5 Step 741/1563 Loss: 1.418 | Acc: 49.145% (11669/23744)\n",
      "Epoch 5 Step 742/1563 Loss: 1.418 | Acc: 49.138% (11683/23776)\n",
      "Epoch 5 Step 743/1563 Loss: 1.418 | Acc: 49.139% (11699/23808)\n",
      "Epoch 5 Step 744/1563 Loss: 1.418 | Acc: 49.148% (11717/23840)\n",
      "Epoch 5 Step 745/1563 Loss: 1.418 | Acc: 49.162% (11736/23872)\n",
      "Epoch 5 Step 746/1563 Loss: 1.418 | Acc: 49.134% (11745/23904)\n",
      "Epoch 5 Step 747/1563 Loss: 1.418 | Acc: 49.144% (11763/23936)\n",
      "Epoch 5 Step 748/1563 Loss: 1.418 | Acc: 49.170% (11785/23968)\n",
      "Epoch 5 Step 749/1563 Loss: 1.418 | Acc: 49.167% (11800/24000)\n",
      "Epoch 5 Step 750/1563 Loss: 1.418 | Acc: 49.159% (11814/24032)\n",
      "Epoch 5 Step 751/1563 Loss: 1.419 | Acc: 49.148% (11827/24064)\n",
      "Epoch 5 Step 752/1563 Loss: 1.419 | Acc: 49.149% (11843/24096)\n",
      "Epoch 5 Step 753/1563 Loss: 1.419 | Acc: 49.142% (11857/24128)\n",
      "Epoch 5 Step 754/1563 Loss: 1.419 | Acc: 49.151% (11875/24160)\n",
      "Epoch 5 Step 755/1563 Loss: 1.419 | Acc: 49.153% (11891/24192)\n",
      "Epoch 5 Step 756/1563 Loss: 1.419 | Acc: 49.129% (11901/24224)\n",
      "Epoch 5 Step 757/1563 Loss: 1.419 | Acc: 49.114% (11913/24256)\n",
      "Epoch 5 Step 758/1563 Loss: 1.420 | Acc: 49.098% (11925/24288)\n",
      "Epoch 5 Step 759/1563 Loss: 1.420 | Acc: 49.095% (11940/24320)\n",
      "Epoch 5 Step 760/1563 Loss: 1.420 | Acc: 49.101% (11957/24352)\n",
      "Epoch 5 Step 761/1563 Loss: 1.420 | Acc: 49.094% (11971/24384)\n",
      "Epoch 5 Step 762/1563 Loss: 1.421 | Acc: 49.087% (11985/24416)\n",
      "Epoch 5 Step 763/1563 Loss: 1.420 | Acc: 49.104% (12005/24448)\n",
      "Epoch 5 Step 764/1563 Loss: 1.420 | Acc: 49.105% (12021/24480)\n",
      "Epoch 5 Step 765/1563 Loss: 1.420 | Acc: 49.102% (12036/24512)\n",
      "Epoch 5 Step 766/1563 Loss: 1.420 | Acc: 49.104% (12052/24544)\n",
      "Epoch 5 Step 767/1563 Loss: 1.420 | Acc: 49.109% (12069/24576)\n",
      "Epoch 5 Step 768/1563 Loss: 1.420 | Acc: 49.106% (12084/24608)\n",
      "Epoch 5 Step 769/1563 Loss: 1.420 | Acc: 49.107% (12100/24640)\n",
      "Epoch 5 Step 770/1563 Loss: 1.420 | Acc: 49.088% (12111/24672)\n",
      "Epoch 5 Step 771/1563 Loss: 1.420 | Acc: 49.069% (12122/24704)\n",
      "Epoch 5 Step 772/1563 Loss: 1.420 | Acc: 49.054% (12134/24736)\n",
      "Epoch 5 Step 773/1563 Loss: 1.420 | Acc: 49.043% (12147/24768)\n",
      "Epoch 5 Step 774/1563 Loss: 1.421 | Acc: 49.032% (12160/24800)\n",
      "Epoch 5 Step 775/1563 Loss: 1.420 | Acc: 49.062% (12183/24832)\n",
      "Epoch 5 Step 776/1563 Loss: 1.420 | Acc: 49.063% (12199/24864)\n",
      "Epoch 5 Step 777/1563 Loss: 1.420 | Acc: 49.056% (12213/24896)\n",
      "Epoch 5 Step 778/1563 Loss: 1.420 | Acc: 49.061% (12230/24928)\n",
      "Epoch 5 Step 779/1563 Loss: 1.420 | Acc: 49.062% (12246/24960)\n",
      "Epoch 5 Step 780/1563 Loss: 1.419 | Acc: 49.068% (12263/24992)\n",
      "Epoch 5 Step 781/1563 Loss: 1.420 | Acc: 49.061% (12277/25024)\n",
      "Epoch 5 Step 782/1563 Loss: 1.420 | Acc: 49.066% (12294/25056)\n",
      "Epoch 5 Step 783/1563 Loss: 1.420 | Acc: 49.071% (12311/25088)\n",
      "Epoch 5 Step 784/1563 Loss: 1.420 | Acc: 49.053% (12322/25120)\n",
      "Epoch 5 Step 785/1563 Loss: 1.419 | Acc: 49.062% (12340/25152)\n",
      "Epoch 5 Step 786/1563 Loss: 1.419 | Acc: 49.091% (12363/25184)\n",
      "Epoch 5 Step 787/1563 Loss: 1.419 | Acc: 49.084% (12377/25216)\n",
      "Epoch 5 Step 788/1563 Loss: 1.419 | Acc: 49.085% (12393/25248)\n",
      "Epoch 5 Step 789/1563 Loss: 1.419 | Acc: 49.102% (12413/25280)\n",
      "Epoch 5 Step 790/1563 Loss: 1.419 | Acc: 49.087% (12425/25312)\n",
      "Epoch 5 Step 791/1563 Loss: 1.419 | Acc: 49.077% (12438/25344)\n",
      "Epoch 5 Step 792/1563 Loss: 1.419 | Acc: 49.086% (12456/25376)\n",
      "Epoch 5 Step 793/1563 Loss: 1.418 | Acc: 49.099% (12475/25408)\n",
      "Epoch 5 Step 794/1563 Loss: 1.419 | Acc: 49.096% (12490/25440)\n",
      "Epoch 5 Step 795/1563 Loss: 1.418 | Acc: 49.101% (12507/25472)\n",
      "Epoch 5 Step 796/1563 Loss: 1.418 | Acc: 49.098% (12522/25504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 797/1563 Loss: 1.418 | Acc: 49.099% (12538/25536)\n",
      "Epoch 5 Step 798/1563 Loss: 1.419 | Acc: 49.089% (12551/25568)\n",
      "Epoch 5 Step 799/1563 Loss: 1.419 | Acc: 49.098% (12569/25600)\n",
      "Epoch 5 Step 800/1563 Loss: 1.419 | Acc: 49.110% (12588/25632)\n",
      "Epoch 5 Step 801/1563 Loss: 1.419 | Acc: 49.108% (12603/25664)\n",
      "Epoch 5 Step 802/1563 Loss: 1.419 | Acc: 49.117% (12621/25696)\n",
      "Epoch 5 Step 803/1563 Loss: 1.419 | Acc: 49.125% (12639/25728)\n",
      "Epoch 5 Step 804/1563 Loss: 1.419 | Acc: 49.119% (12653/25760)\n",
      "Epoch 5 Step 805/1563 Loss: 1.419 | Acc: 49.108% (12666/25792)\n",
      "Epoch 5 Step 806/1563 Loss: 1.420 | Acc: 49.102% (12680/25824)\n",
      "Epoch 5 Step 807/1563 Loss: 1.420 | Acc: 49.091% (12693/25856)\n",
      "Epoch 5 Step 808/1563 Loss: 1.420 | Acc: 49.069% (12703/25888)\n",
      "Epoch 5 Step 809/1563 Loss: 1.420 | Acc: 49.082% (12722/25920)\n",
      "Epoch 5 Step 810/1563 Loss: 1.420 | Acc: 49.094% (12741/25952)\n",
      "Epoch 5 Step 811/1563 Loss: 1.419 | Acc: 49.096% (12757/25984)\n",
      "Epoch 5 Step 812/1563 Loss: 1.420 | Acc: 49.081% (12769/26016)\n",
      "Epoch 5 Step 813/1563 Loss: 1.419 | Acc: 49.105% (12791/26048)\n",
      "Epoch 5 Step 814/1563 Loss: 1.419 | Acc: 49.114% (12809/26080)\n",
      "Epoch 5 Step 815/1563 Loss: 1.419 | Acc: 49.108% (12823/26112)\n",
      "Epoch 5 Step 816/1563 Loss: 1.419 | Acc: 49.097% (12836/26144)\n",
      "Epoch 5 Step 817/1563 Loss: 1.419 | Acc: 49.102% (12853/26176)\n",
      "Epoch 5 Step 818/1563 Loss: 1.419 | Acc: 49.103% (12869/26208)\n",
      "Epoch 5 Step 819/1563 Loss: 1.419 | Acc: 49.108% (12886/26240)\n",
      "Epoch 5 Step 820/1563 Loss: 1.419 | Acc: 49.102% (12900/26272)\n",
      "Epoch 5 Step 821/1563 Loss: 1.418 | Acc: 49.137% (12925/26304)\n",
      "Epoch 5 Step 822/1563 Loss: 1.418 | Acc: 49.142% (12942/26336)\n",
      "Epoch 5 Step 823/1563 Loss: 1.418 | Acc: 49.147% (12959/26368)\n",
      "Epoch 5 Step 824/1563 Loss: 1.418 | Acc: 49.144% (12974/26400)\n",
      "Epoch 5 Step 825/1563 Loss: 1.418 | Acc: 49.130% (12986/26432)\n",
      "Epoch 5 Step 826/1563 Loss: 1.418 | Acc: 49.120% (12999/26464)\n",
      "Epoch 5 Step 827/1563 Loss: 1.418 | Acc: 49.128% (13017/26496)\n",
      "Epoch 5 Step 828/1563 Loss: 1.418 | Acc: 49.144% (13037/26528)\n",
      "Epoch 5 Step 829/1563 Loss: 1.418 | Acc: 49.142% (13052/26560)\n",
      "Epoch 5 Step 830/1563 Loss: 1.418 | Acc: 49.128% (13064/26592)\n",
      "Epoch 5 Step 831/1563 Loss: 1.418 | Acc: 49.140% (13083/26624)\n",
      "Epoch 5 Step 832/1563 Loss: 1.418 | Acc: 49.141% (13099/26656)\n",
      "Epoch 5 Step 833/1563 Loss: 1.418 | Acc: 49.138% (13114/26688)\n",
      "Epoch 5 Step 834/1563 Loss: 1.418 | Acc: 49.135% (13129/26720)\n",
      "Epoch 5 Step 835/1563 Loss: 1.418 | Acc: 49.129% (13143/26752)\n",
      "Epoch 5 Step 836/1563 Loss: 1.418 | Acc: 49.130% (13159/26784)\n",
      "Epoch 5 Step 837/1563 Loss: 1.418 | Acc: 49.139% (13177/26816)\n",
      "Epoch 5 Step 838/1563 Loss: 1.417 | Acc: 49.136% (13192/26848)\n",
      "Epoch 5 Step 839/1563 Loss: 1.418 | Acc: 49.126% (13205/26880)\n",
      "Epoch 5 Step 840/1563 Loss: 1.418 | Acc: 49.127% (13221/26912)\n",
      "Epoch 5 Step 841/1563 Loss: 1.418 | Acc: 49.139% (13240/26944)\n",
      "Epoch 5 Step 842/1563 Loss: 1.418 | Acc: 49.133% (13254/26976)\n",
      "Epoch 5 Step 843/1563 Loss: 1.418 | Acc: 49.126% (13268/27008)\n",
      "Epoch 5 Step 844/1563 Loss: 1.418 | Acc: 49.120% (13282/27040)\n",
      "Epoch 5 Step 845/1563 Loss: 1.418 | Acc: 49.110% (13295/27072)\n",
      "Epoch 5 Step 846/1563 Loss: 1.418 | Acc: 49.129% (13316/27104)\n",
      "Epoch 5 Step 847/1563 Loss: 1.418 | Acc: 49.112% (13327/27136)\n",
      "Epoch 5 Step 848/1563 Loss: 1.418 | Acc: 49.128% (13347/27168)\n",
      "Epoch 5 Step 849/1563 Loss: 1.418 | Acc: 49.132% (13364/27200)\n",
      "Epoch 5 Step 850/1563 Loss: 1.418 | Acc: 49.115% (13375/27232)\n",
      "Epoch 5 Step 851/1563 Loss: 1.419 | Acc: 49.105% (13388/27264)\n",
      "Epoch 5 Step 852/1563 Loss: 1.418 | Acc: 49.110% (13405/27296)\n",
      "Epoch 5 Step 853/1563 Loss: 1.418 | Acc: 49.118% (13423/27328)\n",
      "Epoch 5 Step 854/1563 Loss: 1.418 | Acc: 49.112% (13437/27360)\n",
      "Epoch 5 Step 855/1563 Loss: 1.418 | Acc: 49.113% (13453/27392)\n",
      "Epoch 5 Step 856/1563 Loss: 1.418 | Acc: 49.132% (13474/27424)\n",
      "Epoch 5 Step 857/1563 Loss: 1.418 | Acc: 49.137% (13491/27456)\n",
      "Epoch 5 Step 858/1563 Loss: 1.418 | Acc: 49.131% (13505/27488)\n",
      "Epoch 5 Step 859/1563 Loss: 1.418 | Acc: 49.132% (13521/27520)\n",
      "Epoch 5 Step 860/1563 Loss: 1.418 | Acc: 49.129% (13536/27552)\n",
      "Epoch 5 Step 861/1563 Loss: 1.418 | Acc: 49.134% (13553/27584)\n",
      "Epoch 5 Step 862/1563 Loss: 1.419 | Acc: 49.135% (13569/27616)\n",
      "Epoch 5 Step 863/1563 Loss: 1.419 | Acc: 49.132% (13584/27648)\n",
      "Epoch 5 Step 864/1563 Loss: 1.419 | Acc: 49.140% (13602/27680)\n",
      "Epoch 5 Step 865/1563 Loss: 1.419 | Acc: 49.127% (13614/27712)\n",
      "Epoch 5 Step 866/1563 Loss: 1.419 | Acc: 49.128% (13630/27744)\n",
      "Epoch 5 Step 867/1563 Loss: 1.419 | Acc: 49.118% (13643/27776)\n",
      "Epoch 5 Step 868/1563 Loss: 1.419 | Acc: 49.097% (13653/27808)\n",
      "Epoch 5 Step 869/1563 Loss: 1.419 | Acc: 49.088% (13666/27840)\n",
      "Epoch 5 Step 870/1563 Loss: 1.419 | Acc: 49.089% (13682/27872)\n",
      "Epoch 5 Step 871/1563 Loss: 1.419 | Acc: 49.086% (13697/27904)\n",
      "Epoch 5 Step 872/1563 Loss: 1.419 | Acc: 49.087% (13713/27936)\n",
      "Epoch 5 Step 873/1563 Loss: 1.419 | Acc: 49.088% (13729/27968)\n",
      "Epoch 5 Step 874/1563 Loss: 1.419 | Acc: 49.107% (13750/28000)\n",
      "Epoch 5 Step 875/1563 Loss: 1.419 | Acc: 49.119% (13769/28032)\n",
      "Epoch 5 Step 876/1563 Loss: 1.419 | Acc: 49.109% (13782/28064)\n",
      "Epoch 5 Step 877/1563 Loss: 1.419 | Acc: 49.132% (13804/28096)\n",
      "Epoch 5 Step 878/1563 Loss: 1.419 | Acc: 49.125% (13818/28128)\n",
      "Epoch 5 Step 879/1563 Loss: 1.419 | Acc: 49.130% (13835/28160)\n",
      "Epoch 5 Step 880/1563 Loss: 1.419 | Acc: 49.131% (13851/28192)\n",
      "Epoch 5 Step 881/1563 Loss: 1.419 | Acc: 49.125% (13865/28224)\n",
      "Epoch 5 Step 882/1563 Loss: 1.419 | Acc: 49.136% (13884/28256)\n",
      "Epoch 5 Step 883/1563 Loss: 1.419 | Acc: 49.127% (13897/28288)\n",
      "Epoch 5 Step 884/1563 Loss: 1.419 | Acc: 49.117% (13910/28320)\n",
      "Epoch 5 Step 885/1563 Loss: 1.419 | Acc: 49.111% (13924/28352)\n",
      "Epoch 5 Step 886/1563 Loss: 1.419 | Acc: 49.098% (13936/28384)\n",
      "Epoch 5 Step 887/1563 Loss: 1.419 | Acc: 49.099% (13952/28416)\n",
      "Epoch 5 Step 888/1563 Loss: 1.419 | Acc: 49.104% (13969/28448)\n",
      "Epoch 5 Step 889/1563 Loss: 1.418 | Acc: 49.105% (13985/28480)\n",
      "Epoch 5 Step 890/1563 Loss: 1.419 | Acc: 49.102% (14000/28512)\n",
      "Epoch 5 Step 891/1563 Loss: 1.418 | Acc: 49.128% (14023/28544)\n",
      "Epoch 5 Step 892/1563 Loss: 1.418 | Acc: 49.129% (14039/28576)\n",
      "Epoch 5 Step 893/1563 Loss: 1.418 | Acc: 49.144% (14059/28608)\n",
      "Epoch 5 Step 894/1563 Loss: 1.418 | Acc: 49.148% (14076/28640)\n",
      "Epoch 5 Step 895/1563 Loss: 1.418 | Acc: 49.142% (14090/28672)\n",
      "Epoch 5 Step 896/1563 Loss: 1.418 | Acc: 49.146% (14107/28704)\n",
      "Epoch 5 Step 897/1563 Loss: 1.418 | Acc: 49.154% (14125/28736)\n",
      "Epoch 5 Step 898/1563 Loss: 1.418 | Acc: 49.131% (14134/28768)\n",
      "Epoch 5 Step 899/1563 Loss: 1.418 | Acc: 49.146% (14154/28800)\n",
      "Epoch 5 Step 900/1563 Loss: 1.418 | Acc: 49.136% (14167/28832)\n",
      "Epoch 5 Step 901/1563 Loss: 1.418 | Acc: 49.127% (14180/28864)\n",
      "Epoch 5 Step 902/1563 Loss: 1.418 | Acc: 49.131% (14197/28896)\n",
      "Epoch 5 Step 903/1563 Loss: 1.418 | Acc: 49.129% (14212/28928)\n",
      "Epoch 5 Step 904/1563 Loss: 1.418 | Acc: 49.123% (14226/28960)\n",
      "Epoch 5 Step 905/1563 Loss: 1.418 | Acc: 49.138% (14246/28992)\n",
      "Epoch 5 Step 906/1563 Loss: 1.418 | Acc: 49.152% (14266/29024)\n",
      "Epoch 5 Step 907/1563 Loss: 1.418 | Acc: 49.153% (14282/29056)\n",
      "Epoch 5 Step 908/1563 Loss: 1.418 | Acc: 49.154% (14298/29088)\n",
      "Epoch 5 Step 909/1563 Loss: 1.418 | Acc: 49.159% (14315/29120)\n",
      "Epoch 5 Step 910/1563 Loss: 1.418 | Acc: 49.149% (14328/29152)\n",
      "Epoch 5 Step 911/1563 Loss: 1.418 | Acc: 49.167% (14349/29184)\n",
      "Epoch 5 Step 912/1563 Loss: 1.418 | Acc: 49.148% (14359/29216)\n",
      "Epoch 5 Step 913/1563 Loss: 1.418 | Acc: 49.138% (14372/29248)\n",
      "Epoch 5 Step 914/1563 Loss: 1.418 | Acc: 49.150% (14391/29280)\n",
      "Epoch 5 Step 915/1563 Loss: 1.418 | Acc: 49.137% (14403/29312)\n",
      "Epoch 5 Step 916/1563 Loss: 1.418 | Acc: 49.124% (14415/29344)\n",
      "Epoch 5 Step 917/1563 Loss: 1.419 | Acc: 49.108% (14426/29376)\n",
      "Epoch 5 Step 918/1563 Loss: 1.418 | Acc: 49.123% (14446/29408)\n",
      "Epoch 5 Step 919/1563 Loss: 1.419 | Acc: 49.124% (14462/29440)\n",
      "Epoch 5 Step 920/1563 Loss: 1.418 | Acc: 49.148% (14485/29472)\n",
      "Epoch 5 Step 921/1563 Loss: 1.418 | Acc: 49.153% (14502/29504)\n",
      "Epoch 5 Step 922/1563 Loss: 1.418 | Acc: 49.167% (14522/29536)\n",
      "Epoch 5 Step 923/1563 Loss: 1.418 | Acc: 49.182% (14542/29568)\n",
      "Epoch 5 Step 924/1563 Loss: 1.418 | Acc: 49.162% (14552/29600)\n",
      "Epoch 5 Step 925/1563 Loss: 1.418 | Acc: 49.173% (14571/29632)\n",
      "Epoch 5 Step 926/1563 Loss: 1.418 | Acc: 49.171% (14586/29664)\n",
      "Epoch 5 Step 927/1563 Loss: 1.418 | Acc: 49.158% (14598/29696)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 928/1563 Loss: 1.418 | Acc: 49.162% (14615/29728)\n",
      "Epoch 5 Step 929/1563 Loss: 1.418 | Acc: 49.170% (14633/29760)\n",
      "Epoch 5 Step 930/1563 Loss: 1.418 | Acc: 49.171% (14649/29792)\n",
      "Epoch 5 Step 931/1563 Loss: 1.418 | Acc: 49.168% (14664/29824)\n",
      "Epoch 5 Step 932/1563 Loss: 1.419 | Acc: 49.159% (14677/29856)\n",
      "Epoch 5 Step 933/1563 Loss: 1.419 | Acc: 49.157% (14692/29888)\n",
      "Epoch 5 Step 934/1563 Loss: 1.418 | Acc: 49.171% (14712/29920)\n",
      "Epoch 5 Step 935/1563 Loss: 1.418 | Acc: 49.165% (14726/29952)\n",
      "Epoch 5 Step 936/1563 Loss: 1.418 | Acc: 49.156% (14739/29984)\n",
      "Epoch 5 Step 937/1563 Loss: 1.418 | Acc: 49.164% (14757/30016)\n",
      "Epoch 5 Step 938/1563 Loss: 1.418 | Acc: 49.161% (14772/30048)\n",
      "Epoch 5 Step 939/1563 Loss: 1.418 | Acc: 49.162% (14788/30080)\n",
      "Epoch 5 Step 940/1563 Loss: 1.418 | Acc: 49.170% (14806/30112)\n",
      "Epoch 5 Step 941/1563 Loss: 1.418 | Acc: 49.167% (14821/30144)\n",
      "Epoch 5 Step 942/1563 Loss: 1.418 | Acc: 49.168% (14837/30176)\n",
      "Epoch 5 Step 943/1563 Loss: 1.418 | Acc: 49.172% (14854/30208)\n",
      "Epoch 5 Step 944/1563 Loss: 1.418 | Acc: 49.177% (14871/30240)\n",
      "Epoch 5 Step 945/1563 Loss: 1.418 | Acc: 49.174% (14886/30272)\n",
      "Epoch 5 Step 946/1563 Loss: 1.418 | Acc: 49.168% (14900/30304)\n",
      "Epoch 5 Step 947/1563 Loss: 1.418 | Acc: 49.153% (14911/30336)\n",
      "Epoch 5 Step 948/1563 Loss: 1.418 | Acc: 49.134% (14921/30368)\n",
      "Epoch 5 Step 949/1563 Loss: 1.418 | Acc: 49.125% (14934/30400)\n",
      "Epoch 5 Step 950/1563 Loss: 1.418 | Acc: 49.123% (14949/30432)\n",
      "Epoch 5 Step 951/1563 Loss: 1.418 | Acc: 49.143% (14971/30464)\n",
      "Epoch 5 Step 952/1563 Loss: 1.418 | Acc: 49.138% (14985/30496)\n",
      "Epoch 5 Step 953/1563 Loss: 1.418 | Acc: 49.142% (15002/30528)\n",
      "Epoch 5 Step 954/1563 Loss: 1.418 | Acc: 49.133% (15015/30560)\n",
      "Epoch 5 Step 955/1563 Loss: 1.418 | Acc: 49.124% (15028/30592)\n",
      "Epoch 5 Step 956/1563 Loss: 1.418 | Acc: 49.122% (15043/30624)\n",
      "Epoch 5 Step 957/1563 Loss: 1.418 | Acc: 49.123% (15059/30656)\n",
      "Epoch 5 Step 958/1563 Loss: 1.418 | Acc: 49.123% (15075/30688)\n",
      "Epoch 5 Step 959/1563 Loss: 1.418 | Acc: 49.111% (15087/30720)\n",
      "Epoch 5 Step 960/1563 Loss: 1.418 | Acc: 49.119% (15105/30752)\n",
      "Epoch 5 Step 961/1563 Loss: 1.418 | Acc: 49.103% (15116/30784)\n",
      "Epoch 5 Step 962/1563 Loss: 1.418 | Acc: 49.117% (15136/30816)\n",
      "Epoch 5 Step 963/1563 Loss: 1.418 | Acc: 49.131% (15156/30848)\n",
      "Epoch 5 Step 964/1563 Loss: 1.418 | Acc: 49.126% (15170/30880)\n",
      "Epoch 5 Step 965/1563 Loss: 1.418 | Acc: 49.127% (15186/30912)\n",
      "Epoch 5 Step 966/1563 Loss: 1.417 | Acc: 49.124% (15201/30944)\n",
      "Epoch 5 Step 967/1563 Loss: 1.418 | Acc: 49.112% (15213/30976)\n",
      "Epoch 5 Step 968/1563 Loss: 1.417 | Acc: 49.129% (15234/31008)\n",
      "Epoch 5 Step 969/1563 Loss: 1.417 | Acc: 49.114% (15245/31040)\n",
      "Epoch 5 Step 970/1563 Loss: 1.417 | Acc: 49.115% (15261/31072)\n",
      "Epoch 5 Step 971/1563 Loss: 1.418 | Acc: 49.093% (15270/31104)\n",
      "Epoch 5 Step 972/1563 Loss: 1.418 | Acc: 49.081% (15282/31136)\n",
      "Epoch 5 Step 973/1563 Loss: 1.418 | Acc: 49.092% (15301/31168)\n",
      "Epoch 5 Step 974/1563 Loss: 1.417 | Acc: 49.093% (15317/31200)\n",
      "Epoch 5 Step 975/1563 Loss: 1.418 | Acc: 49.100% (15335/31232)\n",
      "Epoch 5 Step 976/1563 Loss: 1.418 | Acc: 49.095% (15349/31264)\n",
      "Epoch 5 Step 977/1563 Loss: 1.418 | Acc: 49.096% (15365/31296)\n",
      "Epoch 5 Step 978/1563 Loss: 1.417 | Acc: 49.100% (15382/31328)\n",
      "Epoch 5 Step 979/1563 Loss: 1.417 | Acc: 49.114% (15402/31360)\n",
      "Epoch 5 Step 980/1563 Loss: 1.417 | Acc: 49.114% (15418/31392)\n",
      "Epoch 5 Step 981/1563 Loss: 1.417 | Acc: 49.112% (15433/31424)\n",
      "Epoch 5 Step 982/1563 Loss: 1.417 | Acc: 49.113% (15449/31456)\n",
      "Epoch 5 Step 983/1563 Loss: 1.417 | Acc: 49.127% (15469/31488)\n",
      "Epoch 5 Step 984/1563 Loss: 1.417 | Acc: 49.134% (15487/31520)\n",
      "Epoch 5 Step 985/1563 Loss: 1.417 | Acc: 49.128% (15501/31552)\n",
      "Epoch 5 Step 986/1563 Loss: 1.417 | Acc: 49.123% (15515/31584)\n",
      "Epoch 5 Step 987/1563 Loss: 1.417 | Acc: 49.130% (15533/31616)\n",
      "Epoch 5 Step 988/1563 Loss: 1.418 | Acc: 49.122% (15546/31648)\n",
      "Epoch 5 Step 989/1563 Loss: 1.418 | Acc: 49.119% (15561/31680)\n",
      "Epoch 5 Step 990/1563 Loss: 1.418 | Acc: 49.117% (15576/31712)\n",
      "Epoch 5 Step 991/1563 Loss: 1.417 | Acc: 49.134% (15597/31744)\n",
      "Epoch 5 Step 992/1563 Loss: 1.417 | Acc: 49.144% (15616/31776)\n",
      "Epoch 5 Step 993/1563 Loss: 1.417 | Acc: 49.148% (15633/31808)\n",
      "Epoch 5 Step 994/1563 Loss: 1.417 | Acc: 49.136% (15645/31840)\n",
      "Epoch 5 Step 995/1563 Loss: 1.417 | Acc: 49.143% (15663/31872)\n",
      "Epoch 5 Step 996/1563 Loss: 1.418 | Acc: 49.119% (15671/31904)\n",
      "Epoch 5 Step 997/1563 Loss: 1.418 | Acc: 49.111% (15684/31936)\n",
      "Epoch 5 Step 998/1563 Loss: 1.418 | Acc: 49.118% (15702/31968)\n",
      "Epoch 5 Step 999/1563 Loss: 1.418 | Acc: 49.112% (15716/32000)\n",
      "Epoch 5 Step 1000/1563 Loss: 1.418 | Acc: 49.123% (15735/32032)\n",
      "Epoch 5 Step 1001/1563 Loss: 1.417 | Acc: 49.136% (15755/32064)\n",
      "Epoch 5 Step 1002/1563 Loss: 1.418 | Acc: 49.134% (15770/32096)\n",
      "Epoch 5 Step 1003/1563 Loss: 1.418 | Acc: 49.138% (15787/32128)\n",
      "Epoch 5 Step 1004/1563 Loss: 1.418 | Acc: 49.136% (15802/32160)\n",
      "Epoch 5 Step 1005/1563 Loss: 1.418 | Acc: 49.140% (15819/32192)\n",
      "Epoch 5 Step 1006/1563 Loss: 1.418 | Acc: 49.143% (15836/32224)\n",
      "Epoch 5 Step 1007/1563 Loss: 1.417 | Acc: 49.151% (15854/32256)\n",
      "Epoch 5 Step 1008/1563 Loss: 1.418 | Acc: 49.145% (15868/32288)\n",
      "Epoch 5 Step 1009/1563 Loss: 1.417 | Acc: 49.158% (15888/32320)\n",
      "Epoch 5 Step 1010/1563 Loss: 1.417 | Acc: 49.162% (15905/32352)\n",
      "Epoch 5 Step 1011/1563 Loss: 1.417 | Acc: 49.157% (15919/32384)\n",
      "Epoch 5 Step 1012/1563 Loss: 1.417 | Acc: 49.149% (15932/32416)\n",
      "Epoch 5 Step 1013/1563 Loss: 1.417 | Acc: 49.162% (15952/32448)\n",
      "Epoch 5 Step 1014/1563 Loss: 1.417 | Acc: 49.163% (15968/32480)\n",
      "Epoch 5 Step 1015/1563 Loss: 1.417 | Acc: 49.148% (15979/32512)\n",
      "Epoch 5 Step 1016/1563 Loss: 1.417 | Acc: 49.155% (15997/32544)\n",
      "Epoch 5 Step 1017/1563 Loss: 1.417 | Acc: 49.162% (16015/32576)\n",
      "Epoch 5 Step 1018/1563 Loss: 1.417 | Acc: 49.157% (16029/32608)\n",
      "Epoch 5 Step 1019/1563 Loss: 1.417 | Acc: 49.142% (16040/32640)\n",
      "Epoch 5 Step 1020/1563 Loss: 1.417 | Acc: 49.149% (16058/32672)\n",
      "Epoch 5 Step 1021/1563 Loss: 1.417 | Acc: 49.165% (16079/32704)\n",
      "Epoch 5 Step 1022/1563 Loss: 1.417 | Acc: 49.166% (16095/32736)\n",
      "Epoch 5 Step 1023/1563 Loss: 1.417 | Acc: 49.152% (16106/32768)\n",
      "Epoch 5 Step 1024/1563 Loss: 1.417 | Acc: 49.162% (16125/32800)\n",
      "Epoch 5 Step 1025/1563 Loss: 1.417 | Acc: 49.175% (16145/32832)\n",
      "Epoch 5 Step 1026/1563 Loss: 1.418 | Acc: 49.157% (16155/32864)\n",
      "Epoch 5 Step 1027/1563 Loss: 1.418 | Acc: 49.149% (16168/32896)\n",
      "Epoch 5 Step 1028/1563 Loss: 1.418 | Acc: 49.150% (16184/32928)\n",
      "Epoch 5 Step 1029/1563 Loss: 1.418 | Acc: 49.141% (16197/32960)\n",
      "Epoch 5 Step 1030/1563 Loss: 1.418 | Acc: 49.127% (16208/32992)\n",
      "Epoch 5 Step 1031/1563 Loss: 1.419 | Acc: 49.122% (16222/33024)\n",
      "Epoch 5 Step 1032/1563 Loss: 1.419 | Acc: 49.120% (16237/33056)\n",
      "Epoch 5 Step 1033/1563 Loss: 1.419 | Acc: 49.118% (16252/33088)\n",
      "Epoch 5 Step 1034/1563 Loss: 1.419 | Acc: 49.097% (16261/33120)\n",
      "Epoch 5 Step 1035/1563 Loss: 1.420 | Acc: 49.074% (16269/33152)\n",
      "Epoch 5 Step 1036/1563 Loss: 1.420 | Acc: 49.072% (16284/33184)\n",
      "Epoch 5 Step 1037/1563 Loss: 1.419 | Acc: 49.076% (16301/33216)\n",
      "Epoch 5 Step 1038/1563 Loss: 1.419 | Acc: 49.074% (16316/33248)\n",
      "Epoch 5 Step 1039/1563 Loss: 1.419 | Acc: 49.078% (16333/33280)\n",
      "Epoch 5 Step 1040/1563 Loss: 1.419 | Acc: 49.081% (16350/33312)\n",
      "Epoch 5 Step 1041/1563 Loss: 1.419 | Acc: 49.079% (16365/33344)\n",
      "Epoch 5 Step 1042/1563 Loss: 1.418 | Acc: 49.092% (16385/33376)\n",
      "Epoch 5 Step 1043/1563 Loss: 1.418 | Acc: 49.102% (16404/33408)\n",
      "Epoch 5 Step 1044/1563 Loss: 1.418 | Acc: 49.124% (16427/33440)\n",
      "Epoch 5 Step 1045/1563 Loss: 1.418 | Acc: 49.119% (16441/33472)\n",
      "Epoch 5 Step 1046/1563 Loss: 1.418 | Acc: 49.117% (16456/33504)\n",
      "Epoch 5 Step 1047/1563 Loss: 1.418 | Acc: 49.132% (16477/33536)\n",
      "Epoch 5 Step 1048/1563 Loss: 1.418 | Acc: 49.145% (16497/33568)\n",
      "Epoch 5 Step 1049/1563 Loss: 1.418 | Acc: 49.134% (16509/33600)\n",
      "Epoch 5 Step 1050/1563 Loss: 1.418 | Acc: 49.144% (16528/33632)\n",
      "Epoch 5 Step 1051/1563 Loss: 1.418 | Acc: 49.147% (16545/33664)\n",
      "Epoch 5 Step 1052/1563 Loss: 1.418 | Acc: 49.136% (16557/33696)\n",
      "Epoch 5 Step 1053/1563 Loss: 1.418 | Acc: 49.140% (16574/33728)\n",
      "Epoch 5 Step 1054/1563 Loss: 1.418 | Acc: 49.144% (16591/33760)\n",
      "Epoch 5 Step 1055/1563 Loss: 1.418 | Acc: 49.133% (16603/33792)\n",
      "Epoch 5 Step 1056/1563 Loss: 1.418 | Acc: 49.137% (16620/33824)\n",
      "Epoch 5 Step 1057/1563 Loss: 1.418 | Acc: 49.143% (16638/33856)\n",
      "Epoch 5 Step 1058/1563 Loss: 1.418 | Acc: 49.138% (16652/33888)\n",
      "Epoch 5 Step 1059/1563 Loss: 1.418 | Acc: 49.148% (16671/33920)\n",
      "Epoch 5 Step 1060/1563 Loss: 1.418 | Acc: 49.164% (16692/33952)\n",
      "Epoch 5 Step 1061/1563 Loss: 1.418 | Acc: 49.173% (16711/33984)\n",
      "Epoch 5 Step 1062/1563 Loss: 1.418 | Acc: 49.180% (16729/34016)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 1063/1563 Loss: 1.418 | Acc: 49.163% (16739/34048)\n",
      "Epoch 5 Step 1064/1563 Loss: 1.418 | Acc: 49.184% (16762/34080)\n",
      "Epoch 5 Step 1065/1563 Loss: 1.418 | Acc: 49.182% (16777/34112)\n",
      "Epoch 5 Step 1066/1563 Loss: 1.418 | Acc: 49.195% (16797/34144)\n",
      "Epoch 5 Step 1067/1563 Loss: 1.418 | Acc: 49.198% (16814/34176)\n",
      "Epoch 5 Step 1068/1563 Loss: 1.418 | Acc: 49.187% (16826/34208)\n",
      "Epoch 5 Step 1069/1563 Loss: 1.418 | Acc: 49.200% (16846/34240)\n",
      "Epoch 5 Step 1070/1563 Loss: 1.418 | Acc: 49.189% (16858/34272)\n",
      "Epoch 5 Step 1071/1563 Loss: 1.418 | Acc: 49.201% (16878/34304)\n",
      "Epoch 5 Step 1072/1563 Loss: 1.418 | Acc: 49.196% (16892/34336)\n",
      "Epoch 5 Step 1073/1563 Loss: 1.418 | Acc: 49.191% (16906/34368)\n",
      "Epoch 5 Step 1074/1563 Loss: 1.418 | Acc: 49.186% (16920/34400)\n",
      "Epoch 5 Step 1075/1563 Loss: 1.418 | Acc: 49.201% (16941/34432)\n",
      "Epoch 5 Step 1076/1563 Loss: 1.418 | Acc: 49.202% (16957/34464)\n",
      "Epoch 5 Step 1077/1563 Loss: 1.418 | Acc: 49.206% (16974/34496)\n",
      "Epoch 5 Step 1078/1563 Loss: 1.418 | Acc: 49.209% (16991/34528)\n",
      "Epoch 5 Step 1079/1563 Loss: 1.418 | Acc: 49.216% (17009/34560)\n",
      "Epoch 5 Step 1080/1563 Loss: 1.418 | Acc: 49.219% (17026/34592)\n",
      "Epoch 5 Step 1081/1563 Loss: 1.418 | Acc: 49.214% (17040/34624)\n",
      "Epoch 5 Step 1082/1563 Loss: 1.418 | Acc: 49.224% (17059/34656)\n",
      "Epoch 5 Step 1083/1563 Loss: 1.418 | Acc: 49.222% (17074/34688)\n",
      "Epoch 5 Step 1084/1563 Loss: 1.418 | Acc: 49.214% (17087/34720)\n",
      "Epoch 5 Step 1085/1563 Loss: 1.418 | Acc: 49.206% (17100/34752)\n",
      "Epoch 5 Step 1086/1563 Loss: 1.418 | Acc: 49.195% (17112/34784)\n",
      "Epoch 5 Step 1087/1563 Loss: 1.418 | Acc: 49.199% (17129/34816)\n",
      "Epoch 5 Step 1088/1563 Loss: 1.418 | Acc: 49.191% (17142/34848)\n",
      "Epoch 5 Step 1089/1563 Loss: 1.418 | Acc: 49.192% (17158/34880)\n",
      "Epoch 5 Step 1090/1563 Loss: 1.418 | Acc: 49.192% (17174/34912)\n",
      "Epoch 5 Step 1091/1563 Loss: 1.418 | Acc: 49.184% (17187/34944)\n",
      "Epoch 5 Step 1092/1563 Loss: 1.418 | Acc: 49.188% (17204/34976)\n",
      "Epoch 5 Step 1093/1563 Loss: 1.418 | Acc: 49.186% (17219/35008)\n",
      "Epoch 5 Step 1094/1563 Loss: 1.418 | Acc: 49.164% (17227/35040)\n",
      "Epoch 5 Step 1095/1563 Loss: 1.418 | Acc: 49.182% (17249/35072)\n",
      "Epoch 5 Step 1096/1563 Loss: 1.418 | Acc: 49.180% (17264/35104)\n",
      "Epoch 5 Step 1097/1563 Loss: 1.418 | Acc: 49.192% (17284/35136)\n",
      "Epoch 5 Step 1098/1563 Loss: 1.418 | Acc: 49.207% (17305/35168)\n",
      "Epoch 5 Step 1099/1563 Loss: 1.418 | Acc: 49.202% (17319/35200)\n",
      "Epoch 5 Step 1100/1563 Loss: 1.418 | Acc: 49.185% (17329/35232)\n",
      "Epoch 5 Step 1101/1563 Loss: 1.418 | Acc: 49.178% (17342/35264)\n",
      "Epoch 5 Step 1102/1563 Loss: 1.418 | Acc: 49.181% (17359/35296)\n",
      "Epoch 5 Step 1103/1563 Loss: 1.418 | Acc: 49.185% (17376/35328)\n",
      "Epoch 5 Step 1104/1563 Loss: 1.418 | Acc: 49.186% (17392/35360)\n",
      "Epoch 5 Step 1105/1563 Loss: 1.418 | Acc: 49.192% (17410/35392)\n",
      "Epoch 5 Step 1106/1563 Loss: 1.419 | Acc: 49.179% (17421/35424)\n",
      "Epoch 5 Step 1107/1563 Loss: 1.419 | Acc: 49.179% (17437/35456)\n",
      "Epoch 5 Step 1108/1563 Loss: 1.418 | Acc: 49.180% (17453/35488)\n",
      "Epoch 5 Step 1109/1563 Loss: 1.419 | Acc: 49.175% (17467/35520)\n",
      "Epoch 5 Step 1110/1563 Loss: 1.419 | Acc: 49.165% (17479/35552)\n",
      "Epoch 5 Step 1111/1563 Loss: 1.419 | Acc: 49.168% (17496/35584)\n",
      "Epoch 5 Step 1112/1563 Loss: 1.419 | Acc: 49.158% (17508/35616)\n",
      "Epoch 5 Step 1113/1563 Loss: 1.419 | Acc: 49.144% (17519/35648)\n",
      "Epoch 5 Step 1114/1563 Loss: 1.419 | Acc: 49.137% (17532/35680)\n",
      "Epoch 5 Step 1115/1563 Loss: 1.419 | Acc: 49.121% (17542/35712)\n",
      "Epoch 5 Step 1116/1563 Loss: 1.419 | Acc: 49.122% (17558/35744)\n",
      "Epoch 5 Step 1117/1563 Loss: 1.419 | Acc: 49.131% (17577/35776)\n",
      "Epoch 5 Step 1118/1563 Loss: 1.419 | Acc: 49.123% (17590/35808)\n",
      "Epoch 5 Step 1119/1563 Loss: 1.419 | Acc: 49.118% (17604/35840)\n",
      "Epoch 5 Step 1120/1563 Loss: 1.419 | Acc: 49.116% (17619/35872)\n",
      "Epoch 5 Step 1121/1563 Loss: 1.419 | Acc: 49.128% (17639/35904)\n",
      "Epoch 5 Step 1122/1563 Loss: 1.419 | Acc: 49.132% (17656/35936)\n",
      "Epoch 5 Step 1123/1563 Loss: 1.419 | Acc: 49.144% (17676/35968)\n",
      "Epoch 5 Step 1124/1563 Loss: 1.419 | Acc: 49.158% (17697/36000)\n",
      "Epoch 5 Step 1125/1563 Loss: 1.419 | Acc: 49.159% (17713/36032)\n",
      "Epoch 5 Step 1126/1563 Loss: 1.418 | Acc: 49.174% (17734/36064)\n",
      "Epoch 5 Step 1127/1563 Loss: 1.418 | Acc: 49.169% (17748/36096)\n",
      "Epoch 5 Step 1128/1563 Loss: 1.418 | Acc: 49.175% (17766/36128)\n",
      "Epoch 5 Step 1129/1563 Loss: 1.418 | Acc: 49.170% (17780/36160)\n",
      "Epoch 5 Step 1130/1563 Loss: 1.419 | Acc: 49.157% (17791/36192)\n",
      "Epoch 5 Step 1131/1563 Loss: 1.419 | Acc: 49.150% (17804/36224)\n",
      "Epoch 5 Step 1132/1563 Loss: 1.419 | Acc: 49.137% (17815/36256)\n",
      "Epoch 5 Step 1133/1563 Loss: 1.419 | Acc: 49.140% (17832/36288)\n",
      "Epoch 5 Step 1134/1563 Loss: 1.419 | Acc: 49.138% (17847/36320)\n",
      "Epoch 5 Step 1135/1563 Loss: 1.419 | Acc: 49.153% (17868/36352)\n",
      "Epoch 5 Step 1136/1563 Loss: 1.419 | Acc: 49.140% (17879/36384)\n",
      "Epoch 5 Step 1137/1563 Loss: 1.419 | Acc: 49.130% (17891/36416)\n",
      "Epoch 5 Step 1138/1563 Loss: 1.419 | Acc: 49.130% (17907/36448)\n",
      "Epoch 5 Step 1139/1563 Loss: 1.419 | Acc: 49.131% (17923/36480)\n",
      "Epoch 5 Step 1140/1563 Loss: 1.419 | Acc: 49.115% (17933/36512)\n",
      "Epoch 5 Step 1141/1563 Loss: 1.419 | Acc: 49.119% (17950/36544)\n",
      "Epoch 5 Step 1142/1563 Loss: 1.419 | Acc: 49.128% (17969/36576)\n",
      "Epoch 5 Step 1143/1563 Loss: 1.419 | Acc: 49.126% (17984/36608)\n",
      "Epoch 5 Step 1144/1563 Loss: 1.419 | Acc: 49.105% (17992/36640)\n",
      "Epoch 5 Step 1145/1563 Loss: 1.419 | Acc: 49.116% (18012/36672)\n",
      "Epoch 5 Step 1146/1563 Loss: 1.419 | Acc: 49.123% (18030/36704)\n",
      "Epoch 5 Step 1147/1563 Loss: 1.419 | Acc: 49.118% (18044/36736)\n",
      "Epoch 5 Step 1148/1563 Loss: 1.419 | Acc: 49.130% (18064/36768)\n",
      "Epoch 5 Step 1149/1563 Loss: 1.419 | Acc: 49.130% (18080/36800)\n",
      "Epoch 5 Step 1150/1563 Loss: 1.419 | Acc: 49.120% (18092/36832)\n",
      "Epoch 5 Step 1151/1563 Loss: 1.419 | Acc: 49.129% (18111/36864)\n",
      "Epoch 5 Step 1152/1563 Loss: 1.419 | Acc: 49.125% (18125/36896)\n",
      "Epoch 5 Step 1153/1563 Loss: 1.419 | Acc: 49.114% (18137/36928)\n",
      "Epoch 5 Step 1154/1563 Loss: 1.419 | Acc: 49.126% (18157/36960)\n",
      "Epoch 5 Step 1155/1563 Loss: 1.419 | Acc: 49.127% (18173/36992)\n",
      "Epoch 5 Step 1156/1563 Loss: 1.419 | Acc: 49.119% (18186/37024)\n",
      "Epoch 5 Step 1157/1563 Loss: 1.419 | Acc: 49.107% (18197/37056)\n",
      "Epoch 5 Step 1158/1563 Loss: 1.419 | Acc: 49.110% (18214/37088)\n",
      "Epoch 5 Step 1159/1563 Loss: 1.419 | Acc: 49.111% (18230/37120)\n",
      "Epoch 5 Step 1160/1563 Loss: 1.419 | Acc: 49.123% (18250/37152)\n",
      "Epoch 5 Step 1161/1563 Loss: 1.419 | Acc: 49.115% (18263/37184)\n",
      "Epoch 5 Step 1162/1563 Loss: 1.419 | Acc: 49.119% (18280/37216)\n",
      "Epoch 5 Step 1163/1563 Loss: 1.419 | Acc: 49.114% (18294/37248)\n",
      "Epoch 5 Step 1164/1563 Loss: 1.419 | Acc: 49.107% (18307/37280)\n",
      "Epoch 5 Step 1165/1563 Loss: 1.419 | Acc: 49.105% (18322/37312)\n",
      "Epoch 5 Step 1166/1563 Loss: 1.419 | Acc: 49.108% (18339/37344)\n",
      "Epoch 5 Step 1167/1563 Loss: 1.419 | Acc: 49.120% (18359/37376)\n",
      "Epoch 5 Step 1168/1563 Loss: 1.419 | Acc: 49.126% (18377/37408)\n",
      "Epoch 5 Step 1169/1563 Loss: 1.419 | Acc: 49.121% (18391/37440)\n",
      "Epoch 5 Step 1170/1563 Loss: 1.419 | Acc: 49.127% (18409/37472)\n",
      "Epoch 5 Step 1171/1563 Loss: 1.419 | Acc: 49.131% (18426/37504)\n",
      "Epoch 5 Step 1172/1563 Loss: 1.419 | Acc: 49.132% (18442/37536)\n",
      "Epoch 5 Step 1173/1563 Loss: 1.419 | Acc: 49.132% (18458/37568)\n",
      "Epoch 5 Step 1174/1563 Loss: 1.419 | Acc: 49.138% (18476/37600)\n",
      "Epoch 5 Step 1175/1563 Loss: 1.419 | Acc: 49.142% (18493/37632)\n",
      "Epoch 5 Step 1176/1563 Loss: 1.418 | Acc: 49.150% (18512/37664)\n",
      "Epoch 5 Step 1177/1563 Loss: 1.418 | Acc: 49.146% (18526/37696)\n",
      "Epoch 5 Step 1178/1563 Loss: 1.418 | Acc: 49.154% (18545/37728)\n",
      "Epoch 5 Step 1179/1563 Loss: 1.418 | Acc: 49.155% (18561/37760)\n",
      "Epoch 5 Step 1180/1563 Loss: 1.418 | Acc: 49.151% (18575/37792)\n",
      "Epoch 5 Step 1181/1563 Loss: 1.419 | Acc: 49.146% (18589/37824)\n",
      "Epoch 5 Step 1182/1563 Loss: 1.418 | Acc: 49.141% (18603/37856)\n",
      "Epoch 5 Step 1183/1563 Loss: 1.419 | Acc: 49.140% (18618/37888)\n",
      "Epoch 5 Step 1184/1563 Loss: 1.419 | Acc: 49.140% (18634/37920)\n",
      "Epoch 5 Step 1185/1563 Loss: 1.419 | Acc: 49.146% (18652/37952)\n",
      "Epoch 5 Step 1186/1563 Loss: 1.419 | Acc: 49.150% (18669/37984)\n",
      "Epoch 5 Step 1187/1563 Loss: 1.418 | Acc: 49.161% (18689/38016)\n",
      "Epoch 5 Step 1188/1563 Loss: 1.418 | Acc: 49.164% (18706/38048)\n",
      "Epoch 5 Step 1189/1563 Loss: 1.418 | Acc: 49.168% (18723/38080)\n",
      "Epoch 5 Step 1190/1563 Loss: 1.418 | Acc: 49.168% (18739/38112)\n",
      "Epoch 5 Step 1191/1563 Loss: 1.418 | Acc: 49.166% (18754/38144)\n",
      "Epoch 5 Step 1192/1563 Loss: 1.418 | Acc: 49.172% (18772/38176)\n",
      "Epoch 5 Step 1193/1563 Loss: 1.418 | Acc: 49.168% (18786/38208)\n",
      "Epoch 5 Step 1194/1563 Loss: 1.418 | Acc: 49.153% (18796/38240)\n",
      "Epoch 5 Step 1195/1563 Loss: 1.418 | Acc: 49.156% (18813/38272)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 1196/1563 Loss: 1.419 | Acc: 49.152% (18827/38304)\n",
      "Epoch 5 Step 1197/1563 Loss: 1.419 | Acc: 49.137% (18837/38336)\n",
      "Epoch 5 Step 1198/1563 Loss: 1.419 | Acc: 49.140% (18854/38368)\n",
      "Epoch 5 Step 1199/1563 Loss: 1.419 | Acc: 49.141% (18870/38400)\n",
      "Epoch 5 Step 1200/1563 Loss: 1.419 | Acc: 49.141% (18886/38432)\n",
      "Epoch 5 Step 1201/1563 Loss: 1.418 | Acc: 49.158% (18908/38464)\n",
      "Epoch 5 Step 1202/1563 Loss: 1.418 | Acc: 49.161% (18925/38496)\n",
      "Epoch 5 Step 1203/1563 Loss: 1.418 | Acc: 49.164% (18942/38528)\n",
      "Epoch 5 Step 1204/1563 Loss: 1.418 | Acc: 49.165% (18958/38560)\n",
      "Epoch 5 Step 1205/1563 Loss: 1.418 | Acc: 49.171% (18976/38592)\n",
      "Epoch 5 Step 1206/1563 Loss: 1.418 | Acc: 49.164% (18989/38624)\n",
      "Epoch 5 Step 1207/1563 Loss: 1.418 | Acc: 49.170% (19007/38656)\n",
      "Epoch 5 Step 1208/1563 Loss: 1.418 | Acc: 49.178% (19026/38688)\n",
      "Epoch 5 Step 1209/1563 Loss: 1.418 | Acc: 49.176% (19041/38720)\n",
      "Epoch 5 Step 1210/1563 Loss: 1.418 | Acc: 49.169% (19054/38752)\n",
      "Epoch 5 Step 1211/1563 Loss: 1.418 | Acc: 49.180% (19074/38784)\n",
      "Epoch 5 Step 1212/1563 Loss: 1.418 | Acc: 49.170% (19086/38816)\n",
      "Epoch 5 Step 1213/1563 Loss: 1.418 | Acc: 49.181% (19106/38848)\n",
      "Epoch 5 Step 1214/1563 Loss: 1.417 | Acc: 49.198% (19128/38880)\n",
      "Epoch 5 Step 1215/1563 Loss: 1.417 | Acc: 49.198% (19144/38912)\n",
      "Epoch 5 Step 1216/1563 Loss: 1.418 | Acc: 49.189% (19156/38944)\n",
      "Epoch 5 Step 1217/1563 Loss: 1.418 | Acc: 49.182% (19169/38976)\n",
      "Epoch 5 Step 1218/1563 Loss: 1.418 | Acc: 49.182% (19185/39008)\n",
      "Epoch 5 Step 1219/1563 Loss: 1.418 | Acc: 49.180% (19200/39040)\n",
      "Epoch 5 Step 1220/1563 Loss: 1.418 | Acc: 49.173% (19213/39072)\n",
      "Epoch 5 Step 1221/1563 Loss: 1.418 | Acc: 49.174% (19229/39104)\n",
      "Epoch 5 Step 1222/1563 Loss: 1.418 | Acc: 49.177% (19246/39136)\n",
      "Epoch 5 Step 1223/1563 Loss: 1.418 | Acc: 49.178% (19262/39168)\n",
      "Epoch 5 Step 1224/1563 Loss: 1.418 | Acc: 49.168% (19274/39200)\n",
      "Epoch 5 Step 1225/1563 Loss: 1.419 | Acc: 49.159% (19286/39232)\n",
      "Epoch 5 Step 1226/1563 Loss: 1.419 | Acc: 49.165% (19304/39264)\n",
      "Epoch 5 Step 1227/1563 Loss: 1.419 | Acc: 49.160% (19318/39296)\n",
      "Epoch 5 Step 1228/1563 Loss: 1.419 | Acc: 49.158% (19333/39328)\n",
      "Epoch 5 Step 1229/1563 Loss: 1.419 | Acc: 49.157% (19348/39360)\n",
      "Epoch 5 Step 1230/1563 Loss: 1.419 | Acc: 49.144% (19359/39392)\n",
      "Epoch 5 Step 1231/1563 Loss: 1.419 | Acc: 49.138% (19372/39424)\n",
      "Epoch 5 Step 1232/1563 Loss: 1.419 | Acc: 49.128% (19384/39456)\n",
      "Epoch 5 Step 1233/1563 Loss: 1.419 | Acc: 49.129% (19400/39488)\n",
      "Epoch 5 Step 1234/1563 Loss: 1.419 | Acc: 49.140% (19420/39520)\n",
      "Epoch 5 Step 1235/1563 Loss: 1.419 | Acc: 49.145% (19438/39552)\n",
      "Epoch 5 Step 1236/1563 Loss: 1.419 | Acc: 49.144% (19453/39584)\n",
      "Epoch 5 Step 1237/1563 Loss: 1.419 | Acc: 49.147% (19470/39616)\n",
      "Epoch 5 Step 1238/1563 Loss: 1.419 | Acc: 49.145% (19485/39648)\n",
      "Epoch 5 Step 1239/1563 Loss: 1.419 | Acc: 49.156% (19505/39680)\n",
      "Epoch 5 Step 1240/1563 Loss: 1.419 | Acc: 49.166% (19525/39712)\n",
      "Epoch 5 Step 1241/1563 Loss: 1.418 | Acc: 49.160% (19538/39744)\n",
      "Epoch 5 Step 1242/1563 Loss: 1.418 | Acc: 49.175% (19560/39776)\n",
      "Epoch 5 Step 1243/1563 Loss: 1.418 | Acc: 49.176% (19576/39808)\n",
      "Epoch 5 Step 1244/1563 Loss: 1.418 | Acc: 49.182% (19594/39840)\n",
      "Epoch 5 Step 1245/1563 Loss: 1.418 | Acc: 49.182% (19610/39872)\n",
      "Epoch 5 Step 1246/1563 Loss: 1.418 | Acc: 49.178% (19624/39904)\n",
      "Epoch 5 Step 1247/1563 Loss: 1.418 | Acc: 49.174% (19638/39936)\n",
      "Epoch 5 Step 1248/1563 Loss: 1.419 | Acc: 49.157% (19647/39968)\n",
      "Epoch 5 Step 1249/1563 Loss: 1.419 | Acc: 49.165% (19666/40000)\n",
      "Epoch 5 Step 1250/1563 Loss: 1.419 | Acc: 49.171% (19684/40032)\n",
      "Epoch 5 Step 1251/1563 Loss: 1.419 | Acc: 49.171% (19700/40064)\n",
      "Epoch 5 Step 1252/1563 Loss: 1.419 | Acc: 49.172% (19716/40096)\n",
      "Epoch 5 Step 1253/1563 Loss: 1.419 | Acc: 49.180% (19735/40128)\n",
      "Epoch 5 Step 1254/1563 Loss: 1.419 | Acc: 49.183% (19752/40160)\n",
      "Epoch 5 Step 1255/1563 Loss: 1.419 | Acc: 49.189% (19770/40192)\n",
      "Epoch 5 Step 1256/1563 Loss: 1.419 | Acc: 49.187% (19785/40224)\n",
      "Epoch 5 Step 1257/1563 Loss: 1.418 | Acc: 49.188% (19801/40256)\n",
      "Epoch 5 Step 1258/1563 Loss: 1.418 | Acc: 49.188% (19817/40288)\n",
      "Epoch 5 Step 1259/1563 Loss: 1.418 | Acc: 49.187% (19832/40320)\n",
      "Epoch 5 Step 1260/1563 Loss: 1.418 | Acc: 49.185% (19847/40352)\n",
      "Epoch 5 Step 1261/1563 Loss: 1.418 | Acc: 49.180% (19861/40384)\n",
      "Epoch 5 Step 1262/1563 Loss: 1.418 | Acc: 49.186% (19879/40416)\n",
      "Epoch 5 Step 1263/1563 Loss: 1.418 | Acc: 49.192% (19897/40448)\n",
      "Epoch 5 Step 1264/1563 Loss: 1.418 | Acc: 49.190% (19912/40480)\n",
      "Epoch 5 Step 1265/1563 Loss: 1.418 | Acc: 49.180% (19924/40512)\n",
      "Epoch 5 Step 1266/1563 Loss: 1.418 | Acc: 49.181% (19940/40544)\n",
      "Epoch 5 Step 1267/1563 Loss: 1.418 | Acc: 49.189% (19959/40576)\n",
      "Epoch 5 Step 1268/1563 Loss: 1.418 | Acc: 49.192% (19976/40608)\n",
      "Epoch 5 Step 1269/1563 Loss: 1.418 | Acc: 49.198% (19994/40640)\n",
      "Epoch 5 Step 1270/1563 Loss: 1.418 | Acc: 49.203% (20012/40672)\n",
      "Epoch 5 Step 1271/1563 Loss: 1.418 | Acc: 49.209% (20030/40704)\n",
      "Epoch 5 Step 1272/1563 Loss: 1.418 | Acc: 49.212% (20047/40736)\n",
      "Epoch 5 Step 1273/1563 Loss: 1.418 | Acc: 49.215% (20064/40768)\n",
      "Epoch 5 Step 1274/1563 Loss: 1.418 | Acc: 49.216% (20080/40800)\n",
      "Epoch 5 Step 1275/1563 Loss: 1.418 | Acc: 49.216% (20096/40832)\n",
      "Epoch 5 Step 1276/1563 Loss: 1.418 | Acc: 49.219% (20113/40864)\n",
      "Epoch 5 Step 1277/1563 Loss: 1.418 | Acc: 49.210% (20125/40896)\n",
      "Epoch 5 Step 1278/1563 Loss: 1.418 | Acc: 49.201% (20137/40928)\n",
      "Epoch 5 Step 1279/1563 Loss: 1.418 | Acc: 49.202% (20153/40960)\n",
      "Epoch 5 Step 1280/1563 Loss: 1.418 | Acc: 49.205% (20170/40992)\n",
      "Epoch 5 Step 1281/1563 Loss: 1.418 | Acc: 49.203% (20185/41024)\n",
      "Epoch 5 Step 1282/1563 Loss: 1.418 | Acc: 49.184% (20193/41056)\n",
      "Epoch 5 Step 1283/1563 Loss: 1.418 | Acc: 49.192% (20212/41088)\n",
      "Epoch 5 Step 1284/1563 Loss: 1.418 | Acc: 49.193% (20228/41120)\n",
      "Epoch 5 Step 1285/1563 Loss: 1.418 | Acc: 49.203% (20248/41152)\n",
      "Epoch 5 Step 1286/1563 Loss: 1.418 | Acc: 49.208% (20266/41184)\n",
      "Epoch 5 Step 1287/1563 Loss: 1.418 | Acc: 49.214% (20284/41216)\n",
      "Epoch 5 Step 1288/1563 Loss: 1.418 | Acc: 49.212% (20299/41248)\n",
      "Epoch 5 Step 1289/1563 Loss: 1.418 | Acc: 49.215% (20316/41280)\n",
      "Epoch 5 Step 1290/1563 Loss: 1.418 | Acc: 49.221% (20334/41312)\n",
      "Epoch 5 Step 1291/1563 Loss: 1.418 | Acc: 49.228% (20353/41344)\n",
      "Epoch 5 Step 1292/1563 Loss: 1.418 | Acc: 49.219% (20365/41376)\n",
      "Epoch 5 Step 1293/1563 Loss: 1.418 | Acc: 49.205% (20375/41408)\n",
      "Epoch 5 Step 1294/1563 Loss: 1.418 | Acc: 49.218% (20396/41440)\n",
      "Epoch 5 Step 1295/1563 Loss: 1.418 | Acc: 49.214% (20410/41472)\n",
      "Epoch 5 Step 1296/1563 Loss: 1.418 | Acc: 49.205% (20422/41504)\n",
      "Epoch 5 Step 1297/1563 Loss: 1.418 | Acc: 49.201% (20436/41536)\n",
      "Epoch 5 Step 1298/1563 Loss: 1.418 | Acc: 49.206% (20454/41568)\n",
      "Epoch 5 Step 1299/1563 Loss: 1.418 | Acc: 49.200% (20467/41600)\n",
      "Epoch 5 Step 1300/1563 Loss: 1.418 | Acc: 49.195% (20481/41632)\n",
      "Epoch 5 Step 1301/1563 Loss: 1.418 | Acc: 49.191% (20495/41664)\n",
      "Epoch 5 Step 1302/1563 Loss: 1.418 | Acc: 49.180% (20506/41696)\n",
      "Epoch 5 Step 1303/1563 Loss: 1.418 | Acc: 49.190% (20526/41728)\n",
      "Epoch 5 Step 1304/1563 Loss: 1.418 | Acc: 49.188% (20541/41760)\n",
      "Epoch 5 Step 1305/1563 Loss: 1.418 | Acc: 49.189% (20557/41792)\n",
      "Epoch 5 Step 1306/1563 Loss: 1.418 | Acc: 49.194% (20575/41824)\n",
      "Epoch 5 Step 1307/1563 Loss: 1.418 | Acc: 49.183% (20586/41856)\n",
      "Epoch 5 Step 1308/1563 Loss: 1.418 | Acc: 49.184% (20602/41888)\n",
      "Epoch 5 Step 1309/1563 Loss: 1.418 | Acc: 49.187% (20619/41920)\n",
      "Epoch 5 Step 1310/1563 Loss: 1.418 | Acc: 49.194% (20638/41952)\n",
      "Epoch 5 Step 1311/1563 Loss: 1.418 | Acc: 49.195% (20654/41984)\n",
      "Epoch 5 Step 1312/1563 Loss: 1.418 | Acc: 49.200% (20672/42016)\n",
      "Epoch 5 Step 1313/1563 Loss: 1.418 | Acc: 49.191% (20684/42048)\n",
      "Epoch 5 Step 1314/1563 Loss: 1.418 | Acc: 49.199% (20703/42080)\n",
      "Epoch 5 Step 1315/1563 Loss: 1.418 | Acc: 49.200% (20719/42112)\n",
      "Epoch 5 Step 1316/1563 Loss: 1.418 | Acc: 49.198% (20734/42144)\n",
      "Epoch 5 Step 1317/1563 Loss: 1.418 | Acc: 49.213% (20756/42176)\n",
      "Epoch 5 Step 1318/1563 Loss: 1.418 | Acc: 49.216% (20773/42208)\n",
      "Epoch 5 Step 1319/1563 Loss: 1.418 | Acc: 49.212% (20787/42240)\n",
      "Epoch 5 Step 1320/1563 Loss: 1.418 | Acc: 49.210% (20802/42272)\n",
      "Epoch 5 Step 1321/1563 Loss: 1.418 | Acc: 49.220% (20822/42304)\n",
      "Epoch 5 Step 1322/1563 Loss: 1.417 | Acc: 49.221% (20838/42336)\n",
      "Epoch 5 Step 1323/1563 Loss: 1.417 | Acc: 49.231% (20858/42368)\n",
      "Epoch 5 Step 1324/1563 Loss: 1.417 | Acc: 49.231% (20874/42400)\n",
      "Epoch 5 Step 1325/1563 Loss: 1.417 | Acc: 49.236% (20892/42432)\n",
      "Epoch 5 Step 1326/1563 Loss: 1.418 | Acc: 49.225% (20903/42464)\n",
      "Epoch 5 Step 1327/1563 Loss: 1.418 | Acc: 49.228% (20920/42496)\n",
      "Epoch 5 Step 1328/1563 Loss: 1.417 | Acc: 49.226% (20935/42528)\n",
      "Epoch 5 Step 1329/1563 Loss: 1.418 | Acc: 49.222% (20949/42560)\n",
      "Epoch 5 Step 1330/1563 Loss: 1.418 | Acc: 49.213% (20961/42592)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 1331/1563 Loss: 1.418 | Acc: 49.221% (20980/42624)\n",
      "Epoch 5 Step 1332/1563 Loss: 1.418 | Acc: 49.217% (20994/42656)\n",
      "Epoch 5 Step 1333/1563 Loss: 1.418 | Acc: 49.204% (21004/42688)\n",
      "Epoch 5 Step 1334/1563 Loss: 1.418 | Acc: 49.202% (21019/42720)\n",
      "Epoch 5 Step 1335/1563 Loss: 1.418 | Acc: 49.212% (21039/42752)\n",
      "Epoch 5 Step 1336/1563 Loss: 1.418 | Acc: 49.210% (21054/42784)\n",
      "Epoch 5 Step 1337/1563 Loss: 1.418 | Acc: 49.215% (21072/42816)\n",
      "Epoch 5 Step 1338/1563 Loss: 1.418 | Acc: 49.213% (21087/42848)\n",
      "Epoch 5 Step 1339/1563 Loss: 1.418 | Acc: 49.212% (21102/42880)\n",
      "Epoch 5 Step 1340/1563 Loss: 1.418 | Acc: 49.222% (21122/42912)\n",
      "Epoch 5 Step 1341/1563 Loss: 1.418 | Acc: 49.222% (21138/42944)\n",
      "Epoch 5 Step 1342/1563 Loss: 1.418 | Acc: 49.227% (21156/42976)\n",
      "Epoch 5 Step 1343/1563 Loss: 1.418 | Acc: 49.223% (21170/43008)\n",
      "Epoch 5 Step 1344/1563 Loss: 1.417 | Acc: 49.224% (21186/43040)\n",
      "Epoch 5 Step 1345/1563 Loss: 1.417 | Acc: 49.220% (21200/43072)\n",
      "Epoch 5 Step 1346/1563 Loss: 1.417 | Acc: 49.218% (21215/43104)\n",
      "Epoch 5 Step 1347/1563 Loss: 1.417 | Acc: 49.226% (21234/43136)\n",
      "Epoch 5 Step 1348/1563 Loss: 1.417 | Acc: 49.222% (21248/43168)\n",
      "Epoch 5 Step 1349/1563 Loss: 1.417 | Acc: 49.213% (21260/43200)\n",
      "Epoch 5 Step 1350/1563 Loss: 1.417 | Acc: 49.211% (21275/43232)\n",
      "Epoch 5 Step 1351/1563 Loss: 1.418 | Acc: 49.205% (21288/43264)\n",
      "Epoch 5 Step 1352/1563 Loss: 1.418 | Acc: 49.201% (21302/43296)\n",
      "Epoch 5 Step 1353/1563 Loss: 1.418 | Acc: 49.208% (21321/43328)\n",
      "Epoch 5 Step 1354/1563 Loss: 1.418 | Acc: 49.211% (21338/43360)\n",
      "Epoch 5 Step 1355/1563 Loss: 1.418 | Acc: 49.212% (21354/43392)\n",
      "Epoch 5 Step 1356/1563 Loss: 1.418 | Acc: 49.212% (21370/43424)\n",
      "Epoch 5 Step 1357/1563 Loss: 1.418 | Acc: 49.204% (21382/43456)\n",
      "Epoch 5 Step 1358/1563 Loss: 1.417 | Acc: 49.216% (21403/43488)\n",
      "Epoch 5 Step 1359/1563 Loss: 1.417 | Acc: 49.214% (21418/43520)\n",
      "Epoch 5 Step 1360/1563 Loss: 1.417 | Acc: 49.215% (21434/43552)\n",
      "Epoch 5 Step 1361/1563 Loss: 1.418 | Acc: 49.204% (21445/43584)\n",
      "Epoch 5 Step 1362/1563 Loss: 1.417 | Acc: 49.202% (21460/43616)\n",
      "Epoch 5 Step 1363/1563 Loss: 1.417 | Acc: 49.200% (21475/43648)\n",
      "Epoch 5 Step 1364/1563 Loss: 1.418 | Acc: 49.196% (21489/43680)\n",
      "Epoch 5 Step 1365/1563 Loss: 1.418 | Acc: 49.199% (21506/43712)\n",
      "Epoch 5 Step 1366/1563 Loss: 1.418 | Acc: 49.193% (21519/43744)\n",
      "Epoch 5 Step 1367/1563 Loss: 1.418 | Acc: 49.196% (21536/43776)\n",
      "Epoch 5 Step 1368/1563 Loss: 1.418 | Acc: 49.192% (21550/43808)\n",
      "Epoch 5 Step 1369/1563 Loss: 1.418 | Acc: 49.186% (21563/43840)\n",
      "Epoch 5 Step 1370/1563 Loss: 1.418 | Acc: 49.177% (21575/43872)\n",
      "Epoch 5 Step 1371/1563 Loss: 1.418 | Acc: 49.182% (21593/43904)\n",
      "Epoch 5 Step 1372/1563 Loss: 1.418 | Acc: 49.187% (21611/43936)\n",
      "Epoch 5 Step 1373/1563 Loss: 1.418 | Acc: 49.177% (21622/43968)\n",
      "Epoch 5 Step 1374/1563 Loss: 1.418 | Acc: 49.177% (21638/44000)\n",
      "Epoch 5 Step 1375/1563 Loss: 1.418 | Acc: 49.182% (21656/44032)\n",
      "Epoch 5 Step 1376/1563 Loss: 1.418 | Acc: 49.183% (21672/44064)\n",
      "Epoch 5 Step 1377/1563 Loss: 1.418 | Acc: 49.184% (21688/44096)\n",
      "Epoch 5 Step 1378/1563 Loss: 1.418 | Acc: 49.196% (21709/44128)\n",
      "Epoch 5 Step 1379/1563 Loss: 1.418 | Acc: 49.196% (21725/44160)\n",
      "Epoch 5 Step 1380/1563 Loss: 1.418 | Acc: 49.206% (21745/44192)\n",
      "Epoch 5 Step 1381/1563 Loss: 1.418 | Acc: 49.202% (21759/44224)\n",
      "Epoch 5 Step 1382/1563 Loss: 1.418 | Acc: 49.189% (21769/44256)\n",
      "Epoch 5 Step 1383/1563 Loss: 1.418 | Acc: 49.185% (21783/44288)\n",
      "Epoch 5 Step 1384/1563 Loss: 1.418 | Acc: 49.179% (21796/44320)\n",
      "Epoch 5 Step 1385/1563 Loss: 1.419 | Acc: 49.168% (21807/44352)\n",
      "Epoch 5 Step 1386/1563 Loss: 1.419 | Acc: 49.171% (21824/44384)\n",
      "Epoch 5 Step 1387/1563 Loss: 1.419 | Acc: 49.174% (21841/44416)\n",
      "Epoch 5 Step 1388/1563 Loss: 1.419 | Acc: 49.172% (21856/44448)\n",
      "Epoch 5 Step 1389/1563 Loss: 1.419 | Acc: 49.170% (21871/44480)\n",
      "Epoch 5 Step 1390/1563 Loss: 1.419 | Acc: 49.164% (21884/44512)\n",
      "Epoch 5 Step 1391/1563 Loss: 1.419 | Acc: 49.156% (21896/44544)\n",
      "Epoch 5 Step 1392/1563 Loss: 1.419 | Acc: 49.159% (21913/44576)\n",
      "Epoch 5 Step 1393/1563 Loss: 1.419 | Acc: 49.159% (21929/44608)\n",
      "Epoch 5 Step 1394/1563 Loss: 1.419 | Acc: 49.164% (21947/44640)\n",
      "Epoch 5 Step 1395/1563 Loss: 1.419 | Acc: 49.167% (21964/44672)\n",
      "Epoch 5 Step 1396/1563 Loss: 1.419 | Acc: 49.172% (21982/44704)\n",
      "Epoch 5 Step 1397/1563 Loss: 1.419 | Acc: 49.177% (22000/44736)\n",
      "Epoch 5 Step 1398/1563 Loss: 1.419 | Acc: 49.178% (22016/44768)\n",
      "Epoch 5 Step 1399/1563 Loss: 1.419 | Acc: 49.185% (22035/44800)\n",
      "Epoch 5 Step 1400/1563 Loss: 1.419 | Acc: 49.181% (22049/44832)\n",
      "Epoch 5 Step 1401/1563 Loss: 1.419 | Acc: 49.175% (22062/44864)\n",
      "Epoch 5 Step 1402/1563 Loss: 1.419 | Acc: 49.167% (22074/44896)\n",
      "Epoch 5 Step 1403/1563 Loss: 1.420 | Acc: 49.159% (22086/44928)\n",
      "Epoch 5 Step 1404/1563 Loss: 1.419 | Acc: 49.164% (22104/44960)\n",
      "Epoch 5 Step 1405/1563 Loss: 1.419 | Acc: 49.173% (22124/44992)\n",
      "Epoch 5 Step 1406/1563 Loss: 1.419 | Acc: 49.158% (22133/45024)\n",
      "Epoch 5 Step 1407/1563 Loss: 1.419 | Acc: 49.161% (22150/45056)\n",
      "Epoch 5 Step 1408/1563 Loss: 1.420 | Acc: 49.155% (22163/45088)\n",
      "Epoch 5 Step 1409/1563 Loss: 1.420 | Acc: 49.149% (22176/45120)\n",
      "Epoch 5 Step 1410/1563 Loss: 1.420 | Acc: 49.152% (22193/45152)\n",
      "Epoch 5 Step 1411/1563 Loss: 1.420 | Acc: 49.144% (22205/45184)\n",
      "Epoch 5 Step 1412/1563 Loss: 1.420 | Acc: 49.146% (22222/45216)\n",
      "Epoch 5 Step 1413/1563 Loss: 1.420 | Acc: 49.143% (22236/45248)\n",
      "Epoch 5 Step 1414/1563 Loss: 1.420 | Acc: 49.148% (22254/45280)\n",
      "Epoch 5 Step 1415/1563 Loss: 1.420 | Acc: 49.139% (22266/45312)\n",
      "Epoch 5 Step 1416/1563 Loss: 1.420 | Acc: 49.142% (22283/45344)\n",
      "Epoch 5 Step 1417/1563 Loss: 1.420 | Acc: 49.134% (22295/45376)\n",
      "Epoch 5 Step 1418/1563 Loss: 1.420 | Acc: 49.143% (22315/45408)\n",
      "Epoch 5 Step 1419/1563 Loss: 1.420 | Acc: 49.142% (22330/45440)\n",
      "Epoch 5 Step 1420/1563 Loss: 1.420 | Acc: 49.140% (22345/45472)\n",
      "Epoch 5 Step 1421/1563 Loss: 1.420 | Acc: 49.128% (22355/45504)\n",
      "Epoch 5 Step 1422/1563 Loss: 1.420 | Acc: 49.128% (22371/45536)\n",
      "Epoch 5 Step 1423/1563 Loss: 1.420 | Acc: 49.116% (22381/45568)\n",
      "Epoch 5 Step 1424/1563 Loss: 1.421 | Acc: 49.116% (22397/45600)\n",
      "Epoch 5 Step 1425/1563 Loss: 1.421 | Acc: 49.117% (22413/45632)\n",
      "Epoch 5 Step 1426/1563 Loss: 1.421 | Acc: 49.111% (22426/45664)\n",
      "Epoch 5 Step 1427/1563 Loss: 1.420 | Acc: 49.120% (22446/45696)\n",
      "Epoch 5 Step 1428/1563 Loss: 1.421 | Acc: 49.117% (22460/45728)\n",
      "Epoch 5 Step 1429/1563 Loss: 1.421 | Acc: 49.117% (22476/45760)\n",
      "Epoch 5 Step 1430/1563 Loss: 1.421 | Acc: 49.109% (22488/45792)\n",
      "Epoch 5 Step 1431/1563 Loss: 1.421 | Acc: 49.110% (22504/45824)\n",
      "Epoch 5 Step 1432/1563 Loss: 1.421 | Acc: 49.110% (22520/45856)\n",
      "Epoch 5 Step 1433/1563 Loss: 1.421 | Acc: 49.109% (22535/45888)\n",
      "Epoch 5 Step 1434/1563 Loss: 1.421 | Acc: 49.114% (22553/45920)\n",
      "Epoch 5 Step 1435/1563 Loss: 1.421 | Acc: 49.108% (22566/45952)\n",
      "Epoch 5 Step 1436/1563 Loss: 1.421 | Acc: 49.117% (22586/45984)\n",
      "Epoch 5 Step 1437/1563 Loss: 1.421 | Acc: 49.124% (22605/46016)\n",
      "Epoch 5 Step 1438/1563 Loss: 1.421 | Acc: 49.120% (22619/46048)\n",
      "Epoch 5 Step 1439/1563 Loss: 1.421 | Acc: 49.123% (22636/46080)\n",
      "Epoch 5 Step 1440/1563 Loss: 1.421 | Acc: 49.128% (22654/46112)\n",
      "Epoch 5 Step 1441/1563 Loss: 1.421 | Acc: 49.127% (22669/46144)\n",
      "Epoch 5 Step 1442/1563 Loss: 1.421 | Acc: 49.129% (22686/46176)\n",
      "Epoch 5 Step 1443/1563 Loss: 1.421 | Acc: 49.126% (22700/46208)\n",
      "Epoch 5 Step 1444/1563 Loss: 1.421 | Acc: 49.124% (22715/46240)\n",
      "Epoch 5 Step 1445/1563 Loss: 1.421 | Acc: 49.125% (22731/46272)\n",
      "Epoch 5 Step 1446/1563 Loss: 1.421 | Acc: 49.123% (22746/46304)\n",
      "Epoch 5 Step 1447/1563 Loss: 1.421 | Acc: 49.132% (22766/46336)\n",
      "Epoch 5 Step 1448/1563 Loss: 1.421 | Acc: 49.131% (22781/46368)\n",
      "Epoch 5 Step 1449/1563 Loss: 1.421 | Acc: 49.129% (22796/46400)\n",
      "Epoch 5 Step 1450/1563 Loss: 1.421 | Acc: 49.128% (22811/46432)\n",
      "Epoch 5 Step 1451/1563 Loss: 1.421 | Acc: 49.126% (22826/46464)\n",
      "Epoch 5 Step 1452/1563 Loss: 1.421 | Acc: 49.123% (22840/46496)\n",
      "Epoch 5 Step 1453/1563 Loss: 1.421 | Acc: 49.123% (22856/46528)\n",
      "Epoch 5 Step 1454/1563 Loss: 1.421 | Acc: 49.126% (22873/46560)\n",
      "Epoch 5 Step 1455/1563 Loss: 1.421 | Acc: 49.129% (22890/46592)\n",
      "Epoch 5 Step 1456/1563 Loss: 1.421 | Acc: 49.133% (22908/46624)\n",
      "Epoch 5 Step 1457/1563 Loss: 1.421 | Acc: 49.126% (22920/46656)\n",
      "Epoch 5 Step 1458/1563 Loss: 1.421 | Acc: 49.130% (22938/46688)\n",
      "Epoch 5 Step 1459/1563 Loss: 1.421 | Acc: 49.129% (22953/46720)\n",
      "Epoch 5 Step 1460/1563 Loss: 1.421 | Acc: 49.129% (22969/46752)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 1461/1563 Loss: 1.421 | Acc: 49.128% (22984/46784)\n",
      "Epoch 5 Step 1462/1563 Loss: 1.421 | Acc: 49.120% (22996/46816)\n",
      "Epoch 5 Step 1463/1563 Loss: 1.421 | Acc: 49.127% (23015/46848)\n",
      "Epoch 5 Step 1464/1563 Loss: 1.421 | Acc: 49.136% (23035/46880)\n",
      "Epoch 5 Step 1465/1563 Loss: 1.421 | Acc: 49.143% (23054/46912)\n",
      "Epoch 5 Step 1466/1563 Loss: 1.421 | Acc: 49.139% (23068/46944)\n",
      "Epoch 5 Step 1467/1563 Loss: 1.421 | Acc: 49.134% (23081/46976)\n",
      "Epoch 5 Step 1468/1563 Loss: 1.421 | Acc: 49.130% (23095/47008)\n",
      "Epoch 5 Step 1469/1563 Loss: 1.421 | Acc: 49.131% (23111/47040)\n",
      "Epoch 5 Step 1470/1563 Loss: 1.421 | Acc: 49.135% (23129/47072)\n",
      "Epoch 5 Step 1471/1563 Loss: 1.421 | Acc: 49.130% (23142/47104)\n",
      "Epoch 5 Step 1472/1563 Loss: 1.421 | Acc: 49.139% (23162/47136)\n",
      "Epoch 5 Step 1473/1563 Loss: 1.421 | Acc: 49.137% (23177/47168)\n",
      "Epoch 5 Step 1474/1563 Loss: 1.421 | Acc: 49.131% (23190/47200)\n",
      "Epoch 5 Step 1475/1563 Loss: 1.421 | Acc: 49.128% (23204/47232)\n",
      "Epoch 5 Step 1476/1563 Loss: 1.421 | Acc: 49.122% (23217/47264)\n",
      "Epoch 5 Step 1477/1563 Loss: 1.421 | Acc: 49.127% (23235/47296)\n",
      "Epoch 5 Step 1478/1563 Loss: 1.420 | Acc: 49.127% (23251/47328)\n",
      "Epoch 5 Step 1479/1563 Loss: 1.421 | Acc: 49.124% (23265/47360)\n",
      "Epoch 5 Step 1480/1563 Loss: 1.420 | Acc: 49.120% (23279/47392)\n",
      "Epoch 5 Step 1481/1563 Loss: 1.421 | Acc: 49.119% (23294/47424)\n",
      "Epoch 5 Step 1482/1563 Loss: 1.421 | Acc: 49.109% (23305/47456)\n",
      "Epoch 5 Step 1483/1563 Loss: 1.421 | Acc: 49.101% (23317/47488)\n",
      "Epoch 5 Step 1484/1563 Loss: 1.421 | Acc: 49.108% (23336/47520)\n",
      "Epoch 5 Step 1485/1563 Loss: 1.421 | Acc: 49.102% (23349/47552)\n",
      "Epoch 5 Step 1486/1563 Loss: 1.421 | Acc: 49.098% (23363/47584)\n",
      "Epoch 5 Step 1487/1563 Loss: 1.421 | Acc: 49.093% (23376/47616)\n",
      "Epoch 5 Step 1488/1563 Loss: 1.421 | Acc: 49.091% (23391/47648)\n",
      "Epoch 5 Step 1489/1563 Loss: 1.421 | Acc: 49.086% (23404/47680)\n",
      "Epoch 5 Step 1490/1563 Loss: 1.421 | Acc: 49.088% (23421/47712)\n",
      "Epoch 5 Step 1491/1563 Loss: 1.421 | Acc: 49.081% (23433/47744)\n",
      "Epoch 5 Step 1492/1563 Loss: 1.421 | Acc: 49.081% (23449/47776)\n",
      "Epoch 5 Step 1493/1563 Loss: 1.421 | Acc: 49.088% (23468/47808)\n",
      "Epoch 5 Step 1494/1563 Loss: 1.421 | Acc: 49.080% (23480/47840)\n",
      "Epoch 5 Step 1495/1563 Loss: 1.421 | Acc: 49.087% (23499/47872)\n",
      "Epoch 5 Step 1496/1563 Loss: 1.421 | Acc: 49.088% (23515/47904)\n",
      "Epoch 5 Step 1497/1563 Loss: 1.421 | Acc: 49.093% (23533/47936)\n",
      "Epoch 5 Step 1498/1563 Loss: 1.420 | Acc: 49.101% (23553/47968)\n",
      "Epoch 5 Step 1499/1563 Loss: 1.420 | Acc: 49.104% (23570/48000)\n",
      "Epoch 5 Step 1500/1563 Loss: 1.420 | Acc: 49.105% (23586/48032)\n",
      "Epoch 5 Step 1501/1563 Loss: 1.421 | Acc: 49.103% (23601/48064)\n",
      "Epoch 5 Step 1502/1563 Loss: 1.421 | Acc: 49.096% (23613/48096)\n",
      "Epoch 5 Step 1503/1563 Loss: 1.421 | Acc: 49.104% (23633/48128)\n",
      "Epoch 5 Step 1504/1563 Loss: 1.421 | Acc: 49.103% (23648/48160)\n",
      "Epoch 5 Step 1505/1563 Loss: 1.421 | Acc: 49.110% (23667/48192)\n",
      "Epoch 5 Step 1506/1563 Loss: 1.421 | Acc: 49.117% (23686/48224)\n",
      "Epoch 5 Step 1507/1563 Loss: 1.420 | Acc: 49.115% (23701/48256)\n",
      "Epoch 5 Step 1508/1563 Loss: 1.420 | Acc: 49.116% (23717/48288)\n",
      "Epoch 5 Step 1509/1563 Loss: 1.420 | Acc: 49.120% (23735/48320)\n",
      "Epoch 5 Step 1510/1563 Loss: 1.420 | Acc: 49.123% (23752/48352)\n",
      "Epoch 5 Step 1511/1563 Loss: 1.420 | Acc: 49.128% (23770/48384)\n",
      "Epoch 5 Step 1512/1563 Loss: 1.420 | Acc: 49.128% (23786/48416)\n",
      "Epoch 5 Step 1513/1563 Loss: 1.420 | Acc: 49.123% (23799/48448)\n",
      "Epoch 5 Step 1514/1563 Loss: 1.421 | Acc: 49.117% (23812/48480)\n",
      "Epoch 5 Step 1515/1563 Loss: 1.420 | Acc: 49.122% (23830/48512)\n",
      "Epoch 5 Step 1516/1563 Loss: 1.420 | Acc: 49.122% (23846/48544)\n",
      "Epoch 5 Step 1517/1563 Loss: 1.420 | Acc: 49.123% (23862/48576)\n",
      "Epoch 5 Step 1518/1563 Loss: 1.420 | Acc: 49.126% (23879/48608)\n",
      "Epoch 5 Step 1519/1563 Loss: 1.421 | Acc: 49.118% (23891/48640)\n",
      "Epoch 5 Step 1520/1563 Loss: 1.420 | Acc: 49.123% (23909/48672)\n",
      "Epoch 5 Step 1521/1563 Loss: 1.420 | Acc: 49.127% (23927/48704)\n",
      "Epoch 5 Step 1522/1563 Loss: 1.421 | Acc: 49.122% (23940/48736)\n",
      "Epoch 5 Step 1523/1563 Loss: 1.421 | Acc: 49.118% (23954/48768)\n",
      "Epoch 5 Step 1524/1563 Loss: 1.421 | Acc: 49.117% (23969/48800)\n",
      "Epoch 5 Step 1525/1563 Loss: 1.421 | Acc: 49.109% (23981/48832)\n",
      "Epoch 5 Step 1526/1563 Loss: 1.421 | Acc: 49.112% (23998/48864)\n",
      "Epoch 5 Step 1527/1563 Loss: 1.421 | Acc: 49.106% (24011/48896)\n",
      "Epoch 5 Step 1528/1563 Loss: 1.421 | Acc: 49.103% (24025/48928)\n",
      "Epoch 5 Step 1529/1563 Loss: 1.421 | Acc: 49.097% (24038/48960)\n",
      "Epoch 5 Step 1530/1563 Loss: 1.421 | Acc: 49.088% (24049/48992)\n",
      "Epoch 5 Step 1531/1563 Loss: 1.421 | Acc: 49.096% (24069/49024)\n",
      "Epoch 5 Step 1532/1563 Loss: 1.421 | Acc: 49.091% (24082/49056)\n",
      "Epoch 5 Step 1533/1563 Loss: 1.421 | Acc: 49.085% (24095/49088)\n",
      "Epoch 5 Step 1534/1563 Loss: 1.421 | Acc: 49.084% (24110/49120)\n",
      "Epoch 5 Step 1535/1563 Loss: 1.421 | Acc: 49.084% (24126/49152)\n",
      "Epoch 5 Step 1536/1563 Loss: 1.421 | Acc: 49.079% (24139/49184)\n",
      "Epoch 5 Step 1537/1563 Loss: 1.421 | Acc: 49.078% (24154/49216)\n",
      "Epoch 5 Step 1538/1563 Loss: 1.421 | Acc: 49.078% (24170/49248)\n",
      "Epoch 5 Step 1539/1563 Loss: 1.421 | Acc: 49.085% (24189/49280)\n",
      "Epoch 5 Step 1540/1563 Loss: 1.421 | Acc: 49.079% (24202/49312)\n",
      "Epoch 5 Step 1541/1563 Loss: 1.421 | Acc: 49.084% (24220/49344)\n",
      "Epoch 5 Step 1542/1563 Loss: 1.421 | Acc: 49.078% (24233/49376)\n",
      "Epoch 5 Step 1543/1563 Loss: 1.421 | Acc: 49.079% (24249/49408)\n",
      "Epoch 5 Step 1544/1563 Loss: 1.421 | Acc: 49.076% (24263/49440)\n",
      "Epoch 5 Step 1545/1563 Loss: 1.421 | Acc: 49.074% (24278/49472)\n",
      "Epoch 5 Step 1546/1563 Loss: 1.421 | Acc: 49.077% (24295/49504)\n",
      "Epoch 5 Step 1547/1563 Loss: 1.421 | Acc: 49.065% (24305/49536)\n",
      "Epoch 5 Step 1548/1563 Loss: 1.421 | Acc: 49.068% (24322/49568)\n",
      "Epoch 5 Step 1549/1563 Loss: 1.421 | Acc: 49.073% (24340/49600)\n",
      "Epoch 5 Step 1550/1563 Loss: 1.421 | Acc: 49.073% (24356/49632)\n",
      "Epoch 5 Step 1551/1563 Loss: 1.421 | Acc: 49.070% (24370/49664)\n",
      "Epoch 5 Step 1552/1563 Loss: 1.421 | Acc: 49.074% (24388/49696)\n",
      "Epoch 5 Step 1553/1563 Loss: 1.421 | Acc: 49.069% (24401/49728)\n",
      "Epoch 5 Step 1554/1563 Loss: 1.421 | Acc: 49.061% (24413/49760)\n",
      "Epoch 5 Step 1555/1563 Loss: 1.421 | Acc: 49.062% (24429/49792)\n",
      "Epoch 5 Step 1556/1563 Loss: 1.421 | Acc: 49.069% (24448/49824)\n",
      "Epoch 5 Step 1557/1563 Loss: 1.421 | Acc: 49.061% (24460/49856)\n",
      "Epoch 5 Step 1558/1563 Loss: 1.421 | Acc: 49.062% (24476/49888)\n",
      "Epoch 5 Step 1559/1563 Loss: 1.421 | Acc: 49.071% (24496/49920)\n",
      "Epoch 5 Step 1560/1563 Loss: 1.421 | Acc: 49.071% (24512/49952)\n",
      "Epoch 5 Step 1561/1563 Loss: 1.421 | Acc: 49.072% (24528/49984)\n",
      "Epoch 5 Step 1562/1563 Loss: 1.421 | Acc: 49.070% (24535/50000)\n",
      "Epoch 5 Step 0/313 Test Loss: 1.040 | Test Acc: 62.500% (20/32)\n",
      "Epoch 5 Step 1/313 Test Loss: 1.237 | Test Acc: 56.250% (36/64)\n",
      "Epoch 5 Step 2/313 Test Loss: 1.251 | Test Acc: 58.333% (56/96)\n",
      "Epoch 5 Step 3/313 Test Loss: 1.283 | Test Acc: 57.031% (73/128)\n",
      "Epoch 5 Step 4/313 Test Loss: 1.321 | Test Acc: 55.000% (88/160)\n",
      "Epoch 5 Step 5/313 Test Loss: 1.360 | Test Acc: 54.688% (105/192)\n",
      "Epoch 5 Step 6/313 Test Loss: 1.405 | Test Acc: 52.679% (118/224)\n",
      "Epoch 5 Step 7/313 Test Loss: 1.415 | Test Acc: 52.344% (134/256)\n",
      "Epoch 5 Step 8/313 Test Loss: 1.411 | Test Acc: 51.736% (149/288)\n",
      "Epoch 5 Step 9/313 Test Loss: 1.385 | Test Acc: 52.500% (168/320)\n",
      "Epoch 5 Step 10/313 Test Loss: 1.389 | Test Acc: 51.420% (181/352)\n",
      "Epoch 5 Step 11/313 Test Loss: 1.395 | Test Acc: 50.521% (194/384)\n",
      "Epoch 5 Step 12/313 Test Loss: 1.395 | Test Acc: 50.240% (209/416)\n",
      "Epoch 5 Step 13/313 Test Loss: 1.399 | Test Acc: 50.000% (224/448)\n",
      "Epoch 5 Step 14/313 Test Loss: 1.399 | Test Acc: 49.167% (236/480)\n",
      "Epoch 5 Step 15/313 Test Loss: 1.387 | Test Acc: 49.414% (253/512)\n",
      "Epoch 5 Step 16/313 Test Loss: 1.375 | Test Acc: 50.000% (272/544)\n",
      "Epoch 5 Step 17/313 Test Loss: 1.367 | Test Acc: 50.694% (292/576)\n",
      "Epoch 5 Step 18/313 Test Loss: 1.366 | Test Acc: 51.151% (311/608)\n",
      "Epoch 5 Step 19/313 Test Loss: 1.349 | Test Acc: 52.188% (334/640)\n",
      "Epoch 5 Step 20/313 Test Loss: 1.332 | Test Acc: 52.679% (354/672)\n",
      "Epoch 5 Step 21/313 Test Loss: 1.347 | Test Acc: 51.420% (362/704)\n",
      "Epoch 5 Step 22/313 Test Loss: 1.345 | Test Acc: 51.630% (380/736)\n",
      "Epoch 5 Step 23/313 Test Loss: 1.348 | Test Acc: 51.693% (397/768)\n",
      "Epoch 5 Step 24/313 Test Loss: 1.351 | Test Acc: 51.375% (411/800)\n",
      "Epoch 5 Step 25/313 Test Loss: 1.343 | Test Acc: 51.923% (432/832)\n",
      "Epoch 5 Step 26/313 Test Loss: 1.338 | Test Acc: 51.968% (449/864)\n",
      "Epoch 5 Step 27/313 Test Loss: 1.328 | Test Acc: 52.344% (469/896)\n",
      "Epoch 5 Step 28/313 Test Loss: 1.325 | Test Acc: 52.371% (486/928)\n",
      "Epoch 5 Step 29/313 Test Loss: 1.316 | Test Acc: 52.396% (503/960)\n",
      "Epoch 5 Step 30/313 Test Loss: 1.310 | Test Acc: 52.722% (523/992)\n",
      "Epoch 5 Step 31/313 Test Loss: 1.300 | Test Acc: 52.930% (542/1024)\n",
      "Epoch 5 Step 32/313 Test Loss: 1.308 | Test Acc: 52.746% (557/1056)\n",
      "Epoch 5 Step 33/313 Test Loss: 1.305 | Test Acc: 52.941% (576/1088)\n",
      "Epoch 5 Step 34/313 Test Loss: 1.295 | Test Acc: 53.482% (599/1120)\n",
      "Epoch 5 Step 35/313 Test Loss: 1.301 | Test Acc: 53.212% (613/1152)\n",
      "Epoch 5 Step 36/313 Test Loss: 1.299 | Test Acc: 53.041% (628/1184)\n",
      "Epoch 5 Step 37/313 Test Loss: 1.301 | Test Acc: 53.289% (648/1216)\n",
      "Epoch 5 Step 38/313 Test Loss: 1.306 | Test Acc: 53.045% (662/1248)\n",
      "Epoch 5 Step 39/313 Test Loss: 1.308 | Test Acc: 52.812% (676/1280)\n",
      "Epoch 5 Step 40/313 Test Loss: 1.313 | Test Acc: 52.439% (688/1312)\n",
      "Epoch 5 Step 41/313 Test Loss: 1.314 | Test Acc: 52.381% (704/1344)\n",
      "Epoch 5 Step 42/313 Test Loss: 1.310 | Test Acc: 52.398% (721/1376)\n",
      "Epoch 5 Step 43/313 Test Loss: 1.316 | Test Acc: 52.202% (735/1408)\n",
      "Epoch 5 Step 44/313 Test Loss: 1.317 | Test Acc: 52.153% (751/1440)\n",
      "Epoch 5 Step 45/313 Test Loss: 1.313 | Test Acc: 52.242% (769/1472)\n",
      "Epoch 5 Step 46/313 Test Loss: 1.316 | Test Acc: 52.261% (786/1504)\n",
      "Epoch 5 Step 47/313 Test Loss: 1.316 | Test Acc: 52.344% (804/1536)\n",
      "Epoch 5 Step 48/313 Test Loss: 1.315 | Test Acc: 52.296% (820/1568)\n",
      "Epoch 5 Step 49/313 Test Loss: 1.323 | Test Acc: 52.125% (834/1600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 50/313 Test Loss: 1.331 | Test Acc: 51.777% (845/1632)\n",
      "Epoch 5 Step 51/313 Test Loss: 1.328 | Test Acc: 52.163% (868/1664)\n",
      "Epoch 5 Step 52/313 Test Loss: 1.327 | Test Acc: 52.476% (890/1696)\n",
      "Epoch 5 Step 53/313 Test Loss: 1.331 | Test Acc: 52.373% (905/1728)\n",
      "Epoch 5 Step 54/313 Test Loss: 1.332 | Test Acc: 52.386% (922/1760)\n",
      "Epoch 5 Step 55/313 Test Loss: 1.331 | Test Acc: 52.288% (937/1792)\n",
      "Epoch 5 Step 56/313 Test Loss: 1.335 | Test Acc: 52.138% (951/1824)\n",
      "Epoch 5 Step 57/313 Test Loss: 1.336 | Test Acc: 52.209% (969/1856)\n",
      "Epoch 5 Step 58/313 Test Loss: 1.334 | Test Acc: 52.436% (990/1888)\n",
      "Epoch 5 Step 59/313 Test Loss: 1.337 | Test Acc: 52.500% (1008/1920)\n",
      "Epoch 5 Step 60/313 Test Loss: 1.336 | Test Acc: 52.510% (1025/1952)\n",
      "Epoch 5 Step 61/313 Test Loss: 1.336 | Test Acc: 52.520% (1042/1984)\n",
      "Epoch 5 Step 62/313 Test Loss: 1.338 | Test Acc: 52.331% (1055/2016)\n",
      "Epoch 5 Step 63/313 Test Loss: 1.338 | Test Acc: 52.246% (1070/2048)\n",
      "Epoch 5 Step 64/313 Test Loss: 1.335 | Test Acc: 52.163% (1085/2080)\n",
      "Epoch 5 Step 65/313 Test Loss: 1.334 | Test Acc: 52.131% (1101/2112)\n",
      "Epoch 5 Step 66/313 Test Loss: 1.334 | Test Acc: 52.006% (1115/2144)\n",
      "Epoch 5 Step 67/313 Test Loss: 1.338 | Test Acc: 51.838% (1128/2176)\n",
      "Epoch 5 Step 68/313 Test Loss: 1.339 | Test Acc: 51.947% (1147/2208)\n",
      "Epoch 5 Step 69/313 Test Loss: 1.339 | Test Acc: 52.188% (1169/2240)\n",
      "Epoch 5 Step 70/313 Test Loss: 1.339 | Test Acc: 52.201% (1186/2272)\n",
      "Epoch 5 Step 71/313 Test Loss: 1.340 | Test Acc: 52.170% (1202/2304)\n",
      "Epoch 5 Step 72/313 Test Loss: 1.342 | Test Acc: 52.183% (1219/2336)\n",
      "Epoch 5 Step 73/313 Test Loss: 1.340 | Test Acc: 52.323% (1239/2368)\n",
      "Epoch 5 Step 74/313 Test Loss: 1.339 | Test Acc: 52.375% (1257/2400)\n",
      "Epoch 5 Step 75/313 Test Loss: 1.342 | Test Acc: 52.262% (1271/2432)\n",
      "Epoch 5 Step 76/313 Test Loss: 1.341 | Test Acc: 52.435% (1292/2464)\n",
      "Epoch 5 Step 77/313 Test Loss: 1.341 | Test Acc: 52.524% (1311/2496)\n",
      "Epoch 5 Step 78/313 Test Loss: 1.346 | Test Acc: 52.097% (1317/2528)\n",
      "Epoch 5 Step 79/313 Test Loss: 1.351 | Test Acc: 51.953% (1330/2560)\n",
      "Epoch 5 Step 80/313 Test Loss: 1.353 | Test Acc: 51.813% (1343/2592)\n",
      "Epoch 5 Step 81/313 Test Loss: 1.352 | Test Acc: 51.829% (1360/2624)\n",
      "Epoch 5 Step 82/313 Test Loss: 1.353 | Test Acc: 51.920% (1379/2656)\n",
      "Epoch 5 Step 83/313 Test Loss: 1.350 | Test Acc: 51.972% (1397/2688)\n",
      "Epoch 5 Step 84/313 Test Loss: 1.352 | Test Acc: 51.875% (1411/2720)\n",
      "Epoch 5 Step 85/313 Test Loss: 1.352 | Test Acc: 51.744% (1424/2752)\n",
      "Epoch 5 Step 86/313 Test Loss: 1.353 | Test Acc: 51.616% (1437/2784)\n",
      "Epoch 5 Step 87/313 Test Loss: 1.353 | Test Acc: 51.669% (1455/2816)\n",
      "Epoch 5 Step 88/313 Test Loss: 1.354 | Test Acc: 51.756% (1474/2848)\n",
      "Epoch 5 Step 89/313 Test Loss: 1.353 | Test Acc: 51.736% (1490/2880)\n",
      "Epoch 5 Step 90/313 Test Loss: 1.352 | Test Acc: 51.717% (1506/2912)\n",
      "Epoch 5 Step 91/313 Test Loss: 1.349 | Test Acc: 51.868% (1527/2944)\n",
      "Epoch 5 Step 92/313 Test Loss: 1.347 | Test Acc: 51.882% (1544/2976)\n",
      "Epoch 5 Step 93/313 Test Loss: 1.347 | Test Acc: 51.795% (1558/3008)\n",
      "Epoch 5 Step 94/313 Test Loss: 1.347 | Test Acc: 51.908% (1578/3040)\n",
      "Epoch 5 Step 95/313 Test Loss: 1.346 | Test Acc: 51.823% (1592/3072)\n",
      "Epoch 5 Step 96/313 Test Loss: 1.344 | Test Acc: 51.836% (1609/3104)\n",
      "Epoch 5 Step 97/313 Test Loss: 1.345 | Test Acc: 51.849% (1626/3136)\n",
      "Epoch 5 Step 98/313 Test Loss: 1.343 | Test Acc: 51.768% (1640/3168)\n",
      "Epoch 5 Step 99/313 Test Loss: 1.344 | Test Acc: 51.812% (1658/3200)\n",
      "Epoch 5 Step 100/313 Test Loss: 1.348 | Test Acc: 51.547% (1666/3232)\n",
      "Epoch 5 Step 101/313 Test Loss: 1.346 | Test Acc: 51.654% (1686/3264)\n",
      "Epoch 5 Step 102/313 Test Loss: 1.344 | Test Acc: 51.729% (1705/3296)\n",
      "Epoch 5 Step 103/313 Test Loss: 1.344 | Test Acc: 51.743% (1722/3328)\n",
      "Epoch 5 Step 104/313 Test Loss: 1.344 | Test Acc: 51.756% (1739/3360)\n",
      "Epoch 5 Step 105/313 Test Loss: 1.341 | Test Acc: 51.916% (1761/3392)\n",
      "Epoch 5 Step 106/313 Test Loss: 1.341 | Test Acc: 51.840% (1775/3424)\n",
      "Epoch 5 Step 107/313 Test Loss: 1.342 | Test Acc: 51.765% (1789/3456)\n",
      "Epoch 5 Step 108/313 Test Loss: 1.339 | Test Acc: 51.835% (1808/3488)\n",
      "Epoch 5 Step 109/313 Test Loss: 1.342 | Test Acc: 51.705% (1820/3520)\n",
      "Epoch 5 Step 110/313 Test Loss: 1.340 | Test Acc: 51.830% (1841/3552)\n",
      "Epoch 5 Step 111/313 Test Loss: 1.338 | Test Acc: 51.981% (1863/3584)\n",
      "Epoch 5 Step 112/313 Test Loss: 1.338 | Test Acc: 52.046% (1882/3616)\n",
      "Epoch 5 Step 113/313 Test Loss: 1.339 | Test Acc: 52.029% (1898/3648)\n",
      "Epoch 5 Step 114/313 Test Loss: 1.337 | Test Acc: 52.065% (1916/3680)\n",
      "Epoch 5 Step 115/313 Test Loss: 1.337 | Test Acc: 52.074% (1933/3712)\n",
      "Epoch 5 Step 116/313 Test Loss: 1.336 | Test Acc: 52.030% (1948/3744)\n",
      "Epoch 5 Step 117/313 Test Loss: 1.338 | Test Acc: 52.039% (1965/3776)\n",
      "Epoch 5 Step 118/313 Test Loss: 1.337 | Test Acc: 52.075% (1983/3808)\n",
      "Epoch 5 Step 119/313 Test Loss: 1.335 | Test Acc: 52.161% (2003/3840)\n",
      "Epoch 5 Step 120/313 Test Loss: 1.333 | Test Acc: 52.247% (2023/3872)\n",
      "Epoch 5 Step 121/313 Test Loss: 1.331 | Test Acc: 52.305% (2042/3904)\n",
      "Epoch 5 Step 122/313 Test Loss: 1.331 | Test Acc: 52.337% (2060/3936)\n",
      "Epoch 5 Step 123/313 Test Loss: 1.330 | Test Acc: 52.419% (2080/3968)\n",
      "Epoch 5 Step 124/313 Test Loss: 1.331 | Test Acc: 52.350% (2094/4000)\n",
      "Epoch 5 Step 125/313 Test Loss: 1.331 | Test Acc: 52.356% (2111/4032)\n",
      "Epoch 5 Step 126/313 Test Loss: 1.334 | Test Acc: 52.288% (2125/4064)\n",
      "Epoch 5 Step 127/313 Test Loss: 1.331 | Test Acc: 52.368% (2145/4096)\n",
      "Epoch 5 Step 128/313 Test Loss: 1.333 | Test Acc: 52.326% (2160/4128)\n",
      "Epoch 5 Step 129/313 Test Loss: 1.332 | Test Acc: 52.380% (2179/4160)\n",
      "Epoch 5 Step 130/313 Test Loss: 1.330 | Test Acc: 52.529% (2202/4192)\n",
      "Epoch 5 Step 131/313 Test Loss: 1.330 | Test Acc: 52.438% (2215/4224)\n",
      "Epoch 5 Step 132/313 Test Loss: 1.331 | Test Acc: 52.397% (2230/4256)\n",
      "Epoch 5 Step 133/313 Test Loss: 1.331 | Test Acc: 52.402% (2247/4288)\n",
      "Epoch 5 Step 134/313 Test Loss: 1.332 | Test Acc: 52.384% (2263/4320)\n",
      "Epoch 5 Step 135/313 Test Loss: 1.330 | Test Acc: 52.482% (2284/4352)\n",
      "Epoch 5 Step 136/313 Test Loss: 1.330 | Test Acc: 52.509% (2302/4384)\n",
      "Epoch 5 Step 137/313 Test Loss: 1.329 | Test Acc: 52.559% (2321/4416)\n",
      "Epoch 5 Step 138/313 Test Loss: 1.327 | Test Acc: 52.630% (2341/4448)\n",
      "Epoch 5 Step 139/313 Test Loss: 1.327 | Test Acc: 52.634% (2358/4480)\n",
      "Epoch 5 Step 140/313 Test Loss: 1.327 | Test Acc: 52.660% (2376/4512)\n",
      "Epoch 5 Step 141/313 Test Loss: 1.326 | Test Acc: 52.663% (2393/4544)\n",
      "Epoch 5 Step 142/313 Test Loss: 1.328 | Test Acc: 52.622% (2408/4576)\n",
      "Epoch 5 Step 143/313 Test Loss: 1.330 | Test Acc: 52.582% (2423/4608)\n",
      "Epoch 5 Step 144/313 Test Loss: 1.330 | Test Acc: 52.586% (2440/4640)\n",
      "Epoch 5 Step 145/313 Test Loss: 1.327 | Test Acc: 52.740% (2464/4672)\n",
      "Epoch 5 Step 146/313 Test Loss: 1.327 | Test Acc: 52.700% (2479/4704)\n",
      "Epoch 5 Step 147/313 Test Loss: 1.327 | Test Acc: 52.787% (2500/4736)\n",
      "Epoch 5 Step 148/313 Test Loss: 1.328 | Test Acc: 52.789% (2517/4768)\n",
      "Epoch 5 Step 149/313 Test Loss: 1.328 | Test Acc: 52.812% (2535/4800)\n",
      "Epoch 5 Step 150/313 Test Loss: 1.329 | Test Acc: 52.732% (2548/4832)\n",
      "Epoch 5 Step 151/313 Test Loss: 1.326 | Test Acc: 52.796% (2568/4864)\n",
      "Epoch 5 Step 152/313 Test Loss: 1.326 | Test Acc: 52.757% (2583/4896)\n",
      "Epoch 5 Step 153/313 Test Loss: 1.326 | Test Acc: 52.780% (2601/4928)\n",
      "Epoch 5 Step 154/313 Test Loss: 1.325 | Test Acc: 52.782% (2618/4960)\n",
      "Epoch 5 Step 155/313 Test Loss: 1.325 | Test Acc: 52.825% (2637/4992)\n",
      "Epoch 5 Step 156/313 Test Loss: 1.325 | Test Acc: 52.846% (2655/5024)\n",
      "Epoch 5 Step 157/313 Test Loss: 1.324 | Test Acc: 52.809% (2670/5056)\n",
      "Epoch 5 Step 158/313 Test Loss: 1.325 | Test Acc: 52.752% (2684/5088)\n",
      "Epoch 5 Step 159/313 Test Loss: 1.328 | Test Acc: 52.656% (2696/5120)\n",
      "Epoch 5 Step 160/313 Test Loss: 1.327 | Test Acc: 52.717% (2716/5152)\n",
      "Epoch 5 Step 161/313 Test Loss: 1.326 | Test Acc: 52.816% (2738/5184)\n",
      "Epoch 5 Step 162/313 Test Loss: 1.328 | Test Acc: 52.799% (2754/5216)\n",
      "Epoch 5 Step 163/313 Test Loss: 1.329 | Test Acc: 52.744% (2768/5248)\n",
      "Epoch 5 Step 164/313 Test Loss: 1.330 | Test Acc: 52.708% (2783/5280)\n",
      "Epoch 5 Step 165/313 Test Loss: 1.330 | Test Acc: 52.692% (2799/5312)\n",
      "Epoch 5 Step 166/313 Test Loss: 1.332 | Test Acc: 52.638% (2813/5344)\n",
      "Epoch 5 Step 167/313 Test Loss: 1.332 | Test Acc: 52.623% (2829/5376)\n",
      "Epoch 5 Step 168/313 Test Loss: 1.333 | Test Acc: 52.570% (2843/5408)\n",
      "Epoch 5 Step 169/313 Test Loss: 1.332 | Test Acc: 52.574% (2860/5440)\n",
      "Epoch 5 Step 170/313 Test Loss: 1.332 | Test Acc: 52.650% (2881/5472)\n",
      "Epoch 5 Step 171/313 Test Loss: 1.330 | Test Acc: 52.725% (2902/5504)\n",
      "Epoch 5 Step 172/313 Test Loss: 1.331 | Test Acc: 52.691% (2917/5536)\n",
      "Epoch 5 Step 173/313 Test Loss: 1.331 | Test Acc: 52.676% (2933/5568)\n",
      "Epoch 5 Step 174/313 Test Loss: 1.332 | Test Acc: 52.661% (2949/5600)\n",
      "Epoch 5 Step 175/313 Test Loss: 1.332 | Test Acc: 52.646% (2965/5632)\n",
      "Epoch 5 Step 176/313 Test Loss: 1.334 | Test Acc: 52.578% (2978/5664)\n",
      "Epoch 5 Step 177/313 Test Loss: 1.333 | Test Acc: 52.651% (2999/5696)\n",
      "Epoch 5 Step 178/313 Test Loss: 1.331 | Test Acc: 52.689% (3018/5728)\n",
      "Epoch 5 Step 179/313 Test Loss: 1.332 | Test Acc: 52.674% (3034/5760)\n",
      "Epoch 5 Step 180/313 Test Loss: 1.330 | Test Acc: 52.762% (3056/5792)\n",
      "Epoch 5 Step 181/313 Test Loss: 1.330 | Test Acc: 52.764% (3073/5824)\n",
      "Epoch 5 Step 182/313 Test Loss: 1.332 | Test Acc: 52.681% (3085/5856)\n",
      "Epoch 5 Step 183/313 Test Loss: 1.332 | Test Acc: 52.632% (3099/5888)\n",
      "Epoch 5 Step 184/313 Test Loss: 1.334 | Test Acc: 52.551% (3111/5920)\n",
      "Epoch 5 Step 185/313 Test Loss: 1.334 | Test Acc: 52.587% (3130/5952)\n",
      "Epoch 5 Step 186/313 Test Loss: 1.334 | Test Acc: 52.590% (3147/5984)\n",
      "Epoch 5 Step 187/313 Test Loss: 1.334 | Test Acc: 52.527% (3160/6016)\n",
      "Epoch 5 Step 188/313 Test Loss: 1.333 | Test Acc: 52.497% (3175/6048)\n",
      "Epoch 5 Step 189/313 Test Loss: 1.334 | Test Acc: 52.401% (3186/6080)\n",
      "Epoch 5 Step 190/313 Test Loss: 1.333 | Test Acc: 52.438% (3205/6112)\n",
      "Epoch 5 Step 191/313 Test Loss: 1.332 | Test Acc: 52.474% (3224/6144)\n",
      "Epoch 5 Step 192/313 Test Loss: 1.333 | Test Acc: 52.445% (3239/6176)\n",
      "Epoch 5 Step 193/313 Test Loss: 1.332 | Test Acc: 52.465% (3257/6208)\n",
      "Epoch 5 Step 194/313 Test Loss: 1.332 | Test Acc: 52.436% (3272/6240)\n",
      "Epoch 5 Step 195/313 Test Loss: 1.334 | Test Acc: 52.392% (3286/6272)\n",
      "Epoch 5 Step 196/313 Test Loss: 1.335 | Test Acc: 52.364% (3301/6304)\n",
      "Epoch 5 Step 197/313 Test Loss: 1.334 | Test Acc: 52.399% (3320/6336)\n",
      "Epoch 5 Step 198/313 Test Loss: 1.332 | Test Acc: 52.450% (3340/6368)\n",
      "Epoch 5 Step 199/313 Test Loss: 1.333 | Test Acc: 52.438% (3356/6400)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Step 200/313 Test Loss: 1.334 | Test Acc: 52.379% (3369/6432)\n",
      "Epoch 5 Step 201/313 Test Loss: 1.334 | Test Acc: 52.351% (3384/6464)\n",
      "Epoch 5 Step 202/313 Test Loss: 1.336 | Test Acc: 52.340% (3400/6496)\n",
      "Epoch 5 Step 203/313 Test Loss: 1.336 | Test Acc: 52.359% (3418/6528)\n",
      "Epoch 5 Step 204/313 Test Loss: 1.337 | Test Acc: 52.332% (3433/6560)\n",
      "Epoch 5 Step 205/313 Test Loss: 1.337 | Test Acc: 52.351% (3451/6592)\n",
      "Epoch 5 Step 206/313 Test Loss: 1.337 | Test Acc: 52.325% (3466/6624)\n",
      "Epoch 5 Step 207/313 Test Loss: 1.336 | Test Acc: 52.359% (3485/6656)\n",
      "Epoch 5 Step 208/313 Test Loss: 1.336 | Test Acc: 52.362% (3502/6688)\n",
      "Epoch 5 Step 209/313 Test Loss: 1.337 | Test Acc: 52.366% (3519/6720)\n",
      "Epoch 5 Step 210/313 Test Loss: 1.336 | Test Acc: 52.355% (3535/6752)\n",
      "Epoch 5 Step 211/313 Test Loss: 1.337 | Test Acc: 52.329% (3550/6784)\n",
      "Epoch 5 Step 212/313 Test Loss: 1.334 | Test Acc: 52.406% (3572/6816)\n",
      "Epoch 5 Step 213/313 Test Loss: 1.334 | Test Acc: 52.409% (3589/6848)\n",
      "Epoch 5 Step 214/313 Test Loss: 1.336 | Test Acc: 52.311% (3599/6880)\n",
      "Epoch 5 Step 215/313 Test Loss: 1.336 | Test Acc: 52.358% (3619/6912)\n",
      "Epoch 5 Step 216/313 Test Loss: 1.335 | Test Acc: 52.376% (3637/6944)\n",
      "Epoch 5 Step 217/313 Test Loss: 1.337 | Test Acc: 52.322% (3650/6976)\n",
      "Epoch 5 Step 218/313 Test Loss: 1.338 | Test Acc: 52.212% (3659/7008)\n",
      "Epoch 5 Step 219/313 Test Loss: 1.338 | Test Acc: 52.216% (3676/7040)\n",
      "Epoch 5 Step 220/313 Test Loss: 1.339 | Test Acc: 52.220% (3693/7072)\n",
      "Epoch 5 Step 221/313 Test Loss: 1.339 | Test Acc: 52.224% (3710/7104)\n",
      "Epoch 5 Step 222/313 Test Loss: 1.340 | Test Acc: 52.214% (3726/7136)\n",
      "Epoch 5 Step 223/313 Test Loss: 1.339 | Test Acc: 52.204% (3742/7168)\n",
      "Epoch 5 Step 224/313 Test Loss: 1.340 | Test Acc: 52.167% (3756/7200)\n",
      "Epoch 5 Step 225/313 Test Loss: 1.341 | Test Acc: 52.143% (3771/7232)\n",
      "Epoch 5 Step 226/313 Test Loss: 1.342 | Test Acc: 52.106% (3785/7264)\n",
      "Epoch 5 Step 227/313 Test Loss: 1.341 | Test Acc: 52.097% (3801/7296)\n",
      "Epoch 5 Step 228/313 Test Loss: 1.341 | Test Acc: 52.115% (3819/7328)\n",
      "Epoch 5 Step 229/313 Test Loss: 1.339 | Test Acc: 52.201% (3842/7360)\n",
      "Epoch 5 Step 230/313 Test Loss: 1.339 | Test Acc: 52.178% (3857/7392)\n",
      "Epoch 5 Step 231/313 Test Loss: 1.341 | Test Acc: 52.115% (3869/7424)\n",
      "Epoch 5 Step 232/313 Test Loss: 1.341 | Test Acc: 52.133% (3887/7456)\n",
      "Epoch 5 Step 233/313 Test Loss: 1.340 | Test Acc: 52.190% (3908/7488)\n",
      "Epoch 5 Step 234/313 Test Loss: 1.339 | Test Acc: 52.181% (3924/7520)\n",
      "Epoch 5 Step 235/313 Test Loss: 1.340 | Test Acc: 52.198% (3942/7552)\n",
      "Epoch 5 Step 236/313 Test Loss: 1.340 | Test Acc: 52.202% (3959/7584)\n",
      "Epoch 5 Step 237/313 Test Loss: 1.342 | Test Acc: 52.127% (3970/7616)\n",
      "Epoch 5 Step 238/313 Test Loss: 1.342 | Test Acc: 52.131% (3987/7648)\n",
      "Epoch 5 Step 239/313 Test Loss: 1.342 | Test Acc: 52.135% (4004/7680)\n",
      "Epoch 5 Step 240/313 Test Loss: 1.340 | Test Acc: 52.217% (4027/7712)\n",
      "Epoch 5 Step 241/313 Test Loss: 1.340 | Test Acc: 52.208% (4043/7744)\n",
      "Epoch 5 Step 242/313 Test Loss: 1.340 | Test Acc: 52.186% (4058/7776)\n",
      "Epoch 5 Step 243/313 Test Loss: 1.340 | Test Acc: 52.177% (4074/7808)\n",
      "Epoch 5 Step 244/313 Test Loss: 1.340 | Test Acc: 52.156% (4089/7840)\n",
      "Epoch 5 Step 245/313 Test Loss: 1.341 | Test Acc: 52.121% (4103/7872)\n",
      "Epoch 5 Step 246/313 Test Loss: 1.340 | Test Acc: 52.151% (4122/7904)\n",
      "Epoch 5 Step 247/313 Test Loss: 1.340 | Test Acc: 52.092% (4134/7936)\n",
      "Epoch 5 Step 248/313 Test Loss: 1.341 | Test Acc: 52.071% (4149/7968)\n",
      "Epoch 5 Step 249/313 Test Loss: 1.341 | Test Acc: 52.125% (4170/8000)\n",
      "Epoch 5 Step 250/313 Test Loss: 1.341 | Test Acc: 52.104% (4185/8032)\n",
      "Epoch 5 Step 251/313 Test Loss: 1.342 | Test Acc: 52.096% (4201/8064)\n",
      "Epoch 5 Step 252/313 Test Loss: 1.342 | Test Acc: 52.112% (4219/8096)\n",
      "Epoch 5 Step 253/313 Test Loss: 1.343 | Test Acc: 52.092% (4234/8128)\n",
      "Epoch 5 Step 254/313 Test Loss: 1.343 | Test Acc: 52.083% (4250/8160)\n",
      "Epoch 5 Step 255/313 Test Loss: 1.343 | Test Acc: 52.063% (4265/8192)\n",
      "Epoch 5 Step 256/313 Test Loss: 1.343 | Test Acc: 52.043% (4280/8224)\n",
      "Epoch 5 Step 257/313 Test Loss: 1.343 | Test Acc: 52.059% (4298/8256)\n",
      "Epoch 5 Step 258/313 Test Loss: 1.343 | Test Acc: 52.027% (4312/8288)\n",
      "Epoch 5 Step 259/313 Test Loss: 1.344 | Test Acc: 51.971% (4324/8320)\n",
      "Epoch 5 Step 260/313 Test Loss: 1.345 | Test Acc: 51.928% (4337/8352)\n",
      "Epoch 5 Step 261/313 Test Loss: 1.344 | Test Acc: 51.932% (4354/8384)\n",
      "Epoch 5 Step 262/313 Test Loss: 1.344 | Test Acc: 51.901% (4368/8416)\n",
      "Epoch 5 Step 263/313 Test Loss: 1.345 | Test Acc: 51.858% (4381/8448)\n",
      "Epoch 5 Step 264/313 Test Loss: 1.345 | Test Acc: 51.851% (4397/8480)\n",
      "Epoch 5 Step 265/313 Test Loss: 1.345 | Test Acc: 51.880% (4416/8512)\n",
      "Epoch 5 Step 266/313 Test Loss: 1.345 | Test Acc: 51.931% (4437/8544)\n",
      "Epoch 5 Step 267/313 Test Loss: 1.345 | Test Acc: 51.912% (4452/8576)\n",
      "Epoch 5 Step 268/313 Test Loss: 1.345 | Test Acc: 51.894% (4467/8608)\n",
      "Epoch 5 Step 269/313 Test Loss: 1.346 | Test Acc: 51.910% (4485/8640)\n",
      "Epoch 5 Step 270/313 Test Loss: 1.347 | Test Acc: 51.845% (4496/8672)\n",
      "Epoch 5 Step 271/313 Test Loss: 1.346 | Test Acc: 51.838% (4512/8704)\n",
      "Epoch 5 Step 272/313 Test Loss: 1.346 | Test Acc: 51.877% (4532/8736)\n",
      "Epoch 5 Step 273/313 Test Loss: 1.346 | Test Acc: 51.848% (4546/8768)\n",
      "Epoch 5 Step 274/313 Test Loss: 1.345 | Test Acc: 51.875% (4565/8800)\n",
      "Epoch 5 Step 275/313 Test Loss: 1.346 | Test Acc: 51.857% (4580/8832)\n",
      "Epoch 5 Step 276/313 Test Loss: 1.346 | Test Acc: 51.839% (4595/8864)\n",
      "Epoch 5 Step 277/313 Test Loss: 1.346 | Test Acc: 51.888% (4616/8896)\n",
      "Epoch 5 Step 278/313 Test Loss: 1.345 | Test Acc: 51.927% (4636/8928)\n",
      "Epoch 5 Step 279/313 Test Loss: 1.346 | Test Acc: 51.886% (4649/8960)\n",
      "Epoch 5 Step 280/313 Test Loss: 1.346 | Test Acc: 51.868% (4664/8992)\n",
      "Epoch 5 Step 281/313 Test Loss: 1.345 | Test Acc: 51.906% (4684/9024)\n",
      "Epoch 5 Step 282/313 Test Loss: 1.346 | Test Acc: 51.877% (4698/9056)\n",
      "Epoch 5 Step 283/313 Test Loss: 1.345 | Test Acc: 51.882% (4715/9088)\n",
      "Epoch 5 Step 284/313 Test Loss: 1.345 | Test Acc: 51.886% (4732/9120)\n",
      "Epoch 5 Step 285/313 Test Loss: 1.345 | Test Acc: 51.912% (4751/9152)\n",
      "Epoch 5 Step 286/313 Test Loss: 1.344 | Test Acc: 51.960% (4772/9184)\n",
      "Epoch 5 Step 287/313 Test Loss: 1.343 | Test Acc: 52.007% (4793/9216)\n",
      "Epoch 5 Step 288/313 Test Loss: 1.343 | Test Acc: 52.022% (4811/9248)\n",
      "Epoch 5 Step 289/313 Test Loss: 1.343 | Test Acc: 52.037% (4829/9280)\n",
      "Epoch 5 Step 290/313 Test Loss: 1.344 | Test Acc: 52.019% (4844/9312)\n",
      "Epoch 5 Step 291/313 Test Loss: 1.344 | Test Acc: 52.023% (4861/9344)\n",
      "Epoch 5 Step 292/313 Test Loss: 1.344 | Test Acc: 52.048% (4880/9376)\n",
      "Epoch 5 Step 293/313 Test Loss: 1.345 | Test Acc: 52.009% (4893/9408)\n",
      "Epoch 5 Step 294/313 Test Loss: 1.345 | Test Acc: 52.034% (4912/9440)\n",
      "Epoch 5 Step 295/313 Test Loss: 1.345 | Test Acc: 52.048% (4930/9472)\n",
      "Epoch 5 Step 296/313 Test Loss: 1.344 | Test Acc: 52.083% (4950/9504)\n",
      "Epoch 5 Step 297/313 Test Loss: 1.345 | Test Acc: 52.055% (4964/9536)\n",
      "Epoch 5 Step 298/313 Test Loss: 1.344 | Test Acc: 52.090% (4984/9568)\n",
      "Epoch 5 Step 299/313 Test Loss: 1.343 | Test Acc: 52.135% (5005/9600)\n",
      "Epoch 5 Step 300/313 Test Loss: 1.343 | Test Acc: 52.139% (5022/9632)\n",
      "Epoch 5 Step 301/313 Test Loss: 1.343 | Test Acc: 52.111% (5036/9664)\n",
      "Epoch 5 Step 302/313 Test Loss: 1.343 | Test Acc: 52.094% (5051/9696)\n",
      "Epoch 5 Step 303/313 Test Loss: 1.343 | Test Acc: 52.128% (5071/9728)\n",
      "Epoch 5 Step 304/313 Test Loss: 1.344 | Test Acc: 52.111% (5086/9760)\n",
      "Epoch 5 Step 305/313 Test Loss: 1.343 | Test Acc: 52.104% (5102/9792)\n",
      "Epoch 5 Step 306/313 Test Loss: 1.344 | Test Acc: 52.087% (5117/9824)\n",
      "Epoch 5 Step 307/313 Test Loss: 1.344 | Test Acc: 52.070% (5132/9856)\n",
      "Epoch 5 Step 308/313 Test Loss: 1.345 | Test Acc: 52.043% (5146/9888)\n",
      "Epoch 5 Step 309/313 Test Loss: 1.345 | Test Acc: 52.046% (5163/9920)\n",
      "Epoch 5 Step 310/313 Test Loss: 1.345 | Test Acc: 52.000% (5175/9952)\n",
      "Epoch 5 Step 311/313 Test Loss: 1.346 | Test Acc: 51.983% (5190/9984)\n",
      "Epoch 5 Step 312/313 Test Loss: 1.345 | Test Acc: 51.990% (5199/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 6\n",
      "Epoch 6 Step 0/1563 Loss: 1.295 | Acc: 46.875% (15/32)\n",
      "Epoch 6 Step 1/1563 Loss: 1.273 | Acc: 46.875% (30/64)\n",
      "Epoch 6 Step 2/1563 Loss: 1.339 | Acc: 44.792% (43/96)\n",
      "Epoch 6 Step 3/1563 Loss: 1.349 | Acc: 49.219% (63/128)\n",
      "Epoch 6 Step 4/1563 Loss: 1.364 | Acc: 48.750% (78/160)\n",
      "Epoch 6 Step 5/1563 Loss: 1.339 | Acc: 51.562% (99/192)\n",
      "Epoch 6 Step 6/1563 Loss: 1.331 | Acc: 51.339% (115/224)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 7/1563 Loss: 1.318 | Acc: 53.125% (136/256)\n",
      "Epoch 6 Step 8/1563 Loss: 1.325 | Acc: 52.431% (151/288)\n",
      "Epoch 6 Step 9/1563 Loss: 1.344 | Acc: 50.625% (162/320)\n",
      "Epoch 6 Step 10/1563 Loss: 1.371 | Acc: 49.716% (175/352)\n",
      "Epoch 6 Step 11/1563 Loss: 1.404 | Acc: 48.438% (186/384)\n",
      "Epoch 6 Step 12/1563 Loss: 1.405 | Acc: 49.038% (204/416)\n",
      "Epoch 6 Step 13/1563 Loss: 1.405 | Acc: 49.330% (221/448)\n",
      "Epoch 6 Step 14/1563 Loss: 1.390 | Acc: 50.000% (240/480)\n",
      "Epoch 6 Step 15/1563 Loss: 1.363 | Acc: 50.977% (261/512)\n",
      "Epoch 6 Step 16/1563 Loss: 1.360 | Acc: 50.735% (276/544)\n",
      "Epoch 6 Step 17/1563 Loss: 1.352 | Acc: 51.215% (295/576)\n",
      "Epoch 6 Step 18/1563 Loss: 1.356 | Acc: 50.822% (309/608)\n",
      "Epoch 6 Step 19/1563 Loss: 1.338 | Acc: 51.719% (331/640)\n",
      "Epoch 6 Step 20/1563 Loss: 1.355 | Acc: 51.190% (344/672)\n",
      "Epoch 6 Step 21/1563 Loss: 1.368 | Acc: 50.994% (359/704)\n",
      "Epoch 6 Step 22/1563 Loss: 1.365 | Acc: 51.223% (377/736)\n",
      "Epoch 6 Step 23/1563 Loss: 1.370 | Acc: 50.651% (389/768)\n",
      "Epoch 6 Step 24/1563 Loss: 1.372 | Acc: 50.625% (405/800)\n",
      "Epoch 6 Step 25/1563 Loss: 1.381 | Acc: 50.361% (419/832)\n",
      "Epoch 6 Step 26/1563 Loss: 1.381 | Acc: 50.347% (435/864)\n",
      "Epoch 6 Step 27/1563 Loss: 1.379 | Acc: 50.670% (454/896)\n",
      "Epoch 6 Step 28/1563 Loss: 1.372 | Acc: 51.078% (474/928)\n",
      "Epoch 6 Step 29/1563 Loss: 1.377 | Acc: 50.729% (487/960)\n",
      "Epoch 6 Step 30/1563 Loss: 1.379 | Acc: 50.403% (500/992)\n",
      "Epoch 6 Step 31/1563 Loss: 1.371 | Acc: 50.488% (517/1024)\n",
      "Epoch 6 Step 32/1563 Loss: 1.380 | Acc: 50.284% (531/1056)\n",
      "Epoch 6 Step 33/1563 Loss: 1.376 | Acc: 50.184% (546/1088)\n",
      "Epoch 6 Step 34/1563 Loss: 1.379 | Acc: 50.179% (562/1120)\n",
      "Epoch 6 Step 35/1563 Loss: 1.384 | Acc: 50.260% (579/1152)\n",
      "Epoch 6 Step 36/1563 Loss: 1.387 | Acc: 50.084% (593/1184)\n",
      "Epoch 6 Step 37/1563 Loss: 1.391 | Acc: 50.082% (609/1216)\n",
      "Epoch 6 Step 38/1563 Loss: 1.408 | Acc: 49.439% (617/1248)\n",
      "Epoch 6 Step 39/1563 Loss: 1.412 | Acc: 49.141% (629/1280)\n",
      "Epoch 6 Step 40/1563 Loss: 1.415 | Acc: 49.085% (644/1312)\n",
      "Epoch 6 Step 41/1563 Loss: 1.408 | Acc: 49.330% (663/1344)\n",
      "Epoch 6 Step 42/1563 Loss: 1.408 | Acc: 49.346% (679/1376)\n",
      "Epoch 6 Step 43/1563 Loss: 1.407 | Acc: 49.645% (699/1408)\n",
      "Epoch 6 Step 44/1563 Loss: 1.410 | Acc: 49.583% (714/1440)\n",
      "Epoch 6 Step 45/1563 Loss: 1.405 | Acc: 49.796% (733/1472)\n",
      "Epoch 6 Step 46/1563 Loss: 1.415 | Acc: 49.535% (745/1504)\n",
      "Epoch 6 Step 47/1563 Loss: 1.411 | Acc: 49.740% (764/1536)\n",
      "Epoch 6 Step 48/1563 Loss: 1.411 | Acc: 49.809% (781/1568)\n",
      "Epoch 6 Step 49/1563 Loss: 1.411 | Acc: 49.875% (798/1600)\n",
      "Epoch 6 Step 50/1563 Loss: 1.413 | Acc: 49.939% (815/1632)\n",
      "Epoch 6 Step 51/1563 Loss: 1.415 | Acc: 49.760% (828/1664)\n",
      "Epoch 6 Step 52/1563 Loss: 1.415 | Acc: 49.823% (845/1696)\n",
      "Epoch 6 Step 53/1563 Loss: 1.416 | Acc: 49.653% (858/1728)\n",
      "Epoch 6 Step 54/1563 Loss: 1.421 | Acc: 49.432% (870/1760)\n",
      "Epoch 6 Step 55/1563 Loss: 1.421 | Acc: 49.498% (887/1792)\n",
      "Epoch 6 Step 56/1563 Loss: 1.417 | Acc: 49.726% (907/1824)\n",
      "Epoch 6 Step 57/1563 Loss: 1.413 | Acc: 49.838% (925/1856)\n",
      "Epoch 6 Step 58/1563 Loss: 1.414 | Acc: 49.576% (936/1888)\n",
      "Epoch 6 Step 59/1563 Loss: 1.418 | Acc: 49.583% (952/1920)\n",
      "Epoch 6 Step 60/1563 Loss: 1.417 | Acc: 49.488% (966/1952)\n",
      "Epoch 6 Step 61/1563 Loss: 1.421 | Acc: 49.345% (979/1984)\n",
      "Epoch 6 Step 62/1563 Loss: 1.417 | Acc: 49.405% (996/2016)\n",
      "Epoch 6 Step 63/1563 Loss: 1.415 | Acc: 49.512% (1014/2048)\n",
      "Epoch 6 Step 64/1563 Loss: 1.416 | Acc: 49.231% (1024/2080)\n",
      "Epoch 6 Step 65/1563 Loss: 1.414 | Acc: 49.148% (1038/2112)\n",
      "Epoch 6 Step 66/1563 Loss: 1.413 | Acc: 49.394% (1059/2144)\n",
      "Epoch 6 Step 67/1563 Loss: 1.415 | Acc: 49.265% (1072/2176)\n",
      "Epoch 6 Step 68/1563 Loss: 1.414 | Acc: 49.185% (1086/2208)\n",
      "Epoch 6 Step 69/1563 Loss: 1.411 | Acc: 49.107% (1100/2240)\n",
      "Epoch 6 Step 70/1563 Loss: 1.407 | Acc: 49.252% (1119/2272)\n",
      "Epoch 6 Step 71/1563 Loss: 1.404 | Acc: 49.262% (1135/2304)\n",
      "Epoch 6 Step 72/1563 Loss: 1.412 | Acc: 48.973% (1144/2336)\n",
      "Epoch 6 Step 73/1563 Loss: 1.416 | Acc: 48.818% (1156/2368)\n",
      "Epoch 6 Step 74/1563 Loss: 1.417 | Acc: 48.833% (1172/2400)\n",
      "Epoch 6 Step 75/1563 Loss: 1.416 | Acc: 48.766% (1186/2432)\n",
      "Epoch 6 Step 76/1563 Loss: 1.412 | Acc: 48.823% (1203/2464)\n",
      "Epoch 6 Step 77/1563 Loss: 1.411 | Acc: 48.878% (1220/2496)\n",
      "Epoch 6 Step 78/1563 Loss: 1.411 | Acc: 48.813% (1234/2528)\n",
      "Epoch 6 Step 79/1563 Loss: 1.415 | Acc: 48.789% (1249/2560)\n",
      "Epoch 6 Step 80/1563 Loss: 1.423 | Acc: 48.534% (1258/2592)\n",
      "Epoch 6 Step 81/1563 Loss: 1.419 | Acc: 48.590% (1275/2624)\n",
      "Epoch 6 Step 82/1563 Loss: 1.417 | Acc: 48.682% (1293/2656)\n",
      "Epoch 6 Step 83/1563 Loss: 1.415 | Acc: 48.735% (1310/2688)\n",
      "Epoch 6 Step 84/1563 Loss: 1.417 | Acc: 48.640% (1323/2720)\n",
      "Epoch 6 Step 85/1563 Loss: 1.412 | Acc: 48.801% (1343/2752)\n",
      "Epoch 6 Step 86/1563 Loss: 1.412 | Acc: 48.851% (1360/2784)\n",
      "Epoch 6 Step 87/1563 Loss: 1.411 | Acc: 48.793% (1374/2816)\n",
      "Epoch 6 Step 88/1563 Loss: 1.411 | Acc: 48.841% (1391/2848)\n",
      "Epoch 6 Step 89/1563 Loss: 1.411 | Acc: 48.889% (1408/2880)\n",
      "Epoch 6 Step 90/1563 Loss: 1.411 | Acc: 48.867% (1423/2912)\n",
      "Epoch 6 Step 91/1563 Loss: 1.411 | Acc: 48.811% (1437/2944)\n",
      "Epoch 6 Step 92/1563 Loss: 1.409 | Acc: 48.858% (1454/2976)\n",
      "Epoch 6 Step 93/1563 Loss: 1.411 | Acc: 48.703% (1465/3008)\n",
      "Epoch 6 Step 94/1563 Loss: 1.411 | Acc: 48.618% (1478/3040)\n",
      "Epoch 6 Step 95/1563 Loss: 1.413 | Acc: 48.535% (1491/3072)\n",
      "Epoch 6 Step 96/1563 Loss: 1.414 | Acc: 48.550% (1507/3104)\n",
      "Epoch 6 Step 97/1563 Loss: 1.415 | Acc: 48.469% (1520/3136)\n",
      "Epoch 6 Step 98/1563 Loss: 1.414 | Acc: 48.485% (1536/3168)\n",
      "Epoch 6 Step 99/1563 Loss: 1.412 | Acc: 48.594% (1555/3200)\n",
      "Epoch 6 Step 100/1563 Loss: 1.411 | Acc: 48.577% (1570/3232)\n",
      "Epoch 6 Step 101/1563 Loss: 1.410 | Acc: 48.713% (1590/3264)\n",
      "Epoch 6 Step 102/1563 Loss: 1.410 | Acc: 48.695% (1605/3296)\n",
      "Epoch 6 Step 103/1563 Loss: 1.413 | Acc: 48.588% (1617/3328)\n",
      "Epoch 6 Step 104/1563 Loss: 1.411 | Acc: 48.720% (1637/3360)\n",
      "Epoch 6 Step 105/1563 Loss: 1.412 | Acc: 48.732% (1653/3392)\n",
      "Epoch 6 Step 106/1563 Loss: 1.413 | Acc: 48.627% (1665/3424)\n",
      "Epoch 6 Step 107/1563 Loss: 1.411 | Acc: 48.785% (1686/3456)\n",
      "Epoch 6 Step 108/1563 Loss: 1.412 | Acc: 48.710% (1699/3488)\n",
      "Epoch 6 Step 109/1563 Loss: 1.411 | Acc: 48.750% (1716/3520)\n",
      "Epoch 6 Step 110/1563 Loss: 1.413 | Acc: 48.705% (1730/3552)\n",
      "Epoch 6 Step 111/1563 Loss: 1.413 | Acc: 48.633% (1743/3584)\n",
      "Epoch 6 Step 112/1563 Loss: 1.412 | Acc: 48.562% (1756/3616)\n",
      "Epoch 6 Step 113/1563 Loss: 1.410 | Acc: 48.657% (1775/3648)\n",
      "Epoch 6 Step 114/1563 Loss: 1.410 | Acc: 48.587% (1788/3680)\n",
      "Epoch 6 Step 115/1563 Loss: 1.409 | Acc: 48.680% (1807/3712)\n",
      "Epoch 6 Step 116/1563 Loss: 1.408 | Acc: 48.771% (1826/3744)\n",
      "Epoch 6 Step 117/1563 Loss: 1.409 | Acc: 48.808% (1843/3776)\n",
      "Epoch 6 Step 118/1563 Loss: 1.407 | Acc: 48.845% (1860/3808)\n",
      "Epoch 6 Step 119/1563 Loss: 1.408 | Acc: 48.854% (1876/3840)\n",
      "Epoch 6 Step 120/1563 Loss: 1.406 | Acc: 48.941% (1895/3872)\n",
      "Epoch 6 Step 121/1563 Loss: 1.404 | Acc: 49.052% (1915/3904)\n",
      "Epoch 6 Step 122/1563 Loss: 1.404 | Acc: 49.136% (1934/3936)\n",
      "Epoch 6 Step 123/1563 Loss: 1.404 | Acc: 49.068% (1947/3968)\n",
      "Epoch 6 Step 124/1563 Loss: 1.405 | Acc: 49.050% (1962/4000)\n",
      "Epoch 6 Step 125/1563 Loss: 1.405 | Acc: 49.008% (1976/4032)\n",
      "Epoch 6 Step 126/1563 Loss: 1.406 | Acc: 48.967% (1990/4064)\n",
      "Epoch 6 Step 127/1563 Loss: 1.406 | Acc: 48.975% (2006/4096)\n",
      "Epoch 6 Step 128/1563 Loss: 1.407 | Acc: 48.983% (2022/4128)\n",
      "Epoch 6 Step 129/1563 Loss: 1.406 | Acc: 48.942% (2036/4160)\n",
      "Epoch 6 Step 130/1563 Loss: 1.406 | Acc: 48.998% (2054/4192)\n",
      "Epoch 6 Step 131/1563 Loss: 1.406 | Acc: 49.029% (2071/4224)\n",
      "Epoch 6 Step 132/1563 Loss: 1.406 | Acc: 49.084% (2089/4256)\n",
      "Epoch 6 Step 133/1563 Loss: 1.406 | Acc: 49.044% (2103/4288)\n",
      "Epoch 6 Step 134/1563 Loss: 1.409 | Acc: 48.935% (2114/4320)\n",
      "Epoch 6 Step 135/1563 Loss: 1.407 | Acc: 49.012% (2133/4352)\n",
      "Epoch 6 Step 136/1563 Loss: 1.408 | Acc: 48.928% (2145/4384)\n",
      "Epoch 6 Step 137/1563 Loss: 1.407 | Acc: 48.936% (2161/4416)\n",
      "Epoch 6 Step 138/1563 Loss: 1.406 | Acc: 48.943% (2177/4448)\n",
      "Epoch 6 Step 139/1563 Loss: 1.408 | Acc: 48.884% (2190/4480)\n",
      "Epoch 6 Step 140/1563 Loss: 1.407 | Acc: 48.892% (2206/4512)\n",
      "Epoch 6 Step 141/1563 Loss: 1.409 | Acc: 48.856% (2220/4544)\n",
      "Epoch 6 Step 142/1563 Loss: 1.411 | Acc: 48.820% (2234/4576)\n",
      "Epoch 6 Step 143/1563 Loss: 1.412 | Acc: 48.763% (2247/4608)\n",
      "Epoch 6 Step 144/1563 Loss: 1.410 | Acc: 48.793% (2264/4640)\n",
      "Epoch 6 Step 145/1563 Loss: 1.412 | Acc: 48.737% (2277/4672)\n",
      "Epoch 6 Step 146/1563 Loss: 1.412 | Acc: 48.746% (2293/4704)\n",
      "Epoch 6 Step 147/1563 Loss: 1.411 | Acc: 48.860% (2314/4736)\n",
      "Epoch 6 Step 148/1563 Loss: 1.412 | Acc: 48.784% (2326/4768)\n",
      "Epoch 6 Step 149/1563 Loss: 1.415 | Acc: 48.750% (2340/4800)\n",
      "Epoch 6 Step 150/1563 Loss: 1.415 | Acc: 48.738% (2355/4832)\n",
      "Epoch 6 Step 151/1563 Loss: 1.414 | Acc: 48.684% (2368/4864)\n",
      "Epoch 6 Step 152/1563 Loss: 1.415 | Acc: 48.693% (2384/4896)\n",
      "Epoch 6 Step 153/1563 Loss: 1.415 | Acc: 48.701% (2400/4928)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 154/1563 Loss: 1.418 | Acc: 48.649% (2413/4960)\n",
      "Epoch 6 Step 155/1563 Loss: 1.418 | Acc: 48.618% (2427/4992)\n",
      "Epoch 6 Step 156/1563 Loss: 1.417 | Acc: 48.706% (2447/5024)\n",
      "Epoch 6 Step 157/1563 Loss: 1.417 | Acc: 48.675% (2461/5056)\n",
      "Epoch 6 Step 158/1563 Loss: 1.417 | Acc: 48.664% (2476/5088)\n",
      "Epoch 6 Step 159/1563 Loss: 1.417 | Acc: 48.730% (2495/5120)\n",
      "Epoch 6 Step 160/1563 Loss: 1.415 | Acc: 48.758% (2512/5152)\n",
      "Epoch 6 Step 161/1563 Loss: 1.414 | Acc: 48.785% (2529/5184)\n",
      "Epoch 6 Step 162/1563 Loss: 1.415 | Acc: 48.754% (2543/5216)\n",
      "Epoch 6 Step 163/1563 Loss: 1.414 | Acc: 48.761% (2559/5248)\n",
      "Epoch 6 Step 164/1563 Loss: 1.416 | Acc: 48.712% (2572/5280)\n",
      "Epoch 6 Step 165/1563 Loss: 1.418 | Acc: 48.682% (2586/5312)\n",
      "Epoch 6 Step 166/1563 Loss: 1.420 | Acc: 48.578% (2596/5344)\n",
      "Epoch 6 Step 167/1563 Loss: 1.420 | Acc: 48.531% (2609/5376)\n",
      "Epoch 6 Step 168/1563 Loss: 1.420 | Acc: 48.539% (2625/5408)\n",
      "Epoch 6 Step 169/1563 Loss: 1.419 | Acc: 48.603% (2644/5440)\n",
      "Epoch 6 Step 170/1563 Loss: 1.419 | Acc: 48.684% (2664/5472)\n",
      "Epoch 6 Step 171/1563 Loss: 1.418 | Acc: 48.746% (2683/5504)\n",
      "Epoch 6 Step 172/1563 Loss: 1.417 | Acc: 48.808% (2702/5536)\n",
      "Epoch 6 Step 173/1563 Loss: 1.415 | Acc: 48.904% (2723/5568)\n",
      "Epoch 6 Step 174/1563 Loss: 1.415 | Acc: 48.911% (2739/5600)\n",
      "Epoch 6 Step 175/1563 Loss: 1.414 | Acc: 48.917% (2755/5632)\n",
      "Epoch 6 Step 176/1563 Loss: 1.413 | Acc: 48.976% (2774/5664)\n",
      "Epoch 6 Step 177/1563 Loss: 1.416 | Acc: 48.876% (2784/5696)\n",
      "Epoch 6 Step 178/1563 Loss: 1.414 | Acc: 48.935% (2803/5728)\n",
      "Epoch 6 Step 179/1563 Loss: 1.413 | Acc: 48.993% (2822/5760)\n",
      "Epoch 6 Step 180/1563 Loss: 1.413 | Acc: 48.947% (2835/5792)\n",
      "Epoch 6 Step 181/1563 Loss: 1.412 | Acc: 49.004% (2854/5824)\n",
      "Epoch 6 Step 182/1563 Loss: 1.411 | Acc: 49.078% (2874/5856)\n",
      "Epoch 6 Step 183/1563 Loss: 1.410 | Acc: 49.117% (2892/5888)\n",
      "Epoch 6 Step 184/1563 Loss: 1.409 | Acc: 49.155% (2910/5920)\n",
      "Epoch 6 Step 185/1563 Loss: 1.409 | Acc: 49.160% (2926/5952)\n",
      "Epoch 6 Step 186/1563 Loss: 1.408 | Acc: 49.181% (2943/5984)\n",
      "Epoch 6 Step 187/1563 Loss: 1.406 | Acc: 49.235% (2962/6016)\n",
      "Epoch 6 Step 188/1563 Loss: 1.406 | Acc: 49.206% (2976/6048)\n",
      "Epoch 6 Step 189/1563 Loss: 1.408 | Acc: 49.178% (2990/6080)\n",
      "Epoch 6 Step 190/1563 Loss: 1.407 | Acc: 49.215% (3008/6112)\n",
      "Epoch 6 Step 191/1563 Loss: 1.406 | Acc: 49.219% (3024/6144)\n",
      "Epoch 6 Step 192/1563 Loss: 1.406 | Acc: 49.288% (3044/6176)\n",
      "Epoch 6 Step 193/1563 Loss: 1.405 | Acc: 49.323% (3062/6208)\n",
      "Epoch 6 Step 194/1563 Loss: 1.404 | Acc: 49.359% (3080/6240)\n",
      "Epoch 6 Step 195/1563 Loss: 1.404 | Acc: 49.362% (3096/6272)\n",
      "Epoch 6 Step 196/1563 Loss: 1.404 | Acc: 49.381% (3113/6304)\n",
      "Epoch 6 Step 197/1563 Loss: 1.404 | Acc: 49.353% (3127/6336)\n",
      "Epoch 6 Step 198/1563 Loss: 1.404 | Acc: 49.278% (3138/6368)\n",
      "Epoch 6 Step 199/1563 Loss: 1.404 | Acc: 49.328% (3157/6400)\n",
      "Epoch 6 Step 200/1563 Loss: 1.404 | Acc: 49.378% (3176/6432)\n",
      "Epoch 6 Step 201/1563 Loss: 1.403 | Acc: 49.381% (3192/6464)\n",
      "Epoch 6 Step 202/1563 Loss: 1.403 | Acc: 49.369% (3207/6496)\n",
      "Epoch 6 Step 203/1563 Loss: 1.404 | Acc: 49.326% (3220/6528)\n",
      "Epoch 6 Step 204/1563 Loss: 1.405 | Acc: 49.284% (3233/6560)\n",
      "Epoch 6 Step 205/1563 Loss: 1.405 | Acc: 49.302% (3250/6592)\n",
      "Epoch 6 Step 206/1563 Loss: 1.405 | Acc: 49.245% (3262/6624)\n",
      "Epoch 6 Step 207/1563 Loss: 1.407 | Acc: 49.174% (3273/6656)\n",
      "Epoch 6 Step 208/1563 Loss: 1.406 | Acc: 49.193% (3290/6688)\n",
      "Epoch 6 Step 209/1563 Loss: 1.405 | Acc: 49.196% (3306/6720)\n",
      "Epoch 6 Step 210/1563 Loss: 1.405 | Acc: 49.230% (3324/6752)\n",
      "Epoch 6 Step 211/1563 Loss: 1.404 | Acc: 49.278% (3343/6784)\n",
      "Epoch 6 Step 212/1563 Loss: 1.402 | Acc: 49.296% (3360/6816)\n",
      "Epoch 6 Step 213/1563 Loss: 1.402 | Acc: 49.284% (3375/6848)\n",
      "Epoch 6 Step 214/1563 Loss: 1.402 | Acc: 49.273% (3390/6880)\n",
      "Epoch 6 Step 215/1563 Loss: 1.402 | Acc: 49.262% (3405/6912)\n",
      "Epoch 6 Step 216/1563 Loss: 1.404 | Acc: 49.222% (3418/6944)\n",
      "Epoch 6 Step 217/1563 Loss: 1.404 | Acc: 49.183% (3431/6976)\n",
      "Epoch 6 Step 218/1563 Loss: 1.405 | Acc: 49.115% (3442/7008)\n",
      "Epoch 6 Step 219/1563 Loss: 1.405 | Acc: 49.091% (3456/7040)\n",
      "Epoch 6 Step 220/1563 Loss: 1.405 | Acc: 49.067% (3470/7072)\n",
      "Epoch 6 Step 221/1563 Loss: 1.404 | Acc: 49.085% (3487/7104)\n",
      "Epoch 6 Step 222/1563 Loss: 1.404 | Acc: 49.103% (3504/7136)\n",
      "Epoch 6 Step 223/1563 Loss: 1.406 | Acc: 49.009% (3513/7168)\n",
      "Epoch 6 Step 224/1563 Loss: 1.405 | Acc: 49.069% (3533/7200)\n",
      "Epoch 6 Step 225/1563 Loss: 1.405 | Acc: 49.046% (3547/7232)\n",
      "Epoch 6 Step 226/1563 Loss: 1.406 | Acc: 49.050% (3563/7264)\n",
      "Epoch 6 Step 227/1563 Loss: 1.405 | Acc: 49.095% (3582/7296)\n",
      "Epoch 6 Step 228/1563 Loss: 1.405 | Acc: 49.099% (3598/7328)\n",
      "Epoch 6 Step 229/1563 Loss: 1.406 | Acc: 49.117% (3615/7360)\n",
      "Epoch 6 Step 230/1563 Loss: 1.406 | Acc: 49.107% (3630/7392)\n",
      "Epoch 6 Step 231/1563 Loss: 1.406 | Acc: 49.098% (3645/7424)\n",
      "Epoch 6 Step 232/1563 Loss: 1.405 | Acc: 49.101% (3661/7456)\n",
      "Epoch 6 Step 233/1563 Loss: 1.405 | Acc: 49.119% (3678/7488)\n",
      "Epoch 6 Step 234/1563 Loss: 1.406 | Acc: 49.069% (3690/7520)\n",
      "Epoch 6 Step 235/1563 Loss: 1.407 | Acc: 49.047% (3704/7552)\n",
      "Epoch 6 Step 236/1563 Loss: 1.406 | Acc: 49.103% (3724/7584)\n",
      "Epoch 6 Step 237/1563 Loss: 1.405 | Acc: 49.173% (3745/7616)\n",
      "Epoch 6 Step 238/1563 Loss: 1.404 | Acc: 49.229% (3765/7648)\n",
      "Epoch 6 Step 239/1563 Loss: 1.403 | Acc: 49.258% (3783/7680)\n",
      "Epoch 6 Step 240/1563 Loss: 1.404 | Acc: 49.222% (3796/7712)\n",
      "Epoch 6 Step 241/1563 Loss: 1.404 | Acc: 49.225% (3812/7744)\n",
      "Epoch 6 Step 242/1563 Loss: 1.404 | Acc: 49.228% (3828/7776)\n",
      "Epoch 6 Step 243/1563 Loss: 1.404 | Acc: 49.232% (3844/7808)\n",
      "Epoch 6 Step 244/1563 Loss: 1.403 | Acc: 49.196% (3857/7840)\n",
      "Epoch 6 Step 245/1563 Loss: 1.404 | Acc: 49.162% (3870/7872)\n",
      "Epoch 6 Step 246/1563 Loss: 1.403 | Acc: 49.190% (3888/7904)\n",
      "Epoch 6 Step 247/1563 Loss: 1.404 | Acc: 49.181% (3903/7936)\n",
      "Epoch 6 Step 248/1563 Loss: 1.403 | Acc: 49.222% (3922/7968)\n",
      "Epoch 6 Step 249/1563 Loss: 1.402 | Acc: 49.237% (3939/8000)\n",
      "Epoch 6 Step 250/1563 Loss: 1.403 | Acc: 49.241% (3955/8032)\n",
      "Epoch 6 Step 251/1563 Loss: 1.403 | Acc: 49.231% (3970/8064)\n",
      "Epoch 6 Step 252/1563 Loss: 1.404 | Acc: 49.234% (3986/8096)\n",
      "Epoch 6 Step 253/1563 Loss: 1.404 | Acc: 49.237% (4002/8128)\n",
      "Epoch 6 Step 254/1563 Loss: 1.404 | Acc: 49.265% (4020/8160)\n",
      "Epoch 6 Step 255/1563 Loss: 1.403 | Acc: 49.255% (4035/8192)\n",
      "Epoch 6 Step 256/1563 Loss: 1.403 | Acc: 49.258% (4051/8224)\n",
      "Epoch 6 Step 257/1563 Loss: 1.404 | Acc: 49.237% (4065/8256)\n",
      "Epoch 6 Step 258/1563 Loss: 1.404 | Acc: 49.240% (4081/8288)\n",
      "Epoch 6 Step 259/1563 Loss: 1.404 | Acc: 49.291% (4101/8320)\n",
      "Epoch 6 Step 260/1563 Loss: 1.404 | Acc: 49.234% (4112/8352)\n",
      "Epoch 6 Step 261/1563 Loss: 1.404 | Acc: 49.260% (4130/8384)\n",
      "Epoch 6 Step 262/1563 Loss: 1.404 | Acc: 49.251% (4145/8416)\n",
      "Epoch 6 Step 263/1563 Loss: 1.403 | Acc: 49.278% (4163/8448)\n",
      "Epoch 6 Step 264/1563 Loss: 1.402 | Acc: 49.304% (4181/8480)\n",
      "Epoch 6 Step 265/1563 Loss: 1.402 | Acc: 49.319% (4198/8512)\n",
      "Epoch 6 Step 266/1563 Loss: 1.403 | Acc: 49.286% (4211/8544)\n",
      "Epoch 6 Step 267/1563 Loss: 1.403 | Acc: 49.265% (4225/8576)\n",
      "Epoch 6 Step 268/1563 Loss: 1.405 | Acc: 49.280% (4242/8608)\n",
      "Epoch 6 Step 269/1563 Loss: 1.404 | Acc: 49.317% (4261/8640)\n",
      "Epoch 6 Step 270/1563 Loss: 1.404 | Acc: 49.308% (4276/8672)\n",
      "Epoch 6 Step 271/1563 Loss: 1.404 | Acc: 49.322% (4293/8704)\n",
      "Epoch 6 Step 272/1563 Loss: 1.404 | Acc: 49.336% (4310/8736)\n",
      "Epoch 6 Step 273/1563 Loss: 1.404 | Acc: 49.339% (4326/8768)\n",
      "Epoch 6 Step 274/1563 Loss: 1.402 | Acc: 49.409% (4348/8800)\n",
      "Epoch 6 Step 275/1563 Loss: 1.402 | Acc: 49.400% (4363/8832)\n",
      "Epoch 6 Step 276/1563 Loss: 1.402 | Acc: 49.425% (4381/8864)\n",
      "Epoch 6 Step 277/1563 Loss: 1.402 | Acc: 49.404% (4395/8896)\n",
      "Epoch 6 Step 278/1563 Loss: 1.403 | Acc: 49.362% (4407/8928)\n",
      "Epoch 6 Step 279/1563 Loss: 1.403 | Acc: 49.342% (4421/8960)\n",
      "Epoch 6 Step 280/1563 Loss: 1.403 | Acc: 49.333% (4436/8992)\n",
      "Epoch 6 Step 281/1563 Loss: 1.403 | Acc: 49.379% (4456/9024)\n",
      "Epoch 6 Step 282/1563 Loss: 1.403 | Acc: 49.337% (4468/9056)\n",
      "Epoch 6 Step 283/1563 Loss: 1.403 | Acc: 49.340% (4484/9088)\n",
      "Epoch 6 Step 284/1563 Loss: 1.402 | Acc: 49.353% (4501/9120)\n",
      "Epoch 6 Step 285/1563 Loss: 1.401 | Acc: 49.388% (4520/9152)\n",
      "Epoch 6 Step 286/1563 Loss: 1.401 | Acc: 49.390% (4536/9184)\n",
      "Epoch 6 Step 287/1563 Loss: 1.401 | Acc: 49.403% (4553/9216)\n",
      "Epoch 6 Step 288/1563 Loss: 1.400 | Acc: 49.427% (4571/9248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 289/1563 Loss: 1.399 | Acc: 49.504% (4594/9280)\n",
      "Epoch 6 Step 290/1563 Loss: 1.400 | Acc: 49.463% (4606/9312)\n",
      "Epoch 6 Step 291/1563 Loss: 1.399 | Acc: 49.454% (4621/9344)\n",
      "Epoch 6 Step 292/1563 Loss: 1.399 | Acc: 49.477% (4639/9376)\n",
      "Epoch 6 Step 293/1563 Loss: 1.398 | Acc: 49.532% (4660/9408)\n",
      "Epoch 6 Step 294/1563 Loss: 1.397 | Acc: 49.587% (4681/9440)\n",
      "Epoch 6 Step 295/1563 Loss: 1.397 | Acc: 49.557% (4694/9472)\n",
      "Epoch 6 Step 296/1563 Loss: 1.397 | Acc: 49.527% (4707/9504)\n",
      "Epoch 6 Step 297/1563 Loss: 1.397 | Acc: 49.539% (4724/9536)\n",
      "Epoch 6 Step 298/1563 Loss: 1.397 | Acc: 49.530% (4739/9568)\n",
      "Epoch 6 Step 299/1563 Loss: 1.398 | Acc: 49.479% (4750/9600)\n",
      "Epoch 6 Step 300/1563 Loss: 1.398 | Acc: 49.481% (4766/9632)\n",
      "Epoch 6 Step 301/1563 Loss: 1.397 | Acc: 49.472% (4781/9664)\n",
      "Epoch 6 Step 302/1563 Loss: 1.397 | Acc: 49.464% (4796/9696)\n",
      "Epoch 6 Step 303/1563 Loss: 1.398 | Acc: 49.424% (4808/9728)\n",
      "Epoch 6 Step 304/1563 Loss: 1.398 | Acc: 49.447% (4826/9760)\n",
      "Epoch 6 Step 305/1563 Loss: 1.398 | Acc: 49.428% (4840/9792)\n",
      "Epoch 6 Step 306/1563 Loss: 1.398 | Acc: 49.440% (4857/9824)\n",
      "Epoch 6 Step 307/1563 Loss: 1.398 | Acc: 49.422% (4871/9856)\n",
      "Epoch 6 Step 308/1563 Loss: 1.398 | Acc: 49.434% (4888/9888)\n",
      "Epoch 6 Step 309/1563 Loss: 1.398 | Acc: 49.425% (4903/9920)\n",
      "Epoch 6 Step 310/1563 Loss: 1.398 | Acc: 49.457% (4922/9952)\n",
      "Epoch 6 Step 311/1563 Loss: 1.398 | Acc: 49.469% (4939/9984)\n",
      "Epoch 6 Step 312/1563 Loss: 1.398 | Acc: 49.441% (4952/10016)\n",
      "Epoch 6 Step 313/1563 Loss: 1.399 | Acc: 49.393% (4963/10048)\n",
      "Epoch 6 Step 314/1563 Loss: 1.400 | Acc: 49.375% (4977/10080)\n",
      "Epoch 6 Step 315/1563 Loss: 1.400 | Acc: 49.377% (4993/10112)\n",
      "Epoch 6 Step 316/1563 Loss: 1.401 | Acc: 49.349% (5006/10144)\n",
      "Epoch 6 Step 317/1563 Loss: 1.400 | Acc: 49.381% (5025/10176)\n",
      "Epoch 6 Step 318/1563 Loss: 1.400 | Acc: 49.393% (5042/10208)\n",
      "Epoch 6 Step 319/1563 Loss: 1.399 | Acc: 49.434% (5062/10240)\n",
      "Epoch 6 Step 320/1563 Loss: 1.399 | Acc: 49.455% (5080/10272)\n",
      "Epoch 6 Step 321/1563 Loss: 1.398 | Acc: 49.447% (5095/10304)\n",
      "Epoch 6 Step 322/1563 Loss: 1.399 | Acc: 49.429% (5109/10336)\n",
      "Epoch 6 Step 323/1563 Loss: 1.399 | Acc: 49.402% (5122/10368)\n",
      "Epoch 6 Step 324/1563 Loss: 1.399 | Acc: 49.404% (5138/10400)\n",
      "Epoch 6 Step 325/1563 Loss: 1.399 | Acc: 49.358% (5149/10432)\n",
      "Epoch 6 Step 326/1563 Loss: 1.399 | Acc: 49.398% (5169/10464)\n",
      "Epoch 6 Step 327/1563 Loss: 1.398 | Acc: 49.371% (5182/10496)\n",
      "Epoch 6 Step 328/1563 Loss: 1.398 | Acc: 49.383% (5199/10528)\n",
      "Epoch 6 Step 329/1563 Loss: 1.398 | Acc: 49.384% (5215/10560)\n",
      "Epoch 6 Step 330/1563 Loss: 1.398 | Acc: 49.367% (5229/10592)\n",
      "Epoch 6 Step 331/1563 Loss: 1.398 | Acc: 49.369% (5245/10624)\n",
      "Epoch 6 Step 332/1563 Loss: 1.398 | Acc: 49.390% (5263/10656)\n",
      "Epoch 6 Step 333/1563 Loss: 1.398 | Acc: 49.373% (5277/10688)\n",
      "Epoch 6 Step 334/1563 Loss: 1.398 | Acc: 49.366% (5292/10720)\n",
      "Epoch 6 Step 335/1563 Loss: 1.397 | Acc: 49.405% (5312/10752)\n",
      "Epoch 6 Step 336/1563 Loss: 1.396 | Acc: 49.416% (5329/10784)\n",
      "Epoch 6 Step 337/1563 Loss: 1.397 | Acc: 49.408% (5344/10816)\n",
      "Epoch 6 Step 338/1563 Loss: 1.398 | Acc: 49.382% (5357/10848)\n",
      "Epoch 6 Step 339/1563 Loss: 1.398 | Acc: 49.393% (5374/10880)\n",
      "Epoch 6 Step 340/1563 Loss: 1.397 | Acc: 49.395% (5390/10912)\n",
      "Epoch 6 Step 341/1563 Loss: 1.397 | Acc: 49.388% (5405/10944)\n",
      "Epoch 6 Step 342/1563 Loss: 1.397 | Acc: 49.380% (5420/10976)\n",
      "Epoch 6 Step 343/1563 Loss: 1.397 | Acc: 49.364% (5434/11008)\n",
      "Epoch 6 Step 344/1563 Loss: 1.397 | Acc: 49.411% (5455/11040)\n",
      "Epoch 6 Step 345/1563 Loss: 1.397 | Acc: 49.404% (5470/11072)\n",
      "Epoch 6 Step 346/1563 Loss: 1.397 | Acc: 49.397% (5485/11104)\n",
      "Epoch 6 Step 347/1563 Loss: 1.397 | Acc: 49.389% (5500/11136)\n",
      "Epoch 6 Step 348/1563 Loss: 1.397 | Acc: 49.337% (5510/11168)\n",
      "Epoch 6 Step 349/1563 Loss: 1.397 | Acc: 49.312% (5523/11200)\n",
      "Epoch 6 Step 350/1563 Loss: 1.397 | Acc: 49.350% (5543/11232)\n",
      "Epoch 6 Step 351/1563 Loss: 1.397 | Acc: 49.316% (5555/11264)\n",
      "Epoch 6 Step 352/1563 Loss: 1.397 | Acc: 49.336% (5573/11296)\n",
      "Epoch 6 Step 353/1563 Loss: 1.397 | Acc: 49.347% (5590/11328)\n",
      "Epoch 6 Step 354/1563 Loss: 1.396 | Acc: 49.357% (5607/11360)\n",
      "Epoch 6 Step 355/1563 Loss: 1.397 | Acc: 49.342% (5621/11392)\n",
      "Epoch 6 Step 356/1563 Loss: 1.397 | Acc: 49.317% (5634/11424)\n",
      "Epoch 6 Step 357/1563 Loss: 1.397 | Acc: 49.319% (5650/11456)\n",
      "Epoch 6 Step 358/1563 Loss: 1.396 | Acc: 49.312% (5665/11488)\n",
      "Epoch 6 Step 359/1563 Loss: 1.396 | Acc: 49.323% (5682/11520)\n",
      "Epoch 6 Step 360/1563 Loss: 1.397 | Acc: 49.316% (5697/11552)\n",
      "Epoch 6 Step 361/1563 Loss: 1.397 | Acc: 49.327% (5714/11584)\n",
      "Epoch 6 Step 362/1563 Loss: 1.398 | Acc: 49.277% (5724/11616)\n",
      "Epoch 6 Step 363/1563 Loss: 1.399 | Acc: 49.270% (5739/11648)\n",
      "Epoch 6 Step 364/1563 Loss: 1.398 | Acc: 49.264% (5754/11680)\n",
      "Epoch 6 Step 365/1563 Loss: 1.398 | Acc: 49.266% (5770/11712)\n",
      "Epoch 6 Step 366/1563 Loss: 1.399 | Acc: 49.285% (5788/11744)\n",
      "Epoch 6 Step 367/1563 Loss: 1.398 | Acc: 49.287% (5804/11776)\n",
      "Epoch 6 Step 368/1563 Loss: 1.399 | Acc: 49.280% (5819/11808)\n",
      "Epoch 6 Step 369/1563 Loss: 1.400 | Acc: 49.231% (5829/11840)\n",
      "Epoch 6 Step 370/1563 Loss: 1.401 | Acc: 49.183% (5839/11872)\n",
      "Epoch 6 Step 371/1563 Loss: 1.400 | Acc: 49.244% (5862/11904)\n",
      "Epoch 6 Step 372/1563 Loss: 1.400 | Acc: 49.238% (5877/11936)\n",
      "Epoch 6 Step 373/1563 Loss: 1.399 | Acc: 49.281% (5898/11968)\n",
      "Epoch 6 Step 374/1563 Loss: 1.399 | Acc: 49.283% (5914/12000)\n",
      "Epoch 6 Step 375/1563 Loss: 1.399 | Acc: 49.260% (5927/12032)\n",
      "Epoch 6 Step 376/1563 Loss: 1.399 | Acc: 49.262% (5943/12064)\n",
      "Epoch 6 Step 377/1563 Loss: 1.399 | Acc: 49.297% (5963/12096)\n",
      "Epoch 6 Step 378/1563 Loss: 1.398 | Acc: 49.316% (5981/12128)\n",
      "Epoch 6 Step 379/1563 Loss: 1.397 | Acc: 49.326% (5998/12160)\n",
      "Epoch 6 Step 380/1563 Loss: 1.397 | Acc: 49.352% (6017/12192)\n",
      "Epoch 6 Step 381/1563 Loss: 1.396 | Acc: 49.378% (6036/12224)\n",
      "Epoch 6 Step 382/1563 Loss: 1.396 | Acc: 49.380% (6052/12256)\n",
      "Epoch 6 Step 383/1563 Loss: 1.396 | Acc: 49.382% (6068/12288)\n",
      "Epoch 6 Step 384/1563 Loss: 1.397 | Acc: 49.343% (6079/12320)\n",
      "Epoch 6 Step 385/1563 Loss: 1.397 | Acc: 49.344% (6095/12352)\n",
      "Epoch 6 Step 386/1563 Loss: 1.397 | Acc: 49.338% (6110/12384)\n",
      "Epoch 6 Step 387/1563 Loss: 1.396 | Acc: 49.380% (6131/12416)\n",
      "Epoch 6 Step 388/1563 Loss: 1.397 | Acc: 49.317% (6139/12448)\n",
      "Epoch 6 Step 389/1563 Loss: 1.397 | Acc: 49.279% (6150/12480)\n",
      "Epoch 6 Step 390/1563 Loss: 1.398 | Acc: 49.289% (6167/12512)\n",
      "Epoch 6 Step 391/1563 Loss: 1.398 | Acc: 49.275% (6181/12544)\n",
      "Epoch 6 Step 392/1563 Loss: 1.398 | Acc: 49.268% (6196/12576)\n",
      "Epoch 6 Step 393/1563 Loss: 1.398 | Acc: 49.302% (6216/12608)\n",
      "Epoch 6 Step 394/1563 Loss: 1.397 | Acc: 49.312% (6233/12640)\n",
      "Epoch 6 Step 395/1563 Loss: 1.397 | Acc: 49.345% (6253/12672)\n",
      "Epoch 6 Step 396/1563 Loss: 1.397 | Acc: 49.331% (6267/12704)\n",
      "Epoch 6 Step 397/1563 Loss: 1.397 | Acc: 49.340% (6284/12736)\n",
      "Epoch 6 Step 398/1563 Loss: 1.397 | Acc: 49.342% (6300/12768)\n",
      "Epoch 6 Step 399/1563 Loss: 1.397 | Acc: 49.336% (6315/12800)\n",
      "Epoch 6 Step 400/1563 Loss: 1.397 | Acc: 49.330% (6330/12832)\n",
      "Epoch 6 Step 401/1563 Loss: 1.397 | Acc: 49.316% (6344/12864)\n",
      "Epoch 6 Step 402/1563 Loss: 1.398 | Acc: 49.287% (6356/12896)\n",
      "Epoch 6 Step 403/1563 Loss: 1.397 | Acc: 49.288% (6372/12928)\n",
      "Epoch 6 Step 404/1563 Loss: 1.397 | Acc: 49.290% (6388/12960)\n",
      "Epoch 6 Step 405/1563 Loss: 1.397 | Acc: 49.292% (6404/12992)\n",
      "Epoch 6 Step 406/1563 Loss: 1.397 | Acc: 49.271% (6417/13024)\n",
      "Epoch 6 Step 407/1563 Loss: 1.398 | Acc: 49.257% (6431/13056)\n",
      "Epoch 6 Step 408/1563 Loss: 1.398 | Acc: 49.251% (6446/13088)\n",
      "Epoch 6 Step 409/1563 Loss: 1.397 | Acc: 49.268% (6464/13120)\n",
      "Epoch 6 Step 410/1563 Loss: 1.398 | Acc: 49.224% (6474/13152)\n",
      "Epoch 6 Step 411/1563 Loss: 1.398 | Acc: 49.204% (6487/13184)\n",
      "Epoch 6 Step 412/1563 Loss: 1.399 | Acc: 49.175% (6499/13216)\n",
      "Epoch 6 Step 413/1563 Loss: 1.399 | Acc: 49.185% (6516/13248)\n",
      "Epoch 6 Step 414/1563 Loss: 1.399 | Acc: 49.179% (6531/13280)\n",
      "Epoch 6 Step 415/1563 Loss: 1.398 | Acc: 49.196% (6549/13312)\n",
      "Epoch 6 Step 416/1563 Loss: 1.398 | Acc: 49.206% (6566/13344)\n",
      "Epoch 6 Step 417/1563 Loss: 1.397 | Acc: 49.252% (6588/13376)\n",
      "Epoch 6 Step 418/1563 Loss: 1.398 | Acc: 49.232% (6601/13408)\n",
      "Epoch 6 Step 419/1563 Loss: 1.398 | Acc: 49.234% (6617/13440)\n",
      "Epoch 6 Step 420/1563 Loss: 1.398 | Acc: 49.235% (6633/13472)\n",
      "Epoch 6 Step 421/1563 Loss: 1.398 | Acc: 49.267% (6653/13504)\n",
      "Epoch 6 Step 422/1563 Loss: 1.398 | Acc: 49.239% (6665/13536)\n",
      "Epoch 6 Step 423/1563 Loss: 1.398 | Acc: 49.263% (6684/13568)\n",
      "Epoch 6 Step 424/1563 Loss: 1.398 | Acc: 49.250% (6698/13600)\n",
      "Epoch 6 Step 425/1563 Loss: 1.398 | Acc: 49.230% (6711/13632)\n",
      "Epoch 6 Step 426/1563 Loss: 1.397 | Acc: 49.246% (6729/13664)\n",
      "Epoch 6 Step 427/1563 Loss: 1.398 | Acc: 49.219% (6741/13696)\n",
      "Epoch 6 Step 428/1563 Loss: 1.398 | Acc: 49.213% (6756/13728)\n",
      "Epoch 6 Step 429/1563 Loss: 1.398 | Acc: 49.208% (6771/13760)\n",
      "Epoch 6 Step 430/1563 Loss: 1.397 | Acc: 49.246% (6792/13792)\n",
      "Epoch 6 Step 431/1563 Loss: 1.397 | Acc: 49.262% (6810/13824)\n",
      "Epoch 6 Step 432/1563 Loss: 1.397 | Acc: 49.242% (6823/13856)\n",
      "Epoch 6 Step 433/1563 Loss: 1.397 | Acc: 49.244% (6839/13888)\n",
      "Epoch 6 Step 434/1563 Loss: 1.397 | Acc: 49.210% (6850/13920)\n",
      "Epoch 6 Step 435/1563 Loss: 1.397 | Acc: 49.226% (6868/13952)\n",
      "Epoch 6 Step 436/1563 Loss: 1.397 | Acc: 49.221% (6883/13984)\n",
      "Epoch 6 Step 437/1563 Loss: 1.396 | Acc: 49.222% (6899/14016)\n",
      "Epoch 6 Step 438/1563 Loss: 1.397 | Acc: 49.231% (6916/14048)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 439/1563 Loss: 1.397 | Acc: 49.226% (6931/14080)\n",
      "Epoch 6 Step 440/1563 Loss: 1.397 | Acc: 49.249% (6950/14112)\n",
      "Epoch 6 Step 441/1563 Loss: 1.397 | Acc: 49.222% (6962/14144)\n",
      "Epoch 6 Step 442/1563 Loss: 1.397 | Acc: 49.217% (6977/14176)\n",
      "Epoch 6 Step 443/1563 Loss: 1.397 | Acc: 49.205% (6991/14208)\n",
      "Epoch 6 Step 444/1563 Loss: 1.398 | Acc: 49.185% (7004/14240)\n",
      "Epoch 6 Step 445/1563 Loss: 1.397 | Acc: 49.180% (7019/14272)\n",
      "Epoch 6 Step 446/1563 Loss: 1.397 | Acc: 49.189% (7036/14304)\n",
      "Epoch 6 Step 447/1563 Loss: 1.397 | Acc: 49.219% (7056/14336)\n",
      "Epoch 6 Step 448/1563 Loss: 1.397 | Acc: 49.227% (7073/14368)\n",
      "Epoch 6 Step 449/1563 Loss: 1.397 | Acc: 49.236% (7090/14400)\n",
      "Epoch 6 Step 450/1563 Loss: 1.397 | Acc: 49.203% (7101/14432)\n",
      "Epoch 6 Step 451/1563 Loss: 1.397 | Acc: 49.226% (7120/14464)\n",
      "Epoch 6 Step 452/1563 Loss: 1.397 | Acc: 49.220% (7135/14496)\n",
      "Epoch 6 Step 453/1563 Loss: 1.398 | Acc: 49.188% (7146/14528)\n",
      "Epoch 6 Step 454/1563 Loss: 1.398 | Acc: 49.196% (7163/14560)\n",
      "Epoch 6 Step 455/1563 Loss: 1.398 | Acc: 49.205% (7180/14592)\n",
      "Epoch 6 Step 456/1563 Loss: 1.398 | Acc: 49.200% (7195/14624)\n",
      "Epoch 6 Step 457/1563 Loss: 1.399 | Acc: 49.181% (7208/14656)\n",
      "Epoch 6 Step 458/1563 Loss: 1.399 | Acc: 49.183% (7224/14688)\n",
      "Epoch 6 Step 459/1563 Loss: 1.399 | Acc: 49.185% (7240/14720)\n",
      "Epoch 6 Step 460/1563 Loss: 1.399 | Acc: 49.187% (7256/14752)\n",
      "Epoch 6 Step 461/1563 Loss: 1.399 | Acc: 49.168% (7269/14784)\n",
      "Epoch 6 Step 462/1563 Loss: 1.399 | Acc: 49.143% (7281/14816)\n",
      "Epoch 6 Step 463/1563 Loss: 1.399 | Acc: 49.124% (7294/14848)\n",
      "Epoch 6 Step 464/1563 Loss: 1.399 | Acc: 49.126% (7310/14880)\n",
      "Epoch 6 Step 465/1563 Loss: 1.399 | Acc: 49.135% (7327/14912)\n",
      "Epoch 6 Step 466/1563 Loss: 1.399 | Acc: 49.130% (7342/14944)\n",
      "Epoch 6 Step 467/1563 Loss: 1.399 | Acc: 49.119% (7356/14976)\n",
      "Epoch 6 Step 468/1563 Loss: 1.399 | Acc: 49.120% (7372/15008)\n",
      "Epoch 6 Step 469/1563 Loss: 1.399 | Acc: 49.122% (7388/15040)\n",
      "Epoch 6 Step 470/1563 Loss: 1.398 | Acc: 49.191% (7414/15072)\n",
      "Epoch 6 Step 471/1563 Loss: 1.399 | Acc: 49.166% (7426/15104)\n",
      "Epoch 6 Step 472/1563 Loss: 1.398 | Acc: 49.168% (7442/15136)\n",
      "Epoch 6 Step 473/1563 Loss: 1.398 | Acc: 49.189% (7461/15168)\n",
      "Epoch 6 Step 474/1563 Loss: 1.398 | Acc: 49.211% (7480/15200)\n",
      "Epoch 6 Step 475/1563 Loss: 1.398 | Acc: 49.232% (7499/15232)\n",
      "Epoch 6 Step 476/1563 Loss: 1.398 | Acc: 49.247% (7517/15264)\n",
      "Epoch 6 Step 477/1563 Loss: 1.397 | Acc: 49.268% (7536/15296)\n",
      "Epoch 6 Step 478/1563 Loss: 1.398 | Acc: 49.256% (7550/15328)\n",
      "Epoch 6 Step 479/1563 Loss: 1.398 | Acc: 49.264% (7567/15360)\n",
      "Epoch 6 Step 480/1563 Loss: 1.398 | Acc: 49.253% (7581/15392)\n",
      "Epoch 6 Step 481/1563 Loss: 1.398 | Acc: 49.222% (7592/15424)\n",
      "Epoch 6 Step 482/1563 Loss: 1.398 | Acc: 49.249% (7612/15456)\n",
      "Epoch 6 Step 483/1563 Loss: 1.399 | Acc: 49.219% (7623/15488)\n",
      "Epoch 6 Step 484/1563 Loss: 1.400 | Acc: 49.201% (7636/15520)\n",
      "Epoch 6 Step 485/1563 Loss: 1.399 | Acc: 49.216% (7654/15552)\n",
      "Epoch 6 Step 486/1563 Loss: 1.399 | Acc: 49.211% (7669/15584)\n",
      "Epoch 6 Step 487/1563 Loss: 1.400 | Acc: 49.200% (7683/15616)\n",
      "Epoch 6 Step 488/1563 Loss: 1.401 | Acc: 49.208% (7700/15648)\n",
      "Epoch 6 Step 489/1563 Loss: 1.401 | Acc: 49.184% (7712/15680)\n",
      "Epoch 6 Step 490/1563 Loss: 1.401 | Acc: 49.211% (7732/15712)\n",
      "Epoch 6 Step 491/1563 Loss: 1.401 | Acc: 49.193% (7745/15744)\n",
      "Epoch 6 Step 492/1563 Loss: 1.400 | Acc: 49.201% (7762/15776)\n",
      "Epoch 6 Step 493/1563 Loss: 1.401 | Acc: 49.197% (7777/15808)\n",
      "Epoch 6 Step 494/1563 Loss: 1.401 | Acc: 49.217% (7796/15840)\n",
      "Epoch 6 Step 495/1563 Loss: 1.400 | Acc: 49.194% (7808/15872)\n",
      "Epoch 6 Step 496/1563 Loss: 1.400 | Acc: 49.201% (7825/15904)\n",
      "Epoch 6 Step 497/1563 Loss: 1.400 | Acc: 49.197% (7840/15936)\n",
      "Epoch 6 Step 498/1563 Loss: 1.400 | Acc: 49.198% (7856/15968)\n",
      "Epoch 6 Step 499/1563 Loss: 1.400 | Acc: 49.181% (7869/16000)\n",
      "Epoch 6 Step 500/1563 Loss: 1.400 | Acc: 49.177% (7884/16032)\n",
      "Epoch 6 Step 501/1563 Loss: 1.400 | Acc: 49.197% (7903/16064)\n",
      "Epoch 6 Step 502/1563 Loss: 1.401 | Acc: 49.161% (7913/16096)\n",
      "Epoch 6 Step 503/1563 Loss: 1.402 | Acc: 49.151% (7927/16128)\n",
      "Epoch 6 Step 504/1563 Loss: 1.402 | Acc: 49.158% (7944/16160)\n",
      "Epoch 6 Step 505/1563 Loss: 1.401 | Acc: 49.179% (7963/16192)\n",
      "Epoch 6 Step 506/1563 Loss: 1.402 | Acc: 49.168% (7977/16224)\n",
      "Epoch 6 Step 507/1563 Loss: 1.402 | Acc: 49.170% (7993/16256)\n",
      "Epoch 6 Step 508/1563 Loss: 1.402 | Acc: 49.177% (8010/16288)\n",
      "Epoch 6 Step 509/1563 Loss: 1.402 | Acc: 49.191% (8028/16320)\n",
      "Epoch 6 Step 510/1563 Loss: 1.403 | Acc: 49.187% (8043/16352)\n",
      "Epoch 6 Step 511/1563 Loss: 1.403 | Acc: 49.200% (8061/16384)\n",
      "Epoch 6 Step 512/1563 Loss: 1.404 | Acc: 49.196% (8076/16416)\n",
      "Epoch 6 Step 513/1563 Loss: 1.404 | Acc: 49.204% (8093/16448)\n",
      "Epoch 6 Step 514/1563 Loss: 1.404 | Acc: 49.211% (8110/16480)\n",
      "Epoch 6 Step 515/1563 Loss: 1.404 | Acc: 49.213% (8126/16512)\n",
      "Epoch 6 Step 516/1563 Loss: 1.404 | Acc: 49.226% (8144/16544)\n",
      "Epoch 6 Step 517/1563 Loss: 1.403 | Acc: 49.264% (8166/16576)\n",
      "Epoch 6 Step 518/1563 Loss: 1.403 | Acc: 49.241% (8178/16608)\n",
      "Epoch 6 Step 519/1563 Loss: 1.403 | Acc: 49.219% (8190/16640)\n",
      "Epoch 6 Step 520/1563 Loss: 1.404 | Acc: 49.208% (8204/16672)\n",
      "Epoch 6 Step 521/1563 Loss: 1.404 | Acc: 49.186% (8216/16704)\n",
      "Epoch 6 Step 522/1563 Loss: 1.404 | Acc: 49.193% (8233/16736)\n",
      "Epoch 6 Step 523/1563 Loss: 1.404 | Acc: 49.189% (8248/16768)\n",
      "Epoch 6 Step 524/1563 Loss: 1.404 | Acc: 49.196% (8265/16800)\n",
      "Epoch 6 Step 525/1563 Loss: 1.403 | Acc: 49.216% (8284/16832)\n",
      "Epoch 6 Step 526/1563 Loss: 1.403 | Acc: 49.235% (8303/16864)\n",
      "Epoch 6 Step 527/1563 Loss: 1.403 | Acc: 49.237% (8319/16896)\n",
      "Epoch 6 Step 528/1563 Loss: 1.403 | Acc: 49.267% (8340/16928)\n",
      "Epoch 6 Step 529/1563 Loss: 1.403 | Acc: 49.251% (8353/16960)\n",
      "Epoch 6 Step 530/1563 Loss: 1.403 | Acc: 49.241% (8367/16992)\n",
      "Epoch 6 Step 531/1563 Loss: 1.404 | Acc: 49.225% (8380/17024)\n",
      "Epoch 6 Step 532/1563 Loss: 1.404 | Acc: 49.226% (8396/17056)\n",
      "Epoch 6 Step 533/1563 Loss: 1.405 | Acc: 49.204% (8408/17088)\n",
      "Epoch 6 Step 534/1563 Loss: 1.405 | Acc: 49.194% (8422/17120)\n",
      "Epoch 6 Step 535/1563 Loss: 1.405 | Acc: 49.213% (8441/17152)\n",
      "Epoch 6 Step 536/1563 Loss: 1.405 | Acc: 49.203% (8455/17184)\n",
      "Epoch 6 Step 537/1563 Loss: 1.405 | Acc: 49.216% (8473/17216)\n",
      "Epoch 6 Step 538/1563 Loss: 1.405 | Acc: 49.212% (8488/17248)\n",
      "Epoch 6 Step 539/1563 Loss: 1.405 | Acc: 49.184% (8499/17280)\n",
      "Epoch 6 Step 540/1563 Loss: 1.406 | Acc: 49.180% (8514/17312)\n",
      "Epoch 6 Step 541/1563 Loss: 1.405 | Acc: 49.193% (8532/17344)\n",
      "Epoch 6 Step 542/1563 Loss: 1.405 | Acc: 49.200% (8549/17376)\n",
      "Epoch 6 Step 543/1563 Loss: 1.405 | Acc: 49.207% (8566/17408)\n",
      "Epoch 6 Step 544/1563 Loss: 1.405 | Acc: 49.197% (8580/17440)\n",
      "Epoch 6 Step 545/1563 Loss: 1.406 | Acc: 49.182% (8593/17472)\n",
      "Epoch 6 Step 546/1563 Loss: 1.406 | Acc: 49.154% (8604/17504)\n",
      "Epoch 6 Step 547/1563 Loss: 1.406 | Acc: 49.145% (8618/17536)\n",
      "Epoch 6 Step 548/1563 Loss: 1.406 | Acc: 49.135% (8632/17568)\n",
      "Epoch 6 Step 549/1563 Loss: 1.406 | Acc: 49.114% (8644/17600)\n",
      "Epoch 6 Step 550/1563 Loss: 1.406 | Acc: 49.115% (8660/17632)\n",
      "Epoch 6 Step 551/1563 Loss: 1.406 | Acc: 49.106% (8674/17664)\n",
      "Epoch 6 Step 552/1563 Loss: 1.406 | Acc: 49.107% (8690/17696)\n",
      "Epoch 6 Step 553/1563 Loss: 1.407 | Acc: 49.092% (8703/17728)\n",
      "Epoch 6 Step 554/1563 Loss: 1.407 | Acc: 49.093% (8719/17760)\n",
      "Epoch 6 Step 555/1563 Loss: 1.407 | Acc: 49.084% (8733/17792)\n",
      "Epoch 6 Step 556/1563 Loss: 1.407 | Acc: 49.102% (8752/17824)\n",
      "Epoch 6 Step 557/1563 Loss: 1.408 | Acc: 49.093% (8766/17856)\n",
      "Epoch 6 Step 558/1563 Loss: 1.408 | Acc: 49.094% (8782/17888)\n",
      "Epoch 6 Step 559/1563 Loss: 1.408 | Acc: 49.096% (8798/17920)\n",
      "Epoch 6 Step 560/1563 Loss: 1.408 | Acc: 49.098% (8814/17952)\n",
      "Epoch 6 Step 561/1563 Loss: 1.408 | Acc: 49.105% (8831/17984)\n",
      "Epoch 6 Step 562/1563 Loss: 1.408 | Acc: 49.123% (8850/18016)\n",
      "Epoch 6 Step 563/1563 Loss: 1.408 | Acc: 49.119% (8865/18048)\n",
      "Epoch 6 Step 564/1563 Loss: 1.407 | Acc: 49.148% (8886/18080)\n",
      "Epoch 6 Step 565/1563 Loss: 1.407 | Acc: 49.139% (8900/18112)\n",
      "Epoch 6 Step 566/1563 Loss: 1.407 | Acc: 49.140% (8916/18144)\n",
      "Epoch 6 Step 567/1563 Loss: 1.407 | Acc: 49.153% (8934/18176)\n",
      "Epoch 6 Step 568/1563 Loss: 1.406 | Acc: 49.187% (8956/18208)\n",
      "Epoch 6 Step 569/1563 Loss: 1.407 | Acc: 49.167% (8968/18240)\n",
      "Epoch 6 Step 570/1563 Loss: 1.407 | Acc: 49.157% (8982/18272)\n",
      "Epoch 6 Step 571/1563 Loss: 1.406 | Acc: 49.181% (9002/18304)\n",
      "Epoch 6 Step 572/1563 Loss: 1.407 | Acc: 49.187% (9019/18336)\n",
      "Epoch 6 Step 573/1563 Loss: 1.406 | Acc: 49.200% (9037/18368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 574/1563 Loss: 1.407 | Acc: 49.201% (9053/18400)\n",
      "Epoch 6 Step 575/1563 Loss: 1.407 | Acc: 49.186% (9066/18432)\n",
      "Epoch 6 Step 576/1563 Loss: 1.407 | Acc: 49.198% (9084/18464)\n",
      "Epoch 6 Step 577/1563 Loss: 1.406 | Acc: 49.216% (9103/18496)\n",
      "Epoch 6 Step 578/1563 Loss: 1.406 | Acc: 49.234% (9122/18528)\n",
      "Epoch 6 Step 579/1563 Loss: 1.406 | Acc: 49.208% (9133/18560)\n",
      "Epoch 6 Step 580/1563 Loss: 1.406 | Acc: 49.225% (9152/18592)\n",
      "Epoch 6 Step 581/1563 Loss: 1.406 | Acc: 49.221% (9167/18624)\n",
      "Epoch 6 Step 582/1563 Loss: 1.406 | Acc: 49.217% (9182/18656)\n",
      "Epoch 6 Step 583/1563 Loss: 1.406 | Acc: 49.224% (9199/18688)\n",
      "Epoch 6 Step 584/1563 Loss: 1.406 | Acc: 49.225% (9215/18720)\n",
      "Epoch 6 Step 585/1563 Loss: 1.406 | Acc: 49.227% (9231/18752)\n",
      "Epoch 6 Step 586/1563 Loss: 1.407 | Acc: 49.207% (9243/18784)\n",
      "Epoch 6 Step 587/1563 Loss: 1.407 | Acc: 49.171% (9252/18816)\n",
      "Epoch 6 Step 588/1563 Loss: 1.407 | Acc: 49.156% (9265/18848)\n",
      "Epoch 6 Step 589/1563 Loss: 1.407 | Acc: 49.137% (9277/18880)\n",
      "Epoch 6 Step 590/1563 Loss: 1.407 | Acc: 49.149% (9295/18912)\n",
      "Epoch 6 Step 591/1563 Loss: 1.407 | Acc: 49.140% (9309/18944)\n",
      "Epoch 6 Step 592/1563 Loss: 1.407 | Acc: 49.152% (9327/18976)\n",
      "Epoch 6 Step 593/1563 Loss: 1.407 | Acc: 49.164% (9345/19008)\n",
      "Epoch 6 Step 594/1563 Loss: 1.407 | Acc: 49.133% (9355/19040)\n",
      "Epoch 6 Step 595/1563 Loss: 1.407 | Acc: 49.130% (9370/19072)\n",
      "Epoch 6 Step 596/1563 Loss: 1.408 | Acc: 49.121% (9384/19104)\n",
      "Epoch 6 Step 597/1563 Loss: 1.408 | Acc: 49.091% (9394/19136)\n",
      "Epoch 6 Step 598/1563 Loss: 1.408 | Acc: 49.071% (9406/19168)\n",
      "Epoch 6 Step 599/1563 Loss: 1.408 | Acc: 49.042% (9416/19200)\n",
      "Epoch 6 Step 600/1563 Loss: 1.408 | Acc: 49.074% (9438/19232)\n",
      "Epoch 6 Step 601/1563 Loss: 1.408 | Acc: 49.076% (9454/19264)\n",
      "Epoch 6 Step 602/1563 Loss: 1.408 | Acc: 49.072% (9469/19296)\n",
      "Epoch 6 Step 603/1563 Loss: 1.408 | Acc: 49.069% (9484/19328)\n",
      "Epoch 6 Step 604/1563 Loss: 1.408 | Acc: 49.081% (9502/19360)\n",
      "Epoch 6 Step 605/1563 Loss: 1.407 | Acc: 49.098% (9521/19392)\n",
      "Epoch 6 Step 606/1563 Loss: 1.408 | Acc: 49.089% (9535/19424)\n",
      "Epoch 6 Step 607/1563 Loss: 1.407 | Acc: 49.085% (9550/19456)\n",
      "Epoch 6 Step 608/1563 Loss: 1.407 | Acc: 49.097% (9568/19488)\n",
      "Epoch 6 Step 609/1563 Loss: 1.407 | Acc: 49.083% (9581/19520)\n",
      "Epoch 6 Step 610/1563 Loss: 1.408 | Acc: 49.069% (9594/19552)\n",
      "Epoch 6 Step 611/1563 Loss: 1.408 | Acc: 49.060% (9608/19584)\n",
      "Epoch 6 Step 612/1563 Loss: 1.408 | Acc: 49.047% (9621/19616)\n",
      "Epoch 6 Step 613/1563 Loss: 1.408 | Acc: 49.043% (9636/19648)\n",
      "Epoch 6 Step 614/1563 Loss: 1.408 | Acc: 49.055% (9654/19680)\n",
      "Epoch 6 Step 615/1563 Loss: 1.408 | Acc: 49.072% (9673/19712)\n",
      "Epoch 6 Step 616/1563 Loss: 1.408 | Acc: 49.088% (9692/19744)\n",
      "Epoch 6 Step 617/1563 Loss: 1.408 | Acc: 49.080% (9706/19776)\n",
      "Epoch 6 Step 618/1563 Loss: 1.408 | Acc: 49.091% (9724/19808)\n",
      "Epoch 6 Step 619/1563 Loss: 1.408 | Acc: 49.093% (9740/19840)\n",
      "Epoch 6 Step 620/1563 Loss: 1.409 | Acc: 49.079% (9753/19872)\n",
      "Epoch 6 Step 621/1563 Loss: 1.409 | Acc: 49.076% (9768/19904)\n",
      "Epoch 6 Step 622/1563 Loss: 1.409 | Acc: 49.097% (9788/19936)\n",
      "Epoch 6 Step 623/1563 Loss: 1.408 | Acc: 49.109% (9806/19968)\n",
      "Epoch 6 Step 624/1563 Loss: 1.408 | Acc: 49.095% (9819/20000)\n",
      "Epoch 6 Step 625/1563 Loss: 1.408 | Acc: 49.096% (9835/20032)\n",
      "Epoch 6 Step 626/1563 Loss: 1.409 | Acc: 49.083% (9848/20064)\n",
      "Epoch 6 Step 627/1563 Loss: 1.409 | Acc: 49.074% (9862/20096)\n",
      "Epoch 6 Step 628/1563 Loss: 1.410 | Acc: 49.061% (9875/20128)\n",
      "Epoch 6 Step 629/1563 Loss: 1.410 | Acc: 49.038% (9886/20160)\n",
      "Epoch 6 Step 630/1563 Loss: 1.410 | Acc: 49.044% (9903/20192)\n",
      "Epoch 6 Step 631/1563 Loss: 1.410 | Acc: 49.026% (9915/20224)\n",
      "Epoch 6 Step 632/1563 Loss: 1.410 | Acc: 49.027% (9931/20256)\n",
      "Epoch 6 Step 633/1563 Loss: 1.410 | Acc: 49.024% (9946/20288)\n",
      "Epoch 6 Step 634/1563 Loss: 1.409 | Acc: 49.031% (9963/20320)\n",
      "Epoch 6 Step 635/1563 Loss: 1.409 | Acc: 49.062% (9985/20352)\n",
      "Epoch 6 Step 636/1563 Loss: 1.409 | Acc: 49.063% (10001/20384)\n",
      "Epoch 6 Step 637/1563 Loss: 1.409 | Acc: 49.050% (10014/20416)\n",
      "Epoch 6 Step 638/1563 Loss: 1.408 | Acc: 49.051% (10030/20448)\n",
      "Epoch 6 Step 639/1563 Loss: 1.408 | Acc: 49.067% (10049/20480)\n",
      "Epoch 6 Step 640/1563 Loss: 1.408 | Acc: 49.069% (10065/20512)\n",
      "Epoch 6 Step 641/1563 Loss: 1.409 | Acc: 49.065% (10080/20544)\n",
      "Epoch 6 Step 642/1563 Loss: 1.408 | Acc: 49.067% (10096/20576)\n",
      "Epoch 6 Step 643/1563 Loss: 1.408 | Acc: 49.083% (10115/20608)\n",
      "Epoch 6 Step 644/1563 Loss: 1.407 | Acc: 49.089% (10132/20640)\n",
      "Epoch 6 Step 645/1563 Loss: 1.407 | Acc: 49.086% (10147/20672)\n",
      "Epoch 6 Step 646/1563 Loss: 1.408 | Acc: 49.058% (10157/20704)\n",
      "Epoch 6 Step 647/1563 Loss: 1.408 | Acc: 49.040% (10169/20736)\n",
      "Epoch 6 Step 648/1563 Loss: 1.408 | Acc: 49.023% (10181/20768)\n",
      "Epoch 6 Step 649/1563 Loss: 1.409 | Acc: 49.010% (10194/20800)\n",
      "Epoch 6 Step 650/1563 Loss: 1.409 | Acc: 48.997% (10207/20832)\n",
      "Epoch 6 Step 651/1563 Loss: 1.409 | Acc: 49.013% (10226/20864)\n",
      "Epoch 6 Step 652/1563 Loss: 1.409 | Acc: 49.005% (10240/20896)\n",
      "Epoch 6 Step 653/1563 Loss: 1.409 | Acc: 48.997% (10254/20928)\n",
      "Epoch 6 Step 654/1563 Loss: 1.409 | Acc: 49.003% (10271/20960)\n",
      "Epoch 6 Step 655/1563 Loss: 1.409 | Acc: 48.995% (10285/20992)\n",
      "Epoch 6 Step 656/1563 Loss: 1.409 | Acc: 48.996% (10301/21024)\n",
      "Epoch 6 Step 657/1563 Loss: 1.409 | Acc: 49.003% (10318/21056)\n",
      "Epoch 6 Step 658/1563 Loss: 1.409 | Acc: 48.995% (10332/21088)\n",
      "Epoch 6 Step 659/1563 Loss: 1.408 | Acc: 49.006% (10350/21120)\n",
      "Epoch 6 Step 660/1563 Loss: 1.408 | Acc: 49.017% (10368/21152)\n",
      "Epoch 6 Step 661/1563 Loss: 1.408 | Acc: 49.023% (10385/21184)\n",
      "Epoch 6 Step 662/1563 Loss: 1.408 | Acc: 49.038% (10404/21216)\n",
      "Epoch 6 Step 663/1563 Loss: 1.408 | Acc: 49.040% (10420/21248)\n",
      "Epoch 6 Step 664/1563 Loss: 1.407 | Acc: 49.041% (10436/21280)\n",
      "Epoch 6 Step 665/1563 Loss: 1.407 | Acc: 49.047% (10453/21312)\n",
      "Epoch 6 Step 666/1563 Loss: 1.407 | Acc: 49.040% (10467/21344)\n",
      "Epoch 6 Step 667/1563 Loss: 1.407 | Acc: 49.036% (10482/21376)\n",
      "Epoch 6 Step 668/1563 Loss: 1.408 | Acc: 49.024% (10495/21408)\n",
      "Epoch 6 Step 669/1563 Loss: 1.408 | Acc: 49.044% (10515/21440)\n",
      "Epoch 6 Step 670/1563 Loss: 1.408 | Acc: 49.036% (10529/21472)\n",
      "Epoch 6 Step 671/1563 Loss: 1.408 | Acc: 49.042% (10546/21504)\n",
      "Epoch 6 Step 672/1563 Loss: 1.408 | Acc: 49.043% (10562/21536)\n",
      "Epoch 6 Step 673/1563 Loss: 1.408 | Acc: 49.050% (10579/21568)\n",
      "Epoch 6 Step 674/1563 Loss: 1.408 | Acc: 49.051% (10595/21600)\n",
      "Epoch 6 Step 675/1563 Loss: 1.408 | Acc: 49.052% (10611/21632)\n",
      "Epoch 6 Step 676/1563 Loss: 1.409 | Acc: 49.031% (10622/21664)\n",
      "Epoch 6 Step 677/1563 Loss: 1.409 | Acc: 49.051% (10642/21696)\n",
      "Epoch 6 Step 678/1563 Loss: 1.409 | Acc: 49.047% (10657/21728)\n",
      "Epoch 6 Step 679/1563 Loss: 1.409 | Acc: 49.044% (10672/21760)\n",
      "Epoch 6 Step 680/1563 Loss: 1.409 | Acc: 49.046% (10688/21792)\n",
      "Epoch 6 Step 681/1563 Loss: 1.409 | Acc: 49.033% (10701/21824)\n",
      "Epoch 6 Step 682/1563 Loss: 1.409 | Acc: 49.035% (10717/21856)\n",
      "Epoch 6 Step 683/1563 Loss: 1.409 | Acc: 49.045% (10735/21888)\n",
      "Epoch 6 Step 684/1563 Loss: 1.409 | Acc: 49.037% (10749/21920)\n",
      "Epoch 6 Step 685/1563 Loss: 1.409 | Acc: 49.043% (10766/21952)\n",
      "Epoch 6 Step 686/1563 Loss: 1.409 | Acc: 49.040% (10781/21984)\n",
      "Epoch 6 Step 687/1563 Loss: 1.409 | Acc: 49.042% (10797/22016)\n",
      "Epoch 6 Step 688/1563 Loss: 1.409 | Acc: 49.066% (10818/22048)\n",
      "Epoch 6 Step 689/1563 Loss: 1.409 | Acc: 49.058% (10832/22080)\n",
      "Epoch 6 Step 690/1563 Loss: 1.409 | Acc: 49.068% (10850/22112)\n",
      "Epoch 6 Step 691/1563 Loss: 1.409 | Acc: 49.065% (10865/22144)\n",
      "Epoch 6 Step 692/1563 Loss: 1.409 | Acc: 49.071% (10882/22176)\n",
      "Epoch 6 Step 693/1563 Loss: 1.410 | Acc: 49.068% (10897/22208)\n",
      "Epoch 6 Step 694/1563 Loss: 1.409 | Acc: 49.087% (10917/22240)\n",
      "Epoch 6 Step 695/1563 Loss: 1.409 | Acc: 49.093% (10934/22272)\n",
      "Epoch 6 Step 696/1563 Loss: 1.409 | Acc: 49.085% (10948/22304)\n",
      "Epoch 6 Step 697/1563 Loss: 1.409 | Acc: 49.082% (10963/22336)\n",
      "Epoch 6 Step 698/1563 Loss: 1.410 | Acc: 49.070% (10976/22368)\n",
      "Epoch 6 Step 699/1563 Loss: 1.409 | Acc: 49.085% (10995/22400)\n",
      "Epoch 6 Step 700/1563 Loss: 1.410 | Acc: 49.082% (11010/22432)\n",
      "Epoch 6 Step 701/1563 Loss: 1.410 | Acc: 49.074% (11024/22464)\n",
      "Epoch 6 Step 702/1563 Loss: 1.410 | Acc: 49.093% (11044/22496)\n",
      "Epoch 6 Step 703/1563 Loss: 1.410 | Acc: 49.063% (11053/22528)\n",
      "Epoch 6 Step 704/1563 Loss: 1.410 | Acc: 49.069% (11070/22560)\n",
      "Epoch 6 Step 705/1563 Loss: 1.410 | Acc: 49.066% (11085/22592)\n",
      "Epoch 6 Step 706/1563 Loss: 1.410 | Acc: 49.063% (11100/22624)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 707/1563 Loss: 1.410 | Acc: 49.073% (11118/22656)\n",
      "Epoch 6 Step 708/1563 Loss: 1.410 | Acc: 49.079% (11135/22688)\n",
      "Epoch 6 Step 709/1563 Loss: 1.410 | Acc: 49.067% (11148/22720)\n",
      "Epoch 6 Step 710/1563 Loss: 1.410 | Acc: 49.086% (11168/22752)\n",
      "Epoch 6 Step 711/1563 Loss: 1.410 | Acc: 49.105% (11188/22784)\n",
      "Epoch 6 Step 712/1563 Loss: 1.410 | Acc: 49.106% (11204/22816)\n",
      "Epoch 6 Step 713/1563 Loss: 1.410 | Acc: 49.098% (11218/22848)\n",
      "Epoch 6 Step 714/1563 Loss: 1.410 | Acc: 49.091% (11232/22880)\n",
      "Epoch 6 Step 715/1563 Loss: 1.410 | Acc: 49.097% (11249/22912)\n",
      "Epoch 6 Step 716/1563 Loss: 1.410 | Acc: 49.085% (11262/22944)\n",
      "Epoch 6 Step 717/1563 Loss: 1.410 | Acc: 49.077% (11276/22976)\n",
      "Epoch 6 Step 718/1563 Loss: 1.410 | Acc: 49.092% (11295/23008)\n",
      "Epoch 6 Step 719/1563 Loss: 1.410 | Acc: 49.089% (11310/23040)\n",
      "Epoch 6 Step 720/1563 Loss: 1.410 | Acc: 49.077% (11323/23072)\n",
      "Epoch 6 Step 721/1563 Loss: 1.410 | Acc: 49.082% (11340/23104)\n",
      "Epoch 6 Step 722/1563 Loss: 1.411 | Acc: 49.058% (11350/23136)\n",
      "Epoch 6 Step 723/1563 Loss: 1.411 | Acc: 49.042% (11362/23168)\n",
      "Epoch 6 Step 724/1563 Loss: 1.411 | Acc: 49.056% (11381/23200)\n",
      "Epoch 6 Step 725/1563 Loss: 1.411 | Acc: 49.062% (11398/23232)\n",
      "Epoch 6 Step 726/1563 Loss: 1.411 | Acc: 49.067% (11415/23264)\n",
      "Epoch 6 Step 727/1563 Loss: 1.410 | Acc: 49.077% (11433/23296)\n",
      "Epoch 6 Step 728/1563 Loss: 1.410 | Acc: 49.083% (11450/23328)\n",
      "Epoch 6 Step 729/1563 Loss: 1.410 | Acc: 49.080% (11465/23360)\n",
      "Epoch 6 Step 730/1563 Loss: 1.411 | Acc: 49.060% (11476/23392)\n",
      "Epoch 6 Step 731/1563 Loss: 1.410 | Acc: 49.044% (11488/23424)\n",
      "Epoch 6 Step 732/1563 Loss: 1.410 | Acc: 49.036% (11502/23456)\n",
      "Epoch 6 Step 733/1563 Loss: 1.410 | Acc: 49.038% (11518/23488)\n",
      "Epoch 6 Step 734/1563 Loss: 1.411 | Acc: 49.022% (11530/23520)\n",
      "Epoch 6 Step 735/1563 Loss: 1.411 | Acc: 48.998% (11540/23552)\n",
      "Epoch 6 Step 736/1563 Loss: 1.411 | Acc: 48.991% (11554/23584)\n",
      "Epoch 6 Step 737/1563 Loss: 1.411 | Acc: 48.992% (11570/23616)\n",
      "Epoch 6 Step 738/1563 Loss: 1.411 | Acc: 49.002% (11588/23648)\n",
      "Epoch 6 Step 739/1563 Loss: 1.411 | Acc: 49.016% (11607/23680)\n",
      "Epoch 6 Step 740/1563 Loss: 1.411 | Acc: 49.013% (11622/23712)\n",
      "Epoch 6 Step 741/1563 Loss: 1.411 | Acc: 48.998% (11634/23744)\n",
      "Epoch 6 Step 742/1563 Loss: 1.410 | Acc: 49.020% (11655/23776)\n",
      "Epoch 6 Step 743/1563 Loss: 1.410 | Acc: 49.009% (11668/23808)\n",
      "Epoch 6 Step 744/1563 Loss: 1.410 | Acc: 49.010% (11684/23840)\n",
      "Epoch 6 Step 745/1563 Loss: 1.410 | Acc: 49.011% (11700/23872)\n",
      "Epoch 6 Step 746/1563 Loss: 1.410 | Acc: 49.009% (11715/23904)\n",
      "Epoch 6 Step 747/1563 Loss: 1.410 | Acc: 49.018% (11733/23936)\n",
      "Epoch 6 Step 748/1563 Loss: 1.411 | Acc: 49.020% (11749/23968)\n",
      "Epoch 6 Step 749/1563 Loss: 1.410 | Acc: 49.021% (11765/24000)\n",
      "Epoch 6 Step 750/1563 Loss: 1.410 | Acc: 49.039% (11785/24032)\n",
      "Epoch 6 Step 751/1563 Loss: 1.410 | Acc: 49.036% (11800/24064)\n",
      "Epoch 6 Step 752/1563 Loss: 1.410 | Acc: 49.033% (11815/24096)\n",
      "Epoch 6 Step 753/1563 Loss: 1.410 | Acc: 49.022% (11828/24128)\n",
      "Epoch 6 Step 754/1563 Loss: 1.410 | Acc: 49.019% (11843/24160)\n",
      "Epoch 6 Step 755/1563 Loss: 1.410 | Acc: 49.016% (11858/24192)\n",
      "Epoch 6 Step 756/1563 Loss: 1.411 | Acc: 49.005% (11871/24224)\n",
      "Epoch 6 Step 757/1563 Loss: 1.411 | Acc: 48.994% (11884/24256)\n",
      "Epoch 6 Step 758/1563 Loss: 1.411 | Acc: 49.000% (11901/24288)\n",
      "Epoch 6 Step 759/1563 Loss: 1.411 | Acc: 48.993% (11915/24320)\n",
      "Epoch 6 Step 760/1563 Loss: 1.411 | Acc: 48.973% (11926/24352)\n",
      "Epoch 6 Step 761/1563 Loss: 1.411 | Acc: 48.971% (11941/24384)\n",
      "Epoch 6 Step 762/1563 Loss: 1.411 | Acc: 48.964% (11955/24416)\n",
      "Epoch 6 Step 763/1563 Loss: 1.412 | Acc: 48.965% (11971/24448)\n",
      "Epoch 6 Step 764/1563 Loss: 1.411 | Acc: 48.979% (11990/24480)\n",
      "Epoch 6 Step 765/1563 Loss: 1.412 | Acc: 48.960% (12001/24512)\n",
      "Epoch 6 Step 766/1563 Loss: 1.411 | Acc: 48.973% (12020/24544)\n",
      "Epoch 6 Step 767/1563 Loss: 1.411 | Acc: 48.995% (12041/24576)\n",
      "Epoch 6 Step 768/1563 Loss: 1.411 | Acc: 48.988% (12055/24608)\n",
      "Epoch 6 Step 769/1563 Loss: 1.411 | Acc: 48.985% (12070/24640)\n",
      "Epoch 6 Step 770/1563 Loss: 1.411 | Acc: 49.007% (12091/24672)\n",
      "Epoch 6 Step 771/1563 Loss: 1.411 | Acc: 49.000% (12105/24704)\n",
      "Epoch 6 Step 772/1563 Loss: 1.411 | Acc: 49.005% (12122/24736)\n",
      "Epoch 6 Step 773/1563 Loss: 1.411 | Acc: 49.015% (12140/24768)\n",
      "Epoch 6 Step 774/1563 Loss: 1.411 | Acc: 49.020% (12157/24800)\n",
      "Epoch 6 Step 775/1563 Loss: 1.411 | Acc: 49.017% (12172/24832)\n",
      "Epoch 6 Step 776/1563 Loss: 1.411 | Acc: 49.023% (12189/24864)\n",
      "Epoch 6 Step 777/1563 Loss: 1.411 | Acc: 49.028% (12206/24896)\n",
      "Epoch 6 Step 778/1563 Loss: 1.411 | Acc: 49.033% (12223/24928)\n",
      "Epoch 6 Step 779/1563 Loss: 1.411 | Acc: 49.026% (12237/24960)\n",
      "Epoch 6 Step 780/1563 Loss: 1.411 | Acc: 49.012% (12249/24992)\n",
      "Epoch 6 Step 781/1563 Loss: 1.411 | Acc: 49.013% (12265/25024)\n",
      "Epoch 6 Step 782/1563 Loss: 1.411 | Acc: 49.034% (12286/25056)\n",
      "Epoch 6 Step 783/1563 Loss: 1.411 | Acc: 49.031% (12301/25088)\n",
      "Epoch 6 Step 784/1563 Loss: 1.411 | Acc: 49.021% (12314/25120)\n",
      "Epoch 6 Step 785/1563 Loss: 1.411 | Acc: 49.026% (12331/25152)\n",
      "Epoch 6 Step 786/1563 Loss: 1.411 | Acc: 49.047% (12352/25184)\n",
      "Epoch 6 Step 787/1563 Loss: 1.411 | Acc: 49.036% (12365/25216)\n",
      "Epoch 6 Step 788/1563 Loss: 1.411 | Acc: 49.057% (12386/25248)\n",
      "Epoch 6 Step 789/1563 Loss: 1.411 | Acc: 49.062% (12403/25280)\n",
      "Epoch 6 Step 790/1563 Loss: 1.411 | Acc: 49.064% (12419/25312)\n",
      "Epoch 6 Step 791/1563 Loss: 1.411 | Acc: 49.077% (12438/25344)\n",
      "Epoch 6 Step 792/1563 Loss: 1.411 | Acc: 49.074% (12453/25376)\n",
      "Epoch 6 Step 793/1563 Loss: 1.410 | Acc: 49.091% (12473/25408)\n",
      "Epoch 6 Step 794/1563 Loss: 1.410 | Acc: 49.072% (12484/25440)\n",
      "Epoch 6 Step 795/1563 Loss: 1.410 | Acc: 49.073% (12500/25472)\n",
      "Epoch 6 Step 796/1563 Loss: 1.410 | Acc: 49.075% (12516/25504)\n",
      "Epoch 6 Step 797/1563 Loss: 1.410 | Acc: 49.064% (12529/25536)\n",
      "Epoch 6 Step 798/1563 Loss: 1.410 | Acc: 49.057% (12543/25568)\n",
      "Epoch 6 Step 799/1563 Loss: 1.410 | Acc: 49.055% (12558/25600)\n",
      "Epoch 6 Step 800/1563 Loss: 1.410 | Acc: 49.036% (12569/25632)\n",
      "Epoch 6 Step 801/1563 Loss: 1.411 | Acc: 49.030% (12583/25664)\n",
      "Epoch 6 Step 802/1563 Loss: 1.410 | Acc: 49.027% (12598/25696)\n",
      "Epoch 6 Step 803/1563 Loss: 1.410 | Acc: 49.028% (12614/25728)\n",
      "Epoch 6 Step 804/1563 Loss: 1.410 | Acc: 49.033% (12631/25760)\n",
      "Epoch 6 Step 805/1563 Loss: 1.410 | Acc: 49.019% (12643/25792)\n",
      "Epoch 6 Step 806/1563 Loss: 1.410 | Acc: 49.036% (12663/25824)\n",
      "Epoch 6 Step 807/1563 Loss: 1.410 | Acc: 49.049% (12682/25856)\n",
      "Epoch 6 Step 808/1563 Loss: 1.410 | Acc: 49.030% (12693/25888)\n",
      "Epoch 6 Step 809/1563 Loss: 1.411 | Acc: 49.028% (12708/25920)\n",
      "Epoch 6 Step 810/1563 Loss: 1.411 | Acc: 49.006% (12718/25952)\n",
      "Epoch 6 Step 811/1563 Loss: 1.411 | Acc: 48.999% (12732/25984)\n",
      "Epoch 6 Step 812/1563 Loss: 1.411 | Acc: 48.993% (12746/26016)\n",
      "Epoch 6 Step 813/1563 Loss: 1.411 | Acc: 49.002% (12764/26048)\n",
      "Epoch 6 Step 814/1563 Loss: 1.411 | Acc: 49.015% (12783/26080)\n",
      "Epoch 6 Step 815/1563 Loss: 1.411 | Acc: 49.023% (12801/26112)\n",
      "Epoch 6 Step 816/1563 Loss: 1.411 | Acc: 49.021% (12816/26144)\n",
      "Epoch 6 Step 817/1563 Loss: 1.411 | Acc: 49.022% (12832/26176)\n",
      "Epoch 6 Step 818/1563 Loss: 1.410 | Acc: 49.038% (12852/26208)\n",
      "Epoch 6 Step 819/1563 Loss: 1.410 | Acc: 49.024% (12864/26240)\n",
      "Epoch 6 Step 820/1563 Loss: 1.411 | Acc: 49.018% (12878/26272)\n",
      "Epoch 6 Step 821/1563 Loss: 1.410 | Acc: 49.042% (12900/26304)\n",
      "Epoch 6 Step 822/1563 Loss: 1.411 | Acc: 49.017% (12909/26336)\n",
      "Epoch 6 Step 823/1563 Loss: 1.411 | Acc: 49.003% (12921/26368)\n",
      "Epoch 6 Step 824/1563 Loss: 1.411 | Acc: 48.992% (12934/26400)\n",
      "Epoch 6 Step 825/1563 Loss: 1.411 | Acc: 49.001% (12952/26432)\n",
      "Epoch 6 Step 826/1563 Loss: 1.411 | Acc: 48.995% (12966/26464)\n",
      "Epoch 6 Step 827/1563 Loss: 1.411 | Acc: 49.011% (12986/26496)\n",
      "Epoch 6 Step 828/1563 Loss: 1.411 | Acc: 49.009% (13001/26528)\n",
      "Epoch 6 Step 829/1563 Loss: 1.411 | Acc: 49.002% (13015/26560)\n",
      "Epoch 6 Step 830/1563 Loss: 1.411 | Acc: 49.000% (13030/26592)\n",
      "Epoch 6 Step 831/1563 Loss: 1.411 | Acc: 49.016% (13050/26624)\n",
      "Epoch 6 Step 832/1563 Loss: 1.411 | Acc: 49.010% (13064/26656)\n",
      "Epoch 6 Step 833/1563 Loss: 1.410 | Acc: 49.022% (13083/26688)\n",
      "Epoch 6 Step 834/1563 Loss: 1.410 | Acc: 49.016% (13097/26720)\n",
      "Epoch 6 Step 835/1563 Loss: 1.410 | Acc: 49.017% (13113/26752)\n",
      "Epoch 6 Step 836/1563 Loss: 1.410 | Acc: 49.007% (13126/26784)\n",
      "Epoch 6 Step 837/1563 Loss: 1.410 | Acc: 49.001% (13140/26816)\n",
      "Epoch 6 Step 838/1563 Loss: 1.410 | Acc: 49.006% (13157/26848)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 839/1563 Loss: 1.410 | Acc: 49.007% (13173/26880)\n",
      "Epoch 6 Step 840/1563 Loss: 1.410 | Acc: 49.012% (13190/26912)\n",
      "Epoch 6 Step 841/1563 Loss: 1.410 | Acc: 49.005% (13204/26944)\n",
      "Epoch 6 Step 842/1563 Loss: 1.410 | Acc: 49.003% (13219/26976)\n",
      "Epoch 6 Step 843/1563 Loss: 1.410 | Acc: 49.019% (13239/27008)\n",
      "Epoch 6 Step 844/1563 Loss: 1.409 | Acc: 49.038% (13260/27040)\n",
      "Epoch 6 Step 845/1563 Loss: 1.409 | Acc: 49.032% (13274/27072)\n",
      "Epoch 6 Step 846/1563 Loss: 1.409 | Acc: 49.048% (13294/27104)\n",
      "Epoch 6 Step 847/1563 Loss: 1.409 | Acc: 49.038% (13307/27136)\n",
      "Epoch 6 Step 848/1563 Loss: 1.409 | Acc: 49.047% (13325/27168)\n",
      "Epoch 6 Step 849/1563 Loss: 1.410 | Acc: 49.026% (13335/27200)\n",
      "Epoch 6 Step 850/1563 Loss: 1.409 | Acc: 49.034% (13353/27232)\n",
      "Epoch 6 Step 851/1563 Loss: 1.409 | Acc: 49.039% (13370/27264)\n",
      "Epoch 6 Step 852/1563 Loss: 1.409 | Acc: 49.029% (13383/27296)\n",
      "Epoch 6 Step 853/1563 Loss: 1.409 | Acc: 49.023% (13397/27328)\n",
      "Epoch 6 Step 854/1563 Loss: 1.409 | Acc: 49.024% (13413/27360)\n",
      "Epoch 6 Step 855/1563 Loss: 1.410 | Acc: 49.011% (13425/27392)\n",
      "Epoch 6 Step 856/1563 Loss: 1.410 | Acc: 48.990% (13435/27424)\n",
      "Epoch 6 Step 857/1563 Loss: 1.409 | Acc: 48.991% (13451/27456)\n",
      "Epoch 6 Step 858/1563 Loss: 1.409 | Acc: 48.996% (13468/27488)\n",
      "Epoch 6 Step 859/1563 Loss: 1.409 | Acc: 49.001% (13485/27520)\n",
      "Epoch 6 Step 860/1563 Loss: 1.409 | Acc: 49.024% (13507/27552)\n",
      "Epoch 6 Step 861/1563 Loss: 1.409 | Acc: 49.010% (13519/27584)\n",
      "Epoch 6 Step 862/1563 Loss: 1.409 | Acc: 48.986% (13528/27616)\n",
      "Epoch 6 Step 863/1563 Loss: 1.409 | Acc: 48.984% (13543/27648)\n",
      "Epoch 6 Step 864/1563 Loss: 1.409 | Acc: 48.988% (13560/27680)\n",
      "Epoch 6 Step 865/1563 Loss: 1.409 | Acc: 48.997% (13578/27712)\n",
      "Epoch 6 Step 866/1563 Loss: 1.409 | Acc: 48.987% (13591/27744)\n",
      "Epoch 6 Step 867/1563 Loss: 1.409 | Acc: 48.981% (13605/27776)\n",
      "Epoch 6 Step 868/1563 Loss: 1.409 | Acc: 48.993% (13624/27808)\n",
      "Epoch 6 Step 869/1563 Loss: 1.409 | Acc: 49.009% (13644/27840)\n",
      "Epoch 6 Step 870/1563 Loss: 1.409 | Acc: 48.995% (13656/27872)\n",
      "Epoch 6 Step 871/1563 Loss: 1.409 | Acc: 48.982% (13668/27904)\n",
      "Epoch 6 Step 872/1563 Loss: 1.409 | Acc: 48.965% (13679/27936)\n",
      "Epoch 6 Step 873/1563 Loss: 1.409 | Acc: 48.963% (13694/27968)\n",
      "Epoch 6 Step 874/1563 Loss: 1.409 | Acc: 48.954% (13707/28000)\n",
      "Epoch 6 Step 875/1563 Loss: 1.409 | Acc: 48.958% (13724/28032)\n",
      "Epoch 6 Step 876/1563 Loss: 1.410 | Acc: 48.931% (13732/28064)\n",
      "Epoch 6 Step 877/1563 Loss: 1.410 | Acc: 48.918% (13744/28096)\n",
      "Epoch 6 Step 878/1563 Loss: 1.410 | Acc: 48.930% (13763/28128)\n",
      "Epoch 6 Step 879/1563 Loss: 1.410 | Acc: 48.935% (13780/28160)\n",
      "Epoch 6 Step 880/1563 Loss: 1.410 | Acc: 48.929% (13794/28192)\n",
      "Epoch 6 Step 881/1563 Loss: 1.410 | Acc: 48.930% (13810/28224)\n",
      "Epoch 6 Step 882/1563 Loss: 1.410 | Acc: 48.921% (13823/28256)\n",
      "Epoch 6 Step 883/1563 Loss: 1.410 | Acc: 48.915% (13837/28288)\n",
      "Epoch 6 Step 884/1563 Loss: 1.410 | Acc: 48.902% (13849/28320)\n",
      "Epoch 6 Step 885/1563 Loss: 1.410 | Acc: 48.921% (13870/28352)\n",
      "Epoch 6 Step 886/1563 Loss: 1.410 | Acc: 48.904% (13881/28384)\n",
      "Epoch 6 Step 887/1563 Loss: 1.410 | Acc: 48.923% (13902/28416)\n",
      "Epoch 6 Step 888/1563 Loss: 1.410 | Acc: 48.914% (13915/28448)\n",
      "Epoch 6 Step 889/1563 Loss: 1.410 | Acc: 48.908% (13929/28480)\n",
      "Epoch 6 Step 890/1563 Loss: 1.410 | Acc: 48.920% (13948/28512)\n",
      "Epoch 6 Step 891/1563 Loss: 1.410 | Acc: 48.917% (13963/28544)\n",
      "Epoch 6 Step 892/1563 Loss: 1.411 | Acc: 48.898% (13973/28576)\n",
      "Epoch 6 Step 893/1563 Loss: 1.411 | Acc: 48.909% (13992/28608)\n",
      "Epoch 6 Step 894/1563 Loss: 1.411 | Acc: 48.900% (14005/28640)\n",
      "Epoch 6 Step 895/1563 Loss: 1.411 | Acc: 48.894% (14019/28672)\n",
      "Epoch 6 Step 896/1563 Loss: 1.411 | Acc: 48.896% (14035/28704)\n",
      "Epoch 6 Step 897/1563 Loss: 1.411 | Acc: 48.893% (14050/28736)\n",
      "Epoch 6 Step 898/1563 Loss: 1.411 | Acc: 48.881% (14062/28768)\n",
      "Epoch 6 Step 899/1563 Loss: 1.412 | Acc: 48.875% (14076/28800)\n",
      "Epoch 6 Step 900/1563 Loss: 1.412 | Acc: 48.873% (14091/28832)\n",
      "Epoch 6 Step 901/1563 Loss: 1.412 | Acc: 48.871% (14106/28864)\n",
      "Epoch 6 Step 902/1563 Loss: 1.412 | Acc: 48.868% (14121/28896)\n",
      "Epoch 6 Step 903/1563 Loss: 1.412 | Acc: 48.852% (14132/28928)\n",
      "Epoch 6 Step 904/1563 Loss: 1.412 | Acc: 48.860% (14150/28960)\n",
      "Epoch 6 Step 905/1563 Loss: 1.412 | Acc: 48.862% (14166/28992)\n",
      "Epoch 6 Step 906/1563 Loss: 1.413 | Acc: 48.846% (14177/29024)\n",
      "Epoch 6 Step 907/1563 Loss: 1.413 | Acc: 48.847% (14193/29056)\n",
      "Epoch 6 Step 908/1563 Loss: 1.413 | Acc: 48.848% (14209/29088)\n",
      "Epoch 6 Step 909/1563 Loss: 1.413 | Acc: 48.850% (14225/29120)\n",
      "Epoch 6 Step 910/1563 Loss: 1.413 | Acc: 48.854% (14242/29152)\n",
      "Epoch 6 Step 911/1563 Loss: 1.413 | Acc: 48.859% (14259/29184)\n",
      "Epoch 6 Step 912/1563 Loss: 1.413 | Acc: 48.867% (14277/29216)\n",
      "Epoch 6 Step 913/1563 Loss: 1.413 | Acc: 48.861% (14291/29248)\n",
      "Epoch 6 Step 914/1563 Loss: 1.412 | Acc: 48.866% (14308/29280)\n",
      "Epoch 6 Step 915/1563 Loss: 1.413 | Acc: 48.857% (14321/29312)\n",
      "Epoch 6 Step 916/1563 Loss: 1.412 | Acc: 48.879% (14343/29344)\n",
      "Epoch 6 Step 917/1563 Loss: 1.413 | Acc: 48.873% (14357/29376)\n",
      "Epoch 6 Step 918/1563 Loss: 1.413 | Acc: 48.854% (14367/29408)\n",
      "Epoch 6 Step 919/1563 Loss: 1.412 | Acc: 48.862% (14385/29440)\n",
      "Epoch 6 Step 920/1563 Loss: 1.412 | Acc: 48.870% (14403/29472)\n",
      "Epoch 6 Step 921/1563 Loss: 1.412 | Acc: 48.865% (14417/29504)\n",
      "Epoch 6 Step 922/1563 Loss: 1.412 | Acc: 48.883% (14438/29536)\n",
      "Epoch 6 Step 923/1563 Loss: 1.412 | Acc: 48.887% (14455/29568)\n",
      "Epoch 6 Step 924/1563 Loss: 1.412 | Acc: 48.885% (14470/29600)\n",
      "Epoch 6 Step 925/1563 Loss: 1.412 | Acc: 48.896% (14489/29632)\n",
      "Epoch 6 Step 926/1563 Loss: 1.412 | Acc: 48.898% (14505/29664)\n",
      "Epoch 6 Step 927/1563 Loss: 1.412 | Acc: 48.895% (14520/29696)\n",
      "Epoch 6 Step 928/1563 Loss: 1.412 | Acc: 48.907% (14539/29728)\n",
      "Epoch 6 Step 929/1563 Loss: 1.411 | Acc: 48.925% (14560/29760)\n",
      "Epoch 6 Step 930/1563 Loss: 1.411 | Acc: 48.912% (14572/29792)\n",
      "Epoch 6 Step 931/1563 Loss: 1.411 | Acc: 48.924% (14591/29824)\n",
      "Epoch 6 Step 932/1563 Loss: 1.411 | Acc: 48.911% (14603/29856)\n",
      "Epoch 6 Step 933/1563 Loss: 1.412 | Acc: 48.906% (14617/29888)\n",
      "Epoch 6 Step 934/1563 Loss: 1.412 | Acc: 48.900% (14631/29920)\n",
      "Epoch 6 Step 935/1563 Loss: 1.412 | Acc: 48.888% (14643/29952)\n",
      "Epoch 6 Step 936/1563 Loss: 1.412 | Acc: 48.886% (14658/29984)\n",
      "Epoch 6 Step 937/1563 Loss: 1.412 | Acc: 48.884% (14673/30016)\n",
      "Epoch 6 Step 938/1563 Loss: 1.412 | Acc: 48.878% (14687/30048)\n",
      "Epoch 6 Step 939/1563 Loss: 1.412 | Acc: 48.893% (14707/30080)\n",
      "Epoch 6 Step 940/1563 Loss: 1.412 | Acc: 48.891% (14722/30112)\n",
      "Epoch 6 Step 941/1563 Loss: 1.412 | Acc: 48.889% (14737/30144)\n",
      "Epoch 6 Step 942/1563 Loss: 1.411 | Acc: 48.903% (14757/30176)\n",
      "Epoch 6 Step 943/1563 Loss: 1.411 | Acc: 48.908% (14774/30208)\n",
      "Epoch 6 Step 944/1563 Loss: 1.412 | Acc: 48.905% (14789/30240)\n",
      "Epoch 6 Step 945/1563 Loss: 1.412 | Acc: 48.913% (14807/30272)\n",
      "Epoch 6 Step 946/1563 Loss: 1.411 | Acc: 48.924% (14826/30304)\n",
      "Epoch 6 Step 947/1563 Loss: 1.411 | Acc: 48.929% (14843/30336)\n",
      "Epoch 6 Step 948/1563 Loss: 1.411 | Acc: 48.923% (14857/30368)\n",
      "Epoch 6 Step 949/1563 Loss: 1.412 | Acc: 48.905% (14867/30400)\n",
      "Epoch 6 Step 950/1563 Loss: 1.412 | Acc: 48.919% (14887/30432)\n",
      "Epoch 6 Step 951/1563 Loss: 1.412 | Acc: 48.910% (14900/30464)\n",
      "Epoch 6 Step 952/1563 Loss: 1.412 | Acc: 48.921% (14919/30496)\n",
      "Epoch 6 Step 953/1563 Loss: 1.412 | Acc: 48.919% (14934/30528)\n",
      "Epoch 6 Step 954/1563 Loss: 1.412 | Acc: 48.927% (14952/30560)\n",
      "Epoch 6 Step 955/1563 Loss: 1.412 | Acc: 48.918% (14965/30592)\n",
      "Epoch 6 Step 956/1563 Loss: 1.412 | Acc: 48.913% (14979/30624)\n",
      "Epoch 6 Step 957/1563 Loss: 1.412 | Acc: 48.920% (14997/30656)\n",
      "Epoch 6 Step 958/1563 Loss: 1.412 | Acc: 48.918% (15012/30688)\n",
      "Epoch 6 Step 959/1563 Loss: 1.412 | Acc: 48.932% (15032/30720)\n",
      "Epoch 6 Step 960/1563 Loss: 1.411 | Acc: 48.933% (15048/30752)\n",
      "Epoch 6 Step 961/1563 Loss: 1.411 | Acc: 48.941% (15066/30784)\n",
      "Epoch 6 Step 962/1563 Loss: 1.411 | Acc: 48.929% (15078/30816)\n",
      "Epoch 6 Step 963/1563 Loss: 1.411 | Acc: 48.924% (15092/30848)\n",
      "Epoch 6 Step 964/1563 Loss: 1.411 | Acc: 48.922% (15107/30880)\n",
      "Epoch 6 Step 965/1563 Loss: 1.411 | Acc: 48.907% (15118/30912)\n",
      "Epoch 6 Step 966/1563 Loss: 1.411 | Acc: 48.917% (15137/30944)\n",
      "Epoch 6 Step 967/1563 Loss: 1.411 | Acc: 48.925% (15155/30976)\n",
      "Epoch 6 Step 968/1563 Loss: 1.411 | Acc: 48.907% (15165/31008)\n",
      "Epoch 6 Step 969/1563 Loss: 1.411 | Acc: 48.898% (15178/31040)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 970/1563 Loss: 1.411 | Acc: 48.906% (15196/31072)\n",
      "Epoch 6 Step 971/1563 Loss: 1.411 | Acc: 48.897% (15209/31104)\n",
      "Epoch 6 Step 972/1563 Loss: 1.411 | Acc: 48.902% (15226/31136)\n",
      "Epoch 6 Step 973/1563 Loss: 1.411 | Acc: 48.909% (15244/31168)\n",
      "Epoch 6 Step 974/1563 Loss: 1.411 | Acc: 48.894% (15255/31200)\n",
      "Epoch 6 Step 975/1563 Loss: 1.411 | Acc: 48.899% (15272/31232)\n",
      "Epoch 6 Step 976/1563 Loss: 1.411 | Acc: 48.903% (15289/31264)\n",
      "Epoch 6 Step 977/1563 Loss: 1.411 | Acc: 48.901% (15304/31296)\n",
      "Epoch 6 Step 978/1563 Loss: 1.411 | Acc: 48.908% (15322/31328)\n",
      "Epoch 6 Step 979/1563 Loss: 1.410 | Acc: 48.919% (15341/31360)\n",
      "Epoch 6 Step 980/1563 Loss: 1.410 | Acc: 48.942% (15364/31392)\n",
      "Epoch 6 Step 981/1563 Loss: 1.410 | Acc: 48.950% (15382/31424)\n",
      "Epoch 6 Step 982/1563 Loss: 1.410 | Acc: 48.945% (15396/31456)\n",
      "Epoch 6 Step 983/1563 Loss: 1.410 | Acc: 48.971% (15420/31488)\n",
      "Epoch 6 Step 984/1563 Loss: 1.410 | Acc: 48.966% (15434/31520)\n",
      "Epoch 6 Step 985/1563 Loss: 1.410 | Acc: 48.960% (15448/31552)\n",
      "Epoch 6 Step 986/1563 Loss: 1.410 | Acc: 48.965% (15465/31584)\n",
      "Epoch 6 Step 987/1563 Loss: 1.410 | Acc: 48.969% (15482/31616)\n",
      "Epoch 6 Step 988/1563 Loss: 1.410 | Acc: 48.986% (15503/31648)\n",
      "Epoch 6 Step 989/1563 Loss: 1.410 | Acc: 48.971% (15514/31680)\n",
      "Epoch 6 Step 990/1563 Loss: 1.410 | Acc: 48.969% (15529/31712)\n",
      "Epoch 6 Step 991/1563 Loss: 1.410 | Acc: 48.989% (15551/31744)\n",
      "Epoch 6 Step 992/1563 Loss: 1.410 | Acc: 48.984% (15565/31776)\n",
      "Epoch 6 Step 993/1563 Loss: 1.410 | Acc: 48.985% (15581/31808)\n",
      "Epoch 6 Step 994/1563 Loss: 1.410 | Acc: 48.964% (15590/31840)\n",
      "Epoch 6 Step 995/1563 Loss: 1.410 | Acc: 48.974% (15609/31872)\n",
      "Epoch 6 Step 996/1563 Loss: 1.410 | Acc: 48.978% (15626/31904)\n",
      "Epoch 6 Step 997/1563 Loss: 1.410 | Acc: 48.992% (15646/31936)\n",
      "Epoch 6 Step 998/1563 Loss: 1.410 | Acc: 48.999% (15664/31968)\n",
      "Epoch 6 Step 999/1563 Loss: 1.410 | Acc: 49.003% (15681/32000)\n",
      "Epoch 6 Step 1000/1563 Loss: 1.410 | Acc: 49.007% (15698/32032)\n",
      "Epoch 6 Step 1001/1563 Loss: 1.410 | Acc: 48.996% (15710/32064)\n",
      "Epoch 6 Step 1002/1563 Loss: 1.410 | Acc: 49.006% (15729/32096)\n",
      "Epoch 6 Step 1003/1563 Loss: 1.410 | Acc: 49.007% (15745/32128)\n",
      "Epoch 6 Step 1004/1563 Loss: 1.410 | Acc: 49.017% (15764/32160)\n",
      "Epoch 6 Step 1005/1563 Loss: 1.409 | Acc: 49.015% (15779/32192)\n",
      "Epoch 6 Step 1006/1563 Loss: 1.409 | Acc: 49.016% (15795/32224)\n",
      "Epoch 6 Step 1007/1563 Loss: 1.409 | Acc: 49.030% (15815/32256)\n",
      "Epoch 6 Step 1008/1563 Loss: 1.409 | Acc: 49.024% (15829/32288)\n",
      "Epoch 6 Step 1009/1563 Loss: 1.409 | Acc: 49.032% (15847/32320)\n",
      "Epoch 6 Step 1010/1563 Loss: 1.409 | Acc: 49.020% (15859/32352)\n",
      "Epoch 6 Step 1011/1563 Loss: 1.410 | Acc: 49.012% (15872/32384)\n",
      "Epoch 6 Step 1012/1563 Loss: 1.409 | Acc: 49.010% (15887/32416)\n",
      "Epoch 6 Step 1013/1563 Loss: 1.410 | Acc: 48.992% (15897/32448)\n",
      "Epoch 6 Step 1014/1563 Loss: 1.409 | Acc: 49.002% (15916/32480)\n",
      "Epoch 6 Step 1015/1563 Loss: 1.409 | Acc: 49.013% (15935/32512)\n",
      "Epoch 6 Step 1016/1563 Loss: 1.409 | Acc: 49.004% (15948/32544)\n",
      "Epoch 6 Step 1017/1563 Loss: 1.410 | Acc: 48.993% (15960/32576)\n",
      "Epoch 6 Step 1018/1563 Loss: 1.409 | Acc: 49.013% (15982/32608)\n",
      "Epoch 6 Step 1019/1563 Loss: 1.409 | Acc: 48.998% (15993/32640)\n",
      "Epoch 6 Step 1020/1563 Loss: 1.410 | Acc: 48.993% (16007/32672)\n",
      "Epoch 6 Step 1021/1563 Loss: 1.409 | Acc: 49.003% (16026/32704)\n",
      "Epoch 6 Step 1022/1563 Loss: 1.410 | Acc: 48.986% (16036/32736)\n",
      "Epoch 6 Step 1023/1563 Loss: 1.410 | Acc: 48.990% (16053/32768)\n",
      "Epoch 6 Step 1024/1563 Loss: 1.410 | Acc: 48.982% (16066/32800)\n",
      "Epoch 6 Step 1025/1563 Loss: 1.410 | Acc: 48.992% (16085/32832)\n",
      "Epoch 6 Step 1026/1563 Loss: 1.410 | Acc: 48.999% (16103/32864)\n",
      "Epoch 6 Step 1027/1563 Loss: 1.410 | Acc: 48.988% (16115/32896)\n",
      "Epoch 6 Step 1028/1563 Loss: 1.410 | Acc: 48.983% (16129/32928)\n",
      "Epoch 6 Step 1029/1563 Loss: 1.410 | Acc: 48.965% (16139/32960)\n",
      "Epoch 6 Step 1030/1563 Loss: 1.410 | Acc: 48.972% (16157/32992)\n",
      "Epoch 6 Step 1031/1563 Loss: 1.410 | Acc: 48.980% (16175/33024)\n",
      "Epoch 6 Step 1032/1563 Loss: 1.410 | Acc: 48.965% (16186/33056)\n",
      "Epoch 6 Step 1033/1563 Loss: 1.410 | Acc: 48.966% (16202/33088)\n",
      "Epoch 6 Step 1034/1563 Loss: 1.410 | Acc: 48.970% (16219/33120)\n",
      "Epoch 6 Step 1035/1563 Loss: 1.410 | Acc: 48.971% (16235/33152)\n",
      "Epoch 6 Step 1036/1563 Loss: 1.410 | Acc: 48.993% (16258/33184)\n",
      "Epoch 6 Step 1037/1563 Loss: 1.409 | Acc: 49.007% (16278/33216)\n",
      "Epoch 6 Step 1038/1563 Loss: 1.409 | Acc: 49.007% (16294/33248)\n",
      "Epoch 6 Step 1039/1563 Loss: 1.409 | Acc: 49.026% (16316/33280)\n",
      "Epoch 6 Step 1040/1563 Loss: 1.409 | Acc: 49.030% (16333/33312)\n",
      "Epoch 6 Step 1041/1563 Loss: 1.409 | Acc: 49.025% (16347/33344)\n",
      "Epoch 6 Step 1042/1563 Loss: 1.409 | Acc: 49.029% (16364/33376)\n",
      "Epoch 6 Step 1043/1563 Loss: 1.409 | Acc: 49.033% (16381/33408)\n",
      "Epoch 6 Step 1044/1563 Loss: 1.409 | Acc: 49.049% (16402/33440)\n",
      "Epoch 6 Step 1045/1563 Loss: 1.409 | Acc: 49.068% (16424/33472)\n",
      "Epoch 6 Step 1046/1563 Loss: 1.409 | Acc: 49.075% (16442/33504)\n",
      "Epoch 6 Step 1047/1563 Loss: 1.409 | Acc: 49.070% (16456/33536)\n",
      "Epoch 6 Step 1048/1563 Loss: 1.408 | Acc: 49.068% (16471/33568)\n",
      "Epoch 6 Step 1049/1563 Loss: 1.408 | Acc: 49.065% (16486/33600)\n",
      "Epoch 6 Step 1050/1563 Loss: 1.408 | Acc: 49.060% (16500/33632)\n",
      "Epoch 6 Step 1051/1563 Loss: 1.408 | Acc: 49.067% (16518/33664)\n",
      "Epoch 6 Step 1052/1563 Loss: 1.408 | Acc: 49.065% (16533/33696)\n",
      "Epoch 6 Step 1053/1563 Loss: 1.408 | Acc: 49.075% (16552/33728)\n",
      "Epoch 6 Step 1054/1563 Loss: 1.408 | Acc: 49.082% (16570/33760)\n",
      "Epoch 6 Step 1055/1563 Loss: 1.408 | Acc: 49.077% (16584/33792)\n",
      "Epoch 6 Step 1056/1563 Loss: 1.408 | Acc: 49.075% (16599/33824)\n",
      "Epoch 6 Step 1057/1563 Loss: 1.408 | Acc: 49.084% (16618/33856)\n",
      "Epoch 6 Step 1058/1563 Loss: 1.407 | Acc: 49.091% (16636/33888)\n",
      "Epoch 6 Step 1059/1563 Loss: 1.408 | Acc: 49.086% (16650/33920)\n",
      "Epoch 6 Step 1060/1563 Loss: 1.407 | Acc: 49.087% (16666/33952)\n",
      "Epoch 6 Step 1061/1563 Loss: 1.408 | Acc: 49.073% (16677/33984)\n",
      "Epoch 6 Step 1062/1563 Loss: 1.408 | Acc: 49.074% (16693/34016)\n",
      "Epoch 6 Step 1063/1563 Loss: 1.408 | Acc: 49.069% (16707/34048)\n",
      "Epoch 6 Step 1064/1563 Loss: 1.408 | Acc: 49.079% (16726/34080)\n",
      "Epoch 6 Step 1065/1563 Loss: 1.407 | Acc: 49.091% (16746/34112)\n",
      "Epoch 6 Step 1066/1563 Loss: 1.408 | Acc: 49.083% (16759/34144)\n",
      "Epoch 6 Step 1067/1563 Loss: 1.408 | Acc: 49.081% (16774/34176)\n",
      "Epoch 6 Step 1068/1563 Loss: 1.408 | Acc: 49.076% (16788/34208)\n",
      "Epoch 6 Step 1069/1563 Loss: 1.408 | Acc: 49.077% (16804/34240)\n",
      "Epoch 6 Step 1070/1563 Loss: 1.408 | Acc: 49.069% (16817/34272)\n",
      "Epoch 6 Step 1071/1563 Loss: 1.408 | Acc: 49.070% (16833/34304)\n",
      "Epoch 6 Step 1072/1563 Loss: 1.408 | Acc: 49.071% (16849/34336)\n",
      "Epoch 6 Step 1073/1563 Loss: 1.408 | Acc: 49.075% (16866/34368)\n",
      "Epoch 6 Step 1074/1563 Loss: 1.408 | Acc: 49.070% (16880/34400)\n",
      "Epoch 6 Step 1075/1563 Loss: 1.408 | Acc: 49.071% (16896/34432)\n",
      "Epoch 6 Step 1076/1563 Loss: 1.408 | Acc: 49.074% (16913/34464)\n",
      "Epoch 6 Step 1077/1563 Loss: 1.408 | Acc: 49.069% (16927/34496)\n",
      "Epoch 6 Step 1078/1563 Loss: 1.408 | Acc: 49.065% (16941/34528)\n",
      "Epoch 6 Step 1079/1563 Loss: 1.408 | Acc: 49.060% (16955/34560)\n",
      "Epoch 6 Step 1080/1563 Loss: 1.408 | Acc: 49.058% (16970/34592)\n",
      "Epoch 6 Step 1081/1563 Loss: 1.409 | Acc: 49.041% (16980/34624)\n",
      "Epoch 6 Step 1082/1563 Loss: 1.409 | Acc: 49.030% (16992/34656)\n",
      "Epoch 6 Step 1083/1563 Loss: 1.409 | Acc: 49.034% (17009/34688)\n",
      "Epoch 6 Step 1084/1563 Loss: 1.409 | Acc: 49.021% (17020/34720)\n",
      "Epoch 6 Step 1085/1563 Loss: 1.409 | Acc: 49.019% (17035/34752)\n",
      "Epoch 6 Step 1086/1563 Loss: 1.409 | Acc: 49.020% (17051/34784)\n",
      "Epoch 6 Step 1087/1563 Loss: 1.409 | Acc: 49.018% (17066/34816)\n",
      "Epoch 6 Step 1088/1563 Loss: 1.408 | Acc: 49.033% (17087/34848)\n",
      "Epoch 6 Step 1089/1563 Loss: 1.408 | Acc: 49.034% (17103/34880)\n",
      "Epoch 6 Step 1090/1563 Loss: 1.408 | Acc: 49.052% (17125/34912)\n",
      "Epoch 6 Step 1091/1563 Loss: 1.408 | Acc: 49.058% (17143/34944)\n",
      "Epoch 6 Step 1092/1563 Loss: 1.408 | Acc: 49.062% (17160/34976)\n",
      "Epoch 6 Step 1093/1563 Loss: 1.408 | Acc: 49.060% (17175/35008)\n",
      "Epoch 6 Step 1094/1563 Loss: 1.408 | Acc: 49.070% (17194/35040)\n",
      "Epoch 6 Step 1095/1563 Loss: 1.408 | Acc: 49.048% (17202/35072)\n",
      "Epoch 6 Step 1096/1563 Loss: 1.408 | Acc: 49.057% (17221/35104)\n",
      "Epoch 6 Step 1097/1563 Loss: 1.408 | Acc: 49.058% (17237/35136)\n",
      "Epoch 6 Step 1098/1563 Loss: 1.408 | Acc: 49.059% (17253/35168)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 1099/1563 Loss: 1.408 | Acc: 49.048% (17265/35200)\n",
      "Epoch 6 Step 1100/1563 Loss: 1.408 | Acc: 49.052% (17282/35232)\n",
      "Epoch 6 Step 1101/1563 Loss: 1.409 | Acc: 49.044% (17295/35264)\n",
      "Epoch 6 Step 1102/1563 Loss: 1.409 | Acc: 49.057% (17315/35296)\n",
      "Epoch 6 Step 1103/1563 Loss: 1.409 | Acc: 49.052% (17329/35328)\n",
      "Epoch 6 Step 1104/1563 Loss: 1.409 | Acc: 49.033% (17338/35360)\n",
      "Epoch 6 Step 1105/1563 Loss: 1.409 | Acc: 49.037% (17355/35392)\n",
      "Epoch 6 Step 1106/1563 Loss: 1.409 | Acc: 49.046% (17374/35424)\n",
      "Epoch 6 Step 1107/1563 Loss: 1.409 | Acc: 49.041% (17388/35456)\n",
      "Epoch 6 Step 1108/1563 Loss: 1.409 | Acc: 49.042% (17404/35488)\n",
      "Epoch 6 Step 1109/1563 Loss: 1.409 | Acc: 49.048% (17422/35520)\n",
      "Epoch 6 Step 1110/1563 Loss: 1.409 | Acc: 49.049% (17438/35552)\n",
      "Epoch 6 Step 1111/1563 Loss: 1.409 | Acc: 49.053% (17455/35584)\n",
      "Epoch 6 Step 1112/1563 Loss: 1.409 | Acc: 49.051% (17470/35616)\n",
      "Epoch 6 Step 1113/1563 Loss: 1.409 | Acc: 49.046% (17484/35648)\n",
      "Epoch 6 Step 1114/1563 Loss: 1.409 | Acc: 49.061% (17505/35680)\n",
      "Epoch 6 Step 1115/1563 Loss: 1.408 | Acc: 49.068% (17523/35712)\n",
      "Epoch 6 Step 1116/1563 Loss: 1.408 | Acc: 49.082% (17544/35744)\n",
      "Epoch 6 Step 1117/1563 Loss: 1.408 | Acc: 49.089% (17562/35776)\n",
      "Epoch 6 Step 1118/1563 Loss: 1.408 | Acc: 49.087% (17577/35808)\n",
      "Epoch 6 Step 1119/1563 Loss: 1.408 | Acc: 49.099% (17597/35840)\n",
      "Epoch 6 Step 1120/1563 Loss: 1.407 | Acc: 49.111% (17617/35872)\n",
      "Epoch 6 Step 1121/1563 Loss: 1.407 | Acc: 49.106% (17631/35904)\n",
      "Epoch 6 Step 1122/1563 Loss: 1.407 | Acc: 49.115% (17650/35936)\n",
      "Epoch 6 Step 1123/1563 Loss: 1.407 | Acc: 49.119% (17667/35968)\n",
      "Epoch 6 Step 1124/1563 Loss: 1.407 | Acc: 49.117% (17682/36000)\n",
      "Epoch 6 Step 1125/1563 Loss: 1.407 | Acc: 49.120% (17699/36032)\n",
      "Epoch 6 Step 1126/1563 Loss: 1.407 | Acc: 49.124% (17716/36064)\n",
      "Epoch 6 Step 1127/1563 Loss: 1.407 | Acc: 49.119% (17730/36096)\n",
      "Epoch 6 Step 1128/1563 Loss: 1.407 | Acc: 49.134% (17751/36128)\n",
      "Epoch 6 Step 1129/1563 Loss: 1.407 | Acc: 49.134% (17767/36160)\n",
      "Epoch 6 Step 1130/1563 Loss: 1.407 | Acc: 49.132% (17782/36192)\n",
      "Epoch 6 Step 1131/1563 Loss: 1.406 | Acc: 49.136% (17799/36224)\n",
      "Epoch 6 Step 1132/1563 Loss: 1.406 | Acc: 49.142% (17817/36256)\n",
      "Epoch 6 Step 1133/1563 Loss: 1.406 | Acc: 49.160% (17839/36288)\n",
      "Epoch 6 Step 1134/1563 Loss: 1.406 | Acc: 49.155% (17853/36320)\n",
      "Epoch 6 Step 1135/1563 Loss: 1.406 | Acc: 49.158% (17870/36352)\n",
      "Epoch 6 Step 1136/1563 Loss: 1.406 | Acc: 49.170% (17890/36384)\n",
      "Epoch 6 Step 1137/1563 Loss: 1.406 | Acc: 49.171% (17906/36416)\n",
      "Epoch 6 Step 1138/1563 Loss: 1.406 | Acc: 49.163% (17919/36448)\n",
      "Epoch 6 Step 1139/1563 Loss: 1.406 | Acc: 49.167% (17936/36480)\n",
      "Epoch 6 Step 1140/1563 Loss: 1.406 | Acc: 49.162% (17950/36512)\n",
      "Epoch 6 Step 1141/1563 Loss: 1.406 | Acc: 49.168% (17968/36544)\n",
      "Epoch 6 Step 1142/1563 Loss: 1.406 | Acc: 49.163% (17982/36576)\n",
      "Epoch 6 Step 1143/1563 Loss: 1.406 | Acc: 49.175% (18002/36608)\n",
      "Epoch 6 Step 1144/1563 Loss: 1.406 | Acc: 49.159% (18012/36640)\n",
      "Epoch 6 Step 1145/1563 Loss: 1.406 | Acc: 49.157% (18027/36672)\n",
      "Epoch 6 Step 1146/1563 Loss: 1.406 | Acc: 49.153% (18041/36704)\n",
      "Epoch 6 Step 1147/1563 Loss: 1.407 | Acc: 49.132% (18049/36736)\n",
      "Epoch 6 Step 1148/1563 Loss: 1.407 | Acc: 49.119% (18060/36768)\n",
      "Epoch 6 Step 1149/1563 Loss: 1.407 | Acc: 49.122% (18077/36800)\n",
      "Epoch 6 Step 1150/1563 Loss: 1.407 | Acc: 49.123% (18093/36832)\n",
      "Epoch 6 Step 1151/1563 Loss: 1.407 | Acc: 49.118% (18107/36864)\n",
      "Epoch 6 Step 1152/1563 Loss: 1.407 | Acc: 49.119% (18123/36896)\n",
      "Epoch 6 Step 1153/1563 Loss: 1.407 | Acc: 49.112% (18136/36928)\n",
      "Epoch 6 Step 1154/1563 Loss: 1.408 | Acc: 49.113% (18152/36960)\n",
      "Epoch 6 Step 1155/1563 Loss: 1.408 | Acc: 49.121% (18171/36992)\n",
      "Epoch 6 Step 1156/1563 Loss: 1.408 | Acc: 49.122% (18187/37024)\n",
      "Epoch 6 Step 1157/1563 Loss: 1.408 | Acc: 49.118% (18201/37056)\n",
      "Epoch 6 Step 1158/1563 Loss: 1.407 | Acc: 49.124% (18219/37088)\n",
      "Epoch 6 Step 1159/1563 Loss: 1.408 | Acc: 49.116% (18232/37120)\n",
      "Epoch 6 Step 1160/1563 Loss: 1.408 | Acc: 49.123% (18250/37152)\n",
      "Epoch 6 Step 1161/1563 Loss: 1.408 | Acc: 49.123% (18266/37184)\n",
      "Epoch 6 Step 1162/1563 Loss: 1.408 | Acc: 49.127% (18283/37216)\n",
      "Epoch 6 Step 1163/1563 Loss: 1.408 | Acc: 49.114% (18294/37248)\n",
      "Epoch 6 Step 1164/1563 Loss: 1.408 | Acc: 49.115% (18310/37280)\n",
      "Epoch 6 Step 1165/1563 Loss: 1.407 | Acc: 49.126% (18330/37312)\n",
      "Epoch 6 Step 1166/1563 Loss: 1.407 | Acc: 49.138% (18350/37344)\n",
      "Epoch 6 Step 1167/1563 Loss: 1.407 | Acc: 49.133% (18364/37376)\n",
      "Epoch 6 Step 1168/1563 Loss: 1.407 | Acc: 49.145% (18384/37408)\n",
      "Epoch 6 Step 1169/1563 Loss: 1.407 | Acc: 49.137% (18397/37440)\n",
      "Epoch 6 Step 1170/1563 Loss: 1.408 | Acc: 49.125% (18408/37472)\n",
      "Epoch 6 Step 1171/1563 Loss: 1.407 | Acc: 49.128% (18425/37504)\n",
      "Epoch 6 Step 1172/1563 Loss: 1.408 | Acc: 49.118% (18437/37536)\n",
      "Epoch 6 Step 1173/1563 Loss: 1.408 | Acc: 49.106% (18448/37568)\n",
      "Epoch 6 Step 1174/1563 Loss: 1.408 | Acc: 49.106% (18464/37600)\n",
      "Epoch 6 Step 1175/1563 Loss: 1.408 | Acc: 49.112% (18482/37632)\n",
      "Epoch 6 Step 1176/1563 Loss: 1.408 | Acc: 49.111% (18497/37664)\n",
      "Epoch 6 Step 1177/1563 Loss: 1.408 | Acc: 49.098% (18508/37696)\n",
      "Epoch 6 Step 1178/1563 Loss: 1.408 | Acc: 49.099% (18524/37728)\n",
      "Epoch 6 Step 1179/1563 Loss: 1.409 | Acc: 49.094% (18538/37760)\n",
      "Epoch 6 Step 1180/1563 Loss: 1.409 | Acc: 49.108% (18559/37792)\n",
      "Epoch 6 Step 1181/1563 Loss: 1.408 | Acc: 49.114% (18577/37824)\n",
      "Epoch 6 Step 1182/1563 Loss: 1.408 | Acc: 49.115% (18593/37856)\n",
      "Epoch 6 Step 1183/1563 Loss: 1.408 | Acc: 49.113% (18608/37888)\n",
      "Epoch 6 Step 1184/1563 Loss: 1.408 | Acc: 49.098% (18618/37920)\n",
      "Epoch 6 Step 1185/1563 Loss: 1.408 | Acc: 49.107% (18637/37952)\n",
      "Epoch 6 Step 1186/1563 Loss: 1.408 | Acc: 49.102% (18651/37984)\n",
      "Epoch 6 Step 1187/1563 Loss: 1.408 | Acc: 49.106% (18668/38016)\n",
      "Epoch 6 Step 1188/1563 Loss: 1.408 | Acc: 49.104% (18683/38048)\n",
      "Epoch 6 Step 1189/1563 Loss: 1.409 | Acc: 49.084% (18691/38080)\n",
      "Epoch 6 Step 1190/1563 Loss: 1.409 | Acc: 49.092% (18710/38112)\n",
      "Epoch 6 Step 1191/1563 Loss: 1.408 | Acc: 49.106% (18731/38144)\n",
      "Epoch 6 Step 1192/1563 Loss: 1.408 | Acc: 49.112% (18749/38176)\n",
      "Epoch 6 Step 1193/1563 Loss: 1.408 | Acc: 49.121% (18768/38208)\n",
      "Epoch 6 Step 1194/1563 Loss: 1.408 | Acc: 49.132% (18788/38240)\n",
      "Epoch 6 Step 1195/1563 Loss: 1.408 | Acc: 49.138% (18806/38272)\n",
      "Epoch 6 Step 1196/1563 Loss: 1.407 | Acc: 49.154% (18828/38304)\n",
      "Epoch 6 Step 1197/1563 Loss: 1.407 | Acc: 49.150% (18842/38336)\n",
      "Epoch 6 Step 1198/1563 Loss: 1.408 | Acc: 49.137% (18853/38368)\n",
      "Epoch 6 Step 1199/1563 Loss: 1.407 | Acc: 49.141% (18870/38400)\n",
      "Epoch 6 Step 1200/1563 Loss: 1.408 | Acc: 49.128% (18881/38432)\n",
      "Epoch 6 Step 1201/1563 Loss: 1.407 | Acc: 49.134% (18899/38464)\n",
      "Epoch 6 Step 1202/1563 Loss: 1.407 | Acc: 49.140% (18917/38496)\n",
      "Epoch 6 Step 1203/1563 Loss: 1.407 | Acc: 49.138% (18932/38528)\n",
      "Epoch 6 Step 1204/1563 Loss: 1.407 | Acc: 49.142% (18949/38560)\n",
      "Epoch 6 Step 1205/1563 Loss: 1.407 | Acc: 49.142% (18965/38592)\n",
      "Epoch 6 Step 1206/1563 Loss: 1.407 | Acc: 49.135% (18978/38624)\n",
      "Epoch 6 Step 1207/1563 Loss: 1.407 | Acc: 49.141% (18996/38656)\n",
      "Epoch 6 Step 1208/1563 Loss: 1.407 | Acc: 49.124% (19005/38688)\n",
      "Epoch 6 Step 1209/1563 Loss: 1.407 | Acc: 49.114% (19017/38720)\n",
      "Epoch 6 Step 1210/1563 Loss: 1.408 | Acc: 49.105% (19029/38752)\n",
      "Epoch 6 Step 1211/1563 Loss: 1.408 | Acc: 49.098% (19042/38784)\n",
      "Epoch 6 Step 1212/1563 Loss: 1.408 | Acc: 49.091% (19055/38816)\n",
      "Epoch 6 Step 1213/1563 Loss: 1.408 | Acc: 49.084% (19068/38848)\n",
      "Epoch 6 Step 1214/1563 Loss: 1.408 | Acc: 49.084% (19084/38880)\n",
      "Epoch 6 Step 1215/1563 Loss: 1.408 | Acc: 49.093% (19103/38912)\n",
      "Epoch 6 Step 1216/1563 Loss: 1.408 | Acc: 49.094% (19119/38944)\n",
      "Epoch 6 Step 1217/1563 Loss: 1.408 | Acc: 49.089% (19133/38976)\n",
      "Epoch 6 Step 1218/1563 Loss: 1.408 | Acc: 49.085% (19147/39008)\n",
      "Epoch 6 Step 1219/1563 Loss: 1.408 | Acc: 49.083% (19162/39040)\n",
      "Epoch 6 Step 1220/1563 Loss: 1.408 | Acc: 49.074% (19174/39072)\n",
      "Epoch 6 Step 1221/1563 Loss: 1.408 | Acc: 49.087% (19195/39104)\n",
      "Epoch 6 Step 1222/1563 Loss: 1.407 | Acc: 49.090% (19212/39136)\n",
      "Epoch 6 Step 1223/1563 Loss: 1.408 | Acc: 49.099% (19231/39168)\n",
      "Epoch 6 Step 1224/1563 Loss: 1.407 | Acc: 49.094% (19245/39200)\n",
      "Epoch 6 Step 1225/1563 Loss: 1.407 | Acc: 49.093% (19260/39232)\n",
      "Epoch 6 Step 1226/1563 Loss: 1.407 | Acc: 49.088% (19274/39264)\n",
      "Epoch 6 Step 1227/1563 Loss: 1.407 | Acc: 49.099% (19294/39296)\n",
      "Epoch 6 Step 1228/1563 Loss: 1.407 | Acc: 49.102% (19311/39328)\n",
      "Epoch 6 Step 1229/1563 Loss: 1.407 | Acc: 49.098% (19325/39360)\n",
      "Epoch 6 Step 1230/1563 Loss: 1.407 | Acc: 49.094% (19339/39392)\n",
      "Epoch 6 Step 1231/1563 Loss: 1.408 | Acc: 49.084% (19351/39424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 1232/1563 Loss: 1.408 | Acc: 49.090% (19369/39456)\n",
      "Epoch 6 Step 1233/1563 Loss: 1.408 | Acc: 49.096% (19387/39488)\n",
      "Epoch 6 Step 1234/1563 Loss: 1.407 | Acc: 49.097% (19403/39520)\n",
      "Epoch 6 Step 1235/1563 Loss: 1.407 | Acc: 49.085% (19414/39552)\n",
      "Epoch 6 Step 1236/1563 Loss: 1.408 | Acc: 49.075% (19426/39584)\n",
      "Epoch 6 Step 1237/1563 Loss: 1.408 | Acc: 49.064% (19437/39616)\n",
      "Epoch 6 Step 1238/1563 Loss: 1.408 | Acc: 49.072% (19456/39648)\n",
      "Epoch 6 Step 1239/1563 Loss: 1.408 | Acc: 49.080% (19475/39680)\n",
      "Epoch 6 Step 1240/1563 Loss: 1.408 | Acc: 49.081% (19491/39712)\n",
      "Epoch 6 Step 1241/1563 Loss: 1.408 | Acc: 49.087% (19509/39744)\n",
      "Epoch 6 Step 1242/1563 Loss: 1.407 | Acc: 49.092% (19527/39776)\n",
      "Epoch 6 Step 1243/1563 Loss: 1.407 | Acc: 49.093% (19543/39808)\n",
      "Epoch 6 Step 1244/1563 Loss: 1.407 | Acc: 49.096% (19560/39840)\n",
      "Epoch 6 Step 1245/1563 Loss: 1.407 | Acc: 49.095% (19575/39872)\n",
      "Epoch 6 Step 1246/1563 Loss: 1.407 | Acc: 49.088% (19588/39904)\n",
      "Epoch 6 Step 1247/1563 Loss: 1.407 | Acc: 49.106% (19611/39936)\n",
      "Epoch 6 Step 1248/1563 Loss: 1.407 | Acc: 49.112% (19629/39968)\n",
      "Epoch 6 Step 1249/1563 Loss: 1.408 | Acc: 49.097% (19639/40000)\n",
      "Epoch 6 Step 1250/1563 Loss: 1.408 | Acc: 49.096% (19654/40032)\n",
      "Epoch 6 Step 1251/1563 Loss: 1.407 | Acc: 49.096% (19670/40064)\n",
      "Epoch 6 Step 1252/1563 Loss: 1.407 | Acc: 49.100% (19687/40096)\n",
      "Epoch 6 Step 1253/1563 Loss: 1.407 | Acc: 49.103% (19704/40128)\n",
      "Epoch 6 Step 1254/1563 Loss: 1.407 | Acc: 49.094% (19716/40160)\n",
      "Epoch 6 Step 1255/1563 Loss: 1.407 | Acc: 49.094% (19732/40192)\n",
      "Epoch 6 Step 1256/1563 Loss: 1.407 | Acc: 49.085% (19744/40224)\n",
      "Epoch 6 Step 1257/1563 Loss: 1.407 | Acc: 49.081% (19758/40256)\n",
      "Epoch 6 Step 1258/1563 Loss: 1.407 | Acc: 49.087% (19776/40288)\n",
      "Epoch 6 Step 1259/1563 Loss: 1.407 | Acc: 49.077% (19788/40320)\n",
      "Epoch 6 Step 1260/1563 Loss: 1.407 | Acc: 49.078% (19804/40352)\n",
      "Epoch 6 Step 1261/1563 Loss: 1.407 | Acc: 49.084% (19822/40384)\n",
      "Epoch 6 Step 1262/1563 Loss: 1.407 | Acc: 49.085% (19838/40416)\n",
      "Epoch 6 Step 1263/1563 Loss: 1.407 | Acc: 49.075% (19850/40448)\n",
      "Epoch 6 Step 1264/1563 Loss: 1.407 | Acc: 49.076% (19866/40480)\n",
      "Epoch 6 Step 1265/1563 Loss: 1.407 | Acc: 49.067% (19878/40512)\n",
      "Epoch 6 Step 1266/1563 Loss: 1.407 | Acc: 49.070% (19895/40544)\n",
      "Epoch 6 Step 1267/1563 Loss: 1.407 | Acc: 49.073% (19912/40576)\n",
      "Epoch 6 Step 1268/1563 Loss: 1.407 | Acc: 49.077% (19929/40608)\n",
      "Epoch 6 Step 1269/1563 Loss: 1.407 | Acc: 49.085% (19948/40640)\n",
      "Epoch 6 Step 1270/1563 Loss: 1.407 | Acc: 49.076% (19960/40672)\n",
      "Epoch 6 Step 1271/1563 Loss: 1.407 | Acc: 49.079% (19977/40704)\n",
      "Epoch 6 Step 1272/1563 Loss: 1.407 | Acc: 49.079% (19993/40736)\n",
      "Epoch 6 Step 1273/1563 Loss: 1.407 | Acc: 49.090% (20013/40768)\n",
      "Epoch 6 Step 1274/1563 Loss: 1.407 | Acc: 49.098% (20032/40800)\n",
      "Epoch 6 Step 1275/1563 Loss: 1.407 | Acc: 49.101% (20049/40832)\n",
      "Epoch 6 Step 1276/1563 Loss: 1.407 | Acc: 49.097% (20063/40864)\n",
      "Epoch 6 Step 1277/1563 Loss: 1.407 | Acc: 49.117% (20087/40896)\n",
      "Epoch 6 Step 1278/1563 Loss: 1.407 | Acc: 49.128% (20107/40928)\n",
      "Epoch 6 Step 1279/1563 Loss: 1.407 | Acc: 49.124% (20121/40960)\n",
      "Epoch 6 Step 1280/1563 Loss: 1.407 | Acc: 49.134% (20141/40992)\n",
      "Epoch 6 Step 1281/1563 Loss: 1.407 | Acc: 49.142% (20160/41024)\n",
      "Epoch 6 Step 1282/1563 Loss: 1.406 | Acc: 49.150% (20179/41056)\n",
      "Epoch 6 Step 1283/1563 Loss: 1.407 | Acc: 49.143% (20192/41088)\n",
      "Epoch 6 Step 1284/1563 Loss: 1.407 | Acc: 49.144% (20208/41120)\n",
      "Epoch 6 Step 1285/1563 Loss: 1.407 | Acc: 49.149% (20226/41152)\n",
      "Epoch 6 Step 1286/1563 Loss: 1.406 | Acc: 49.148% (20241/41184)\n",
      "Epoch 6 Step 1287/1563 Loss: 1.407 | Acc: 49.144% (20255/41216)\n",
      "Epoch 6 Step 1288/1563 Loss: 1.407 | Acc: 49.149% (20273/41248)\n",
      "Epoch 6 Step 1289/1563 Loss: 1.407 | Acc: 49.147% (20288/41280)\n",
      "Epoch 6 Step 1290/1563 Loss: 1.406 | Acc: 49.162% (20310/41312)\n",
      "Epoch 6 Step 1291/1563 Loss: 1.406 | Acc: 49.168% (20328/41344)\n",
      "Epoch 6 Step 1292/1563 Loss: 1.406 | Acc: 49.157% (20339/41376)\n",
      "Epoch 6 Step 1293/1563 Loss: 1.406 | Acc: 49.162% (20357/41408)\n",
      "Epoch 6 Step 1294/1563 Loss: 1.406 | Acc: 49.175% (20378/41440)\n",
      "Epoch 6 Step 1295/1563 Loss: 1.406 | Acc: 49.187% (20399/41472)\n",
      "Epoch 6 Step 1296/1563 Loss: 1.406 | Acc: 49.198% (20419/41504)\n",
      "Epoch 6 Step 1297/1563 Loss: 1.406 | Acc: 49.198% (20435/41536)\n",
      "Epoch 6 Step 1298/1563 Loss: 1.406 | Acc: 49.204% (20453/41568)\n",
      "Epoch 6 Step 1299/1563 Loss: 1.406 | Acc: 49.209% (20471/41600)\n",
      "Epoch 6 Step 1300/1563 Loss: 1.406 | Acc: 49.205% (20485/41632)\n",
      "Epoch 6 Step 1301/1563 Loss: 1.406 | Acc: 49.208% (20502/41664)\n",
      "Epoch 6 Step 1302/1563 Loss: 1.406 | Acc: 49.211% (20519/41696)\n",
      "Epoch 6 Step 1303/1563 Loss: 1.406 | Acc: 49.212% (20535/41728)\n",
      "Epoch 6 Step 1304/1563 Loss: 1.406 | Acc: 49.215% (20552/41760)\n",
      "Epoch 6 Step 1305/1563 Loss: 1.406 | Acc: 49.208% (20565/41792)\n",
      "Epoch 6 Step 1306/1563 Loss: 1.406 | Acc: 49.213% (20583/41824)\n",
      "Epoch 6 Step 1307/1563 Loss: 1.406 | Acc: 49.226% (20604/41856)\n",
      "Epoch 6 Step 1308/1563 Loss: 1.405 | Acc: 49.234% (20623/41888)\n",
      "Epoch 6 Step 1309/1563 Loss: 1.405 | Acc: 49.241% (20642/41920)\n",
      "Epoch 6 Step 1310/1563 Loss: 1.405 | Acc: 49.247% (20660/41952)\n",
      "Epoch 6 Step 1311/1563 Loss: 1.405 | Acc: 49.247% (20676/41984)\n",
      "Epoch 6 Step 1312/1563 Loss: 1.405 | Acc: 49.253% (20694/42016)\n",
      "Epoch 6 Step 1313/1563 Loss: 1.405 | Acc: 49.260% (20713/42048)\n",
      "Epoch 6 Step 1314/1563 Loss: 1.404 | Acc: 49.261% (20729/42080)\n",
      "Epoch 6 Step 1315/1563 Loss: 1.404 | Acc: 49.259% (20744/42112)\n",
      "Epoch 6 Step 1316/1563 Loss: 1.405 | Acc: 49.248% (20755/42144)\n",
      "Epoch 6 Step 1317/1563 Loss: 1.405 | Acc: 49.253% (20773/42176)\n",
      "Epoch 6 Step 1318/1563 Loss: 1.404 | Acc: 49.258% (20791/42208)\n",
      "Epoch 6 Step 1319/1563 Loss: 1.405 | Acc: 49.245% (20801/42240)\n",
      "Epoch 6 Step 1320/1563 Loss: 1.405 | Acc: 49.243% (20816/42272)\n",
      "Epoch 6 Step 1321/1563 Loss: 1.405 | Acc: 49.246% (20833/42304)\n",
      "Epoch 6 Step 1322/1563 Loss: 1.404 | Acc: 49.254% (20852/42336)\n",
      "Epoch 6 Step 1323/1563 Loss: 1.404 | Acc: 49.268% (20874/42368)\n",
      "Epoch 6 Step 1324/1563 Loss: 1.404 | Acc: 49.271% (20891/42400)\n",
      "Epoch 6 Step 1325/1563 Loss: 1.404 | Acc: 49.276% (20909/42432)\n",
      "Epoch 6 Step 1326/1563 Loss: 1.404 | Acc: 49.275% (20924/42464)\n",
      "Epoch 6 Step 1327/1563 Loss: 1.404 | Acc: 49.271% (20938/42496)\n",
      "Epoch 6 Step 1328/1563 Loss: 1.404 | Acc: 49.278% (20957/42528)\n",
      "Epoch 6 Step 1329/1563 Loss: 1.403 | Acc: 49.290% (20978/42560)\n",
      "Epoch 6 Step 1330/1563 Loss: 1.404 | Acc: 49.293% (20995/42592)\n",
      "Epoch 6 Step 1331/1563 Loss: 1.404 | Acc: 49.294% (21011/42624)\n",
      "Epoch 6 Step 1332/1563 Loss: 1.404 | Acc: 49.294% (21027/42656)\n",
      "Epoch 6 Step 1333/1563 Loss: 1.403 | Acc: 49.297% (21044/42688)\n",
      "Epoch 6 Step 1334/1563 Loss: 1.403 | Acc: 49.307% (21064/42720)\n",
      "Epoch 6 Step 1335/1563 Loss: 1.403 | Acc: 49.303% (21078/42752)\n",
      "Epoch 6 Step 1336/1563 Loss: 1.404 | Acc: 49.292% (21089/42784)\n",
      "Epoch 6 Step 1337/1563 Loss: 1.403 | Acc: 49.304% (21110/42816)\n",
      "Epoch 6 Step 1338/1563 Loss: 1.404 | Acc: 49.298% (21123/42848)\n",
      "Epoch 6 Step 1339/1563 Loss: 1.404 | Acc: 49.291% (21136/42880)\n",
      "Epoch 6 Step 1340/1563 Loss: 1.403 | Acc: 49.294% (21153/42912)\n",
      "Epoch 6 Step 1341/1563 Loss: 1.403 | Acc: 49.290% (21167/42944)\n",
      "Epoch 6 Step 1342/1563 Loss: 1.404 | Acc: 49.286% (21181/42976)\n",
      "Epoch 6 Step 1343/1563 Loss: 1.403 | Acc: 49.289% (21198/43008)\n",
      "Epoch 6 Step 1344/1563 Loss: 1.403 | Acc: 49.294% (21216/43040)\n",
      "Epoch 6 Step 1345/1563 Loss: 1.403 | Acc: 49.297% (21233/43072)\n",
      "Epoch 6 Step 1346/1563 Loss: 1.403 | Acc: 49.309% (21254/43104)\n",
      "Epoch 6 Step 1347/1563 Loss: 1.403 | Acc: 49.298% (21265/43136)\n",
      "Epoch 6 Step 1348/1563 Loss: 1.403 | Acc: 49.289% (21277/43168)\n",
      "Epoch 6 Step 1349/1563 Loss: 1.403 | Acc: 49.292% (21294/43200)\n",
      "Epoch 6 Step 1350/1563 Loss: 1.403 | Acc: 49.304% (21315/43232)\n",
      "Epoch 6 Step 1351/1563 Loss: 1.403 | Acc: 49.295% (21327/43264)\n",
      "Epoch 6 Step 1352/1563 Loss: 1.403 | Acc: 49.309% (21349/43296)\n",
      "Epoch 6 Step 1353/1563 Loss: 1.403 | Acc: 49.308% (21364/43328)\n",
      "Epoch 6 Step 1354/1563 Loss: 1.403 | Acc: 49.310% (21381/43360)\n",
      "Epoch 6 Step 1355/1563 Loss: 1.403 | Acc: 49.302% (21393/43392)\n",
      "Epoch 6 Step 1356/1563 Loss: 1.403 | Acc: 49.305% (21410/43424)\n",
      "Epoch 6 Step 1357/1563 Loss: 1.404 | Acc: 49.307% (21427/43456)\n",
      "Epoch 6 Step 1358/1563 Loss: 1.403 | Acc: 49.306% (21442/43488)\n",
      "Epoch 6 Step 1359/1563 Loss: 1.404 | Acc: 49.304% (21457/43520)\n",
      "Epoch 6 Step 1360/1563 Loss: 1.403 | Acc: 49.309% (21475/43552)\n",
      "Epoch 6 Step 1361/1563 Loss: 1.403 | Acc: 49.307% (21490/43584)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 1362/1563 Loss: 1.404 | Acc: 49.298% (21502/43616)\n",
      "Epoch 6 Step 1363/1563 Loss: 1.404 | Acc: 49.290% (21514/43648)\n",
      "Epoch 6 Step 1364/1563 Loss: 1.404 | Acc: 49.293% (21531/43680)\n",
      "Epoch 6 Step 1365/1563 Loss: 1.404 | Acc: 49.298% (21549/43712)\n",
      "Epoch 6 Step 1366/1563 Loss: 1.404 | Acc: 49.300% (21566/43744)\n",
      "Epoch 6 Step 1367/1563 Loss: 1.404 | Acc: 49.296% (21580/43776)\n",
      "Epoch 6 Step 1368/1563 Loss: 1.404 | Acc: 49.301% (21598/43808)\n",
      "Epoch 6 Step 1369/1563 Loss: 1.404 | Acc: 49.295% (21611/43840)\n",
      "Epoch 6 Step 1370/1563 Loss: 1.404 | Acc: 49.296% (21627/43872)\n",
      "Epoch 6 Step 1371/1563 Loss: 1.404 | Acc: 49.294% (21642/43904)\n",
      "Epoch 6 Step 1372/1563 Loss: 1.404 | Acc: 49.294% (21658/43936)\n",
      "Epoch 6 Step 1373/1563 Loss: 1.404 | Acc: 49.297% (21675/43968)\n",
      "Epoch 6 Step 1374/1563 Loss: 1.404 | Acc: 49.311% (21697/44000)\n",
      "Epoch 6 Step 1375/1563 Loss: 1.404 | Acc: 49.307% (21711/44032)\n",
      "Epoch 6 Step 1376/1563 Loss: 1.404 | Acc: 49.312% (21729/44064)\n",
      "Epoch 6 Step 1377/1563 Loss: 1.404 | Acc: 49.311% (21744/44096)\n",
      "Epoch 6 Step 1378/1563 Loss: 1.404 | Acc: 49.313% (21761/44128)\n",
      "Epoch 6 Step 1379/1563 Loss: 1.404 | Acc: 49.307% (21774/44160)\n",
      "Epoch 6 Step 1380/1563 Loss: 1.404 | Acc: 49.310% (21791/44192)\n",
      "Epoch 6 Step 1381/1563 Loss: 1.404 | Acc: 49.317% (21810/44224)\n",
      "Epoch 6 Step 1382/1563 Loss: 1.404 | Acc: 49.309% (21822/44256)\n",
      "Epoch 6 Step 1383/1563 Loss: 1.404 | Acc: 49.305% (21836/44288)\n",
      "Epoch 6 Step 1384/1563 Loss: 1.404 | Acc: 49.307% (21853/44320)\n",
      "Epoch 6 Step 1385/1563 Loss: 1.404 | Acc: 49.301% (21866/44352)\n",
      "Epoch 6 Step 1386/1563 Loss: 1.404 | Acc: 49.304% (21883/44384)\n",
      "Epoch 6 Step 1387/1563 Loss: 1.404 | Acc: 49.304% (21899/44416)\n",
      "Epoch 6 Step 1388/1563 Loss: 1.404 | Acc: 49.314% (21919/44448)\n",
      "Epoch 6 Step 1389/1563 Loss: 1.404 | Acc: 49.314% (21935/44480)\n",
      "Epoch 6 Step 1390/1563 Loss: 1.404 | Acc: 49.315% (21951/44512)\n",
      "Epoch 6 Step 1391/1563 Loss: 1.404 | Acc: 49.324% (21971/44544)\n",
      "Epoch 6 Step 1392/1563 Loss: 1.404 | Acc: 49.329% (21989/44576)\n",
      "Epoch 6 Step 1393/1563 Loss: 1.404 | Acc: 49.336% (22008/44608)\n",
      "Epoch 6 Step 1394/1563 Loss: 1.403 | Acc: 49.346% (22028/44640)\n",
      "Epoch 6 Step 1395/1563 Loss: 1.404 | Acc: 49.340% (22041/44672)\n",
      "Epoch 6 Step 1396/1563 Loss: 1.404 | Acc: 49.340% (22057/44704)\n",
      "Epoch 6 Step 1397/1563 Loss: 1.403 | Acc: 49.341% (22073/44736)\n",
      "Epoch 6 Step 1398/1563 Loss: 1.404 | Acc: 49.337% (22087/44768)\n",
      "Epoch 6 Step 1399/1563 Loss: 1.403 | Acc: 49.342% (22105/44800)\n",
      "Epoch 6 Step 1400/1563 Loss: 1.403 | Acc: 49.342% (22121/44832)\n",
      "Epoch 6 Step 1401/1563 Loss: 1.403 | Acc: 49.345% (22138/44864)\n",
      "Epoch 6 Step 1402/1563 Loss: 1.403 | Acc: 49.347% (22155/44896)\n",
      "Epoch 6 Step 1403/1563 Loss: 1.403 | Acc: 49.352% (22173/44928)\n",
      "Epoch 6 Step 1404/1563 Loss: 1.403 | Acc: 49.351% (22188/44960)\n",
      "Epoch 6 Step 1405/1563 Loss: 1.403 | Acc: 49.358% (22207/44992)\n",
      "Epoch 6 Step 1406/1563 Loss: 1.404 | Acc: 49.356% (22222/45024)\n",
      "Epoch 6 Step 1407/1563 Loss: 1.404 | Acc: 49.354% (22237/45056)\n",
      "Epoch 6 Step 1408/1563 Loss: 1.404 | Acc: 49.357% (22254/45088)\n",
      "Epoch 6 Step 1409/1563 Loss: 1.404 | Acc: 49.359% (22271/45120)\n",
      "Epoch 6 Step 1410/1563 Loss: 1.404 | Acc: 49.362% (22288/45152)\n",
      "Epoch 6 Step 1411/1563 Loss: 1.404 | Acc: 49.358% (22302/45184)\n",
      "Epoch 6 Step 1412/1563 Loss: 1.404 | Acc: 49.370% (22323/45216)\n",
      "Epoch 6 Step 1413/1563 Loss: 1.404 | Acc: 49.372% (22340/45248)\n",
      "Epoch 6 Step 1414/1563 Loss: 1.404 | Acc: 49.371% (22355/45280)\n",
      "Epoch 6 Step 1415/1563 Loss: 1.403 | Acc: 49.371% (22371/45312)\n",
      "Epoch 6 Step 1416/1563 Loss: 1.403 | Acc: 49.369% (22386/45344)\n",
      "Epoch 6 Step 1417/1563 Loss: 1.403 | Acc: 49.381% (22407/45376)\n",
      "Epoch 6 Step 1418/1563 Loss: 1.403 | Acc: 49.375% (22420/45408)\n",
      "Epoch 6 Step 1419/1563 Loss: 1.403 | Acc: 49.379% (22438/45440)\n",
      "Epoch 6 Step 1420/1563 Loss: 1.403 | Acc: 49.373% (22451/45472)\n",
      "Epoch 6 Step 1421/1563 Loss: 1.403 | Acc: 49.389% (22474/45504)\n",
      "Epoch 6 Step 1422/1563 Loss: 1.403 | Acc: 49.396% (22493/45536)\n",
      "Epoch 6 Step 1423/1563 Loss: 1.403 | Acc: 49.379% (22501/45568)\n",
      "Epoch 6 Step 1424/1563 Loss: 1.403 | Acc: 49.384% (22519/45600)\n",
      "Epoch 6 Step 1425/1563 Loss: 1.403 | Acc: 49.382% (22534/45632)\n",
      "Epoch 6 Step 1426/1563 Loss: 1.403 | Acc: 49.385% (22551/45664)\n",
      "Epoch 6 Step 1427/1563 Loss: 1.403 | Acc: 49.379% (22564/45696)\n",
      "Epoch 6 Step 1428/1563 Loss: 1.403 | Acc: 49.372% (22577/45728)\n",
      "Epoch 6 Step 1429/1563 Loss: 1.403 | Acc: 49.364% (22589/45760)\n",
      "Epoch 6 Step 1430/1563 Loss: 1.403 | Acc: 49.369% (22607/45792)\n",
      "Epoch 6 Step 1431/1563 Loss: 1.403 | Acc: 49.365% (22621/45824)\n",
      "Epoch 6 Step 1432/1563 Loss: 1.403 | Acc: 49.368% (22638/45856)\n",
      "Epoch 6 Step 1433/1563 Loss: 1.403 | Acc: 49.366% (22653/45888)\n",
      "Epoch 6 Step 1434/1563 Loss: 1.403 | Acc: 49.362% (22667/45920)\n",
      "Epoch 6 Step 1435/1563 Loss: 1.403 | Acc: 49.362% (22683/45952)\n",
      "Epoch 6 Step 1436/1563 Loss: 1.403 | Acc: 49.367% (22701/45984)\n",
      "Epoch 6 Step 1437/1563 Loss: 1.403 | Acc: 49.376% (22721/46016)\n",
      "Epoch 6 Step 1438/1563 Loss: 1.403 | Acc: 49.390% (22743/46048)\n",
      "Epoch 6 Step 1439/1563 Loss: 1.403 | Acc: 49.401% (22764/46080)\n",
      "Epoch 6 Step 1440/1563 Loss: 1.403 | Acc: 49.404% (22781/46112)\n",
      "Epoch 6 Step 1441/1563 Loss: 1.402 | Acc: 49.398% (22794/46144)\n",
      "Epoch 6 Step 1442/1563 Loss: 1.403 | Acc: 49.389% (22806/46176)\n",
      "Epoch 6 Step 1443/1563 Loss: 1.403 | Acc: 49.379% (22817/46208)\n",
      "Epoch 6 Step 1444/1563 Loss: 1.403 | Acc: 49.384% (22835/46240)\n",
      "Epoch 6 Step 1445/1563 Loss: 1.403 | Acc: 49.384% (22851/46272)\n",
      "Epoch 6 Step 1446/1563 Loss: 1.403 | Acc: 49.391% (22870/46304)\n",
      "Epoch 6 Step 1447/1563 Loss: 1.403 | Acc: 49.400% (22890/46336)\n",
      "Epoch 6 Step 1448/1563 Loss: 1.403 | Acc: 49.403% (22907/46368)\n",
      "Epoch 6 Step 1449/1563 Loss: 1.403 | Acc: 49.403% (22923/46400)\n",
      "Epoch 6 Step 1450/1563 Loss: 1.403 | Acc: 49.397% (22936/46432)\n",
      "Epoch 6 Step 1451/1563 Loss: 1.403 | Acc: 49.400% (22953/46464)\n",
      "Epoch 6 Step 1452/1563 Loss: 1.403 | Acc: 49.398% (22968/46496)\n",
      "Epoch 6 Step 1453/1563 Loss: 1.403 | Acc: 49.407% (22988/46528)\n",
      "Epoch 6 Step 1454/1563 Loss: 1.403 | Acc: 49.399% (23000/46560)\n",
      "Epoch 6 Step 1455/1563 Loss: 1.403 | Acc: 49.403% (23018/46592)\n",
      "Epoch 6 Step 1456/1563 Loss: 1.403 | Acc: 49.406% (23035/46624)\n",
      "Epoch 6 Step 1457/1563 Loss: 1.403 | Acc: 49.404% (23050/46656)\n",
      "Epoch 6 Step 1458/1563 Loss: 1.403 | Acc: 49.405% (23066/46688)\n",
      "Epoch 6 Step 1459/1563 Loss: 1.403 | Acc: 49.409% (23084/46720)\n",
      "Epoch 6 Step 1460/1563 Loss: 1.402 | Acc: 49.405% (23098/46752)\n",
      "Epoch 6 Step 1461/1563 Loss: 1.402 | Acc: 49.406% (23114/46784)\n",
      "Epoch 6 Step 1462/1563 Loss: 1.402 | Acc: 49.406% (23130/46816)\n",
      "Epoch 6 Step 1463/1563 Loss: 1.402 | Acc: 49.407% (23146/46848)\n",
      "Epoch 6 Step 1464/1563 Loss: 1.402 | Acc: 49.409% (23163/46880)\n",
      "Epoch 6 Step 1465/1563 Loss: 1.402 | Acc: 49.418% (23183/46912)\n",
      "Epoch 6 Step 1466/1563 Loss: 1.402 | Acc: 49.408% (23194/46944)\n",
      "Epoch 6 Step 1467/1563 Loss: 1.402 | Acc: 49.408% (23210/46976)\n",
      "Epoch 6 Step 1468/1563 Loss: 1.402 | Acc: 49.415% (23229/47008)\n",
      "Epoch 6 Step 1469/1563 Loss: 1.402 | Acc: 49.415% (23245/47040)\n",
      "Epoch 6 Step 1470/1563 Loss: 1.402 | Acc: 49.420% (23263/47072)\n",
      "Epoch 6 Step 1471/1563 Loss: 1.402 | Acc: 49.420% (23279/47104)\n",
      "Epoch 6 Step 1472/1563 Loss: 1.402 | Acc: 49.419% (23294/47136)\n",
      "Epoch 6 Step 1473/1563 Loss: 1.402 | Acc: 49.423% (23312/47168)\n",
      "Epoch 6 Step 1474/1563 Loss: 1.402 | Acc: 49.424% (23328/47200)\n",
      "Epoch 6 Step 1475/1563 Loss: 1.402 | Acc: 49.420% (23342/47232)\n",
      "Epoch 6 Step 1476/1563 Loss: 1.402 | Acc: 49.427% (23361/47264)\n",
      "Epoch 6 Step 1477/1563 Loss: 1.402 | Acc: 49.425% (23376/47296)\n",
      "Epoch 6 Step 1478/1563 Loss: 1.402 | Acc: 49.425% (23392/47328)\n",
      "Epoch 6 Step 1479/1563 Loss: 1.402 | Acc: 49.417% (23404/47360)\n",
      "Epoch 6 Step 1480/1563 Loss: 1.402 | Acc: 49.426% (23424/47392)\n",
      "Epoch 6 Step 1481/1563 Loss: 1.402 | Acc: 49.414% (23434/47424)\n",
      "Epoch 6 Step 1482/1563 Loss: 1.402 | Acc: 49.414% (23450/47456)\n",
      "Epoch 6 Step 1483/1563 Loss: 1.402 | Acc: 49.417% (23467/47488)\n",
      "Epoch 6 Step 1484/1563 Loss: 1.402 | Acc: 49.411% (23480/47520)\n",
      "Epoch 6 Step 1485/1563 Loss: 1.402 | Acc: 49.407% (23494/47552)\n",
      "Epoch 6 Step 1486/1563 Loss: 1.402 | Acc: 49.418% (23515/47584)\n",
      "Epoch 6 Step 1487/1563 Loss: 1.401 | Acc: 49.429% (23536/47616)\n",
      "Epoch 6 Step 1488/1563 Loss: 1.401 | Acc: 49.431% (23553/47648)\n",
      "Epoch 6 Step 1489/1563 Loss: 1.401 | Acc: 49.440% (23573/47680)\n",
      "Epoch 6 Step 1490/1563 Loss: 1.401 | Acc: 49.438% (23588/47712)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 1491/1563 Loss: 1.401 | Acc: 49.445% (23607/47744)\n",
      "Epoch 6 Step 1492/1563 Loss: 1.401 | Acc: 49.452% (23626/47776)\n",
      "Epoch 6 Step 1493/1563 Loss: 1.401 | Acc: 49.448% (23640/47808)\n",
      "Epoch 6 Step 1494/1563 Loss: 1.401 | Acc: 49.452% (23658/47840)\n",
      "Epoch 6 Step 1495/1563 Loss: 1.401 | Acc: 49.459% (23677/47872)\n",
      "Epoch 6 Step 1496/1563 Loss: 1.401 | Acc: 49.453% (23690/47904)\n",
      "Epoch 6 Step 1497/1563 Loss: 1.401 | Acc: 49.460% (23709/47936)\n",
      "Epoch 6 Step 1498/1563 Loss: 1.401 | Acc: 49.460% (23725/47968)\n",
      "Epoch 6 Step 1499/1563 Loss: 1.401 | Acc: 49.465% (23743/48000)\n",
      "Epoch 6 Step 1500/1563 Loss: 1.401 | Acc: 49.471% (23762/48032)\n",
      "Epoch 6 Step 1501/1563 Loss: 1.401 | Acc: 49.469% (23777/48064)\n",
      "Epoch 6 Step 1502/1563 Loss: 1.401 | Acc: 49.472% (23794/48096)\n",
      "Epoch 6 Step 1503/1563 Loss: 1.401 | Acc: 49.468% (23808/48128)\n",
      "Epoch 6 Step 1504/1563 Loss: 1.401 | Acc: 49.479% (23829/48160)\n",
      "Epoch 6 Step 1505/1563 Loss: 1.401 | Acc: 49.485% (23848/48192)\n",
      "Epoch 6 Step 1506/1563 Loss: 1.401 | Acc: 49.486% (23864/48224)\n",
      "Epoch 6 Step 1507/1563 Loss: 1.401 | Acc: 49.494% (23884/48256)\n",
      "Epoch 6 Step 1508/1563 Loss: 1.401 | Acc: 49.493% (23899/48288)\n",
      "Epoch 6 Step 1509/1563 Loss: 1.401 | Acc: 49.489% (23913/48320)\n",
      "Epoch 6 Step 1510/1563 Loss: 1.401 | Acc: 49.485% (23927/48352)\n",
      "Epoch 6 Step 1511/1563 Loss: 1.401 | Acc: 49.481% (23941/48384)\n",
      "Epoch 6 Step 1512/1563 Loss: 1.401 | Acc: 49.490% (23961/48416)\n",
      "Epoch 6 Step 1513/1563 Loss: 1.401 | Acc: 49.490% (23977/48448)\n",
      "Epoch 6 Step 1514/1563 Loss: 1.400 | Acc: 49.493% (23994/48480)\n",
      "Epoch 6 Step 1515/1563 Loss: 1.400 | Acc: 49.495% (24011/48512)\n",
      "Epoch 6 Step 1516/1563 Loss: 1.400 | Acc: 49.495% (24027/48544)\n",
      "Epoch 6 Step 1517/1563 Loss: 1.401 | Acc: 49.494% (24042/48576)\n",
      "Epoch 6 Step 1518/1563 Loss: 1.401 | Acc: 49.490% (24056/48608)\n",
      "Epoch 6 Step 1519/1563 Loss: 1.400 | Acc: 49.496% (24075/48640)\n",
      "Epoch 6 Step 1520/1563 Loss: 1.401 | Acc: 49.488% (24087/48672)\n",
      "Epoch 6 Step 1521/1563 Loss: 1.401 | Acc: 49.487% (24102/48704)\n",
      "Epoch 6 Step 1522/1563 Loss: 1.401 | Acc: 49.481% (24115/48736)\n",
      "Epoch 6 Step 1523/1563 Loss: 1.401 | Acc: 49.483% (24132/48768)\n",
      "Epoch 6 Step 1524/1563 Loss: 1.401 | Acc: 49.486% (24149/48800)\n",
      "Epoch 6 Step 1525/1563 Loss: 1.401 | Acc: 49.476% (24160/48832)\n",
      "Epoch 6 Step 1526/1563 Loss: 1.401 | Acc: 49.472% (24174/48864)\n",
      "Epoch 6 Step 1527/1563 Loss: 1.401 | Acc: 49.470% (24189/48896)\n",
      "Epoch 6 Step 1528/1563 Loss: 1.400 | Acc: 49.481% (24210/48928)\n",
      "Epoch 6 Step 1529/1563 Loss: 1.400 | Acc: 49.481% (24226/48960)\n",
      "Epoch 6 Step 1530/1563 Loss: 1.400 | Acc: 49.473% (24238/48992)\n",
      "Epoch 6 Step 1531/1563 Loss: 1.401 | Acc: 49.468% (24251/49024)\n",
      "Epoch 6 Step 1532/1563 Loss: 1.401 | Acc: 49.462% (24264/49056)\n",
      "Epoch 6 Step 1533/1563 Loss: 1.401 | Acc: 49.464% (24281/49088)\n",
      "Epoch 6 Step 1534/1563 Loss: 1.401 | Acc: 49.463% (24296/49120)\n",
      "Epoch 6 Step 1535/1563 Loss: 1.401 | Acc: 49.451% (24306/49152)\n",
      "Epoch 6 Step 1536/1563 Loss: 1.401 | Acc: 49.447% (24320/49184)\n",
      "Epoch 6 Step 1537/1563 Loss: 1.401 | Acc: 49.441% (24333/49216)\n",
      "Epoch 6 Step 1538/1563 Loss: 1.401 | Acc: 49.454% (24355/49248)\n",
      "Epoch 6 Step 1539/1563 Loss: 1.401 | Acc: 49.458% (24373/49280)\n",
      "Epoch 6 Step 1540/1563 Loss: 1.401 | Acc: 49.459% (24389/49312)\n",
      "Epoch 6 Step 1541/1563 Loss: 1.400 | Acc: 49.459% (24405/49344)\n",
      "Epoch 6 Step 1542/1563 Loss: 1.400 | Acc: 49.463% (24423/49376)\n",
      "Epoch 6 Step 1543/1563 Loss: 1.400 | Acc: 49.470% (24442/49408)\n",
      "Epoch 6 Step 1544/1563 Loss: 1.400 | Acc: 49.464% (24455/49440)\n",
      "Epoch 6 Step 1545/1563 Loss: 1.400 | Acc: 49.464% (24471/49472)\n",
      "Epoch 6 Step 1546/1563 Loss: 1.400 | Acc: 49.459% (24484/49504)\n",
      "Epoch 6 Step 1547/1563 Loss: 1.400 | Acc: 49.455% (24498/49536)\n",
      "Epoch 6 Step 1548/1563 Loss: 1.400 | Acc: 49.455% (24514/49568)\n",
      "Epoch 6 Step 1549/1563 Loss: 1.400 | Acc: 49.456% (24530/49600)\n",
      "Epoch 6 Step 1550/1563 Loss: 1.400 | Acc: 49.456% (24546/49632)\n",
      "Epoch 6 Step 1551/1563 Loss: 1.400 | Acc: 49.446% (24557/49664)\n",
      "Epoch 6 Step 1552/1563 Loss: 1.401 | Acc: 49.439% (24569/49696)\n",
      "Epoch 6 Step 1553/1563 Loss: 1.401 | Acc: 49.425% (24578/49728)\n",
      "Epoch 6 Step 1554/1563 Loss: 1.401 | Acc: 49.419% (24591/49760)\n",
      "Epoch 6 Step 1555/1563 Loss: 1.401 | Acc: 49.406% (24600/49792)\n",
      "Epoch 6 Step 1556/1563 Loss: 1.401 | Acc: 49.414% (24620/49824)\n",
      "Epoch 6 Step 1557/1563 Loss: 1.401 | Acc: 49.416% (24637/49856)\n",
      "Epoch 6 Step 1558/1563 Loss: 1.401 | Acc: 49.421% (24655/49888)\n",
      "Epoch 6 Step 1559/1563 Loss: 1.401 | Acc: 49.409% (24665/49920)\n",
      "Epoch 6 Step 1560/1563 Loss: 1.401 | Acc: 49.415% (24684/49952)\n",
      "Epoch 6 Step 1561/1563 Loss: 1.401 | Acc: 49.416% (24700/49984)\n",
      "Epoch 6 Step 1562/1563 Loss: 1.401 | Acc: 49.418% (24709/50000)\n",
      "Epoch 6 Step 0/313 Test Loss: 1.060 | Test Acc: 62.500% (20/32)\n",
      "Epoch 6 Step 1/313 Test Loss: 1.247 | Test Acc: 54.688% (35/64)\n",
      "Epoch 6 Step 2/313 Test Loss: 1.239 | Test Acc: 58.333% (56/96)\n",
      "Epoch 6 Step 3/313 Test Loss: 1.232 | Test Acc: 57.031% (73/128)\n",
      "Epoch 6 Step 4/313 Test Loss: 1.269 | Test Acc: 55.000% (88/160)\n",
      "Epoch 6 Step 5/313 Test Loss: 1.283 | Test Acc: 54.167% (104/192)\n",
      "Epoch 6 Step 6/313 Test Loss: 1.326 | Test Acc: 53.571% (120/224)\n",
      "Epoch 6 Step 7/313 Test Loss: 1.348 | Test Acc: 53.906% (138/256)\n",
      "Epoch 6 Step 8/313 Test Loss: 1.361 | Test Acc: 51.736% (149/288)\n",
      "Epoch 6 Step 9/313 Test Loss: 1.332 | Test Acc: 53.125% (170/320)\n",
      "Epoch 6 Step 10/313 Test Loss: 1.320 | Test Acc: 53.125% (187/352)\n",
      "Epoch 6 Step 11/313 Test Loss: 1.332 | Test Acc: 52.604% (202/384)\n",
      "Epoch 6 Step 12/313 Test Loss: 1.317 | Test Acc: 53.606% (223/416)\n",
      "Epoch 6 Step 13/313 Test Loss: 1.325 | Test Acc: 53.795% (241/448)\n",
      "Epoch 6 Step 14/313 Test Loss: 1.334 | Test Acc: 52.708% (253/480)\n",
      "Epoch 6 Step 15/313 Test Loss: 1.318 | Test Acc: 53.125% (272/512)\n",
      "Epoch 6 Step 16/313 Test Loss: 1.305 | Test Acc: 53.493% (291/544)\n",
      "Epoch 6 Step 17/313 Test Loss: 1.296 | Test Acc: 53.646% (309/576)\n",
      "Epoch 6 Step 18/313 Test Loss: 1.297 | Test Acc: 53.783% (327/608)\n",
      "Epoch 6 Step 19/313 Test Loss: 1.278 | Test Acc: 54.375% (348/640)\n",
      "Epoch 6 Step 20/313 Test Loss: 1.269 | Test Acc: 54.613% (367/672)\n",
      "Epoch 6 Step 21/313 Test Loss: 1.281 | Test Acc: 54.403% (383/704)\n",
      "Epoch 6 Step 22/313 Test Loss: 1.279 | Test Acc: 54.348% (400/736)\n",
      "Epoch 6 Step 23/313 Test Loss: 1.278 | Test Acc: 54.427% (418/768)\n",
      "Epoch 6 Step 24/313 Test Loss: 1.282 | Test Acc: 54.250% (434/800)\n",
      "Epoch 6 Step 25/313 Test Loss: 1.280 | Test Acc: 54.327% (452/832)\n",
      "Epoch 6 Step 26/313 Test Loss: 1.280 | Test Acc: 54.282% (469/864)\n",
      "Epoch 6 Step 27/313 Test Loss: 1.277 | Test Acc: 54.241% (486/896)\n",
      "Epoch 6 Step 28/313 Test Loss: 1.276 | Test Acc: 54.203% (503/928)\n",
      "Epoch 6 Step 29/313 Test Loss: 1.270 | Test Acc: 54.167% (520/960)\n",
      "Epoch 6 Step 30/313 Test Loss: 1.264 | Test Acc: 54.335% (539/992)\n",
      "Epoch 6 Step 31/313 Test Loss: 1.254 | Test Acc: 54.883% (562/1024)\n",
      "Epoch 6 Step 32/313 Test Loss: 1.260 | Test Acc: 54.735% (578/1056)\n",
      "Epoch 6 Step 33/313 Test Loss: 1.263 | Test Acc: 54.779% (596/1088)\n",
      "Epoch 6 Step 34/313 Test Loss: 1.255 | Test Acc: 55.089% (617/1120)\n",
      "Epoch 6 Step 35/313 Test Loss: 1.266 | Test Acc: 54.514% (628/1152)\n",
      "Epoch 6 Step 36/313 Test Loss: 1.265 | Test Acc: 54.392% (644/1184)\n",
      "Epoch 6 Step 37/313 Test Loss: 1.264 | Test Acc: 54.605% (664/1216)\n",
      "Epoch 6 Step 38/313 Test Loss: 1.272 | Test Acc: 54.327% (678/1248)\n",
      "Epoch 6 Step 39/313 Test Loss: 1.275 | Test Acc: 53.906% (690/1280)\n",
      "Epoch 6 Step 40/313 Test Loss: 1.278 | Test Acc: 53.354% (700/1312)\n",
      "Epoch 6 Step 41/313 Test Loss: 1.281 | Test Acc: 53.274% (716/1344)\n",
      "Epoch 6 Step 42/313 Test Loss: 1.275 | Test Acc: 53.416% (735/1376)\n",
      "Epoch 6 Step 43/313 Test Loss: 1.281 | Test Acc: 53.196% (749/1408)\n",
      "Epoch 6 Step 44/313 Test Loss: 1.285 | Test Acc: 52.917% (762/1440)\n",
      "Epoch 6 Step 45/313 Test Loss: 1.282 | Test Acc: 52.921% (779/1472)\n",
      "Epoch 6 Step 46/313 Test Loss: 1.282 | Test Acc: 52.926% (796/1504)\n",
      "Epoch 6 Step 47/313 Test Loss: 1.283 | Test Acc: 52.930% (813/1536)\n",
      "Epoch 6 Step 48/313 Test Loss: 1.279 | Test Acc: 52.934% (830/1568)\n",
      "Epoch 6 Step 49/313 Test Loss: 1.286 | Test Acc: 52.688% (843/1600)\n",
      "Epoch 6 Step 50/313 Test Loss: 1.296 | Test Acc: 52.328% (854/1632)\n",
      "Epoch 6 Step 51/313 Test Loss: 1.293 | Test Acc: 52.464% (873/1664)\n",
      "Epoch 6 Step 52/313 Test Loss: 1.292 | Test Acc: 52.594% (892/1696)\n",
      "Epoch 6 Step 53/313 Test Loss: 1.297 | Test Acc: 52.546% (908/1728)\n",
      "Epoch 6 Step 54/313 Test Loss: 1.301 | Test Acc: 52.500% (924/1760)\n",
      "Epoch 6 Step 55/313 Test Loss: 1.299 | Test Acc: 52.455% (940/1792)\n",
      "Epoch 6 Step 56/313 Test Loss: 1.298 | Test Acc: 52.412% (956/1824)\n",
      "Epoch 6 Step 57/313 Test Loss: 1.298 | Test Acc: 52.478% (974/1856)\n",
      "Epoch 6 Step 58/313 Test Loss: 1.297 | Test Acc: 52.595% (993/1888)\n",
      "Epoch 6 Step 59/313 Test Loss: 1.300 | Test Acc: 52.604% (1010/1920)\n",
      "Epoch 6 Step 60/313 Test Loss: 1.301 | Test Acc: 52.459% (1024/1952)\n",
      "Epoch 6 Step 61/313 Test Loss: 1.303 | Test Acc: 52.470% (1041/1984)\n",
      "Epoch 6 Step 62/313 Test Loss: 1.307 | Test Acc: 52.282% (1054/2016)\n",
      "Epoch 6 Step 63/313 Test Loss: 1.306 | Test Acc: 52.197% (1069/2048)\n",
      "Epoch 6 Step 64/313 Test Loss: 1.303 | Test Acc: 52.260% (1087/2080)\n",
      "Epoch 6 Step 65/313 Test Loss: 1.301 | Test Acc: 52.415% (1107/2112)\n",
      "Epoch 6 Step 66/313 Test Loss: 1.301 | Test Acc: 52.425% (1124/2144)\n",
      "Epoch 6 Step 67/313 Test Loss: 1.304 | Test Acc: 52.344% (1139/2176)\n",
      "Epoch 6 Step 68/313 Test Loss: 1.306 | Test Acc: 52.355% (1156/2208)\n",
      "Epoch 6 Step 69/313 Test Loss: 1.304 | Test Acc: 52.545% (1177/2240)\n",
      "Epoch 6 Step 70/313 Test Loss: 1.303 | Test Acc: 52.641% (1196/2272)\n",
      "Epoch 6 Step 71/313 Test Loss: 1.307 | Test Acc: 52.517% (1210/2304)\n",
      "Epoch 6 Step 72/313 Test Loss: 1.307 | Test Acc: 52.611% (1229/2336)\n",
      "Epoch 6 Step 73/313 Test Loss: 1.304 | Test Acc: 52.829% (1251/2368)\n",
      "Epoch 6 Step 74/313 Test Loss: 1.304 | Test Acc: 52.917% (1270/2400)\n",
      "Epoch 6 Step 75/313 Test Loss: 1.304 | Test Acc: 52.878% (1286/2432)\n",
      "Epoch 6 Step 76/313 Test Loss: 1.303 | Test Acc: 52.963% (1305/2464)\n",
      "Epoch 6 Step 77/313 Test Loss: 1.302 | Test Acc: 53.085% (1325/2496)\n",
      "Epoch 6 Step 78/313 Test Loss: 1.309 | Test Acc: 52.809% (1335/2528)\n",
      "Epoch 6 Step 79/313 Test Loss: 1.312 | Test Acc: 52.773% (1351/2560)\n",
      "Epoch 6 Step 80/313 Test Loss: 1.313 | Test Acc: 52.662% (1365/2592)\n",
      "Epoch 6 Step 81/313 Test Loss: 1.312 | Test Acc: 52.858% (1387/2624)\n",
      "Epoch 6 Step 82/313 Test Loss: 1.313 | Test Acc: 52.824% (1403/2656)\n",
      "Epoch 6 Step 83/313 Test Loss: 1.311 | Test Acc: 52.939% (1423/2688)\n",
      "Epoch 6 Step 84/313 Test Loss: 1.313 | Test Acc: 52.868% (1438/2720)\n",
      "Epoch 6 Step 85/313 Test Loss: 1.313 | Test Acc: 52.725% (1451/2752)\n",
      "Epoch 6 Step 86/313 Test Loss: 1.315 | Test Acc: 52.586% (1464/2784)\n",
      "Epoch 6 Step 87/313 Test Loss: 1.313 | Test Acc: 52.734% (1485/2816)\n",
      "Epoch 6 Step 88/313 Test Loss: 1.315 | Test Acc: 52.669% (1500/2848)\n",
      "Epoch 6 Step 89/313 Test Loss: 1.315 | Test Acc: 52.639% (1516/2880)\n",
      "Epoch 6 Step 90/313 Test Loss: 1.314 | Test Acc: 52.713% (1535/2912)\n",
      "Epoch 6 Step 91/313 Test Loss: 1.310 | Test Acc: 52.717% (1552/2944)\n",
      "Epoch 6 Step 92/313 Test Loss: 1.310 | Test Acc: 52.789% (1571/2976)\n",
      "Epoch 6 Step 93/313 Test Loss: 1.311 | Test Acc: 52.726% (1586/3008)\n",
      "Epoch 6 Step 94/313 Test Loss: 1.309 | Test Acc: 52.730% (1603/3040)\n",
      "Epoch 6 Step 95/313 Test Loss: 1.309 | Test Acc: 52.702% (1619/3072)\n",
      "Epoch 6 Step 96/313 Test Loss: 1.309 | Test Acc: 52.674% (1635/3104)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 97/313 Test Loss: 1.310 | Test Acc: 52.583% (1649/3136)\n",
      "Epoch 6 Step 98/313 Test Loss: 1.309 | Test Acc: 52.494% (1663/3168)\n",
      "Epoch 6 Step 99/313 Test Loss: 1.311 | Test Acc: 52.438% (1678/3200)\n",
      "Epoch 6 Step 100/313 Test Loss: 1.314 | Test Acc: 52.290% (1690/3232)\n",
      "Epoch 6 Step 101/313 Test Loss: 1.312 | Test Acc: 52.390% (1710/3264)\n",
      "Epoch 6 Step 102/313 Test Loss: 1.311 | Test Acc: 52.549% (1732/3296)\n",
      "Epoch 6 Step 103/313 Test Loss: 1.311 | Test Acc: 52.524% (1748/3328)\n",
      "Epoch 6 Step 104/313 Test Loss: 1.311 | Test Acc: 52.589% (1767/3360)\n",
      "Epoch 6 Step 105/313 Test Loss: 1.308 | Test Acc: 52.653% (1786/3392)\n",
      "Epoch 6 Step 106/313 Test Loss: 1.308 | Test Acc: 52.716% (1805/3424)\n",
      "Epoch 6 Step 107/313 Test Loss: 1.308 | Test Acc: 52.691% (1821/3456)\n",
      "Epoch 6 Step 108/313 Test Loss: 1.306 | Test Acc: 52.810% (1842/3488)\n",
      "Epoch 6 Step 109/313 Test Loss: 1.308 | Test Acc: 52.784% (1858/3520)\n",
      "Epoch 6 Step 110/313 Test Loss: 1.306 | Test Acc: 52.928% (1880/3552)\n",
      "Epoch 6 Step 111/313 Test Loss: 1.306 | Test Acc: 52.930% (1897/3584)\n",
      "Epoch 6 Step 112/313 Test Loss: 1.306 | Test Acc: 52.931% (1914/3616)\n",
      "Epoch 6 Step 113/313 Test Loss: 1.307 | Test Acc: 52.878% (1929/3648)\n",
      "Epoch 6 Step 114/313 Test Loss: 1.305 | Test Acc: 52.962% (1949/3680)\n",
      "Epoch 6 Step 115/313 Test Loss: 1.305 | Test Acc: 52.990% (1967/3712)\n",
      "Epoch 6 Step 116/313 Test Loss: 1.305 | Test Acc: 53.018% (1985/3744)\n",
      "Epoch 6 Step 117/313 Test Loss: 1.306 | Test Acc: 53.072% (2004/3776)\n",
      "Epoch 6 Step 118/313 Test Loss: 1.305 | Test Acc: 53.125% (2023/3808)\n",
      "Epoch 6 Step 119/313 Test Loss: 1.304 | Test Acc: 53.151% (2041/3840)\n",
      "Epoch 6 Step 120/313 Test Loss: 1.302 | Test Acc: 53.202% (2060/3872)\n",
      "Epoch 6 Step 121/313 Test Loss: 1.301 | Test Acc: 53.202% (2077/3904)\n",
      "Epoch 6 Step 122/313 Test Loss: 1.302 | Test Acc: 53.201% (2094/3936)\n",
      "Epoch 6 Step 123/313 Test Loss: 1.301 | Test Acc: 53.352% (2117/3968)\n",
      "Epoch 6 Step 124/313 Test Loss: 1.303 | Test Acc: 53.275% (2131/4000)\n",
      "Epoch 6 Step 125/313 Test Loss: 1.303 | Test Acc: 53.274% (2148/4032)\n",
      "Epoch 6 Step 126/313 Test Loss: 1.306 | Test Acc: 53.248% (2164/4064)\n",
      "Epoch 6 Step 127/313 Test Loss: 1.304 | Test Acc: 53.296% (2183/4096)\n",
      "Epoch 6 Step 128/313 Test Loss: 1.305 | Test Acc: 53.222% (2197/4128)\n",
      "Epoch 6 Step 129/313 Test Loss: 1.304 | Test Acc: 53.293% (2217/4160)\n",
      "Epoch 6 Step 130/313 Test Loss: 1.302 | Test Acc: 53.387% (2238/4192)\n",
      "Epoch 6 Step 131/313 Test Loss: 1.302 | Test Acc: 53.362% (2254/4224)\n",
      "Epoch 6 Step 132/313 Test Loss: 1.302 | Test Acc: 53.383% (2272/4256)\n",
      "Epoch 6 Step 133/313 Test Loss: 1.301 | Test Acc: 53.405% (2290/4288)\n",
      "Epoch 6 Step 134/313 Test Loss: 1.303 | Test Acc: 53.356% (2305/4320)\n",
      "Epoch 6 Step 135/313 Test Loss: 1.300 | Test Acc: 53.401% (2324/4352)\n",
      "Epoch 6 Step 136/313 Test Loss: 1.300 | Test Acc: 53.422% (2342/4384)\n",
      "Epoch 6 Step 137/313 Test Loss: 1.299 | Test Acc: 53.510% (2363/4416)\n",
      "Epoch 6 Step 138/313 Test Loss: 1.297 | Test Acc: 53.552% (2382/4448)\n",
      "Epoch 6 Step 139/313 Test Loss: 1.297 | Test Acc: 53.549% (2399/4480)\n",
      "Epoch 6 Step 140/313 Test Loss: 1.297 | Test Acc: 53.635% (2420/4512)\n",
      "Epoch 6 Step 141/313 Test Loss: 1.297 | Test Acc: 53.609% (2436/4544)\n",
      "Epoch 6 Step 142/313 Test Loss: 1.298 | Test Acc: 53.518% (2449/4576)\n",
      "Epoch 6 Step 143/313 Test Loss: 1.301 | Test Acc: 53.429% (2462/4608)\n",
      "Epoch 6 Step 144/313 Test Loss: 1.301 | Test Acc: 53.384% (2477/4640)\n",
      "Epoch 6 Step 145/313 Test Loss: 1.299 | Test Acc: 53.467% (2498/4672)\n",
      "Epoch 6 Step 146/313 Test Loss: 1.299 | Test Acc: 53.423% (2513/4704)\n",
      "Epoch 6 Step 147/313 Test Loss: 1.300 | Test Acc: 53.378% (2528/4736)\n",
      "Epoch 6 Step 148/313 Test Loss: 1.301 | Test Acc: 53.398% (2546/4768)\n",
      "Epoch 6 Step 149/313 Test Loss: 1.301 | Test Acc: 53.375% (2562/4800)\n",
      "Epoch 6 Step 150/313 Test Loss: 1.301 | Test Acc: 53.373% (2579/4832)\n",
      "Epoch 6 Step 151/313 Test Loss: 1.298 | Test Acc: 53.475% (2601/4864)\n",
      "Epoch 6 Step 152/313 Test Loss: 1.299 | Test Acc: 53.431% (2616/4896)\n",
      "Epoch 6 Step 153/313 Test Loss: 1.297 | Test Acc: 53.551% (2639/4928)\n",
      "Epoch 6 Step 154/313 Test Loss: 1.296 | Test Acc: 53.548% (2656/4960)\n",
      "Epoch 6 Step 155/313 Test Loss: 1.297 | Test Acc: 53.486% (2670/4992)\n",
      "Epoch 6 Step 156/313 Test Loss: 1.297 | Test Acc: 53.463% (2686/5024)\n",
      "Epoch 6 Step 157/313 Test Loss: 1.296 | Test Acc: 53.461% (2703/5056)\n",
      "Epoch 6 Step 158/313 Test Loss: 1.298 | Test Acc: 53.361% (2715/5088)\n",
      "Epoch 6 Step 159/313 Test Loss: 1.300 | Test Acc: 53.242% (2726/5120)\n",
      "Epoch 6 Step 160/313 Test Loss: 1.300 | Test Acc: 53.300% (2746/5152)\n",
      "Epoch 6 Step 161/313 Test Loss: 1.299 | Test Acc: 53.414% (2769/5184)\n",
      "Epoch 6 Step 162/313 Test Loss: 1.300 | Test Acc: 53.393% (2785/5216)\n",
      "Epoch 6 Step 163/313 Test Loss: 1.300 | Test Acc: 53.373% (2801/5248)\n",
      "Epoch 6 Step 164/313 Test Loss: 1.300 | Test Acc: 53.390% (2819/5280)\n",
      "Epoch 6 Step 165/313 Test Loss: 1.301 | Test Acc: 53.389% (2836/5312)\n",
      "Epoch 6 Step 166/313 Test Loss: 1.303 | Test Acc: 53.368% (2852/5344)\n",
      "Epoch 6 Step 167/313 Test Loss: 1.304 | Test Acc: 53.385% (2870/5376)\n",
      "Epoch 6 Step 168/313 Test Loss: 1.304 | Test Acc: 53.365% (2886/5408)\n",
      "Epoch 6 Step 169/313 Test Loss: 1.302 | Test Acc: 53.401% (2905/5440)\n",
      "Epoch 6 Step 170/313 Test Loss: 1.302 | Test Acc: 53.417% (2923/5472)\n",
      "Epoch 6 Step 171/313 Test Loss: 1.302 | Test Acc: 53.452% (2942/5504)\n",
      "Epoch 6 Step 172/313 Test Loss: 1.302 | Test Acc: 53.432% (2958/5536)\n",
      "Epoch 6 Step 173/313 Test Loss: 1.302 | Test Acc: 53.430% (2975/5568)\n",
      "Epoch 6 Step 174/313 Test Loss: 1.302 | Test Acc: 53.393% (2990/5600)\n",
      "Epoch 6 Step 175/313 Test Loss: 1.304 | Test Acc: 53.303% (3002/5632)\n",
      "Epoch 6 Step 176/313 Test Loss: 1.305 | Test Acc: 53.178% (3012/5664)\n",
      "Epoch 6 Step 177/313 Test Loss: 1.304 | Test Acc: 53.318% (3037/5696)\n",
      "Epoch 6 Step 178/313 Test Loss: 1.302 | Test Acc: 53.387% (3058/5728)\n",
      "Epoch 6 Step 179/313 Test Loss: 1.303 | Test Acc: 53.351% (3073/5760)\n",
      "Epoch 6 Step 180/313 Test Loss: 1.300 | Test Acc: 53.453% (3096/5792)\n",
      "Epoch 6 Step 181/313 Test Loss: 1.301 | Test Acc: 53.400% (3110/5824)\n",
      "Epoch 6 Step 182/313 Test Loss: 1.304 | Test Acc: 53.279% (3120/5856)\n",
      "Epoch 6 Step 183/313 Test Loss: 1.303 | Test Acc: 53.261% (3136/5888)\n",
      "Epoch 6 Step 184/313 Test Loss: 1.306 | Test Acc: 53.193% (3149/5920)\n",
      "Epoch 6 Step 185/313 Test Loss: 1.306 | Test Acc: 53.159% (3164/5952)\n",
      "Epoch 6 Step 186/313 Test Loss: 1.306 | Test Acc: 53.158% (3181/5984)\n",
      "Epoch 6 Step 187/313 Test Loss: 1.306 | Test Acc: 53.108% (3195/6016)\n",
      "Epoch 6 Step 188/313 Test Loss: 1.305 | Test Acc: 53.092% (3211/6048)\n",
      "Epoch 6 Step 189/313 Test Loss: 1.307 | Test Acc: 53.043% (3225/6080)\n",
      "Epoch 6 Step 190/313 Test Loss: 1.305 | Test Acc: 53.076% (3244/6112)\n",
      "Epoch 6 Step 191/313 Test Loss: 1.305 | Test Acc: 53.109% (3263/6144)\n",
      "Epoch 6 Step 192/313 Test Loss: 1.306 | Test Acc: 53.044% (3276/6176)\n",
      "Epoch 6 Step 193/313 Test Loss: 1.306 | Test Acc: 53.028% (3292/6208)\n",
      "Epoch 6 Step 194/313 Test Loss: 1.306 | Test Acc: 53.013% (3308/6240)\n",
      "Epoch 6 Step 195/313 Test Loss: 1.308 | Test Acc: 52.934% (3320/6272)\n",
      "Epoch 6 Step 196/313 Test Loss: 1.309 | Test Acc: 52.887% (3334/6304)\n",
      "Epoch 6 Step 197/313 Test Loss: 1.309 | Test Acc: 52.920% (3353/6336)\n",
      "Epoch 6 Step 198/313 Test Loss: 1.306 | Test Acc: 53.046% (3378/6368)\n",
      "Epoch 6 Step 199/313 Test Loss: 1.307 | Test Acc: 52.953% (3389/6400)\n",
      "Epoch 6 Step 200/313 Test Loss: 1.308 | Test Acc: 52.907% (3403/6432)\n",
      "Epoch 6 Step 201/313 Test Loss: 1.309 | Test Acc: 52.893% (3419/6464)\n",
      "Epoch 6 Step 202/313 Test Loss: 1.311 | Test Acc: 52.802% (3430/6496)\n",
      "Epoch 6 Step 203/313 Test Loss: 1.311 | Test Acc: 52.803% (3447/6528)\n",
      "Epoch 6 Step 204/313 Test Loss: 1.313 | Test Acc: 52.774% (3462/6560)\n",
      "Epoch 6 Step 205/313 Test Loss: 1.313 | Test Acc: 52.700% (3474/6592)\n",
      "Epoch 6 Step 206/313 Test Loss: 1.312 | Test Acc: 52.717% (3492/6624)\n",
      "Epoch 6 Step 207/313 Test Loss: 1.311 | Test Acc: 52.749% (3511/6656)\n",
      "Epoch 6 Step 208/313 Test Loss: 1.312 | Test Acc: 52.736% (3527/6688)\n",
      "Epoch 6 Step 209/313 Test Loss: 1.313 | Test Acc: 52.708% (3542/6720)\n",
      "Epoch 6 Step 210/313 Test Loss: 1.313 | Test Acc: 52.710% (3559/6752)\n",
      "Epoch 6 Step 211/313 Test Loss: 1.312 | Test Acc: 52.712% (3576/6784)\n",
      "Epoch 6 Step 212/313 Test Loss: 1.311 | Test Acc: 52.788% (3598/6816)\n",
      "Epoch 6 Step 213/313 Test Loss: 1.311 | Test Acc: 52.731% (3611/6848)\n",
      "Epoch 6 Step 214/313 Test Loss: 1.313 | Test Acc: 52.674% (3624/6880)\n",
      "Epoch 6 Step 215/313 Test Loss: 1.312 | Test Acc: 52.677% (3641/6912)\n",
      "Epoch 6 Step 216/313 Test Loss: 1.312 | Test Acc: 52.650% (3656/6944)\n",
      "Epoch 6 Step 217/313 Test Loss: 1.314 | Test Acc: 52.609% (3670/6976)\n",
      "Epoch 6 Step 218/313 Test Loss: 1.316 | Test Acc: 52.526% (3681/7008)\n",
      "Epoch 6 Step 219/313 Test Loss: 1.315 | Test Acc: 52.571% (3701/7040)\n",
      "Epoch 6 Step 220/313 Test Loss: 1.316 | Test Acc: 52.588% (3719/7072)\n",
      "Epoch 6 Step 221/313 Test Loss: 1.315 | Test Acc: 52.590% (3736/7104)\n",
      "Epoch 6 Step 222/313 Test Loss: 1.316 | Test Acc: 52.578% (3752/7136)\n",
      "Epoch 6 Step 223/313 Test Loss: 1.316 | Test Acc: 52.609% (3771/7168)\n",
      "Epoch 6 Step 224/313 Test Loss: 1.317 | Test Acc: 52.597% (3787/7200)\n",
      "Epoch 6 Step 225/313 Test Loss: 1.317 | Test Acc: 52.586% (3803/7232)\n",
      "Epoch 6 Step 226/313 Test Loss: 1.318 | Test Acc: 52.561% (3818/7264)\n",
      "Epoch 6 Step 227/313 Test Loss: 1.316 | Test Acc: 52.604% (3838/7296)\n",
      "Epoch 6 Step 228/313 Test Loss: 1.316 | Test Acc: 52.593% (3854/7328)\n",
      "Epoch 6 Step 229/313 Test Loss: 1.315 | Test Acc: 52.609% (3872/7360)\n",
      "Epoch 6 Step 230/313 Test Loss: 1.315 | Test Acc: 52.624% (3890/7392)\n",
      "Epoch 6 Step 231/313 Test Loss: 1.317 | Test Acc: 52.546% (3901/7424)\n",
      "Epoch 6 Step 232/313 Test Loss: 1.317 | Test Acc: 52.535% (3917/7456)\n",
      "Epoch 6 Step 233/313 Test Loss: 1.316 | Test Acc: 52.577% (3937/7488)\n",
      "Epoch 6 Step 234/313 Test Loss: 1.315 | Test Acc: 52.580% (3954/7520)\n",
      "Epoch 6 Step 235/313 Test Loss: 1.315 | Test Acc: 52.635% (3975/7552)\n",
      "Epoch 6 Step 236/313 Test Loss: 1.315 | Test Acc: 52.637% (3992/7584)\n",
      "Epoch 6 Step 237/313 Test Loss: 1.316 | Test Acc: 52.626% (4008/7616)\n",
      "Epoch 6 Step 238/313 Test Loss: 1.316 | Test Acc: 52.667% (4028/7648)\n",
      "Epoch 6 Step 239/313 Test Loss: 1.315 | Test Acc: 52.695% (4047/7680)\n",
      "Epoch 6 Step 240/313 Test Loss: 1.313 | Test Acc: 52.762% (4069/7712)\n",
      "Epoch 6 Step 241/313 Test Loss: 1.313 | Test Acc: 52.789% (4088/7744)\n",
      "Epoch 6 Step 242/313 Test Loss: 1.313 | Test Acc: 52.791% (4105/7776)\n",
      "Epoch 6 Step 243/313 Test Loss: 1.314 | Test Acc: 52.792% (4122/7808)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Step 244/313 Test Loss: 1.314 | Test Acc: 52.819% (4141/7840)\n",
      "Epoch 6 Step 245/313 Test Loss: 1.314 | Test Acc: 52.820% (4158/7872)\n",
      "Epoch 6 Step 246/313 Test Loss: 1.313 | Test Acc: 52.859% (4178/7904)\n",
      "Epoch 6 Step 247/313 Test Loss: 1.313 | Test Acc: 52.848% (4194/7936)\n",
      "Epoch 6 Step 248/313 Test Loss: 1.314 | Test Acc: 52.849% (4211/7968)\n",
      "Epoch 6 Step 249/313 Test Loss: 1.314 | Test Acc: 52.888% (4231/8000)\n",
      "Epoch 6 Step 250/313 Test Loss: 1.314 | Test Acc: 52.851% (4245/8032)\n",
      "Epoch 6 Step 251/313 Test Loss: 1.315 | Test Acc: 52.827% (4260/8064)\n",
      "Epoch 6 Step 252/313 Test Loss: 1.314 | Test Acc: 52.841% (4278/8096)\n",
      "Epoch 6 Step 253/313 Test Loss: 1.315 | Test Acc: 52.830% (4294/8128)\n",
      "Epoch 6 Step 254/313 Test Loss: 1.316 | Test Acc: 52.855% (4313/8160)\n",
      "Epoch 6 Step 255/313 Test Loss: 1.315 | Test Acc: 52.869% (4331/8192)\n",
      "Epoch 6 Step 256/313 Test Loss: 1.316 | Test Acc: 52.809% (4343/8224)\n",
      "Epoch 6 Step 257/313 Test Loss: 1.316 | Test Acc: 52.846% (4363/8256)\n",
      "Epoch 6 Step 258/313 Test Loss: 1.317 | Test Acc: 52.787% (4375/8288)\n",
      "Epoch 6 Step 259/313 Test Loss: 1.318 | Test Acc: 52.692% (4384/8320)\n",
      "Epoch 6 Step 260/313 Test Loss: 1.319 | Test Acc: 52.670% (4399/8352)\n",
      "Epoch 6 Step 261/313 Test Loss: 1.319 | Test Acc: 52.684% (4417/8384)\n",
      "Epoch 6 Step 262/313 Test Loss: 1.319 | Test Acc: 52.685% (4434/8416)\n",
      "Epoch 6 Step 263/313 Test Loss: 1.319 | Test Acc: 52.699% (4452/8448)\n",
      "Epoch 6 Step 264/313 Test Loss: 1.319 | Test Acc: 52.689% (4468/8480)\n",
      "Epoch 6 Step 265/313 Test Loss: 1.319 | Test Acc: 52.702% (4486/8512)\n",
      "Epoch 6 Step 266/313 Test Loss: 1.319 | Test Acc: 52.727% (4505/8544)\n",
      "Epoch 6 Step 267/313 Test Loss: 1.319 | Test Acc: 52.717% (4521/8576)\n",
      "Epoch 6 Step 268/313 Test Loss: 1.319 | Test Acc: 52.718% (4538/8608)\n",
      "Epoch 6 Step 269/313 Test Loss: 1.320 | Test Acc: 52.731% (4556/8640)\n",
      "Epoch 6 Step 270/313 Test Loss: 1.321 | Test Acc: 52.675% (4568/8672)\n",
      "Epoch 6 Step 271/313 Test Loss: 1.320 | Test Acc: 52.700% (4587/8704)\n",
      "Epoch 6 Step 272/313 Test Loss: 1.319 | Test Acc: 52.747% (4608/8736)\n",
      "Epoch 6 Step 273/313 Test Loss: 1.320 | Test Acc: 52.737% (4624/8768)\n",
      "Epoch 6 Step 274/313 Test Loss: 1.319 | Test Acc: 52.795% (4646/8800)\n",
      "Epoch 6 Step 275/313 Test Loss: 1.319 | Test Acc: 52.785% (4662/8832)\n",
      "Epoch 6 Step 276/313 Test Loss: 1.319 | Test Acc: 52.787% (4679/8864)\n",
      "Epoch 6 Step 277/313 Test Loss: 1.319 | Test Acc: 52.821% (4699/8896)\n",
      "Epoch 6 Step 278/313 Test Loss: 1.318 | Test Acc: 52.879% (4721/8928)\n",
      "Epoch 6 Step 279/313 Test Loss: 1.319 | Test Acc: 52.824% (4733/8960)\n",
      "Epoch 6 Step 280/313 Test Loss: 1.319 | Test Acc: 52.825% (4750/8992)\n",
      "Epoch 6 Step 281/313 Test Loss: 1.318 | Test Acc: 52.859% (4770/9024)\n",
      "Epoch 6 Step 282/313 Test Loss: 1.319 | Test Acc: 52.838% (4785/9056)\n",
      "Epoch 6 Step 283/313 Test Loss: 1.318 | Test Acc: 52.872% (4805/9088)\n",
      "Epoch 6 Step 284/313 Test Loss: 1.318 | Test Acc: 52.895% (4824/9120)\n",
      "Epoch 6 Step 285/313 Test Loss: 1.318 | Test Acc: 52.885% (4840/9152)\n",
      "Epoch 6 Step 286/313 Test Loss: 1.317 | Test Acc: 52.918% (4860/9184)\n",
      "Epoch 6 Step 287/313 Test Loss: 1.317 | Test Acc: 52.930% (4878/9216)\n",
      "Epoch 6 Step 288/313 Test Loss: 1.317 | Test Acc: 52.930% (4895/9248)\n",
      "Epoch 6 Step 289/313 Test Loss: 1.316 | Test Acc: 52.953% (4914/9280)\n",
      "Epoch 6 Step 290/313 Test Loss: 1.317 | Test Acc: 52.953% (4931/9312)\n",
      "Epoch 6 Step 291/313 Test Loss: 1.316 | Test Acc: 52.943% (4947/9344)\n",
      "Epoch 6 Step 292/313 Test Loss: 1.316 | Test Acc: 52.997% (4969/9376)\n",
      "Epoch 6 Step 293/313 Test Loss: 1.316 | Test Acc: 52.976% (4984/9408)\n",
      "Epoch 6 Step 294/313 Test Loss: 1.316 | Test Acc: 52.998% (5003/9440)\n",
      "Epoch 6 Step 295/313 Test Loss: 1.316 | Test Acc: 52.967% (5017/9472)\n",
      "Epoch 6 Step 296/313 Test Loss: 1.316 | Test Acc: 52.999% (5037/9504)\n",
      "Epoch 6 Step 297/313 Test Loss: 1.317 | Test Acc: 52.978% (5052/9536)\n",
      "Epoch 6 Step 298/313 Test Loss: 1.316 | Test Acc: 53.031% (5074/9568)\n",
      "Epoch 6 Step 299/313 Test Loss: 1.316 | Test Acc: 53.052% (5093/9600)\n",
      "Epoch 6 Step 300/313 Test Loss: 1.316 | Test Acc: 53.063% (5111/9632)\n",
      "Epoch 6 Step 301/313 Test Loss: 1.316 | Test Acc: 53.042% (5126/9664)\n",
      "Epoch 6 Step 302/313 Test Loss: 1.316 | Test Acc: 53.012% (5140/9696)\n",
      "Epoch 6 Step 303/313 Test Loss: 1.316 | Test Acc: 53.022% (5158/9728)\n",
      "Epoch 6 Step 304/313 Test Loss: 1.317 | Test Acc: 52.992% (5172/9760)\n",
      "Epoch 6 Step 305/313 Test Loss: 1.316 | Test Acc: 52.972% (5187/9792)\n",
      "Epoch 6 Step 306/313 Test Loss: 1.317 | Test Acc: 52.942% (5201/9824)\n",
      "Epoch 6 Step 307/313 Test Loss: 1.318 | Test Acc: 52.902% (5214/9856)\n",
      "Epoch 6 Step 308/313 Test Loss: 1.319 | Test Acc: 52.882% (5229/9888)\n",
      "Epoch 6 Step 309/313 Test Loss: 1.318 | Test Acc: 52.883% (5246/9920)\n",
      "Epoch 6 Step 310/313 Test Loss: 1.319 | Test Acc: 52.874% (5262/9952)\n",
      "Epoch 6 Step 311/313 Test Loss: 1.319 | Test Acc: 52.865% (5278/9984)\n",
      "Epoch 6 Step 312/313 Test Loss: 1.318 | Test Acc: 52.850% (5285/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "Epoch 7 Step 0/1563 Loss: 1.228 | Acc: 50.000% (16/32)\n",
      "Epoch 7 Step 1/1563 Loss: 1.116 | Acc: 57.812% (37/64)\n",
      "Epoch 7 Step 2/1563 Loss: 1.119 | Acc: 59.375% (57/96)\n",
      "Epoch 7 Step 3/1563 Loss: 1.258 | Acc: 53.906% (69/128)\n",
      "Epoch 7 Step 4/1563 Loss: 1.284 | Acc: 55.000% (88/160)\n",
      "Epoch 7 Step 5/1563 Loss: 1.299 | Acc: 53.646% (103/192)\n",
      "Epoch 7 Step 6/1563 Loss: 1.303 | Acc: 52.232% (117/224)\n",
      "Epoch 7 Step 7/1563 Loss: 1.340 | Acc: 52.734% (135/256)\n",
      "Epoch 7 Step 8/1563 Loss: 1.358 | Acc: 51.736% (149/288)\n",
      "Epoch 7 Step 9/1563 Loss: 1.344 | Acc: 52.500% (168/320)\n",
      "Epoch 7 Step 10/1563 Loss: 1.355 | Acc: 51.420% (181/352)\n",
      "Epoch 7 Step 11/1563 Loss: 1.336 | Acc: 52.344% (201/384)\n",
      "Epoch 7 Step 12/1563 Loss: 1.370 | Acc: 51.202% (213/416)\n",
      "Epoch 7 Step 13/1563 Loss: 1.392 | Acc: 51.116% (229/448)\n",
      "Epoch 7 Step 14/1563 Loss: 1.372 | Acc: 51.458% (247/480)\n",
      "Epoch 7 Step 15/1563 Loss: 1.365 | Acc: 50.977% (261/512)\n",
      "Epoch 7 Step 16/1563 Loss: 1.351 | Acc: 52.390% (285/544)\n",
      "Epoch 7 Step 17/1563 Loss: 1.351 | Acc: 52.257% (301/576)\n",
      "Epoch 7 Step 18/1563 Loss: 1.350 | Acc: 52.467% (319/608)\n",
      "Epoch 7 Step 19/1563 Loss: 1.361 | Acc: 52.500% (336/640)\n",
      "Epoch 7 Step 20/1563 Loss: 1.372 | Acc: 51.786% (348/672)\n",
      "Epoch 7 Step 21/1563 Loss: 1.366 | Acc: 51.705% (364/704)\n",
      "Epoch 7 Step 22/1563 Loss: 1.363 | Acc: 51.630% (380/736)\n",
      "Epoch 7 Step 23/1563 Loss: 1.359 | Acc: 52.214% (401/768)\n",
      "Epoch 7 Step 24/1563 Loss: 1.359 | Acc: 52.250% (418/800)\n",
      "Epoch 7 Step 25/1563 Loss: 1.360 | Acc: 52.043% (433/832)\n",
      "Epoch 7 Step 26/1563 Loss: 1.355 | Acc: 51.968% (449/864)\n",
      "Epoch 7 Step 27/1563 Loss: 1.371 | Acc: 51.674% (463/896)\n",
      "Epoch 7 Step 28/1563 Loss: 1.374 | Acc: 51.724% (480/928)\n",
      "Epoch 7 Step 29/1563 Loss: 1.375 | Acc: 51.667% (496/960)\n",
      "Epoch 7 Step 30/1563 Loss: 1.384 | Acc: 51.714% (513/992)\n",
      "Epoch 7 Step 31/1563 Loss: 1.379 | Acc: 51.953% (532/1024)\n",
      "Epoch 7 Step 32/1563 Loss: 1.376 | Acc: 51.799% (547/1056)\n",
      "Epoch 7 Step 33/1563 Loss: 1.375 | Acc: 51.654% (562/1088)\n",
      "Epoch 7 Step 34/1563 Loss: 1.370 | Acc: 51.964% (582/1120)\n",
      "Epoch 7 Step 35/1563 Loss: 1.374 | Acc: 51.649% (595/1152)\n",
      "Epoch 7 Step 36/1563 Loss: 1.370 | Acc: 51.689% (612/1184)\n",
      "Epoch 7 Step 37/1563 Loss: 1.362 | Acc: 51.974% (632/1216)\n",
      "Epoch 7 Step 38/1563 Loss: 1.359 | Acc: 52.163% (651/1248)\n",
      "Epoch 7 Step 39/1563 Loss: 1.358 | Acc: 52.109% (667/1280)\n",
      "Epoch 7 Step 40/1563 Loss: 1.357 | Acc: 52.134% (684/1312)\n",
      "Epoch 7 Step 41/1563 Loss: 1.354 | Acc: 52.381% (704/1344)\n",
      "Epoch 7 Step 42/1563 Loss: 1.352 | Acc: 52.326% (720/1376)\n",
      "Epoch 7 Step 43/1563 Loss: 1.355 | Acc: 52.060% (733/1408)\n",
      "Epoch 7 Step 44/1563 Loss: 1.358 | Acc: 51.875% (747/1440)\n",
      "Epoch 7 Step 45/1563 Loss: 1.362 | Acc: 51.562% (759/1472)\n",
      "Epoch 7 Step 46/1563 Loss: 1.357 | Acc: 51.795% (779/1504)\n",
      "Epoch 7 Step 47/1563 Loss: 1.360 | Acc: 51.497% (791/1536)\n",
      "Epoch 7 Step 48/1563 Loss: 1.360 | Acc: 51.531% (808/1568)\n",
      "Epoch 7 Step 49/1563 Loss: 1.355 | Acc: 51.750% (828/1600)\n",
      "Epoch 7 Step 50/1563 Loss: 1.357 | Acc: 51.838% (846/1632)\n",
      "Epoch 7 Step 51/1563 Loss: 1.358 | Acc: 51.743% (861/1664)\n",
      "Epoch 7 Step 52/1563 Loss: 1.358 | Acc: 51.828% (879/1696)\n",
      "Epoch 7 Step 53/1563 Loss: 1.364 | Acc: 51.562% (891/1728)\n",
      "Epoch 7 Step 54/1563 Loss: 1.364 | Acc: 51.477% (906/1760)\n",
      "Epoch 7 Step 55/1563 Loss: 1.364 | Acc: 51.618% (925/1792)\n",
      "Epoch 7 Step 56/1563 Loss: 1.364 | Acc: 51.371% (937/1824)\n",
      "Epoch 7 Step 57/1563 Loss: 1.366 | Acc: 51.401% (954/1856)\n",
      "Epoch 7 Step 58/1563 Loss: 1.370 | Acc: 51.377% (970/1888)\n",
      "Epoch 7 Step 59/1563 Loss: 1.370 | Acc: 51.510% (989/1920)\n",
      "Epoch 7 Step 60/1563 Loss: 1.368 | Acc: 51.332% (1002/1952)\n",
      "Epoch 7 Step 61/1563 Loss: 1.369 | Acc: 51.210% (1016/1984)\n",
      "Epoch 7 Step 62/1563 Loss: 1.370 | Acc: 51.091% (1030/2016)\n",
      "Epoch 7 Step 63/1563 Loss: 1.371 | Acc: 51.074% (1046/2048)\n",
      "Epoch 7 Step 64/1563 Loss: 1.376 | Acc: 50.673% (1054/2080)\n",
      "Epoch 7 Step 65/1563 Loss: 1.374 | Acc: 50.805% (1073/2112)\n",
      "Epoch 7 Step 66/1563 Loss: 1.373 | Acc: 50.886% (1091/2144)\n",
      "Epoch 7 Step 67/1563 Loss: 1.372 | Acc: 50.827% (1106/2176)\n",
      "Epoch 7 Step 68/1563 Loss: 1.373 | Acc: 50.770% (1121/2208)\n",
      "Epoch 7 Step 69/1563 Loss: 1.374 | Acc: 50.804% (1138/2240)\n",
      "Epoch 7 Step 70/1563 Loss: 1.374 | Acc: 50.748% (1153/2272)\n",
      "Epoch 7 Step 71/1563 Loss: 1.371 | Acc: 50.868% (1172/2304)\n",
      "Epoch 7 Step 72/1563 Loss: 1.371 | Acc: 50.642% (1183/2336)\n",
      "Epoch 7 Step 73/1563 Loss: 1.372 | Acc: 50.591% (1198/2368)\n",
      "Epoch 7 Step 74/1563 Loss: 1.372 | Acc: 50.583% (1214/2400)\n",
      "Epoch 7 Step 75/1563 Loss: 1.373 | Acc: 50.535% (1229/2432)\n",
      "Epoch 7 Step 76/1563 Loss: 1.373 | Acc: 50.609% (1247/2464)\n",
      "Epoch 7 Step 77/1563 Loss: 1.373 | Acc: 50.561% (1262/2496)\n",
      "Epoch 7 Step 78/1563 Loss: 1.373 | Acc: 50.554% (1278/2528)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 79/1563 Loss: 1.375 | Acc: 50.391% (1290/2560)\n",
      "Epoch 7 Step 80/1563 Loss: 1.373 | Acc: 50.617% (1312/2592)\n",
      "Epoch 7 Step 81/1563 Loss: 1.375 | Acc: 50.495% (1325/2624)\n",
      "Epoch 7 Step 82/1563 Loss: 1.371 | Acc: 50.678% (1346/2656)\n",
      "Epoch 7 Step 83/1563 Loss: 1.368 | Acc: 50.670% (1362/2688)\n",
      "Epoch 7 Step 84/1563 Loss: 1.366 | Acc: 50.699% (1379/2720)\n",
      "Epoch 7 Step 85/1563 Loss: 1.364 | Acc: 50.799% (1398/2752)\n",
      "Epoch 7 Step 86/1563 Loss: 1.364 | Acc: 50.718% (1412/2784)\n",
      "Epoch 7 Step 87/1563 Loss: 1.363 | Acc: 50.817% (1431/2816)\n",
      "Epoch 7 Step 88/1563 Loss: 1.363 | Acc: 50.843% (1448/2848)\n",
      "Epoch 7 Step 89/1563 Loss: 1.361 | Acc: 50.833% (1464/2880)\n",
      "Epoch 7 Step 90/1563 Loss: 1.362 | Acc: 50.790% (1479/2912)\n",
      "Epoch 7 Step 91/1563 Loss: 1.366 | Acc: 50.679% (1492/2944)\n",
      "Epoch 7 Step 92/1563 Loss: 1.366 | Acc: 50.638% (1507/2976)\n",
      "Epoch 7 Step 93/1563 Loss: 1.363 | Acc: 50.665% (1524/3008)\n",
      "Epoch 7 Step 94/1563 Loss: 1.362 | Acc: 50.757% (1543/3040)\n",
      "Epoch 7 Step 95/1563 Loss: 1.362 | Acc: 50.749% (1559/3072)\n",
      "Epoch 7 Step 96/1563 Loss: 1.366 | Acc: 50.644% (1572/3104)\n",
      "Epoch 7 Step 97/1563 Loss: 1.364 | Acc: 50.606% (1587/3136)\n",
      "Epoch 7 Step 98/1563 Loss: 1.363 | Acc: 50.663% (1605/3168)\n",
      "Epoch 7 Step 99/1563 Loss: 1.366 | Acc: 50.562% (1618/3200)\n",
      "Epoch 7 Step 100/1563 Loss: 1.370 | Acc: 50.371% (1628/3232)\n",
      "Epoch 7 Step 101/1563 Loss: 1.369 | Acc: 50.429% (1646/3264)\n",
      "Epoch 7 Step 102/1563 Loss: 1.370 | Acc: 50.546% (1666/3296)\n",
      "Epoch 7 Step 103/1563 Loss: 1.372 | Acc: 50.451% (1679/3328)\n",
      "Epoch 7 Step 104/1563 Loss: 1.372 | Acc: 50.327% (1691/3360)\n",
      "Epoch 7 Step 105/1563 Loss: 1.373 | Acc: 50.295% (1706/3392)\n",
      "Epoch 7 Step 106/1563 Loss: 1.372 | Acc: 50.204% (1719/3424)\n",
      "Epoch 7 Step 107/1563 Loss: 1.371 | Acc: 50.347% (1740/3456)\n",
      "Epoch 7 Step 108/1563 Loss: 1.370 | Acc: 50.344% (1756/3488)\n",
      "Epoch 7 Step 109/1563 Loss: 1.368 | Acc: 50.312% (1771/3520)\n",
      "Epoch 7 Step 110/1563 Loss: 1.366 | Acc: 50.394% (1790/3552)\n",
      "Epoch 7 Step 111/1563 Loss: 1.370 | Acc: 50.251% (1801/3584)\n",
      "Epoch 7 Step 112/1563 Loss: 1.369 | Acc: 50.277% (1818/3616)\n",
      "Epoch 7 Step 113/1563 Loss: 1.366 | Acc: 50.411% (1839/3648)\n",
      "Epoch 7 Step 114/1563 Loss: 1.365 | Acc: 50.408% (1855/3680)\n",
      "Epoch 7 Step 115/1563 Loss: 1.365 | Acc: 50.404% (1871/3712)\n",
      "Epoch 7 Step 116/1563 Loss: 1.364 | Acc: 50.507% (1891/3744)\n",
      "Epoch 7 Step 117/1563 Loss: 1.364 | Acc: 50.530% (1908/3776)\n",
      "Epoch 7 Step 118/1563 Loss: 1.363 | Acc: 50.630% (1928/3808)\n",
      "Epoch 7 Step 119/1563 Loss: 1.365 | Acc: 50.573% (1942/3840)\n",
      "Epoch 7 Step 120/1563 Loss: 1.365 | Acc: 50.620% (1960/3872)\n",
      "Epoch 7 Step 121/1563 Loss: 1.366 | Acc: 50.640% (1977/3904)\n",
      "Epoch 7 Step 122/1563 Loss: 1.364 | Acc: 50.711% (1996/3936)\n",
      "Epoch 7 Step 123/1563 Loss: 1.366 | Acc: 50.630% (2009/3968)\n",
      "Epoch 7 Step 124/1563 Loss: 1.369 | Acc: 50.500% (2020/4000)\n",
      "Epoch 7 Step 125/1563 Loss: 1.368 | Acc: 50.570% (2039/4032)\n",
      "Epoch 7 Step 126/1563 Loss: 1.369 | Acc: 50.418% (2049/4064)\n",
      "Epoch 7 Step 127/1563 Loss: 1.367 | Acc: 50.439% (2066/4096)\n",
      "Epoch 7 Step 128/1563 Loss: 1.372 | Acc: 50.315% (2077/4128)\n",
      "Epoch 7 Step 129/1563 Loss: 1.373 | Acc: 50.264% (2091/4160)\n",
      "Epoch 7 Step 130/1563 Loss: 1.373 | Acc: 50.215% (2105/4192)\n",
      "Epoch 7 Step 131/1563 Loss: 1.370 | Acc: 50.308% (2125/4224)\n",
      "Epoch 7 Step 132/1563 Loss: 1.370 | Acc: 50.376% (2144/4256)\n",
      "Epoch 7 Step 133/1563 Loss: 1.370 | Acc: 50.373% (2160/4288)\n",
      "Epoch 7 Step 134/1563 Loss: 1.368 | Acc: 50.509% (2182/4320)\n",
      "Epoch 7 Step 135/1563 Loss: 1.367 | Acc: 50.574% (2201/4352)\n",
      "Epoch 7 Step 136/1563 Loss: 1.364 | Acc: 50.684% (2222/4384)\n",
      "Epoch 7 Step 137/1563 Loss: 1.365 | Acc: 50.679% (2238/4416)\n",
      "Epoch 7 Step 138/1563 Loss: 1.364 | Acc: 50.719% (2256/4448)\n",
      "Epoch 7 Step 139/1563 Loss: 1.363 | Acc: 50.714% (2272/4480)\n",
      "Epoch 7 Step 140/1563 Loss: 1.364 | Acc: 50.709% (2288/4512)\n",
      "Epoch 7 Step 141/1563 Loss: 1.363 | Acc: 50.726% (2305/4544)\n",
      "Epoch 7 Step 142/1563 Loss: 1.360 | Acc: 50.765% (2323/4576)\n",
      "Epoch 7 Step 143/1563 Loss: 1.363 | Acc: 50.629% (2333/4608)\n",
      "Epoch 7 Step 144/1563 Loss: 1.362 | Acc: 50.625% (2349/4640)\n",
      "Epoch 7 Step 145/1563 Loss: 1.361 | Acc: 50.706% (2369/4672)\n",
      "Epoch 7 Step 146/1563 Loss: 1.361 | Acc: 50.702% (2385/4704)\n",
      "Epoch 7 Step 147/1563 Loss: 1.362 | Acc: 50.718% (2402/4736)\n",
      "Epoch 7 Step 148/1563 Loss: 1.361 | Acc: 50.692% (2417/4768)\n",
      "Epoch 7 Step 149/1563 Loss: 1.361 | Acc: 50.688% (2433/4800)\n",
      "Epoch 7 Step 150/1563 Loss: 1.362 | Acc: 50.683% (2449/4832)\n",
      "Epoch 7 Step 151/1563 Loss: 1.361 | Acc: 50.678% (2465/4864)\n",
      "Epoch 7 Step 152/1563 Loss: 1.361 | Acc: 50.694% (2482/4896)\n",
      "Epoch 7 Step 153/1563 Loss: 1.364 | Acc: 50.588% (2493/4928)\n",
      "Epoch 7 Step 154/1563 Loss: 1.366 | Acc: 50.544% (2507/4960)\n",
      "Epoch 7 Step 155/1563 Loss: 1.367 | Acc: 50.541% (2523/4992)\n",
      "Epoch 7 Step 156/1563 Loss: 1.369 | Acc: 50.498% (2537/5024)\n",
      "Epoch 7 Step 157/1563 Loss: 1.369 | Acc: 50.494% (2553/5056)\n",
      "Epoch 7 Step 158/1563 Loss: 1.370 | Acc: 50.452% (2567/5088)\n",
      "Epoch 7 Step 159/1563 Loss: 1.372 | Acc: 50.371% (2579/5120)\n",
      "Epoch 7 Step 160/1563 Loss: 1.370 | Acc: 50.485% (2601/5152)\n",
      "Epoch 7 Step 161/1563 Loss: 1.368 | Acc: 50.540% (2620/5184)\n",
      "Epoch 7 Step 162/1563 Loss: 1.369 | Acc: 50.518% (2635/5216)\n",
      "Epoch 7 Step 163/1563 Loss: 1.369 | Acc: 50.534% (2652/5248)\n",
      "Epoch 7 Step 164/1563 Loss: 1.369 | Acc: 50.511% (2667/5280)\n",
      "Epoch 7 Step 165/1563 Loss: 1.368 | Acc: 50.546% (2685/5312)\n",
      "Epoch 7 Step 166/1563 Loss: 1.370 | Acc: 50.468% (2697/5344)\n",
      "Epoch 7 Step 167/1563 Loss: 1.370 | Acc: 50.465% (2713/5376)\n",
      "Epoch 7 Step 168/1563 Loss: 1.369 | Acc: 50.518% (2732/5408)\n",
      "Epoch 7 Step 169/1563 Loss: 1.368 | Acc: 50.551% (2750/5440)\n",
      "Epoch 7 Step 170/1563 Loss: 1.369 | Acc: 50.585% (2768/5472)\n",
      "Epoch 7 Step 171/1563 Loss: 1.370 | Acc: 50.581% (2784/5504)\n",
      "Epoch 7 Step 172/1563 Loss: 1.371 | Acc: 50.524% (2797/5536)\n",
      "Epoch 7 Step 173/1563 Loss: 1.371 | Acc: 50.485% (2811/5568)\n",
      "Epoch 7 Step 174/1563 Loss: 1.370 | Acc: 50.500% (2828/5600)\n",
      "Epoch 7 Step 175/1563 Loss: 1.369 | Acc: 50.533% (2846/5632)\n",
      "Epoch 7 Step 176/1563 Loss: 1.369 | Acc: 50.530% (2862/5664)\n",
      "Epoch 7 Step 177/1563 Loss: 1.371 | Acc: 50.421% (2872/5696)\n",
      "Epoch 7 Step 178/1563 Loss: 1.372 | Acc: 50.402% (2887/5728)\n",
      "Epoch 7 Step 179/1563 Loss: 1.372 | Acc: 50.434% (2905/5760)\n",
      "Epoch 7 Step 180/1563 Loss: 1.373 | Acc: 50.432% (2921/5792)\n",
      "Epoch 7 Step 181/1563 Loss: 1.373 | Acc: 50.446% (2938/5824)\n",
      "Epoch 7 Step 182/1563 Loss: 1.372 | Acc: 50.495% (2957/5856)\n",
      "Epoch 7 Step 183/1563 Loss: 1.371 | Acc: 50.493% (2973/5888)\n",
      "Epoch 7 Step 184/1563 Loss: 1.371 | Acc: 50.473% (2988/5920)\n",
      "Epoch 7 Step 185/1563 Loss: 1.372 | Acc: 50.420% (3001/5952)\n",
      "Epoch 7 Step 186/1563 Loss: 1.372 | Acc: 50.434% (3018/5984)\n",
      "Epoch 7 Step 187/1563 Loss: 1.373 | Acc: 50.382% (3031/6016)\n",
      "Epoch 7 Step 188/1563 Loss: 1.374 | Acc: 50.364% (3046/6048)\n",
      "Epoch 7 Step 189/1563 Loss: 1.373 | Acc: 50.411% (3065/6080)\n",
      "Epoch 7 Step 190/1563 Loss: 1.374 | Acc: 50.360% (3078/6112)\n",
      "Epoch 7 Step 191/1563 Loss: 1.374 | Acc: 50.326% (3092/6144)\n",
      "Epoch 7 Step 192/1563 Loss: 1.373 | Acc: 50.372% (3111/6176)\n",
      "Epoch 7 Step 193/1563 Loss: 1.371 | Acc: 50.403% (3129/6208)\n",
      "Epoch 7 Step 194/1563 Loss: 1.370 | Acc: 50.369% (3143/6240)\n",
      "Epoch 7 Step 195/1563 Loss: 1.370 | Acc: 50.351% (3158/6272)\n",
      "Epoch 7 Step 196/1563 Loss: 1.370 | Acc: 50.365% (3175/6304)\n",
      "Epoch 7 Step 197/1563 Loss: 1.369 | Acc: 50.395% (3193/6336)\n",
      "Epoch 7 Step 198/1563 Loss: 1.368 | Acc: 50.424% (3211/6368)\n",
      "Epoch 7 Step 199/1563 Loss: 1.368 | Acc: 50.453% (3229/6400)\n",
      "Epoch 7 Step 200/1563 Loss: 1.369 | Acc: 50.435% (3244/6432)\n",
      "Epoch 7 Step 201/1563 Loss: 1.368 | Acc: 50.433% (3260/6464)\n",
      "Epoch 7 Step 202/1563 Loss: 1.369 | Acc: 50.431% (3276/6496)\n",
      "Epoch 7 Step 203/1563 Loss: 1.368 | Acc: 50.429% (3292/6528)\n",
      "Epoch 7 Step 204/1563 Loss: 1.366 | Acc: 50.518% (3314/6560)\n",
      "Epoch 7 Step 205/1563 Loss: 1.365 | Acc: 50.546% (3332/6592)\n",
      "Epoch 7 Step 206/1563 Loss: 1.366 | Acc: 50.513% (3346/6624)\n",
      "Epoch 7 Step 207/1563 Loss: 1.365 | Acc: 50.541% (3364/6656)\n",
      "Epoch 7 Step 208/1563 Loss: 1.364 | Acc: 50.598% (3384/6688)\n",
      "Epoch 7 Step 209/1563 Loss: 1.364 | Acc: 50.610% (3401/6720)\n",
      "Epoch 7 Step 210/1563 Loss: 1.364 | Acc: 50.563% (3414/6752)\n",
      "Epoch 7 Step 211/1563 Loss: 1.366 | Acc: 50.501% (3426/6784)\n",
      "Epoch 7 Step 212/1563 Loss: 1.366 | Acc: 50.513% (3443/6816)\n",
      "Epoch 7 Step 213/1563 Loss: 1.365 | Acc: 50.526% (3460/6848)\n",
      "Epoch 7 Step 214/1563 Loss: 1.364 | Acc: 50.480% (3473/6880)\n",
      "Epoch 7 Step 215/1563 Loss: 1.363 | Acc: 50.521% (3492/6912)\n",
      "Epoch 7 Step 216/1563 Loss: 1.364 | Acc: 50.547% (3510/6944)\n",
      "Epoch 7 Step 217/1563 Loss: 1.362 | Acc: 50.516% (3524/6976)\n",
      "Epoch 7 Step 218/1563 Loss: 1.362 | Acc: 50.499% (3539/7008)\n",
      "Epoch 7 Step 219/1563 Loss: 1.363 | Acc: 50.455% (3552/7040)\n",
      "Epoch 7 Step 220/1563 Loss: 1.364 | Acc: 50.481% (3570/7072)\n",
      "Epoch 7 Step 221/1563 Loss: 1.365 | Acc: 50.450% (3584/7104)\n",
      "Epoch 7 Step 222/1563 Loss: 1.366 | Acc: 50.420% (3598/7136)\n",
      "Epoch 7 Step 223/1563 Loss: 1.368 | Acc: 50.377% (3611/7168)\n",
      "Epoch 7 Step 224/1563 Loss: 1.368 | Acc: 50.431% (3631/7200)\n",
      "Epoch 7 Step 225/1563 Loss: 1.369 | Acc: 50.387% (3644/7232)\n",
      "Epoch 7 Step 226/1563 Loss: 1.368 | Acc: 50.454% (3665/7264)\n",
      "Epoch 7 Step 227/1563 Loss: 1.367 | Acc: 50.480% (3683/7296)\n",
      "Epoch 7 Step 228/1563 Loss: 1.367 | Acc: 50.519% (3702/7328)\n",
      "Epoch 7 Step 229/1563 Loss: 1.367 | Acc: 50.516% (3718/7360)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 230/1563 Loss: 1.367 | Acc: 50.487% (3732/7392)\n",
      "Epoch 7 Step 231/1563 Loss: 1.367 | Acc: 50.512% (3750/7424)\n",
      "Epoch 7 Step 232/1563 Loss: 1.368 | Acc: 50.523% (3767/7456)\n",
      "Epoch 7 Step 233/1563 Loss: 1.369 | Acc: 50.507% (3782/7488)\n",
      "Epoch 7 Step 234/1563 Loss: 1.369 | Acc: 50.465% (3795/7520)\n",
      "Epoch 7 Step 235/1563 Loss: 1.369 | Acc: 50.437% (3809/7552)\n",
      "Epoch 7 Step 236/1563 Loss: 1.369 | Acc: 50.435% (3825/7584)\n",
      "Epoch 7 Step 237/1563 Loss: 1.370 | Acc: 50.407% (3839/7616)\n",
      "Epoch 7 Step 238/1563 Loss: 1.371 | Acc: 50.353% (3851/7648)\n",
      "Epoch 7 Step 239/1563 Loss: 1.371 | Acc: 50.339% (3866/7680)\n",
      "Epoch 7 Step 240/1563 Loss: 1.371 | Acc: 50.350% (3883/7712)\n",
      "Epoch 7 Step 241/1563 Loss: 1.371 | Acc: 50.362% (3900/7744)\n",
      "Epoch 7 Step 242/1563 Loss: 1.370 | Acc: 50.399% (3919/7776)\n",
      "Epoch 7 Step 243/1563 Loss: 1.371 | Acc: 50.346% (3931/7808)\n",
      "Epoch 7 Step 244/1563 Loss: 1.372 | Acc: 50.344% (3947/7840)\n",
      "Epoch 7 Step 245/1563 Loss: 1.371 | Acc: 50.356% (3964/7872)\n",
      "Epoch 7 Step 246/1563 Loss: 1.372 | Acc: 50.329% (3978/7904)\n",
      "Epoch 7 Step 247/1563 Loss: 1.372 | Acc: 50.265% (3989/7936)\n",
      "Epoch 7 Step 248/1563 Loss: 1.372 | Acc: 50.264% (4005/7968)\n",
      "Epoch 7 Step 249/1563 Loss: 1.371 | Acc: 50.263% (4021/8000)\n",
      "Epoch 7 Step 250/1563 Loss: 1.371 | Acc: 50.199% (4032/8032)\n",
      "Epoch 7 Step 251/1563 Loss: 1.371 | Acc: 50.236% (4051/8064)\n",
      "Epoch 7 Step 252/1563 Loss: 1.370 | Acc: 50.259% (4069/8096)\n",
      "Epoch 7 Step 253/1563 Loss: 1.369 | Acc: 50.295% (4088/8128)\n",
      "Epoch 7 Step 254/1563 Loss: 1.369 | Acc: 50.294% (4104/8160)\n",
      "Epoch 7 Step 255/1563 Loss: 1.368 | Acc: 50.342% (4124/8192)\n",
      "Epoch 7 Step 256/1563 Loss: 1.369 | Acc: 50.304% (4137/8224)\n",
      "Epoch 7 Step 257/1563 Loss: 1.368 | Acc: 50.315% (4154/8256)\n",
      "Epoch 7 Step 258/1563 Loss: 1.368 | Acc: 50.326% (4171/8288)\n",
      "Epoch 7 Step 259/1563 Loss: 1.368 | Acc: 50.349% (4189/8320)\n",
      "Epoch 7 Step 260/1563 Loss: 1.369 | Acc: 50.359% (4206/8352)\n",
      "Epoch 7 Step 261/1563 Loss: 1.368 | Acc: 50.429% (4228/8384)\n",
      "Epoch 7 Step 262/1563 Loss: 1.368 | Acc: 50.416% (4243/8416)\n",
      "Epoch 7 Step 263/1563 Loss: 1.369 | Acc: 50.367% (4255/8448)\n",
      "Epoch 7 Step 264/1563 Loss: 1.368 | Acc: 50.413% (4275/8480)\n",
      "Epoch 7 Step 265/1563 Loss: 1.368 | Acc: 50.411% (4291/8512)\n",
      "Epoch 7 Step 266/1563 Loss: 1.367 | Acc: 50.421% (4308/8544)\n",
      "Epoch 7 Step 267/1563 Loss: 1.368 | Acc: 50.431% (4325/8576)\n",
      "Epoch 7 Step 268/1563 Loss: 1.368 | Acc: 50.418% (4340/8608)\n",
      "Epoch 7 Step 269/1563 Loss: 1.367 | Acc: 50.486% (4362/8640)\n",
      "Epoch 7 Step 270/1563 Loss: 1.366 | Acc: 50.484% (4378/8672)\n",
      "Epoch 7 Step 271/1563 Loss: 1.365 | Acc: 50.494% (4395/8704)\n",
      "Epoch 7 Step 272/1563 Loss: 1.365 | Acc: 50.481% (4410/8736)\n",
      "Epoch 7 Step 273/1563 Loss: 1.365 | Acc: 50.479% (4426/8768)\n",
      "Epoch 7 Step 274/1563 Loss: 1.364 | Acc: 50.511% (4445/8800)\n",
      "Epoch 7 Step 275/1563 Loss: 1.364 | Acc: 50.510% (4461/8832)\n",
      "Epoch 7 Step 276/1563 Loss: 1.364 | Acc: 50.485% (4475/8864)\n",
      "Epoch 7 Step 277/1563 Loss: 1.364 | Acc: 50.517% (4494/8896)\n",
      "Epoch 7 Step 278/1563 Loss: 1.364 | Acc: 50.526% (4511/8928)\n",
      "Epoch 7 Step 279/1563 Loss: 1.364 | Acc: 50.525% (4527/8960)\n",
      "Epoch 7 Step 280/1563 Loss: 1.363 | Acc: 50.556% (4546/8992)\n",
      "Epoch 7 Step 281/1563 Loss: 1.362 | Acc: 50.576% (4564/9024)\n",
      "Epoch 7 Step 282/1563 Loss: 1.363 | Acc: 50.563% (4579/9056)\n",
      "Epoch 7 Step 283/1563 Loss: 1.363 | Acc: 50.594% (4598/9088)\n",
      "Epoch 7 Step 284/1563 Loss: 1.363 | Acc: 50.603% (4615/9120)\n",
      "Epoch 7 Step 285/1563 Loss: 1.362 | Acc: 50.667% (4637/9152)\n",
      "Epoch 7 Step 286/1563 Loss: 1.363 | Acc: 50.632% (4650/9184)\n",
      "Epoch 7 Step 287/1563 Loss: 1.364 | Acc: 50.629% (4666/9216)\n",
      "Epoch 7 Step 288/1563 Loss: 1.362 | Acc: 50.670% (4686/9248)\n",
      "Epoch 7 Step 289/1563 Loss: 1.363 | Acc: 50.700% (4705/9280)\n",
      "Epoch 7 Step 290/1563 Loss: 1.363 | Acc: 50.687% (4720/9312)\n",
      "Epoch 7 Step 291/1563 Loss: 1.364 | Acc: 50.664% (4734/9344)\n",
      "Epoch 7 Step 292/1563 Loss: 1.364 | Acc: 50.661% (4750/9376)\n",
      "Epoch 7 Step 293/1563 Loss: 1.365 | Acc: 50.723% (4772/9408)\n",
      "Epoch 7 Step 294/1563 Loss: 1.365 | Acc: 50.699% (4786/9440)\n",
      "Epoch 7 Step 295/1563 Loss: 1.365 | Acc: 50.665% (4799/9472)\n",
      "Epoch 7 Step 296/1563 Loss: 1.365 | Acc: 50.652% (4814/9504)\n",
      "Epoch 7 Step 297/1563 Loss: 1.365 | Acc: 50.682% (4833/9536)\n",
      "Epoch 7 Step 298/1563 Loss: 1.365 | Acc: 50.711% (4852/9568)\n",
      "Epoch 7 Step 299/1563 Loss: 1.366 | Acc: 50.677% (4865/9600)\n",
      "Epoch 7 Step 300/1563 Loss: 1.366 | Acc: 50.706% (4884/9632)\n",
      "Epoch 7 Step 301/1563 Loss: 1.365 | Acc: 50.755% (4905/9664)\n",
      "Epoch 7 Step 302/1563 Loss: 1.366 | Acc: 50.763% (4922/9696)\n",
      "Epoch 7 Step 303/1563 Loss: 1.366 | Acc: 50.812% (4943/9728)\n",
      "Epoch 7 Step 304/1563 Loss: 1.366 | Acc: 50.820% (4960/9760)\n",
      "Epoch 7 Step 305/1563 Loss: 1.367 | Acc: 50.786% (4973/9792)\n",
      "Epoch 7 Step 306/1563 Loss: 1.368 | Acc: 50.743% (4985/9824)\n",
      "Epoch 7 Step 307/1563 Loss: 1.368 | Acc: 50.771% (5004/9856)\n",
      "Epoch 7 Step 308/1563 Loss: 1.367 | Acc: 50.789% (5022/9888)\n",
      "Epoch 7 Step 309/1563 Loss: 1.368 | Acc: 50.776% (5037/9920)\n",
      "Epoch 7 Step 310/1563 Loss: 1.368 | Acc: 50.744% (5050/9952)\n",
      "Epoch 7 Step 311/1563 Loss: 1.367 | Acc: 50.761% (5068/9984)\n",
      "Epoch 7 Step 312/1563 Loss: 1.368 | Acc: 50.779% (5086/10016)\n",
      "Epoch 7 Step 313/1563 Loss: 1.367 | Acc: 50.776% (5102/10048)\n",
      "Epoch 7 Step 314/1563 Loss: 1.368 | Acc: 50.774% (5118/10080)\n",
      "Epoch 7 Step 315/1563 Loss: 1.367 | Acc: 50.781% (5135/10112)\n",
      "Epoch 7 Step 316/1563 Loss: 1.366 | Acc: 50.818% (5155/10144)\n",
      "Epoch 7 Step 317/1563 Loss: 1.366 | Acc: 50.845% (5174/10176)\n",
      "Epoch 7 Step 318/1563 Loss: 1.365 | Acc: 50.891% (5195/10208)\n",
      "Epoch 7 Step 319/1563 Loss: 1.365 | Acc: 50.879% (5210/10240)\n",
      "Epoch 7 Step 320/1563 Loss: 1.365 | Acc: 50.886% (5227/10272)\n",
      "Epoch 7 Step 321/1563 Loss: 1.364 | Acc: 50.922% (5247/10304)\n",
      "Epoch 7 Step 322/1563 Loss: 1.363 | Acc: 50.938% (5265/10336)\n",
      "Epoch 7 Step 323/1563 Loss: 1.363 | Acc: 50.936% (5281/10368)\n",
      "Epoch 7 Step 324/1563 Loss: 1.363 | Acc: 50.962% (5300/10400)\n",
      "Epoch 7 Step 325/1563 Loss: 1.363 | Acc: 50.978% (5318/10432)\n",
      "Epoch 7 Step 326/1563 Loss: 1.362 | Acc: 51.013% (5338/10464)\n",
      "Epoch 7 Step 327/1563 Loss: 1.361 | Acc: 51.058% (5359/10496)\n",
      "Epoch 7 Step 328/1563 Loss: 1.361 | Acc: 51.035% (5373/10528)\n",
      "Epoch 7 Step 329/1563 Loss: 1.361 | Acc: 51.023% (5388/10560)\n",
      "Epoch 7 Step 330/1563 Loss: 1.361 | Acc: 51.029% (5405/10592)\n",
      "Epoch 7 Step 331/1563 Loss: 1.361 | Acc: 50.970% (5415/10624)\n",
      "Epoch 7 Step 332/1563 Loss: 1.363 | Acc: 50.882% (5422/10656)\n",
      "Epoch 7 Step 333/1563 Loss: 1.362 | Acc: 50.917% (5442/10688)\n",
      "Epoch 7 Step 334/1563 Loss: 1.362 | Acc: 50.877% (5454/10720)\n",
      "Epoch 7 Step 335/1563 Loss: 1.361 | Acc: 50.930% (5476/10752)\n",
      "Epoch 7 Step 336/1563 Loss: 1.361 | Acc: 50.955% (5495/10784)\n",
      "Epoch 7 Step 337/1563 Loss: 1.361 | Acc: 50.934% (5509/10816)\n",
      "Epoch 7 Step 338/1563 Loss: 1.361 | Acc: 50.894% (5521/10848)\n",
      "Epoch 7 Step 339/1563 Loss: 1.361 | Acc: 50.919% (5540/10880)\n",
      "Epoch 7 Step 340/1563 Loss: 1.361 | Acc: 50.907% (5555/10912)\n",
      "Epoch 7 Step 341/1563 Loss: 1.361 | Acc: 50.923% (5573/10944)\n",
      "Epoch 7 Step 342/1563 Loss: 1.360 | Acc: 50.957% (5593/10976)\n",
      "Epoch 7 Step 343/1563 Loss: 1.360 | Acc: 51.008% (5615/11008)\n",
      "Epoch 7 Step 344/1563 Loss: 1.360 | Acc: 50.978% (5628/11040)\n",
      "Epoch 7 Step 345/1563 Loss: 1.360 | Acc: 51.003% (5647/11072)\n",
      "Epoch 7 Step 346/1563 Loss: 1.360 | Acc: 50.991% (5662/11104)\n",
      "Epoch 7 Step 347/1563 Loss: 1.360 | Acc: 51.006% (5680/11136)\n",
      "Epoch 7 Step 348/1563 Loss: 1.361 | Acc: 50.994% (5695/11168)\n",
      "Epoch 7 Step 349/1563 Loss: 1.361 | Acc: 51.018% (5714/11200)\n",
      "Epoch 7 Step 350/1563 Loss: 1.360 | Acc: 51.051% (5734/11232)\n",
      "Epoch 7 Step 351/1563 Loss: 1.360 | Acc: 51.065% (5752/11264)\n",
      "Epoch 7 Step 352/1563 Loss: 1.362 | Acc: 51.027% (5764/11296)\n",
      "Epoch 7 Step 353/1563 Loss: 1.361 | Acc: 51.068% (5785/11328)\n",
      "Epoch 7 Step 354/1563 Loss: 1.361 | Acc: 51.056% (5800/11360)\n",
      "Epoch 7 Step 355/1563 Loss: 1.362 | Acc: 51.053% (5816/11392)\n",
      "Epoch 7 Step 356/1563 Loss: 1.361 | Acc: 51.068% (5834/11424)\n",
      "Epoch 7 Step 357/1563 Loss: 1.362 | Acc: 51.039% (5847/11456)\n",
      "Epoch 7 Step 358/1563 Loss: 1.362 | Acc: 51.045% (5864/11488)\n",
      "Epoch 7 Step 359/1563 Loss: 1.362 | Acc: 51.042% (5880/11520)\n",
      "Epoch 7 Step 360/1563 Loss: 1.362 | Acc: 51.056% (5898/11552)\n",
      "Epoch 7 Step 361/1563 Loss: 1.361 | Acc: 51.070% (5916/11584)\n",
      "Epoch 7 Step 362/1563 Loss: 1.361 | Acc: 51.093% (5935/11616)\n",
      "Epoch 7 Step 363/1563 Loss: 1.362 | Acc: 51.065% (5948/11648)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 364/1563 Loss: 1.361 | Acc: 51.096% (5968/11680)\n",
      "Epoch 7 Step 365/1563 Loss: 1.361 | Acc: 51.084% (5983/11712)\n",
      "Epoch 7 Step 366/1563 Loss: 1.362 | Acc: 51.064% (5997/11744)\n",
      "Epoch 7 Step 367/1563 Loss: 1.363 | Acc: 51.053% (6012/11776)\n",
      "Epoch 7 Step 368/1563 Loss: 1.363 | Acc: 51.050% (6028/11808)\n",
      "Epoch 7 Step 369/1563 Loss: 1.362 | Acc: 51.064% (6046/11840)\n",
      "Epoch 7 Step 370/1563 Loss: 1.362 | Acc: 51.036% (6059/11872)\n",
      "Epoch 7 Step 371/1563 Loss: 1.362 | Acc: 51.075% (6080/11904)\n",
      "Epoch 7 Step 372/1563 Loss: 1.361 | Acc: 51.098% (6099/11936)\n",
      "Epoch 7 Step 373/1563 Loss: 1.363 | Acc: 51.053% (6110/11968)\n",
      "Epoch 7 Step 374/1563 Loss: 1.363 | Acc: 51.058% (6127/12000)\n",
      "Epoch 7 Step 375/1563 Loss: 1.363 | Acc: 51.039% (6141/12032)\n",
      "Epoch 7 Step 376/1563 Loss: 1.363 | Acc: 51.044% (6158/12064)\n",
      "Epoch 7 Step 377/1563 Loss: 1.363 | Acc: 51.042% (6174/12096)\n",
      "Epoch 7 Step 378/1563 Loss: 1.364 | Acc: 51.022% (6188/12128)\n",
      "Epoch 7 Step 379/1563 Loss: 1.364 | Acc: 51.003% (6202/12160)\n",
      "Epoch 7 Step 380/1563 Loss: 1.364 | Acc: 51.001% (6218/12192)\n",
      "Epoch 7 Step 381/1563 Loss: 1.365 | Acc: 50.990% (6233/12224)\n",
      "Epoch 7 Step 382/1563 Loss: 1.364 | Acc: 50.987% (6249/12256)\n",
      "Epoch 7 Step 383/1563 Loss: 1.364 | Acc: 50.985% (6265/12288)\n",
      "Epoch 7 Step 384/1563 Loss: 1.364 | Acc: 50.958% (6278/12320)\n",
      "Epoch 7 Step 385/1563 Loss: 1.364 | Acc: 50.996% (6299/12352)\n",
      "Epoch 7 Step 386/1563 Loss: 1.363 | Acc: 50.993% (6315/12384)\n",
      "Epoch 7 Step 387/1563 Loss: 1.364 | Acc: 50.975% (6329/12416)\n",
      "Epoch 7 Step 388/1563 Loss: 1.364 | Acc: 50.972% (6345/12448)\n",
      "Epoch 7 Step 389/1563 Loss: 1.365 | Acc: 50.986% (6363/12480)\n",
      "Epoch 7 Step 390/1563 Loss: 1.364 | Acc: 50.983% (6379/12512)\n",
      "Epoch 7 Step 391/1563 Loss: 1.364 | Acc: 51.044% (6403/12544)\n",
      "Epoch 7 Step 392/1563 Loss: 1.364 | Acc: 51.042% (6419/12576)\n",
      "Epoch 7 Step 393/1563 Loss: 1.363 | Acc: 51.079% (6440/12608)\n",
      "Epoch 7 Step 394/1563 Loss: 1.363 | Acc: 51.084% (6457/12640)\n",
      "Epoch 7 Step 395/1563 Loss: 1.363 | Acc: 51.081% (6473/12672)\n",
      "Epoch 7 Step 396/1563 Loss: 1.363 | Acc: 51.078% (6489/12704)\n",
      "Epoch 7 Step 397/1563 Loss: 1.364 | Acc: 51.044% (6501/12736)\n",
      "Epoch 7 Step 398/1563 Loss: 1.363 | Acc: 51.049% (6518/12768)\n",
      "Epoch 7 Step 399/1563 Loss: 1.363 | Acc: 51.078% (6538/12800)\n",
      "Epoch 7 Step 400/1563 Loss: 1.363 | Acc: 51.083% (6555/12832)\n",
      "Epoch 7 Step 401/1563 Loss: 1.363 | Acc: 51.112% (6575/12864)\n",
      "Epoch 7 Step 402/1563 Loss: 1.363 | Acc: 51.109% (6591/12896)\n",
      "Epoch 7 Step 403/1563 Loss: 1.363 | Acc: 51.122% (6609/12928)\n",
      "Epoch 7 Step 404/1563 Loss: 1.363 | Acc: 51.142% (6628/12960)\n",
      "Epoch 7 Step 405/1563 Loss: 1.364 | Acc: 51.108% (6640/12992)\n",
      "Epoch 7 Step 406/1563 Loss: 1.364 | Acc: 51.144% (6661/13024)\n",
      "Epoch 7 Step 407/1563 Loss: 1.364 | Acc: 51.134% (6676/13056)\n",
      "Epoch 7 Step 408/1563 Loss: 1.364 | Acc: 51.108% (6689/13088)\n",
      "Epoch 7 Step 409/1563 Loss: 1.364 | Acc: 51.105% (6705/13120)\n",
      "Epoch 7 Step 410/1563 Loss: 1.364 | Acc: 51.125% (6724/13152)\n",
      "Epoch 7 Step 411/1563 Loss: 1.364 | Acc: 51.130% (6741/13184)\n",
      "Epoch 7 Step 412/1563 Loss: 1.364 | Acc: 51.120% (6756/13216)\n",
      "Epoch 7 Step 413/1563 Loss: 1.364 | Acc: 51.147% (6776/13248)\n",
      "Epoch 7 Step 414/1563 Loss: 1.363 | Acc: 51.152% (6793/13280)\n",
      "Epoch 7 Step 415/1563 Loss: 1.363 | Acc: 51.172% (6812/13312)\n",
      "Epoch 7 Step 416/1563 Loss: 1.364 | Acc: 51.132% (6823/13344)\n",
      "Epoch 7 Step 417/1563 Loss: 1.364 | Acc: 51.151% (6842/13376)\n",
      "Epoch 7 Step 418/1563 Loss: 1.363 | Acc: 51.156% (6859/13408)\n",
      "Epoch 7 Step 419/1563 Loss: 1.364 | Acc: 51.153% (6875/13440)\n",
      "Epoch 7 Step 420/1563 Loss: 1.363 | Acc: 51.158% (6892/13472)\n",
      "Epoch 7 Step 421/1563 Loss: 1.363 | Acc: 51.155% (6908/13504)\n",
      "Epoch 7 Step 422/1563 Loss: 1.363 | Acc: 51.167% (6926/13536)\n",
      "Epoch 7 Step 423/1563 Loss: 1.363 | Acc: 51.165% (6942/13568)\n",
      "Epoch 7 Step 424/1563 Loss: 1.363 | Acc: 51.147% (6956/13600)\n",
      "Epoch 7 Step 425/1563 Loss: 1.363 | Acc: 51.181% (6977/13632)\n",
      "Epoch 7 Step 426/1563 Loss: 1.363 | Acc: 51.178% (6993/13664)\n",
      "Epoch 7 Step 427/1563 Loss: 1.363 | Acc: 51.205% (7013/13696)\n",
      "Epoch 7 Step 428/1563 Loss: 1.363 | Acc: 51.231% (7033/13728)\n",
      "Epoch 7 Step 429/1563 Loss: 1.363 | Acc: 51.235% (7050/13760)\n",
      "Epoch 7 Step 430/1563 Loss: 1.363 | Acc: 51.233% (7066/13792)\n",
      "Epoch 7 Step 431/1563 Loss: 1.363 | Acc: 51.259% (7086/13824)\n",
      "Epoch 7 Step 432/1563 Loss: 1.363 | Acc: 51.241% (7100/13856)\n",
      "Epoch 7 Step 433/1563 Loss: 1.363 | Acc: 51.210% (7112/13888)\n",
      "Epoch 7 Step 434/1563 Loss: 1.363 | Acc: 51.178% (7124/13920)\n",
      "Epoch 7 Step 435/1563 Loss: 1.362 | Acc: 51.204% (7144/13952)\n",
      "Epoch 7 Step 436/1563 Loss: 1.363 | Acc: 51.209% (7161/13984)\n",
      "Epoch 7 Step 437/1563 Loss: 1.362 | Acc: 51.220% (7179/14016)\n",
      "Epoch 7 Step 438/1563 Loss: 1.362 | Acc: 51.224% (7196/14048)\n",
      "Epoch 7 Step 439/1563 Loss: 1.363 | Acc: 51.222% (7212/14080)\n",
      "Epoch 7 Step 440/1563 Loss: 1.363 | Acc: 51.219% (7228/14112)\n",
      "Epoch 7 Step 441/1563 Loss: 1.363 | Acc: 51.223% (7245/14144)\n",
      "Epoch 7 Step 442/1563 Loss: 1.363 | Acc: 51.234% (7263/14176)\n",
      "Epoch 7 Step 443/1563 Loss: 1.363 | Acc: 51.246% (7281/14208)\n",
      "Epoch 7 Step 444/1563 Loss: 1.363 | Acc: 51.236% (7296/14240)\n",
      "Epoch 7 Step 445/1563 Loss: 1.362 | Acc: 51.254% (7315/14272)\n",
      "Epoch 7 Step 446/1563 Loss: 1.362 | Acc: 51.279% (7335/14304)\n",
      "Epoch 7 Step 447/1563 Loss: 1.362 | Acc: 51.263% (7349/14336)\n",
      "Epoch 7 Step 448/1563 Loss: 1.363 | Acc: 51.232% (7361/14368)\n",
      "Epoch 7 Step 449/1563 Loss: 1.364 | Acc: 51.188% (7371/14400)\n",
      "Epoch 7 Step 450/1563 Loss: 1.364 | Acc: 51.192% (7388/14432)\n",
      "Epoch 7 Step 451/1563 Loss: 1.364 | Acc: 51.217% (7408/14464)\n",
      "Epoch 7 Step 452/1563 Loss: 1.365 | Acc: 51.166% (7417/14496)\n",
      "Epoch 7 Step 453/1563 Loss: 1.365 | Acc: 51.143% (7430/14528)\n",
      "Epoch 7 Step 454/1563 Loss: 1.366 | Acc: 51.133% (7445/14560)\n",
      "Epoch 7 Step 455/1563 Loss: 1.365 | Acc: 51.144% (7463/14592)\n",
      "Epoch 7 Step 456/1563 Loss: 1.365 | Acc: 51.142% (7479/14624)\n",
      "Epoch 7 Step 457/1563 Loss: 1.364 | Acc: 51.174% (7500/14656)\n",
      "Epoch 7 Step 458/1563 Loss: 1.364 | Acc: 51.164% (7515/14688)\n",
      "Epoch 7 Step 459/1563 Loss: 1.363 | Acc: 51.202% (7537/14720)\n",
      "Epoch 7 Step 460/1563 Loss: 1.363 | Acc: 51.227% (7557/14752)\n",
      "Epoch 7 Step 461/1563 Loss: 1.363 | Acc: 51.211% (7571/14784)\n",
      "Epoch 7 Step 462/1563 Loss: 1.363 | Acc: 51.181% (7583/14816)\n",
      "Epoch 7 Step 463/1563 Loss: 1.364 | Acc: 51.158% (7596/14848)\n",
      "Epoch 7 Step 464/1563 Loss: 1.364 | Acc: 51.163% (7613/14880)\n",
      "Epoch 7 Step 465/1563 Loss: 1.363 | Acc: 51.200% (7635/14912)\n",
      "Epoch 7 Step 466/1563 Loss: 1.363 | Acc: 51.184% (7649/14944)\n",
      "Epoch 7 Step 467/1563 Loss: 1.363 | Acc: 51.155% (7661/14976)\n",
      "Epoch 7 Step 468/1563 Loss: 1.363 | Acc: 51.146% (7676/15008)\n",
      "Epoch 7 Step 469/1563 Loss: 1.363 | Acc: 51.150% (7693/15040)\n",
      "Epoch 7 Step 470/1563 Loss: 1.363 | Acc: 51.135% (7707/15072)\n",
      "Epoch 7 Step 471/1563 Loss: 1.362 | Acc: 51.159% (7727/15104)\n",
      "Epoch 7 Step 472/1563 Loss: 1.362 | Acc: 51.143% (7741/15136)\n",
      "Epoch 7 Step 473/1563 Loss: 1.362 | Acc: 51.154% (7759/15168)\n",
      "Epoch 7 Step 474/1563 Loss: 1.362 | Acc: 51.171% (7778/15200)\n",
      "Epoch 7 Step 475/1563 Loss: 1.362 | Acc: 51.182% (7796/15232)\n",
      "Epoch 7 Step 476/1563 Loss: 1.362 | Acc: 51.212% (7817/15264)\n",
      "Epoch 7 Step 477/1563 Loss: 1.362 | Acc: 51.203% (7832/15296)\n",
      "Epoch 7 Step 478/1563 Loss: 1.362 | Acc: 51.187% (7846/15328)\n",
      "Epoch 7 Step 479/1563 Loss: 1.362 | Acc: 51.198% (7864/15360)\n",
      "Epoch 7 Step 480/1563 Loss: 1.362 | Acc: 51.208% (7882/15392)\n",
      "Epoch 7 Step 481/1563 Loss: 1.363 | Acc: 51.206% (7898/15424)\n",
      "Epoch 7 Step 482/1563 Loss: 1.363 | Acc: 51.197% (7913/15456)\n",
      "Epoch 7 Step 483/1563 Loss: 1.363 | Acc: 51.182% (7927/15488)\n",
      "Epoch 7 Step 484/1563 Loss: 1.363 | Acc: 51.205% (7947/15520)\n",
      "Epoch 7 Step 485/1563 Loss: 1.364 | Acc: 51.202% (7963/15552)\n",
      "Epoch 7 Step 486/1563 Loss: 1.364 | Acc: 51.194% (7978/15584)\n",
      "Epoch 7 Step 487/1563 Loss: 1.365 | Acc: 51.172% (7991/15616)\n",
      "Epoch 7 Step 488/1563 Loss: 1.365 | Acc: 51.182% (8009/15648)\n",
      "Epoch 7 Step 489/1563 Loss: 1.365 | Acc: 51.199% (8028/15680)\n",
      "Epoch 7 Step 490/1563 Loss: 1.364 | Acc: 51.222% (8048/15712)\n",
      "Epoch 7 Step 491/1563 Loss: 1.364 | Acc: 51.258% (8070/15744)\n",
      "Epoch 7 Step 492/1563 Loss: 1.364 | Acc: 51.255% (8086/15776)\n",
      "Epoch 7 Step 493/1563 Loss: 1.364 | Acc: 51.278% (8106/15808)\n",
      "Epoch 7 Step 494/1563 Loss: 1.364 | Acc: 51.294% (8125/15840)\n",
      "Epoch 7 Step 495/1563 Loss: 1.364 | Acc: 51.304% (8143/15872)\n",
      "Epoch 7 Step 496/1563 Loss: 1.364 | Acc: 51.308% (8160/15904)\n",
      "Epoch 7 Step 497/1563 Loss: 1.363 | Acc: 51.330% (8180/15936)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 498/1563 Loss: 1.363 | Acc: 51.340% (8198/15968)\n",
      "Epoch 7 Step 499/1563 Loss: 1.363 | Acc: 51.344% (8215/16000)\n",
      "Epoch 7 Step 500/1563 Loss: 1.364 | Acc: 51.329% (8229/16032)\n",
      "Epoch 7 Step 501/1563 Loss: 1.364 | Acc: 51.320% (8244/16064)\n",
      "Epoch 7 Step 502/1563 Loss: 1.364 | Acc: 51.292% (8256/16096)\n",
      "Epoch 7 Step 503/1563 Loss: 1.364 | Acc: 51.283% (8271/16128)\n",
      "Epoch 7 Step 504/1563 Loss: 1.364 | Acc: 51.300% (8290/16160)\n",
      "Epoch 7 Step 505/1563 Loss: 1.364 | Acc: 51.272% (8302/16192)\n",
      "Epoch 7 Step 506/1563 Loss: 1.364 | Acc: 51.282% (8320/16224)\n",
      "Epoch 7 Step 507/1563 Loss: 1.364 | Acc: 51.298% (8339/16256)\n",
      "Epoch 7 Step 508/1563 Loss: 1.364 | Acc: 51.314% (8358/16288)\n",
      "Epoch 7 Step 509/1563 Loss: 1.364 | Acc: 51.311% (8374/16320)\n",
      "Epoch 7 Step 510/1563 Loss: 1.364 | Acc: 51.327% (8393/16352)\n",
      "Epoch 7 Step 511/1563 Loss: 1.364 | Acc: 51.324% (8409/16384)\n",
      "Epoch 7 Step 512/1563 Loss: 1.364 | Acc: 51.340% (8428/16416)\n",
      "Epoch 7 Step 513/1563 Loss: 1.363 | Acc: 51.368% (8449/16448)\n",
      "Epoch 7 Step 514/1563 Loss: 1.363 | Acc: 51.383% (8468/16480)\n",
      "Epoch 7 Step 515/1563 Loss: 1.363 | Acc: 51.375% (8483/16512)\n",
      "Epoch 7 Step 516/1563 Loss: 1.364 | Acc: 51.372% (8499/16544)\n",
      "Epoch 7 Step 517/1563 Loss: 1.364 | Acc: 51.369% (8515/16576)\n",
      "Epoch 7 Step 518/1563 Loss: 1.364 | Acc: 51.385% (8534/16608)\n",
      "Epoch 7 Step 519/1563 Loss: 1.363 | Acc: 51.382% (8550/16640)\n",
      "Epoch 7 Step 520/1563 Loss: 1.363 | Acc: 51.380% (8566/16672)\n",
      "Epoch 7 Step 521/1563 Loss: 1.363 | Acc: 51.401% (8586/16704)\n",
      "Epoch 7 Step 522/1563 Loss: 1.363 | Acc: 51.416% (8605/16736)\n",
      "Epoch 7 Step 523/1563 Loss: 1.363 | Acc: 51.396% (8618/16768)\n",
      "Epoch 7 Step 524/1563 Loss: 1.363 | Acc: 51.423% (8639/16800)\n",
      "Epoch 7 Step 525/1563 Loss: 1.364 | Acc: 51.408% (8653/16832)\n",
      "Epoch 7 Step 526/1563 Loss: 1.364 | Acc: 51.399% (8668/16864)\n",
      "Epoch 7 Step 527/1563 Loss: 1.365 | Acc: 51.373% (8680/16896)\n",
      "Epoch 7 Step 528/1563 Loss: 1.366 | Acc: 51.311% (8686/16928)\n",
      "Epoch 7 Step 529/1563 Loss: 1.366 | Acc: 51.303% (8701/16960)\n",
      "Epoch 7 Step 530/1563 Loss: 1.365 | Acc: 51.306% (8718/16992)\n",
      "Epoch 7 Step 531/1563 Loss: 1.365 | Acc: 51.304% (8734/17024)\n",
      "Epoch 7 Step 532/1563 Loss: 1.365 | Acc: 51.313% (8752/17056)\n",
      "Epoch 7 Step 533/1563 Loss: 1.365 | Acc: 51.323% (8770/17088)\n",
      "Epoch 7 Step 534/1563 Loss: 1.364 | Acc: 51.320% (8786/17120)\n",
      "Epoch 7 Step 535/1563 Loss: 1.364 | Acc: 51.323% (8803/17152)\n",
      "Epoch 7 Step 536/1563 Loss: 1.365 | Acc: 51.304% (8816/17184)\n",
      "Epoch 7 Step 537/1563 Loss: 1.364 | Acc: 51.307% (8833/17216)\n",
      "Epoch 7 Step 538/1563 Loss: 1.365 | Acc: 51.252% (8840/17248)\n",
      "Epoch 7 Step 539/1563 Loss: 1.365 | Acc: 51.267% (8859/17280)\n",
      "Epoch 7 Step 540/1563 Loss: 1.366 | Acc: 51.248% (8872/17312)\n",
      "Epoch 7 Step 541/1563 Loss: 1.366 | Acc: 51.245% (8888/17344)\n",
      "Epoch 7 Step 542/1563 Loss: 1.367 | Acc: 51.237% (8903/17376)\n",
      "Epoch 7 Step 543/1563 Loss: 1.367 | Acc: 51.247% (8921/17408)\n",
      "Epoch 7 Step 544/1563 Loss: 1.367 | Acc: 51.267% (8941/17440)\n",
      "Epoch 7 Step 545/1563 Loss: 1.366 | Acc: 51.265% (8957/17472)\n",
      "Epoch 7 Step 546/1563 Loss: 1.366 | Acc: 51.257% (8972/17504)\n",
      "Epoch 7 Step 547/1563 Loss: 1.367 | Acc: 51.226% (8983/17536)\n",
      "Epoch 7 Step 548/1563 Loss: 1.367 | Acc: 51.247% (9003/17568)\n",
      "Epoch 7 Step 549/1563 Loss: 1.367 | Acc: 51.267% (9023/17600)\n",
      "Epoch 7 Step 550/1563 Loss: 1.367 | Acc: 51.265% (9039/17632)\n",
      "Epoch 7 Step 551/1563 Loss: 1.367 | Acc: 51.274% (9057/17664)\n",
      "Epoch 7 Step 552/1563 Loss: 1.367 | Acc: 51.232% (9066/17696)\n",
      "Epoch 7 Step 553/1563 Loss: 1.368 | Acc: 51.207% (9078/17728)\n",
      "Epoch 7 Step 554/1563 Loss: 1.369 | Acc: 51.177% (9089/17760)\n",
      "Epoch 7 Step 555/1563 Loss: 1.369 | Acc: 51.147% (9100/17792)\n",
      "Epoch 7 Step 556/1563 Loss: 1.369 | Acc: 51.156% (9118/17824)\n",
      "Epoch 7 Step 557/1563 Loss: 1.368 | Acc: 51.182% (9139/17856)\n",
      "Epoch 7 Step 558/1563 Loss: 1.369 | Acc: 51.174% (9154/17888)\n",
      "Epoch 7 Step 559/1563 Loss: 1.369 | Acc: 51.155% (9167/17920)\n",
      "Epoch 7 Step 560/1563 Loss: 1.369 | Acc: 51.159% (9184/17952)\n",
      "Epoch 7 Step 561/1563 Loss: 1.370 | Acc: 51.145% (9198/17984)\n",
      "Epoch 7 Step 562/1563 Loss: 1.370 | Acc: 51.149% (9215/18016)\n",
      "Epoch 7 Step 563/1563 Loss: 1.369 | Acc: 51.141% (9230/18048)\n",
      "Epoch 7 Step 564/1563 Loss: 1.369 | Acc: 51.156% (9249/18080)\n",
      "Epoch 7 Step 565/1563 Loss: 1.369 | Acc: 51.143% (9263/18112)\n",
      "Epoch 7 Step 566/1563 Loss: 1.369 | Acc: 51.185% (9287/18144)\n",
      "Epoch 7 Step 567/1563 Loss: 1.368 | Acc: 51.194% (9305/18176)\n",
      "Epoch 7 Step 568/1563 Loss: 1.368 | Acc: 51.225% (9327/18208)\n",
      "Epoch 7 Step 569/1563 Loss: 1.368 | Acc: 51.217% (9342/18240)\n",
      "Epoch 7 Step 570/1563 Loss: 1.368 | Acc: 51.188% (9353/18272)\n",
      "Epoch 7 Step 571/1563 Loss: 1.369 | Acc: 51.186% (9369/18304)\n",
      "Epoch 7 Step 572/1563 Loss: 1.369 | Acc: 51.178% (9384/18336)\n",
      "Epoch 7 Step 573/1563 Loss: 1.369 | Acc: 51.187% (9402/18368)\n",
      "Epoch 7 Step 574/1563 Loss: 1.369 | Acc: 51.190% (9419/18400)\n",
      "Epoch 7 Step 575/1563 Loss: 1.369 | Acc: 51.183% (9434/18432)\n",
      "Epoch 7 Step 576/1563 Loss: 1.369 | Acc: 51.202% (9454/18464)\n",
      "Epoch 7 Step 577/1563 Loss: 1.369 | Acc: 51.195% (9469/18496)\n",
      "Epoch 7 Step 578/1563 Loss: 1.369 | Acc: 51.209% (9488/18528)\n",
      "Epoch 7 Step 579/1563 Loss: 1.369 | Acc: 51.207% (9504/18560)\n",
      "Epoch 7 Step 580/1563 Loss: 1.369 | Acc: 51.194% (9518/18592)\n",
      "Epoch 7 Step 581/1563 Loss: 1.370 | Acc: 51.181% (9532/18624)\n",
      "Epoch 7 Step 582/1563 Loss: 1.369 | Acc: 51.174% (9547/18656)\n",
      "Epoch 7 Step 583/1563 Loss: 1.369 | Acc: 51.193% (9567/18688)\n",
      "Epoch 7 Step 584/1563 Loss: 1.369 | Acc: 51.175% (9580/18720)\n",
      "Epoch 7 Step 585/1563 Loss: 1.369 | Acc: 51.200% (9601/18752)\n",
      "Epoch 7 Step 586/1563 Loss: 1.369 | Acc: 51.203% (9618/18784)\n",
      "Epoch 7 Step 587/1563 Loss: 1.369 | Acc: 51.217% (9637/18816)\n",
      "Epoch 7 Step 588/1563 Loss: 1.369 | Acc: 51.194% (9649/18848)\n",
      "Epoch 7 Step 589/1563 Loss: 1.370 | Acc: 51.160% (9659/18880)\n",
      "Epoch 7 Step 590/1563 Loss: 1.370 | Acc: 51.184% (9680/18912)\n",
      "Epoch 7 Step 591/1563 Loss: 1.370 | Acc: 51.204% (9700/18944)\n",
      "Epoch 7 Step 592/1563 Loss: 1.370 | Acc: 51.186% (9713/18976)\n",
      "Epoch 7 Step 593/1563 Loss: 1.370 | Acc: 51.205% (9733/19008)\n",
      "Epoch 7 Step 594/1563 Loss: 1.371 | Acc: 51.176% (9744/19040)\n",
      "Epoch 7 Step 595/1563 Loss: 1.371 | Acc: 51.180% (9761/19072)\n",
      "Epoch 7 Step 596/1563 Loss: 1.370 | Acc: 51.220% (9785/19104)\n",
      "Epoch 7 Step 597/1563 Loss: 1.370 | Acc: 51.228% (9803/19136)\n",
      "Epoch 7 Step 598/1563 Loss: 1.370 | Acc: 51.226% (9819/19168)\n",
      "Epoch 7 Step 599/1563 Loss: 1.370 | Acc: 51.219% (9834/19200)\n",
      "Epoch 7 Step 600/1563 Loss: 1.370 | Acc: 51.238% (9854/19232)\n",
      "Epoch 7 Step 601/1563 Loss: 1.370 | Acc: 51.235% (9870/19264)\n",
      "Epoch 7 Step 602/1563 Loss: 1.370 | Acc: 51.239% (9887/19296)\n",
      "Epoch 7 Step 603/1563 Loss: 1.370 | Acc: 51.242% (9904/19328)\n",
      "Epoch 7 Step 604/1563 Loss: 1.371 | Acc: 51.198% (9912/19360)\n",
      "Epoch 7 Step 605/1563 Loss: 1.371 | Acc: 51.181% (9925/19392)\n",
      "Epoch 7 Step 606/1563 Loss: 1.371 | Acc: 51.174% (9940/19424)\n",
      "Epoch 7 Step 607/1563 Loss: 1.371 | Acc: 51.167% (9955/19456)\n",
      "Epoch 7 Step 608/1563 Loss: 1.371 | Acc: 51.180% (9974/19488)\n",
      "Epoch 7 Step 609/1563 Loss: 1.371 | Acc: 51.183% (9991/19520)\n",
      "Epoch 7 Step 610/1563 Loss: 1.372 | Acc: 51.166% (10004/19552)\n",
      "Epoch 7 Step 611/1563 Loss: 1.372 | Acc: 51.174% (10022/19584)\n",
      "Epoch 7 Step 612/1563 Loss: 1.372 | Acc: 51.167% (10037/19616)\n",
      "Epoch 7 Step 613/1563 Loss: 1.372 | Acc: 51.196% (10059/19648)\n",
      "Epoch 7 Step 614/1563 Loss: 1.372 | Acc: 51.209% (10078/19680)\n",
      "Epoch 7 Step 615/1563 Loss: 1.373 | Acc: 51.167% (10086/19712)\n",
      "Epoch 7 Step 616/1563 Loss: 1.373 | Acc: 51.170% (10103/19744)\n",
      "Epoch 7 Step 617/1563 Loss: 1.373 | Acc: 51.168% (10119/19776)\n",
      "Epoch 7 Step 618/1563 Loss: 1.374 | Acc: 51.141% (10130/19808)\n",
      "Epoch 7 Step 619/1563 Loss: 1.374 | Acc: 51.134% (10145/19840)\n",
      "Epoch 7 Step 620/1563 Loss: 1.374 | Acc: 51.132% (10161/19872)\n",
      "Epoch 7 Step 621/1563 Loss: 1.374 | Acc: 51.125% (10176/19904)\n",
      "Epoch 7 Step 622/1563 Loss: 1.374 | Acc: 51.119% (10191/19936)\n",
      "Epoch 7 Step 623/1563 Loss: 1.374 | Acc: 51.122% (10208/19968)\n",
      "Epoch 7 Step 624/1563 Loss: 1.374 | Acc: 51.120% (10224/20000)\n",
      "Epoch 7 Step 625/1563 Loss: 1.374 | Acc: 51.108% (10238/20032)\n",
      "Epoch 7 Step 626/1563 Loss: 1.374 | Acc: 51.131% (10259/20064)\n",
      "Epoch 7 Step 627/1563 Loss: 1.374 | Acc: 51.120% (10273/20096)\n",
      "Epoch 7 Step 628/1563 Loss: 1.375 | Acc: 51.088% (10283/20128)\n",
      "Epoch 7 Step 629/1563 Loss: 1.374 | Acc: 51.101% (10302/20160)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 630/1563 Loss: 1.374 | Acc: 51.104% (10319/20192)\n",
      "Epoch 7 Step 631/1563 Loss: 1.375 | Acc: 51.093% (10333/20224)\n",
      "Epoch 7 Step 632/1563 Loss: 1.375 | Acc: 51.096% (10350/20256)\n",
      "Epoch 7 Step 633/1563 Loss: 1.375 | Acc: 51.119% (10371/20288)\n",
      "Epoch 7 Step 634/1563 Loss: 1.374 | Acc: 51.112% (10386/20320)\n",
      "Epoch 7 Step 635/1563 Loss: 1.375 | Acc: 51.110% (10402/20352)\n",
      "Epoch 7 Step 636/1563 Loss: 1.375 | Acc: 51.094% (10415/20384)\n",
      "Epoch 7 Step 637/1563 Loss: 1.375 | Acc: 51.087% (10430/20416)\n",
      "Epoch 7 Step 638/1563 Loss: 1.375 | Acc: 51.076% (10444/20448)\n",
      "Epoch 7 Step 639/1563 Loss: 1.375 | Acc: 51.064% (10458/20480)\n",
      "Epoch 7 Step 640/1563 Loss: 1.375 | Acc: 51.068% (10475/20512)\n",
      "Epoch 7 Step 641/1563 Loss: 1.375 | Acc: 51.066% (10491/20544)\n",
      "Epoch 7 Step 642/1563 Loss: 1.375 | Acc: 51.050% (10504/20576)\n",
      "Epoch 7 Step 643/1563 Loss: 1.375 | Acc: 51.038% (10518/20608)\n",
      "Epoch 7 Step 644/1563 Loss: 1.375 | Acc: 51.037% (10534/20640)\n",
      "Epoch 7 Step 645/1563 Loss: 1.375 | Acc: 51.050% (10553/20672)\n",
      "Epoch 7 Step 646/1563 Loss: 1.375 | Acc: 51.043% (10568/20704)\n",
      "Epoch 7 Step 647/1563 Loss: 1.375 | Acc: 51.046% (10585/20736)\n",
      "Epoch 7 Step 648/1563 Loss: 1.375 | Acc: 51.040% (10600/20768)\n",
      "Epoch 7 Step 649/1563 Loss: 1.375 | Acc: 51.038% (10616/20800)\n",
      "Epoch 7 Step 650/1563 Loss: 1.375 | Acc: 51.042% (10633/20832)\n",
      "Epoch 7 Step 651/1563 Loss: 1.375 | Acc: 51.021% (10645/20864)\n",
      "Epoch 7 Step 652/1563 Loss: 1.375 | Acc: 51.024% (10662/20896)\n",
      "Epoch 7 Step 653/1563 Loss: 1.375 | Acc: 51.013% (10676/20928)\n",
      "Epoch 7 Step 654/1563 Loss: 1.376 | Acc: 51.007% (10691/20960)\n",
      "Epoch 7 Step 655/1563 Loss: 1.375 | Acc: 51.034% (10713/20992)\n",
      "Epoch 7 Step 656/1563 Loss: 1.375 | Acc: 51.051% (10733/21024)\n",
      "Epoch 7 Step 657/1563 Loss: 1.375 | Acc: 51.050% (10749/21056)\n",
      "Epoch 7 Step 658/1563 Loss: 1.375 | Acc: 51.039% (10763/21088)\n",
      "Epoch 7 Step 659/1563 Loss: 1.375 | Acc: 51.023% (10776/21120)\n",
      "Epoch 7 Step 660/1563 Loss: 1.375 | Acc: 51.007% (10789/21152)\n",
      "Epoch 7 Step 661/1563 Loss: 1.375 | Acc: 50.991% (10802/21184)\n",
      "Epoch 7 Step 662/1563 Loss: 1.375 | Acc: 50.985% (10817/21216)\n",
      "Epoch 7 Step 663/1563 Loss: 1.375 | Acc: 50.993% (10835/21248)\n",
      "Epoch 7 Step 664/1563 Loss: 1.375 | Acc: 50.982% (10849/21280)\n",
      "Epoch 7 Step 665/1563 Loss: 1.375 | Acc: 50.976% (10864/21312)\n",
      "Epoch 7 Step 666/1563 Loss: 1.375 | Acc: 50.956% (10876/21344)\n",
      "Epoch 7 Step 667/1563 Loss: 1.376 | Acc: 50.936% (10888/21376)\n",
      "Epoch 7 Step 668/1563 Loss: 1.376 | Acc: 50.939% (10905/21408)\n",
      "Epoch 7 Step 669/1563 Loss: 1.376 | Acc: 50.933% (10920/21440)\n",
      "Epoch 7 Step 670/1563 Loss: 1.376 | Acc: 50.908% (10931/21472)\n",
      "Epoch 7 Step 671/1563 Loss: 1.377 | Acc: 50.898% (10945/21504)\n",
      "Epoch 7 Step 672/1563 Loss: 1.376 | Acc: 50.905% (10963/21536)\n",
      "Epoch 7 Step 673/1563 Loss: 1.376 | Acc: 50.904% (10979/21568)\n",
      "Epoch 7 Step 674/1563 Loss: 1.376 | Acc: 50.903% (10995/21600)\n",
      "Epoch 7 Step 675/1563 Loss: 1.376 | Acc: 50.897% (11010/21632)\n",
      "Epoch 7 Step 676/1563 Loss: 1.376 | Acc: 50.900% (11027/21664)\n",
      "Epoch 7 Step 677/1563 Loss: 1.376 | Acc: 50.885% (11040/21696)\n",
      "Epoch 7 Step 678/1563 Loss: 1.376 | Acc: 50.879% (11055/21728)\n",
      "Epoch 7 Step 679/1563 Loss: 1.376 | Acc: 50.869% (11069/21760)\n",
      "Epoch 7 Step 680/1563 Loss: 1.376 | Acc: 50.890% (11090/21792)\n",
      "Epoch 7 Step 681/1563 Loss: 1.376 | Acc: 50.884% (11105/21824)\n",
      "Epoch 7 Step 682/1563 Loss: 1.376 | Acc: 50.911% (11127/21856)\n",
      "Epoch 7 Step 683/1563 Loss: 1.376 | Acc: 50.932% (11148/21888)\n",
      "Epoch 7 Step 684/1563 Loss: 1.376 | Acc: 50.940% (11166/21920)\n",
      "Epoch 7 Step 685/1563 Loss: 1.376 | Acc: 50.929% (11180/21952)\n",
      "Epoch 7 Step 686/1563 Loss: 1.376 | Acc: 50.932% (11197/21984)\n",
      "Epoch 7 Step 687/1563 Loss: 1.375 | Acc: 50.931% (11213/22016)\n",
      "Epoch 7 Step 688/1563 Loss: 1.376 | Acc: 50.921% (11227/22048)\n",
      "Epoch 7 Step 689/1563 Loss: 1.376 | Acc: 50.928% (11245/22080)\n",
      "Epoch 7 Step 690/1563 Loss: 1.375 | Acc: 50.923% (11260/22112)\n",
      "Epoch 7 Step 691/1563 Loss: 1.375 | Acc: 50.930% (11278/22144)\n",
      "Epoch 7 Step 692/1563 Loss: 1.376 | Acc: 50.915% (11291/22176)\n",
      "Epoch 7 Step 693/1563 Loss: 1.376 | Acc: 50.919% (11308/22208)\n",
      "Epoch 7 Step 694/1563 Loss: 1.375 | Acc: 50.931% (11327/22240)\n",
      "Epoch 7 Step 695/1563 Loss: 1.375 | Acc: 50.925% (11342/22272)\n",
      "Epoch 7 Step 696/1563 Loss: 1.375 | Acc: 50.924% (11358/22304)\n",
      "Epoch 7 Step 697/1563 Loss: 1.376 | Acc: 50.904% (11370/22336)\n",
      "Epoch 7 Step 698/1563 Loss: 1.375 | Acc: 50.899% (11385/22368)\n",
      "Epoch 7 Step 699/1563 Loss: 1.375 | Acc: 50.924% (11407/22400)\n",
      "Epoch 7 Step 700/1563 Loss: 1.375 | Acc: 50.923% (11423/22432)\n",
      "Epoch 7 Step 701/1563 Loss: 1.375 | Acc: 50.917% (11438/22464)\n",
      "Epoch 7 Step 702/1563 Loss: 1.375 | Acc: 50.902% (11451/22496)\n",
      "Epoch 7 Step 703/1563 Loss: 1.375 | Acc: 50.910% (11469/22528)\n",
      "Epoch 7 Step 704/1563 Loss: 1.375 | Acc: 50.909% (11485/22560)\n",
      "Epoch 7 Step 705/1563 Loss: 1.375 | Acc: 50.921% (11504/22592)\n",
      "Epoch 7 Step 706/1563 Loss: 1.375 | Acc: 50.906% (11517/22624)\n",
      "Epoch 7 Step 707/1563 Loss: 1.375 | Acc: 50.909% (11534/22656)\n",
      "Epoch 7 Step 708/1563 Loss: 1.375 | Acc: 50.921% (11553/22688)\n",
      "Epoch 7 Step 709/1563 Loss: 1.376 | Acc: 50.911% (11567/22720)\n",
      "Epoch 7 Step 710/1563 Loss: 1.376 | Acc: 50.932% (11588/22752)\n",
      "Epoch 7 Step 711/1563 Loss: 1.375 | Acc: 50.944% (11607/22784)\n",
      "Epoch 7 Step 712/1563 Loss: 1.375 | Acc: 50.964% (11628/22816)\n",
      "Epoch 7 Step 713/1563 Loss: 1.375 | Acc: 50.954% (11642/22848)\n",
      "Epoch 7 Step 714/1563 Loss: 1.375 | Acc: 50.957% (11659/22880)\n",
      "Epoch 7 Step 715/1563 Loss: 1.375 | Acc: 50.969% (11678/22912)\n",
      "Epoch 7 Step 716/1563 Loss: 1.375 | Acc: 50.963% (11693/22944)\n",
      "Epoch 7 Step 717/1563 Loss: 1.375 | Acc: 50.971% (11711/22976)\n",
      "Epoch 7 Step 718/1563 Loss: 1.375 | Acc: 50.974% (11728/23008)\n",
      "Epoch 7 Step 719/1563 Loss: 1.375 | Acc: 50.972% (11744/23040)\n",
      "Epoch 7 Step 720/1563 Loss: 1.375 | Acc: 50.975% (11761/23072)\n",
      "Epoch 7 Step 721/1563 Loss: 1.375 | Acc: 50.974% (11777/23104)\n",
      "Epoch 7 Step 722/1563 Loss: 1.375 | Acc: 51.003% (11800/23136)\n",
      "Epoch 7 Step 723/1563 Loss: 1.375 | Acc: 50.997% (11815/23168)\n",
      "Epoch 7 Step 724/1563 Loss: 1.375 | Acc: 51.013% (11835/23200)\n",
      "Epoch 7 Step 725/1563 Loss: 1.375 | Acc: 51.029% (11855/23232)\n",
      "Epoch 7 Step 726/1563 Loss: 1.375 | Acc: 51.014% (11868/23264)\n",
      "Epoch 7 Step 727/1563 Loss: 1.375 | Acc: 50.983% (11877/23296)\n",
      "Epoch 7 Step 728/1563 Loss: 1.376 | Acc: 50.973% (11891/23328)\n",
      "Epoch 7 Step 729/1563 Loss: 1.376 | Acc: 50.963% (11905/23360)\n",
      "Epoch 7 Step 730/1563 Loss: 1.376 | Acc: 50.936% (11915/23392)\n",
      "Epoch 7 Step 731/1563 Loss: 1.377 | Acc: 50.918% (11927/23424)\n",
      "Epoch 7 Step 732/1563 Loss: 1.377 | Acc: 50.917% (11943/23456)\n",
      "Epoch 7 Step 733/1563 Loss: 1.376 | Acc: 50.915% (11959/23488)\n",
      "Epoch 7 Step 734/1563 Loss: 1.376 | Acc: 50.927% (11978/23520)\n",
      "Epoch 7 Step 735/1563 Loss: 1.376 | Acc: 50.917% (11992/23552)\n",
      "Epoch 7 Step 736/1563 Loss: 1.376 | Acc: 50.912% (12007/23584)\n",
      "Epoch 7 Step 737/1563 Loss: 1.376 | Acc: 50.906% (12022/23616)\n",
      "Epoch 7 Step 738/1563 Loss: 1.377 | Acc: 50.901% (12037/23648)\n",
      "Epoch 7 Step 739/1563 Loss: 1.376 | Acc: 50.904% (12054/23680)\n",
      "Epoch 7 Step 740/1563 Loss: 1.376 | Acc: 50.915% (12073/23712)\n",
      "Epoch 7 Step 741/1563 Loss: 1.376 | Acc: 50.901% (12086/23744)\n",
      "Epoch 7 Step 742/1563 Loss: 1.376 | Acc: 50.900% (12102/23776)\n",
      "Epoch 7 Step 743/1563 Loss: 1.375 | Acc: 50.924% (12124/23808)\n",
      "Epoch 7 Step 744/1563 Loss: 1.376 | Acc: 50.910% (12137/23840)\n",
      "Epoch 7 Step 745/1563 Loss: 1.376 | Acc: 50.884% (12147/23872)\n",
      "Epoch 7 Step 746/1563 Loss: 1.376 | Acc: 50.874% (12161/23904)\n",
      "Epoch 7 Step 747/1563 Loss: 1.375 | Acc: 50.894% (12182/23936)\n",
      "Epoch 7 Step 748/1563 Loss: 1.376 | Acc: 50.889% (12197/23968)\n",
      "Epoch 7 Step 749/1563 Loss: 1.376 | Acc: 50.879% (12211/24000)\n",
      "Epoch 7 Step 750/1563 Loss: 1.376 | Acc: 50.886% (12229/24032)\n",
      "Epoch 7 Step 751/1563 Loss: 1.375 | Acc: 50.910% (12251/24064)\n",
      "Epoch 7 Step 752/1563 Loss: 1.375 | Acc: 50.913% (12268/24096)\n",
      "Epoch 7 Step 753/1563 Loss: 1.375 | Acc: 50.912% (12284/24128)\n",
      "Epoch 7 Step 754/1563 Loss: 1.375 | Acc: 50.919% (12302/24160)\n",
      "Epoch 7 Step 755/1563 Loss: 1.375 | Acc: 50.914% (12317/24192)\n",
      "Epoch 7 Step 756/1563 Loss: 1.375 | Acc: 50.912% (12333/24224)\n",
      "Epoch 7 Step 757/1563 Loss: 1.375 | Acc: 50.928% (12353/24256)\n",
      "Epoch 7 Step 758/1563 Loss: 1.375 | Acc: 50.910% (12365/24288)\n",
      "Epoch 7 Step 759/1563 Loss: 1.375 | Acc: 50.909% (12381/24320)\n",
      "Epoch 7 Step 760/1563 Loss: 1.375 | Acc: 50.899% (12395/24352)\n",
      "Epoch 7 Step 761/1563 Loss: 1.375 | Acc: 50.898% (12411/24384)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 762/1563 Loss: 1.374 | Acc: 50.913% (12431/24416)\n",
      "Epoch 7 Step 763/1563 Loss: 1.374 | Acc: 50.920% (12449/24448)\n",
      "Epoch 7 Step 764/1563 Loss: 1.374 | Acc: 50.919% (12465/24480)\n",
      "Epoch 7 Step 765/1563 Loss: 1.375 | Acc: 50.889% (12474/24512)\n",
      "Epoch 7 Step 766/1563 Loss: 1.375 | Acc: 50.888% (12490/24544)\n",
      "Epoch 7 Step 767/1563 Loss: 1.374 | Acc: 50.903% (12510/24576)\n",
      "Epoch 7 Step 768/1563 Loss: 1.375 | Acc: 50.882% (12521/24608)\n",
      "Epoch 7 Step 769/1563 Loss: 1.375 | Acc: 50.869% (12534/24640)\n",
      "Epoch 7 Step 770/1563 Loss: 1.374 | Acc: 50.867% (12550/24672)\n",
      "Epoch 7 Step 771/1563 Loss: 1.374 | Acc: 50.858% (12564/24704)\n",
      "Epoch 7 Step 772/1563 Loss: 1.374 | Acc: 50.845% (12577/24736)\n",
      "Epoch 7 Step 773/1563 Loss: 1.375 | Acc: 50.828% (12589/24768)\n",
      "Epoch 7 Step 774/1563 Loss: 1.375 | Acc: 50.802% (12599/24800)\n",
      "Epoch 7 Step 775/1563 Loss: 1.375 | Acc: 50.801% (12615/24832)\n",
      "Epoch 7 Step 776/1563 Loss: 1.375 | Acc: 50.808% (12633/24864)\n",
      "Epoch 7 Step 777/1563 Loss: 1.375 | Acc: 50.811% (12650/24896)\n",
      "Epoch 7 Step 778/1563 Loss: 1.375 | Acc: 50.806% (12665/24928)\n",
      "Epoch 7 Step 779/1563 Loss: 1.376 | Acc: 50.793% (12678/24960)\n",
      "Epoch 7 Step 780/1563 Loss: 1.376 | Acc: 50.772% (12689/24992)\n",
      "Epoch 7 Step 781/1563 Loss: 1.376 | Acc: 50.759% (12702/25024)\n",
      "Epoch 7 Step 782/1563 Loss: 1.376 | Acc: 50.770% (12721/25056)\n",
      "Epoch 7 Step 783/1563 Loss: 1.376 | Acc: 50.745% (12731/25088)\n",
      "Epoch 7 Step 784/1563 Loss: 1.376 | Acc: 50.756% (12750/25120)\n",
      "Epoch 7 Step 785/1563 Loss: 1.376 | Acc: 50.759% (12767/25152)\n",
      "Epoch 7 Step 786/1563 Loss: 1.376 | Acc: 50.750% (12781/25184)\n",
      "Epoch 7 Step 787/1563 Loss: 1.377 | Acc: 50.742% (12795/25216)\n",
      "Epoch 7 Step 788/1563 Loss: 1.376 | Acc: 50.756% (12815/25248)\n",
      "Epoch 7 Step 789/1563 Loss: 1.376 | Acc: 50.759% (12832/25280)\n",
      "Epoch 7 Step 790/1563 Loss: 1.376 | Acc: 50.747% (12845/25312)\n",
      "Epoch 7 Step 791/1563 Loss: 1.377 | Acc: 50.742% (12860/25344)\n",
      "Epoch 7 Step 792/1563 Loss: 1.377 | Acc: 50.721% (12871/25376)\n",
      "Epoch 7 Step 793/1563 Loss: 1.377 | Acc: 50.712% (12885/25408)\n",
      "Epoch 7 Step 794/1563 Loss: 1.377 | Acc: 50.704% (12899/25440)\n",
      "Epoch 7 Step 795/1563 Loss: 1.377 | Acc: 50.707% (12916/25472)\n",
      "Epoch 7 Step 796/1563 Loss: 1.377 | Acc: 50.710% (12933/25504)\n",
      "Epoch 7 Step 797/1563 Loss: 1.377 | Acc: 50.689% (12944/25536)\n",
      "Epoch 7 Step 798/1563 Loss: 1.377 | Acc: 50.688% (12960/25568)\n",
      "Epoch 7 Step 799/1563 Loss: 1.377 | Acc: 50.680% (12974/25600)\n",
      "Epoch 7 Step 800/1563 Loss: 1.377 | Acc: 50.675% (12989/25632)\n",
      "Epoch 7 Step 801/1563 Loss: 1.378 | Acc: 50.655% (13000/25664)\n",
      "Epoch 7 Step 802/1563 Loss: 1.378 | Acc: 50.654% (13016/25696)\n",
      "Epoch 7 Step 803/1563 Loss: 1.378 | Acc: 50.657% (13033/25728)\n",
      "Epoch 7 Step 804/1563 Loss: 1.378 | Acc: 50.672% (13053/25760)\n",
      "Epoch 7 Step 805/1563 Loss: 1.378 | Acc: 50.667% (13068/25792)\n",
      "Epoch 7 Step 806/1563 Loss: 1.378 | Acc: 50.670% (13085/25824)\n",
      "Epoch 7 Step 807/1563 Loss: 1.378 | Acc: 50.669% (13101/25856)\n",
      "Epoch 7 Step 808/1563 Loss: 1.378 | Acc: 50.664% (13116/25888)\n",
      "Epoch 7 Step 809/1563 Loss: 1.378 | Acc: 50.648% (13128/25920)\n",
      "Epoch 7 Step 810/1563 Loss: 1.378 | Acc: 50.632% (13140/25952)\n",
      "Epoch 7 Step 811/1563 Loss: 1.378 | Acc: 50.623% (13154/25984)\n",
      "Epoch 7 Step 812/1563 Loss: 1.378 | Acc: 50.630% (13172/26016)\n",
      "Epoch 7 Step 813/1563 Loss: 1.378 | Acc: 50.622% (13186/26048)\n",
      "Epoch 7 Step 814/1563 Loss: 1.378 | Acc: 50.644% (13208/26080)\n",
      "Epoch 7 Step 815/1563 Loss: 1.378 | Acc: 50.647% (13225/26112)\n",
      "Epoch 7 Step 816/1563 Loss: 1.378 | Acc: 50.662% (13245/26144)\n",
      "Epoch 7 Step 817/1563 Loss: 1.378 | Acc: 50.657% (13260/26176)\n",
      "Epoch 7 Step 818/1563 Loss: 1.378 | Acc: 50.668% (13279/26208)\n",
      "Epoch 7 Step 819/1563 Loss: 1.378 | Acc: 50.663% (13294/26240)\n",
      "Epoch 7 Step 820/1563 Loss: 1.378 | Acc: 50.655% (13308/26272)\n",
      "Epoch 7 Step 821/1563 Loss: 1.377 | Acc: 50.658% (13325/26304)\n",
      "Epoch 7 Step 822/1563 Loss: 1.378 | Acc: 50.634% (13335/26336)\n",
      "Epoch 7 Step 823/1563 Loss: 1.378 | Acc: 50.637% (13352/26368)\n",
      "Epoch 7 Step 824/1563 Loss: 1.378 | Acc: 50.636% (13368/26400)\n",
      "Epoch 7 Step 825/1563 Loss: 1.378 | Acc: 50.643% (13386/26432)\n",
      "Epoch 7 Step 826/1563 Loss: 1.378 | Acc: 50.623% (13397/26464)\n",
      "Epoch 7 Step 827/1563 Loss: 1.378 | Acc: 50.642% (13418/26496)\n",
      "Epoch 7 Step 828/1563 Loss: 1.377 | Acc: 50.660% (13439/26528)\n",
      "Epoch 7 Step 829/1563 Loss: 1.377 | Acc: 50.670% (13458/26560)\n",
      "Epoch 7 Step 830/1563 Loss: 1.377 | Acc: 50.684% (13478/26592)\n",
      "Epoch 7 Step 831/1563 Loss: 1.377 | Acc: 50.695% (13497/26624)\n",
      "Epoch 7 Step 832/1563 Loss: 1.376 | Acc: 50.709% (13517/26656)\n",
      "Epoch 7 Step 833/1563 Loss: 1.376 | Acc: 50.708% (13533/26688)\n",
      "Epoch 7 Step 834/1563 Loss: 1.376 | Acc: 50.704% (13548/26720)\n",
      "Epoch 7 Step 835/1563 Loss: 1.376 | Acc: 50.703% (13564/26752)\n",
      "Epoch 7 Step 836/1563 Loss: 1.376 | Acc: 50.698% (13579/26784)\n",
      "Epoch 7 Step 837/1563 Loss: 1.377 | Acc: 50.694% (13594/26816)\n",
      "Epoch 7 Step 838/1563 Loss: 1.377 | Acc: 50.700% (13612/26848)\n",
      "Epoch 7 Step 839/1563 Loss: 1.377 | Acc: 50.699% (13628/26880)\n",
      "Epoch 7 Step 840/1563 Loss: 1.376 | Acc: 50.706% (13646/26912)\n",
      "Epoch 7 Step 841/1563 Loss: 1.376 | Acc: 50.709% (13663/26944)\n",
      "Epoch 7 Step 842/1563 Loss: 1.376 | Acc: 50.701% (13677/26976)\n",
      "Epoch 7 Step 843/1563 Loss: 1.376 | Acc: 50.689% (13690/27008)\n",
      "Epoch 7 Step 844/1563 Loss: 1.376 | Acc: 50.692% (13707/27040)\n",
      "Epoch 7 Step 845/1563 Loss: 1.376 | Acc: 50.698% (13725/27072)\n",
      "Epoch 7 Step 846/1563 Loss: 1.376 | Acc: 50.690% (13739/27104)\n",
      "Epoch 7 Step 847/1563 Loss: 1.376 | Acc: 50.685% (13754/27136)\n",
      "Epoch 7 Step 848/1563 Loss: 1.376 | Acc: 50.688% (13771/27168)\n",
      "Epoch 7 Step 849/1563 Loss: 1.376 | Acc: 50.695% (13789/27200)\n",
      "Epoch 7 Step 850/1563 Loss: 1.376 | Acc: 50.712% (13810/27232)\n",
      "Epoch 7 Step 851/1563 Loss: 1.376 | Acc: 50.693% (13821/27264)\n",
      "Epoch 7 Step 852/1563 Loss: 1.376 | Acc: 50.692% (13837/27296)\n",
      "Epoch 7 Step 853/1563 Loss: 1.376 | Acc: 50.684% (13851/27328)\n",
      "Epoch 7 Step 854/1563 Loss: 1.376 | Acc: 50.687% (13868/27360)\n",
      "Epoch 7 Step 855/1563 Loss: 1.376 | Acc: 50.690% (13885/27392)\n",
      "Epoch 7 Step 856/1563 Loss: 1.376 | Acc: 50.682% (13899/27424)\n",
      "Epoch 7 Step 857/1563 Loss: 1.377 | Acc: 50.685% (13916/27456)\n",
      "Epoch 7 Step 858/1563 Loss: 1.377 | Acc: 50.691% (13934/27488)\n",
      "Epoch 7 Step 859/1563 Loss: 1.377 | Acc: 50.687% (13949/27520)\n",
      "Epoch 7 Step 860/1563 Loss: 1.377 | Acc: 50.690% (13966/27552)\n",
      "Epoch 7 Step 861/1563 Loss: 1.377 | Acc: 50.689% (13982/27584)\n",
      "Epoch 7 Step 862/1563 Loss: 1.377 | Acc: 50.684% (13997/27616)\n",
      "Epoch 7 Step 863/1563 Loss: 1.377 | Acc: 50.673% (14010/27648)\n",
      "Epoch 7 Step 864/1563 Loss: 1.377 | Acc: 50.683% (14029/27680)\n",
      "Epoch 7 Step 865/1563 Loss: 1.376 | Acc: 50.689% (14047/27712)\n",
      "Epoch 7 Step 866/1563 Loss: 1.377 | Acc: 50.688% (14063/27744)\n",
      "Epoch 7 Step 867/1563 Loss: 1.376 | Acc: 50.695% (14081/27776)\n",
      "Epoch 7 Step 868/1563 Loss: 1.377 | Acc: 50.676% (14092/27808)\n",
      "Epoch 7 Step 869/1563 Loss: 1.377 | Acc: 50.672% (14107/27840)\n",
      "Epoch 7 Step 870/1563 Loss: 1.377 | Acc: 50.660% (14120/27872)\n",
      "Epoch 7 Step 871/1563 Loss: 1.377 | Acc: 50.677% (14141/27904)\n",
      "Epoch 7 Step 872/1563 Loss: 1.376 | Acc: 50.680% (14158/27936)\n",
      "Epoch 7 Step 873/1563 Loss: 1.376 | Acc: 50.686% (14176/27968)\n",
      "Epoch 7 Step 874/1563 Loss: 1.376 | Acc: 50.671% (14188/28000)\n",
      "Epoch 7 Step 875/1563 Loss: 1.377 | Acc: 50.674% (14205/28032)\n",
      "Epoch 7 Step 876/1563 Loss: 1.377 | Acc: 50.670% (14220/28064)\n",
      "Epoch 7 Step 877/1563 Loss: 1.377 | Acc: 50.673% (14237/28096)\n",
      "Epoch 7 Step 878/1563 Loss: 1.377 | Acc: 50.672% (14253/28128)\n",
      "Epoch 7 Step 879/1563 Loss: 1.377 | Acc: 50.675% (14270/28160)\n",
      "Epoch 7 Step 880/1563 Loss: 1.377 | Acc: 50.670% (14285/28192)\n",
      "Epoch 7 Step 881/1563 Loss: 1.377 | Acc: 50.659% (14298/28224)\n",
      "Epoch 7 Step 882/1563 Loss: 1.377 | Acc: 50.655% (14313/28256)\n",
      "Epoch 7 Step 883/1563 Loss: 1.378 | Acc: 50.640% (14325/28288)\n",
      "Epoch 7 Step 884/1563 Loss: 1.378 | Acc: 50.632% (14339/28320)\n",
      "Epoch 7 Step 885/1563 Loss: 1.378 | Acc: 50.638% (14357/28352)\n",
      "Epoch 7 Step 886/1563 Loss: 1.378 | Acc: 50.645% (14375/28384)\n",
      "Epoch 7 Step 887/1563 Loss: 1.378 | Acc: 50.655% (14394/28416)\n",
      "Epoch 7 Step 888/1563 Loss: 1.378 | Acc: 50.650% (14409/28448)\n",
      "Epoch 7 Step 889/1563 Loss: 1.378 | Acc: 50.646% (14424/28480)\n",
      "Epoch 7 Step 890/1563 Loss: 1.377 | Acc: 50.642% (14439/28512)\n",
      "Epoch 7 Step 891/1563 Loss: 1.378 | Acc: 50.652% (14458/28544)\n",
      "Epoch 7 Step 892/1563 Loss: 1.378 | Acc: 50.640% (14471/28576)\n",
      "Epoch 7 Step 893/1563 Loss: 1.378 | Acc: 50.636% (14486/28608)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 894/1563 Loss: 1.378 | Acc: 50.611% (14495/28640)\n",
      "Epoch 7 Step 895/1563 Loss: 1.378 | Acc: 50.610% (14511/28672)\n",
      "Epoch 7 Step 896/1563 Loss: 1.378 | Acc: 50.617% (14529/28704)\n",
      "Epoch 7 Step 897/1563 Loss: 1.378 | Acc: 50.609% (14543/28736)\n",
      "Epoch 7 Step 898/1563 Loss: 1.378 | Acc: 50.594% (14555/28768)\n",
      "Epoch 7 Step 899/1563 Loss: 1.378 | Acc: 50.601% (14573/28800)\n",
      "Epoch 7 Step 900/1563 Loss: 1.377 | Acc: 50.617% (14594/28832)\n",
      "Epoch 7 Step 901/1563 Loss: 1.378 | Acc: 50.620% (14611/28864)\n",
      "Epoch 7 Step 902/1563 Loss: 1.377 | Acc: 50.630% (14630/28896)\n",
      "Epoch 7 Step 903/1563 Loss: 1.377 | Acc: 50.636% (14648/28928)\n",
      "Epoch 7 Step 904/1563 Loss: 1.377 | Acc: 50.615% (14658/28960)\n",
      "Epoch 7 Step 905/1563 Loss: 1.378 | Acc: 50.600% (14670/28992)\n",
      "Epoch 7 Step 906/1563 Loss: 1.378 | Acc: 50.593% (14684/29024)\n",
      "Epoch 7 Step 907/1563 Loss: 1.378 | Acc: 50.582% (14697/29056)\n",
      "Epoch 7 Step 908/1563 Loss: 1.378 | Acc: 50.581% (14713/29088)\n",
      "Epoch 7 Step 909/1563 Loss: 1.377 | Acc: 50.601% (14735/29120)\n",
      "Epoch 7 Step 910/1563 Loss: 1.377 | Acc: 50.597% (14750/29152)\n",
      "Epoch 7 Step 911/1563 Loss: 1.377 | Acc: 50.606% (14769/29184)\n",
      "Epoch 7 Step 912/1563 Loss: 1.377 | Acc: 50.609% (14786/29216)\n",
      "Epoch 7 Step 913/1563 Loss: 1.377 | Acc: 50.615% (14804/29248)\n",
      "Epoch 7 Step 914/1563 Loss: 1.377 | Acc: 50.611% (14819/29280)\n",
      "Epoch 7 Step 915/1563 Loss: 1.377 | Acc: 50.611% (14835/29312)\n",
      "Epoch 7 Step 916/1563 Loss: 1.377 | Acc: 50.590% (14845/29344)\n",
      "Epoch 7 Step 917/1563 Loss: 1.377 | Acc: 50.589% (14861/29376)\n",
      "Epoch 7 Step 918/1563 Loss: 1.376 | Acc: 50.598% (14880/29408)\n",
      "Epoch 7 Step 919/1563 Loss: 1.376 | Acc: 50.625% (14904/29440)\n",
      "Epoch 7 Step 920/1563 Loss: 1.376 | Acc: 50.624% (14920/29472)\n",
      "Epoch 7 Step 921/1563 Loss: 1.376 | Acc: 50.627% (14937/29504)\n",
      "Epoch 7 Step 922/1563 Loss: 1.376 | Acc: 50.637% (14956/29536)\n",
      "Epoch 7 Step 923/1563 Loss: 1.375 | Acc: 50.653% (14977/29568)\n",
      "Epoch 7 Step 924/1563 Loss: 1.375 | Acc: 50.655% (14994/29600)\n",
      "Epoch 7 Step 925/1563 Loss: 1.375 | Acc: 50.661% (15012/29632)\n",
      "Epoch 7 Step 926/1563 Loss: 1.375 | Acc: 50.654% (15026/29664)\n",
      "Epoch 7 Step 927/1563 Loss: 1.375 | Acc: 50.643% (15039/29696)\n",
      "Epoch 7 Step 928/1563 Loss: 1.375 | Acc: 50.639% (15054/29728)\n",
      "Epoch 7 Step 929/1563 Loss: 1.376 | Acc: 50.635% (15069/29760)\n",
      "Epoch 7 Step 930/1563 Loss: 1.376 | Acc: 50.641% (15087/29792)\n",
      "Epoch 7 Step 931/1563 Loss: 1.375 | Acc: 50.654% (15107/29824)\n",
      "Epoch 7 Step 932/1563 Loss: 1.375 | Acc: 50.646% (15121/29856)\n",
      "Epoch 7 Step 933/1563 Loss: 1.375 | Acc: 50.662% (15142/29888)\n",
      "Epoch 7 Step 934/1563 Loss: 1.375 | Acc: 50.668% (15160/29920)\n",
      "Epoch 7 Step 935/1563 Loss: 1.375 | Acc: 50.661% (15174/29952)\n",
      "Epoch 7 Step 936/1563 Loss: 1.375 | Acc: 50.654% (15188/29984)\n",
      "Epoch 7 Step 937/1563 Loss: 1.375 | Acc: 50.653% (15204/30016)\n",
      "Epoch 7 Step 938/1563 Loss: 1.375 | Acc: 50.659% (15222/30048)\n",
      "Epoch 7 Step 939/1563 Loss: 1.375 | Acc: 50.665% (15240/30080)\n",
      "Epoch 7 Step 940/1563 Loss: 1.376 | Acc: 50.661% (15255/30112)\n",
      "Epoch 7 Step 941/1563 Loss: 1.376 | Acc: 50.660% (15271/30144)\n",
      "Epoch 7 Step 942/1563 Loss: 1.376 | Acc: 50.636% (15280/30176)\n",
      "Epoch 7 Step 943/1563 Loss: 1.376 | Acc: 50.632% (15295/30208)\n",
      "Epoch 7 Step 944/1563 Loss: 1.376 | Acc: 50.628% (15310/30240)\n",
      "Epoch 7 Step 945/1563 Loss: 1.376 | Acc: 50.611% (15321/30272)\n",
      "Epoch 7 Step 946/1563 Loss: 1.376 | Acc: 50.610% (15337/30304)\n",
      "Epoch 7 Step 947/1563 Loss: 1.376 | Acc: 50.610% (15353/30336)\n",
      "Epoch 7 Step 948/1563 Loss: 1.376 | Acc: 50.616% (15371/30368)\n",
      "Epoch 7 Step 949/1563 Loss: 1.377 | Acc: 50.592% (15380/30400)\n",
      "Epoch 7 Step 950/1563 Loss: 1.377 | Acc: 50.585% (15394/30432)\n",
      "Epoch 7 Step 951/1563 Loss: 1.377 | Acc: 50.584% (15410/30464)\n",
      "Epoch 7 Step 952/1563 Loss: 1.377 | Acc: 50.590% (15428/30496)\n",
      "Epoch 7 Step 953/1563 Loss: 1.377 | Acc: 50.586% (15443/30528)\n",
      "Epoch 7 Step 954/1563 Loss: 1.377 | Acc: 50.589% (15460/30560)\n",
      "Epoch 7 Step 955/1563 Loss: 1.377 | Acc: 50.601% (15480/30592)\n",
      "Epoch 7 Step 956/1563 Loss: 1.376 | Acc: 50.611% (15499/30624)\n",
      "Epoch 7 Step 957/1563 Loss: 1.376 | Acc: 50.613% (15516/30656)\n",
      "Epoch 7 Step 958/1563 Loss: 1.376 | Acc: 50.619% (15534/30688)\n",
      "Epoch 7 Step 959/1563 Loss: 1.376 | Acc: 50.632% (15554/30720)\n",
      "Epoch 7 Step 960/1563 Loss: 1.376 | Acc: 50.631% (15570/30752)\n",
      "Epoch 7 Step 961/1563 Loss: 1.376 | Acc: 50.627% (15585/30784)\n",
      "Epoch 7 Step 962/1563 Loss: 1.377 | Acc: 50.600% (15593/30816)\n",
      "Epoch 7 Step 963/1563 Loss: 1.377 | Acc: 50.596% (15608/30848)\n",
      "Epoch 7 Step 964/1563 Loss: 1.377 | Acc: 50.599% (15625/30880)\n",
      "Epoch 7 Step 965/1563 Loss: 1.377 | Acc: 50.592% (15639/30912)\n",
      "Epoch 7 Step 966/1563 Loss: 1.377 | Acc: 50.608% (15660/30944)\n",
      "Epoch 7 Step 967/1563 Loss: 1.377 | Acc: 50.604% (15675/30976)\n",
      "Epoch 7 Step 968/1563 Loss: 1.377 | Acc: 50.610% (15693/31008)\n",
      "Epoch 7 Step 969/1563 Loss: 1.377 | Acc: 50.625% (15714/31040)\n",
      "Epoch 7 Step 970/1563 Loss: 1.377 | Acc: 50.624% (15730/31072)\n",
      "Epoch 7 Step 971/1563 Loss: 1.377 | Acc: 50.624% (15746/31104)\n",
      "Epoch 7 Step 972/1563 Loss: 1.377 | Acc: 50.626% (15763/31136)\n",
      "Epoch 7 Step 973/1563 Loss: 1.376 | Acc: 50.632% (15781/31168)\n",
      "Epoch 7 Step 974/1563 Loss: 1.376 | Acc: 50.647% (15802/31200)\n",
      "Epoch 7 Step 975/1563 Loss: 1.376 | Acc: 50.634% (15814/31232)\n",
      "Epoch 7 Step 976/1563 Loss: 1.377 | Acc: 50.627% (15828/31264)\n",
      "Epoch 7 Step 977/1563 Loss: 1.377 | Acc: 50.623% (15843/31296)\n",
      "Epoch 7 Step 978/1563 Loss: 1.377 | Acc: 50.613% (15856/31328)\n",
      "Epoch 7 Step 979/1563 Loss: 1.377 | Acc: 50.622% (15875/31360)\n",
      "Epoch 7 Step 980/1563 Loss: 1.376 | Acc: 50.621% (15891/31392)\n",
      "Epoch 7 Step 981/1563 Loss: 1.376 | Acc: 50.624% (15908/31424)\n",
      "Epoch 7 Step 982/1563 Loss: 1.376 | Acc: 50.639% (15929/31456)\n",
      "Epoch 7 Step 983/1563 Loss: 1.376 | Acc: 50.638% (15945/31488)\n",
      "Epoch 7 Step 984/1563 Loss: 1.376 | Acc: 50.638% (15961/31520)\n",
      "Epoch 7 Step 985/1563 Loss: 1.376 | Acc: 50.628% (15974/31552)\n",
      "Epoch 7 Step 986/1563 Loss: 1.376 | Acc: 50.630% (15991/31584)\n",
      "Epoch 7 Step 987/1563 Loss: 1.376 | Acc: 50.636% (16009/31616)\n",
      "Epoch 7 Step 988/1563 Loss: 1.376 | Acc: 50.629% (16023/31648)\n",
      "Epoch 7 Step 989/1563 Loss: 1.376 | Acc: 50.638% (16042/31680)\n",
      "Epoch 7 Step 990/1563 Loss: 1.376 | Acc: 50.643% (16060/31712)\n",
      "Epoch 7 Step 991/1563 Loss: 1.376 | Acc: 50.630% (16072/31744)\n",
      "Epoch 7 Step 992/1563 Loss: 1.376 | Acc: 50.633% (16089/31776)\n",
      "Epoch 7 Step 993/1563 Loss: 1.377 | Acc: 50.626% (16103/31808)\n",
      "Epoch 7 Step 994/1563 Loss: 1.377 | Acc: 50.631% (16121/31840)\n",
      "Epoch 7 Step 995/1563 Loss: 1.377 | Acc: 50.640% (16140/31872)\n",
      "Epoch 7 Step 996/1563 Loss: 1.377 | Acc: 50.630% (16153/31904)\n",
      "Epoch 7 Step 997/1563 Loss: 1.377 | Acc: 50.623% (16167/31936)\n",
      "Epoch 7 Step 998/1563 Loss: 1.377 | Acc: 50.626% (16184/31968)\n",
      "Epoch 7 Step 999/1563 Loss: 1.377 | Acc: 50.631% (16202/32000)\n",
      "Epoch 7 Step 1000/1563 Loss: 1.376 | Acc: 50.640% (16221/32032)\n",
      "Epoch 7 Step 1001/1563 Loss: 1.376 | Acc: 50.646% (16239/32064)\n",
      "Epoch 7 Step 1002/1563 Loss: 1.377 | Acc: 50.645% (16255/32096)\n",
      "Epoch 7 Step 1003/1563 Loss: 1.376 | Acc: 50.654% (16274/32128)\n",
      "Epoch 7 Step 1004/1563 Loss: 1.376 | Acc: 50.665% (16294/32160)\n",
      "Epoch 7 Step 1005/1563 Loss: 1.376 | Acc: 50.655% (16307/32192)\n",
      "Epoch 7 Step 1006/1563 Loss: 1.377 | Acc: 50.639% (16318/32224)\n",
      "Epoch 7 Step 1007/1563 Loss: 1.377 | Acc: 50.651% (16338/32256)\n",
      "Epoch 7 Step 1008/1563 Loss: 1.377 | Acc: 50.657% (16356/32288)\n",
      "Epoch 7 Step 1009/1563 Loss: 1.377 | Acc: 50.662% (16374/32320)\n",
      "Epoch 7 Step 1010/1563 Loss: 1.377 | Acc: 50.652% (16387/32352)\n",
      "Epoch 7 Step 1011/1563 Loss: 1.377 | Acc: 50.633% (16397/32384)\n",
      "Epoch 7 Step 1012/1563 Loss: 1.377 | Acc: 50.635% (16414/32416)\n",
      "Epoch 7 Step 1013/1563 Loss: 1.377 | Acc: 50.626% (16427/32448)\n",
      "Epoch 7 Step 1014/1563 Loss: 1.377 | Acc: 50.631% (16445/32480)\n",
      "Epoch 7 Step 1015/1563 Loss: 1.377 | Acc: 50.634% (16462/32512)\n",
      "Epoch 7 Step 1016/1563 Loss: 1.377 | Acc: 50.636% (16479/32544)\n",
      "Epoch 7 Step 1017/1563 Loss: 1.377 | Acc: 50.645% (16498/32576)\n",
      "Epoch 7 Step 1018/1563 Loss: 1.376 | Acc: 50.656% (16518/32608)\n",
      "Epoch 7 Step 1019/1563 Loss: 1.377 | Acc: 50.656% (16534/32640)\n",
      "Epoch 7 Step 1020/1563 Loss: 1.376 | Acc: 50.661% (16552/32672)\n",
      "Epoch 7 Step 1021/1563 Loss: 1.376 | Acc: 50.670% (16571/32704)\n",
      "Epoch 7 Step 1022/1563 Loss: 1.376 | Acc: 50.663% (16585/32736)\n",
      "Epoch 7 Step 1023/1563 Loss: 1.376 | Acc: 50.668% (16603/32768)\n",
      "Epoch 7 Step 1024/1563 Loss: 1.376 | Acc: 50.668% (16619/32800)\n",
      "Epoch 7 Step 1025/1563 Loss: 1.376 | Acc: 50.649% (16629/32832)\n",
      "Epoch 7 Step 1026/1563 Loss: 1.376 | Acc: 50.642% (16643/32864)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 1027/1563 Loss: 1.376 | Acc: 50.638% (16658/32896)\n",
      "Epoch 7 Step 1028/1563 Loss: 1.376 | Acc: 50.638% (16674/32928)\n",
      "Epoch 7 Step 1029/1563 Loss: 1.376 | Acc: 50.637% (16690/32960)\n",
      "Epoch 7 Step 1030/1563 Loss: 1.376 | Acc: 50.646% (16709/32992)\n",
      "Epoch 7 Step 1031/1563 Loss: 1.376 | Acc: 50.648% (16726/33024)\n",
      "Epoch 7 Step 1032/1563 Loss: 1.377 | Acc: 50.623% (16734/33056)\n",
      "Epoch 7 Step 1033/1563 Loss: 1.377 | Acc: 50.632% (16753/33088)\n",
      "Epoch 7 Step 1034/1563 Loss: 1.377 | Acc: 50.631% (16769/33120)\n",
      "Epoch 7 Step 1035/1563 Loss: 1.377 | Acc: 50.630% (16785/33152)\n",
      "Epoch 7 Step 1036/1563 Loss: 1.377 | Acc: 50.624% (16799/33184)\n",
      "Epoch 7 Step 1037/1563 Loss: 1.377 | Acc: 50.629% (16817/33216)\n",
      "Epoch 7 Step 1038/1563 Loss: 1.377 | Acc: 50.626% (16832/33248)\n",
      "Epoch 7 Step 1039/1563 Loss: 1.377 | Acc: 50.625% (16848/33280)\n",
      "Epoch 7 Step 1040/1563 Loss: 1.377 | Acc: 50.615% (16861/33312)\n",
      "Epoch 7 Step 1041/1563 Loss: 1.377 | Acc: 50.609% (16875/33344)\n",
      "Epoch 7 Step 1042/1563 Loss: 1.377 | Acc: 50.599% (16888/33376)\n",
      "Epoch 7 Step 1043/1563 Loss: 1.377 | Acc: 50.599% (16904/33408)\n",
      "Epoch 7 Step 1044/1563 Loss: 1.377 | Acc: 50.580% (16914/33440)\n",
      "Epoch 7 Step 1045/1563 Loss: 1.378 | Acc: 50.559% (16923/33472)\n",
      "Epoch 7 Step 1046/1563 Loss: 1.378 | Acc: 50.552% (16937/33504)\n",
      "Epoch 7 Step 1047/1563 Loss: 1.378 | Acc: 50.549% (16952/33536)\n",
      "Epoch 7 Step 1048/1563 Loss: 1.378 | Acc: 50.542% (16966/33568)\n",
      "Epoch 7 Step 1049/1563 Loss: 1.378 | Acc: 50.545% (16983/33600)\n",
      "Epoch 7 Step 1050/1563 Loss: 1.378 | Acc: 50.547% (17000/33632)\n",
      "Epoch 7 Step 1051/1563 Loss: 1.378 | Acc: 50.538% (17013/33664)\n",
      "Epoch 7 Step 1052/1563 Loss: 1.378 | Acc: 50.537% (17029/33696)\n",
      "Epoch 7 Step 1053/1563 Loss: 1.378 | Acc: 50.534% (17044/33728)\n",
      "Epoch 7 Step 1054/1563 Loss: 1.378 | Acc: 50.536% (17061/33760)\n",
      "Epoch 7 Step 1055/1563 Loss: 1.378 | Acc: 50.536% (17077/33792)\n",
      "Epoch 7 Step 1056/1563 Loss: 1.378 | Acc: 50.535% (17093/33824)\n",
      "Epoch 7 Step 1057/1563 Loss: 1.379 | Acc: 50.520% (17104/33856)\n",
      "Epoch 7 Step 1058/1563 Loss: 1.379 | Acc: 50.519% (17120/33888)\n",
      "Epoch 7 Step 1059/1563 Loss: 1.379 | Acc: 50.528% (17139/33920)\n",
      "Epoch 7 Step 1060/1563 Loss: 1.379 | Acc: 50.527% (17155/33952)\n",
      "Epoch 7 Step 1061/1563 Loss: 1.379 | Acc: 50.536% (17174/33984)\n",
      "Epoch 7 Step 1062/1563 Loss: 1.379 | Acc: 50.538% (17191/34016)\n",
      "Epoch 7 Step 1063/1563 Loss: 1.379 | Acc: 50.540% (17208/34048)\n",
      "Epoch 7 Step 1064/1563 Loss: 1.378 | Acc: 50.549% (17227/34080)\n",
      "Epoch 7 Step 1065/1563 Loss: 1.379 | Acc: 50.542% (17241/34112)\n",
      "Epoch 7 Step 1066/1563 Loss: 1.379 | Acc: 50.539% (17256/34144)\n",
      "Epoch 7 Step 1067/1563 Loss: 1.379 | Acc: 50.541% (17273/34176)\n",
      "Epoch 7 Step 1068/1563 Loss: 1.379 | Acc: 50.541% (17289/34208)\n",
      "Epoch 7 Step 1069/1563 Loss: 1.379 | Acc: 50.546% (17307/34240)\n",
      "Epoch 7 Step 1070/1563 Loss: 1.378 | Acc: 50.546% (17323/34272)\n",
      "Epoch 7 Step 1071/1563 Loss: 1.378 | Acc: 50.557% (17343/34304)\n",
      "Epoch 7 Step 1072/1563 Loss: 1.378 | Acc: 50.550% (17357/34336)\n",
      "Epoch 7 Step 1073/1563 Loss: 1.378 | Acc: 50.541% (17370/34368)\n",
      "Epoch 7 Step 1074/1563 Loss: 1.378 | Acc: 50.549% (17389/34400)\n",
      "Epoch 7 Step 1075/1563 Loss: 1.378 | Acc: 50.561% (17409/34432)\n",
      "Epoch 7 Step 1076/1563 Loss: 1.378 | Acc: 50.575% (17430/34464)\n",
      "Epoch 7 Step 1077/1563 Loss: 1.378 | Acc: 50.571% (17445/34496)\n",
      "Epoch 7 Step 1078/1563 Loss: 1.379 | Acc: 50.562% (17458/34528)\n",
      "Epoch 7 Step 1079/1563 Loss: 1.378 | Acc: 50.576% (17479/34560)\n",
      "Epoch 7 Step 1080/1563 Loss: 1.378 | Acc: 50.572% (17494/34592)\n",
      "Epoch 7 Step 1081/1563 Loss: 1.378 | Acc: 50.572% (17510/34624)\n",
      "Epoch 7 Step 1082/1563 Loss: 1.379 | Acc: 50.560% (17522/34656)\n",
      "Epoch 7 Step 1083/1563 Loss: 1.379 | Acc: 50.548% (17534/34688)\n",
      "Epoch 7 Step 1084/1563 Loss: 1.379 | Acc: 50.550% (17551/34720)\n",
      "Epoch 7 Step 1085/1563 Loss: 1.379 | Acc: 50.555% (17569/34752)\n",
      "Epoch 7 Step 1086/1563 Loss: 1.379 | Acc: 50.552% (17584/34784)\n",
      "Epoch 7 Step 1087/1563 Loss: 1.379 | Acc: 50.543% (17597/34816)\n",
      "Epoch 7 Step 1088/1563 Loss: 1.379 | Acc: 50.537% (17611/34848)\n",
      "Epoch 7 Step 1089/1563 Loss: 1.379 | Acc: 50.539% (17628/34880)\n",
      "Epoch 7 Step 1090/1563 Loss: 1.380 | Acc: 50.524% (17639/34912)\n",
      "Epoch 7 Step 1091/1563 Loss: 1.379 | Acc: 50.535% (17659/34944)\n",
      "Epoch 7 Step 1092/1563 Loss: 1.379 | Acc: 50.540% (17677/34976)\n",
      "Epoch 7 Step 1093/1563 Loss: 1.379 | Acc: 50.543% (17694/35008)\n",
      "Epoch 7 Step 1094/1563 Loss: 1.379 | Acc: 50.548% (17712/35040)\n",
      "Epoch 7 Step 1095/1563 Loss: 1.380 | Acc: 50.539% (17725/35072)\n",
      "Epoch 7 Step 1096/1563 Loss: 1.380 | Acc: 50.547% (17744/35104)\n",
      "Epoch 7 Step 1097/1563 Loss: 1.379 | Acc: 50.555% (17763/35136)\n",
      "Epoch 7 Step 1098/1563 Loss: 1.380 | Acc: 50.549% (17777/35168)\n",
      "Epoch 7 Step 1099/1563 Loss: 1.380 | Acc: 50.548% (17793/35200)\n",
      "Epoch 7 Step 1100/1563 Loss: 1.380 | Acc: 50.539% (17806/35232)\n",
      "Epoch 7 Step 1101/1563 Loss: 1.380 | Acc: 50.536% (17821/35264)\n",
      "Epoch 7 Step 1102/1563 Loss: 1.380 | Acc: 50.544% (17840/35296)\n",
      "Epoch 7 Step 1103/1563 Loss: 1.380 | Acc: 50.538% (17854/35328)\n",
      "Epoch 7 Step 1104/1563 Loss: 1.380 | Acc: 50.546% (17873/35360)\n",
      "Epoch 7 Step 1105/1563 Loss: 1.380 | Acc: 50.551% (17891/35392)\n",
      "Epoch 7 Step 1106/1563 Loss: 1.380 | Acc: 50.565% (17912/35424)\n",
      "Epoch 7 Step 1107/1563 Loss: 1.380 | Acc: 50.556% (17925/35456)\n",
      "Epoch 7 Step 1108/1563 Loss: 1.380 | Acc: 50.564% (17944/35488)\n",
      "Epoch 7 Step 1109/1563 Loss: 1.380 | Acc: 50.560% (17959/35520)\n",
      "Epoch 7 Step 1110/1563 Loss: 1.380 | Acc: 50.563% (17976/35552)\n",
      "Epoch 7 Step 1111/1563 Loss: 1.380 | Acc: 50.554% (17989/35584)\n",
      "Epoch 7 Step 1112/1563 Loss: 1.380 | Acc: 50.564% (18009/35616)\n",
      "Epoch 7 Step 1113/1563 Loss: 1.380 | Acc: 50.567% (18026/35648)\n",
      "Epoch 7 Step 1114/1563 Loss: 1.380 | Acc: 50.561% (18040/35680)\n",
      "Epoch 7 Step 1115/1563 Loss: 1.380 | Acc: 50.563% (18057/35712)\n",
      "Epoch 7 Step 1116/1563 Loss: 1.380 | Acc: 50.562% (18073/35744)\n",
      "Epoch 7 Step 1117/1563 Loss: 1.380 | Acc: 50.556% (18087/35776)\n",
      "Epoch 7 Step 1118/1563 Loss: 1.380 | Acc: 50.564% (18106/35808)\n",
      "Epoch 7 Step 1119/1563 Loss: 1.380 | Acc: 50.566% (18123/35840)\n",
      "Epoch 7 Step 1120/1563 Loss: 1.380 | Acc: 50.563% (18138/35872)\n",
      "Epoch 7 Step 1121/1563 Loss: 1.380 | Acc: 50.571% (18157/35904)\n",
      "Epoch 7 Step 1122/1563 Loss: 1.380 | Acc: 50.557% (18168/35936)\n",
      "Epoch 7 Step 1123/1563 Loss: 1.380 | Acc: 50.559% (18185/35968)\n",
      "Epoch 7 Step 1124/1563 Loss: 1.381 | Acc: 50.550% (18198/36000)\n",
      "Epoch 7 Step 1125/1563 Loss: 1.381 | Acc: 50.541% (18211/36032)\n",
      "Epoch 7 Step 1126/1563 Loss: 1.381 | Acc: 50.546% (18229/36064)\n",
      "Epoch 7 Step 1127/1563 Loss: 1.381 | Acc: 50.537% (18242/36096)\n",
      "Epoch 7 Step 1128/1563 Loss: 1.381 | Acc: 50.531% (18256/36128)\n",
      "Epoch 7 Step 1129/1563 Loss: 1.381 | Acc: 50.534% (18273/36160)\n",
      "Epoch 7 Step 1130/1563 Loss: 1.381 | Acc: 50.536% (18290/36192)\n",
      "Epoch 7 Step 1131/1563 Loss: 1.380 | Acc: 50.538% (18307/36224)\n",
      "Epoch 7 Step 1132/1563 Loss: 1.380 | Acc: 50.535% (18322/36256)\n",
      "Epoch 7 Step 1133/1563 Loss: 1.380 | Acc: 50.532% (18337/36288)\n",
      "Epoch 7 Step 1134/1563 Loss: 1.381 | Acc: 50.529% (18352/36320)\n",
      "Epoch 7 Step 1135/1563 Loss: 1.381 | Acc: 50.531% (18369/36352)\n",
      "Epoch 7 Step 1136/1563 Loss: 1.381 | Acc: 50.539% (18388/36384)\n",
      "Epoch 7 Step 1137/1563 Loss: 1.380 | Acc: 50.538% (18404/36416)\n",
      "Epoch 7 Step 1138/1563 Loss: 1.380 | Acc: 50.535% (18419/36448)\n",
      "Epoch 7 Step 1139/1563 Loss: 1.380 | Acc: 50.548% (18440/36480)\n",
      "Epoch 7 Step 1140/1563 Loss: 1.380 | Acc: 50.540% (18453/36512)\n",
      "Epoch 7 Step 1141/1563 Loss: 1.380 | Acc: 50.542% (18470/36544)\n",
      "Epoch 7 Step 1142/1563 Loss: 1.380 | Acc: 50.539% (18485/36576)\n",
      "Epoch 7 Step 1143/1563 Loss: 1.380 | Acc: 50.535% (18500/36608)\n",
      "Epoch 7 Step 1144/1563 Loss: 1.380 | Acc: 50.529% (18514/36640)\n",
      "Epoch 7 Step 1145/1563 Loss: 1.380 | Acc: 50.534% (18532/36672)\n",
      "Epoch 7 Step 1146/1563 Loss: 1.380 | Acc: 50.531% (18547/36704)\n",
      "Epoch 7 Step 1147/1563 Loss: 1.381 | Acc: 50.528% (18562/36736)\n",
      "Epoch 7 Step 1148/1563 Loss: 1.381 | Acc: 50.533% (18580/36768)\n",
      "Epoch 7 Step 1149/1563 Loss: 1.381 | Acc: 50.530% (18595/36800)\n",
      "Epoch 7 Step 1150/1563 Loss: 1.380 | Acc: 50.546% (18617/36832)\n",
      "Epoch 7 Step 1151/1563 Loss: 1.380 | Acc: 50.543% (18632/36864)\n",
      "Epoch 7 Step 1152/1563 Loss: 1.380 | Acc: 50.545% (18649/36896)\n",
      "Epoch 7 Step 1153/1563 Loss: 1.380 | Acc: 50.555% (18669/36928)\n",
      "Epoch 7 Step 1154/1563 Loss: 1.380 | Acc: 50.560% (18687/36960)\n",
      "Epoch 7 Step 1155/1563 Loss: 1.380 | Acc: 50.565% (18705/36992)\n",
      "Epoch 7 Step 1156/1563 Loss: 1.380 | Acc: 50.570% (18723/37024)\n",
      "Epoch 7 Step 1157/1563 Loss: 1.380 | Acc: 50.564% (18737/37056)\n",
      "Epoch 7 Step 1158/1563 Loss: 1.380 | Acc: 50.553% (18749/37088)\n",
      "Epoch 7 Step 1159/1563 Loss: 1.380 | Acc: 50.563% (18769/37120)\n",
      "Epoch 7 Step 1160/1563 Loss: 1.380 | Acc: 50.568% (18787/37152)\n",
      "Epoch 7 Step 1161/1563 Loss: 1.380 | Acc: 50.562% (18801/37184)\n",
      "Epoch 7 Step 1162/1563 Loss: 1.381 | Acc: 50.548% (18812/37216)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 1163/1563 Loss: 1.381 | Acc: 50.548% (18828/37248)\n",
      "Epoch 7 Step 1164/1563 Loss: 1.381 | Acc: 50.545% (18843/37280)\n",
      "Epoch 7 Step 1165/1563 Loss: 1.381 | Acc: 50.547% (18860/37312)\n",
      "Epoch 7 Step 1166/1563 Loss: 1.381 | Acc: 50.536% (18872/37344)\n",
      "Epoch 7 Step 1167/1563 Loss: 1.381 | Acc: 50.535% (18888/37376)\n",
      "Epoch 7 Step 1168/1563 Loss: 1.381 | Acc: 50.540% (18906/37408)\n",
      "Epoch 7 Step 1169/1563 Loss: 1.381 | Acc: 50.553% (18927/37440)\n",
      "Epoch 7 Step 1170/1563 Loss: 1.381 | Acc: 50.550% (18942/37472)\n",
      "Epoch 7 Step 1171/1563 Loss: 1.381 | Acc: 50.549% (18958/37504)\n",
      "Epoch 7 Step 1172/1563 Loss: 1.380 | Acc: 50.554% (18976/37536)\n",
      "Epoch 7 Step 1173/1563 Loss: 1.380 | Acc: 50.562% (18995/37568)\n",
      "Epoch 7 Step 1174/1563 Loss: 1.380 | Acc: 50.577% (19017/37600)\n",
      "Epoch 7 Step 1175/1563 Loss: 1.380 | Acc: 50.574% (19032/37632)\n",
      "Epoch 7 Step 1176/1563 Loss: 1.380 | Acc: 50.576% (19049/37664)\n",
      "Epoch 7 Step 1177/1563 Loss: 1.380 | Acc: 50.568% (19062/37696)\n",
      "Epoch 7 Step 1178/1563 Loss: 1.380 | Acc: 50.570% (19079/37728)\n",
      "Epoch 7 Step 1179/1563 Loss: 1.380 | Acc: 50.588% (19102/37760)\n",
      "Epoch 7 Step 1180/1563 Loss: 1.380 | Acc: 50.590% (19119/37792)\n",
      "Epoch 7 Step 1181/1563 Loss: 1.380 | Acc: 50.576% (19130/37824)\n",
      "Epoch 7 Step 1182/1563 Loss: 1.380 | Acc: 50.560% (19140/37856)\n",
      "Epoch 7 Step 1183/1563 Loss: 1.380 | Acc: 50.570% (19160/37888)\n",
      "Epoch 7 Step 1184/1563 Loss: 1.380 | Acc: 50.570% (19176/37920)\n",
      "Epoch 7 Step 1185/1563 Loss: 1.380 | Acc: 50.572% (19193/37952)\n",
      "Epoch 7 Step 1186/1563 Loss: 1.380 | Acc: 50.561% (19205/37984)\n",
      "Epoch 7 Step 1187/1563 Loss: 1.380 | Acc: 50.563% (19222/38016)\n",
      "Epoch 7 Step 1188/1563 Loss: 1.380 | Acc: 50.570% (19241/38048)\n",
      "Epoch 7 Step 1189/1563 Loss: 1.379 | Acc: 50.575% (19259/38080)\n",
      "Epoch 7 Step 1190/1563 Loss: 1.379 | Acc: 50.577% (19276/38112)\n",
      "Epoch 7 Step 1191/1563 Loss: 1.380 | Acc: 50.566% (19288/38144)\n",
      "Epoch 7 Step 1192/1563 Loss: 1.380 | Acc: 50.568% (19305/38176)\n",
      "Epoch 7 Step 1193/1563 Loss: 1.380 | Acc: 50.563% (19319/38208)\n",
      "Epoch 7 Step 1194/1563 Loss: 1.380 | Acc: 50.575% (19340/38240)\n",
      "Epoch 7 Step 1195/1563 Loss: 1.380 | Acc: 50.572% (19355/38272)\n",
      "Epoch 7 Step 1196/1563 Loss: 1.380 | Acc: 50.564% (19368/38304)\n",
      "Epoch 7 Step 1197/1563 Loss: 1.380 | Acc: 50.556% (19381/38336)\n",
      "Epoch 7 Step 1198/1563 Loss: 1.380 | Acc: 50.553% (19396/38368)\n",
      "Epoch 7 Step 1199/1563 Loss: 1.380 | Acc: 50.557% (19414/38400)\n",
      "Epoch 7 Step 1200/1563 Loss: 1.380 | Acc: 50.562% (19432/38432)\n",
      "Epoch 7 Step 1201/1563 Loss: 1.380 | Acc: 50.564% (19449/38464)\n",
      "Epoch 7 Step 1202/1563 Loss: 1.380 | Acc: 50.571% (19468/38496)\n",
      "Epoch 7 Step 1203/1563 Loss: 1.380 | Acc: 50.576% (19486/38528)\n",
      "Epoch 7 Step 1204/1563 Loss: 1.380 | Acc: 50.586% (19506/38560)\n",
      "Epoch 7 Step 1205/1563 Loss: 1.380 | Acc: 50.580% (19520/38592)\n",
      "Epoch 7 Step 1206/1563 Loss: 1.380 | Acc: 50.583% (19537/38624)\n",
      "Epoch 7 Step 1207/1563 Loss: 1.380 | Acc: 50.587% (19555/38656)\n",
      "Epoch 7 Step 1208/1563 Loss: 1.379 | Acc: 50.592% (19573/38688)\n",
      "Epoch 7 Step 1209/1563 Loss: 1.380 | Acc: 50.589% (19588/38720)\n",
      "Epoch 7 Step 1210/1563 Loss: 1.380 | Acc: 50.583% (19602/38752)\n",
      "Epoch 7 Step 1211/1563 Loss: 1.379 | Acc: 50.585% (19619/38784)\n",
      "Epoch 7 Step 1212/1563 Loss: 1.380 | Acc: 50.577% (19632/38816)\n",
      "Epoch 7 Step 1213/1563 Loss: 1.380 | Acc: 50.574% (19647/38848)\n",
      "Epoch 7 Step 1214/1563 Loss: 1.379 | Acc: 50.589% (19669/38880)\n",
      "Epoch 7 Step 1215/1563 Loss: 1.379 | Acc: 50.589% (19685/38912)\n",
      "Epoch 7 Step 1216/1563 Loss: 1.379 | Acc: 50.591% (19702/38944)\n",
      "Epoch 7 Step 1217/1563 Loss: 1.379 | Acc: 50.585% (19716/38976)\n",
      "Epoch 7 Step 1218/1563 Loss: 1.379 | Acc: 50.587% (19733/39008)\n",
      "Epoch 7 Step 1219/1563 Loss: 1.379 | Acc: 50.594% (19752/39040)\n",
      "Epoch 7 Step 1220/1563 Loss: 1.379 | Acc: 50.596% (19769/39072)\n",
      "Epoch 7 Step 1221/1563 Loss: 1.379 | Acc: 50.614% (19792/39104)\n",
      "Epoch 7 Step 1222/1563 Loss: 1.379 | Acc: 50.611% (19807/39136)\n",
      "Epoch 7 Step 1223/1563 Loss: 1.379 | Acc: 50.615% (19825/39168)\n",
      "Epoch 7 Step 1224/1563 Loss: 1.378 | Acc: 50.612% (19840/39200)\n",
      "Epoch 7 Step 1225/1563 Loss: 1.379 | Acc: 50.604% (19853/39232)\n",
      "Epoch 7 Step 1226/1563 Loss: 1.379 | Acc: 50.606% (19870/39264)\n",
      "Epoch 7 Step 1227/1563 Loss: 1.379 | Acc: 50.601% (19884/39296)\n",
      "Epoch 7 Step 1228/1563 Loss: 1.379 | Acc: 50.608% (19903/39328)\n",
      "Epoch 7 Step 1229/1563 Loss: 1.379 | Acc: 50.607% (19919/39360)\n",
      "Epoch 7 Step 1230/1563 Loss: 1.378 | Acc: 50.612% (19937/39392)\n",
      "Epoch 7 Step 1231/1563 Loss: 1.379 | Acc: 50.601% (19949/39424)\n",
      "Epoch 7 Step 1232/1563 Loss: 1.379 | Acc: 50.588% (19960/39456)\n",
      "Epoch 7 Step 1233/1563 Loss: 1.379 | Acc: 50.582% (19974/39488)\n",
      "Epoch 7 Step 1234/1563 Loss: 1.379 | Acc: 50.585% (19991/39520)\n",
      "Epoch 7 Step 1235/1563 Loss: 1.379 | Acc: 50.576% (20004/39552)\n",
      "Epoch 7 Step 1236/1563 Loss: 1.379 | Acc: 50.573% (20019/39584)\n",
      "Epoch 7 Step 1237/1563 Loss: 1.379 | Acc: 50.563% (20031/39616)\n",
      "Epoch 7 Step 1238/1563 Loss: 1.379 | Acc: 50.565% (20048/39648)\n",
      "Epoch 7 Step 1239/1563 Loss: 1.379 | Acc: 50.565% (20064/39680)\n",
      "Epoch 7 Step 1240/1563 Loss: 1.379 | Acc: 50.569% (20082/39712)\n",
      "Epoch 7 Step 1241/1563 Loss: 1.378 | Acc: 50.571% (20099/39744)\n",
      "Epoch 7 Step 1242/1563 Loss: 1.378 | Acc: 50.561% (20111/39776)\n",
      "Epoch 7 Step 1243/1563 Loss: 1.378 | Acc: 50.565% (20129/39808)\n",
      "Epoch 7 Step 1244/1563 Loss: 1.378 | Acc: 50.570% (20147/39840)\n",
      "Epoch 7 Step 1245/1563 Loss: 1.378 | Acc: 50.577% (20166/39872)\n",
      "Epoch 7 Step 1246/1563 Loss: 1.378 | Acc: 50.576% (20182/39904)\n",
      "Epoch 7 Step 1247/1563 Loss: 1.378 | Acc: 50.596% (20206/39936)\n",
      "Epoch 7 Step 1248/1563 Loss: 1.378 | Acc: 50.590% (20220/39968)\n",
      "Epoch 7 Step 1249/1563 Loss: 1.378 | Acc: 50.587% (20235/40000)\n",
      "Epoch 7 Step 1250/1563 Loss: 1.378 | Acc: 50.582% (20249/40032)\n",
      "Epoch 7 Step 1251/1563 Loss: 1.378 | Acc: 50.587% (20267/40064)\n",
      "Epoch 7 Step 1252/1563 Loss: 1.378 | Acc: 50.581% (20281/40096)\n",
      "Epoch 7 Step 1253/1563 Loss: 1.378 | Acc: 50.576% (20295/40128)\n",
      "Epoch 7 Step 1254/1563 Loss: 1.378 | Acc: 50.568% (20308/40160)\n",
      "Epoch 7 Step 1255/1563 Loss: 1.378 | Acc: 50.560% (20321/40192)\n",
      "Epoch 7 Step 1256/1563 Loss: 1.378 | Acc: 50.574% (20343/40224)\n",
      "Epoch 7 Step 1257/1563 Loss: 1.378 | Acc: 50.561% (20354/40256)\n",
      "Epoch 7 Step 1258/1563 Loss: 1.379 | Acc: 50.549% (20365/40288)\n",
      "Epoch 7 Step 1259/1563 Loss: 1.379 | Acc: 50.543% (20379/40320)\n",
      "Epoch 7 Step 1260/1563 Loss: 1.379 | Acc: 50.545% (20396/40352)\n",
      "Epoch 7 Step 1261/1563 Loss: 1.379 | Acc: 50.545% (20412/40384)\n",
      "Epoch 7 Step 1262/1563 Loss: 1.379 | Acc: 50.534% (20424/40416)\n",
      "Epoch 7 Step 1263/1563 Loss: 1.379 | Acc: 50.546% (20445/40448)\n",
      "Epoch 7 Step 1264/1563 Loss: 1.379 | Acc: 50.541% (20459/40480)\n",
      "Epoch 7 Step 1265/1563 Loss: 1.379 | Acc: 50.538% (20474/40512)\n",
      "Epoch 7 Step 1266/1563 Loss: 1.379 | Acc: 50.533% (20488/40544)\n",
      "Epoch 7 Step 1267/1563 Loss: 1.379 | Acc: 50.527% (20502/40576)\n",
      "Epoch 7 Step 1268/1563 Loss: 1.379 | Acc: 50.529% (20519/40608)\n",
      "Epoch 7 Step 1269/1563 Loss: 1.379 | Acc: 50.519% (20531/40640)\n",
      "Epoch 7 Step 1270/1563 Loss: 1.379 | Acc: 50.524% (20549/40672)\n",
      "Epoch 7 Step 1271/1563 Loss: 1.379 | Acc: 50.533% (20569/40704)\n",
      "Epoch 7 Step 1272/1563 Loss: 1.379 | Acc: 50.525% (20582/40736)\n",
      "Epoch 7 Step 1273/1563 Loss: 1.380 | Acc: 50.518% (20595/40768)\n",
      "Epoch 7 Step 1274/1563 Loss: 1.380 | Acc: 50.522% (20613/40800)\n",
      "Epoch 7 Step 1275/1563 Loss: 1.380 | Acc: 50.512% (20625/40832)\n",
      "Epoch 7 Step 1276/1563 Loss: 1.380 | Acc: 50.509% (20640/40864)\n",
      "Epoch 7 Step 1277/1563 Loss: 1.380 | Acc: 50.511% (20657/40896)\n",
      "Epoch 7 Step 1278/1563 Loss: 1.380 | Acc: 50.503% (20670/40928)\n",
      "Epoch 7 Step 1279/1563 Loss: 1.380 | Acc: 50.508% (20688/40960)\n",
      "Epoch 7 Step 1280/1563 Loss: 1.380 | Acc: 50.507% (20704/40992)\n",
      "Epoch 7 Step 1281/1563 Loss: 1.380 | Acc: 50.492% (20714/41024)\n",
      "Epoch 7 Step 1282/1563 Loss: 1.380 | Acc: 50.494% (20731/41056)\n",
      "Epoch 7 Step 1283/1563 Loss: 1.380 | Acc: 50.489% (20745/41088)\n",
      "Epoch 7 Step 1284/1563 Loss: 1.380 | Acc: 50.494% (20763/41120)\n",
      "Epoch 7 Step 1285/1563 Loss: 1.380 | Acc: 50.498% (20781/41152)\n",
      "Epoch 7 Step 1286/1563 Loss: 1.380 | Acc: 50.498% (20797/41184)\n",
      "Epoch 7 Step 1287/1563 Loss: 1.380 | Acc: 50.500% (20814/41216)\n",
      "Epoch 7 Step 1288/1563 Loss: 1.380 | Acc: 50.485% (20824/41248)\n",
      "Epoch 7 Step 1289/1563 Loss: 1.380 | Acc: 50.482% (20839/41280)\n",
      "Epoch 7 Step 1290/1563 Loss: 1.380 | Acc: 50.477% (20853/41312)\n",
      "Epoch 7 Step 1291/1563 Loss: 1.381 | Acc: 50.474% (20868/41344)\n",
      "Epoch 7 Step 1292/1563 Loss: 1.381 | Acc: 50.474% (20884/41376)\n",
      "Epoch 7 Step 1293/1563 Loss: 1.381 | Acc: 50.481% (20903/41408)\n",
      "Epoch 7 Step 1294/1563 Loss: 1.381 | Acc: 50.483% (20920/41440)\n",
      "Epoch 7 Step 1295/1563 Loss: 1.381 | Acc: 50.477% (20934/41472)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 1296/1563 Loss: 1.381 | Acc: 50.477% (20950/41504)\n",
      "Epoch 7 Step 1297/1563 Loss: 1.381 | Acc: 50.482% (20968/41536)\n",
      "Epoch 7 Step 1298/1563 Loss: 1.381 | Acc: 50.481% (20984/41568)\n",
      "Epoch 7 Step 1299/1563 Loss: 1.381 | Acc: 50.474% (20997/41600)\n",
      "Epoch 7 Step 1300/1563 Loss: 1.381 | Acc: 50.490% (21020/41632)\n",
      "Epoch 7 Step 1301/1563 Loss: 1.380 | Acc: 50.487% (21035/41664)\n",
      "Epoch 7 Step 1302/1563 Loss: 1.380 | Acc: 50.504% (21058/41696)\n",
      "Epoch 7 Step 1303/1563 Loss: 1.380 | Acc: 50.506% (21075/41728)\n",
      "Epoch 7 Step 1304/1563 Loss: 1.380 | Acc: 50.498% (21088/41760)\n",
      "Epoch 7 Step 1305/1563 Loss: 1.380 | Acc: 50.500% (21105/41792)\n",
      "Epoch 7 Step 1306/1563 Loss: 1.380 | Acc: 50.502% (21122/41824)\n",
      "Epoch 7 Step 1307/1563 Loss: 1.380 | Acc: 50.502% (21138/41856)\n",
      "Epoch 7 Step 1308/1563 Loss: 1.380 | Acc: 50.497% (21152/41888)\n",
      "Epoch 7 Step 1309/1563 Loss: 1.381 | Acc: 50.487% (21164/41920)\n",
      "Epoch 7 Step 1310/1563 Loss: 1.381 | Acc: 50.479% (21177/41952)\n",
      "Epoch 7 Step 1311/1563 Loss: 1.381 | Acc: 50.484% (21195/41984)\n",
      "Epoch 7 Step 1312/1563 Loss: 1.381 | Acc: 50.490% (21214/42016)\n",
      "Epoch 7 Step 1313/1563 Loss: 1.381 | Acc: 50.497% (21233/42048)\n",
      "Epoch 7 Step 1314/1563 Loss: 1.381 | Acc: 50.494% (21248/42080)\n",
      "Epoch 7 Step 1315/1563 Loss: 1.381 | Acc: 50.487% (21261/42112)\n",
      "Epoch 7 Step 1316/1563 Loss: 1.381 | Acc: 50.484% (21276/42144)\n",
      "Epoch 7 Step 1317/1563 Loss: 1.381 | Acc: 50.498% (21298/42176)\n",
      "Epoch 7 Step 1318/1563 Loss: 1.381 | Acc: 50.495% (21313/42208)\n",
      "Epoch 7 Step 1319/1563 Loss: 1.380 | Acc: 50.509% (21335/42240)\n",
      "Epoch 7 Step 1320/1563 Loss: 1.380 | Acc: 50.511% (21352/42272)\n",
      "Epoch 7 Step 1321/1563 Loss: 1.380 | Acc: 50.518% (21371/42304)\n",
      "Epoch 7 Step 1322/1563 Loss: 1.380 | Acc: 50.510% (21384/42336)\n",
      "Epoch 7 Step 1323/1563 Loss: 1.381 | Acc: 50.503% (21397/42368)\n",
      "Epoch 7 Step 1324/1563 Loss: 1.380 | Acc: 50.509% (21416/42400)\n",
      "Epoch 7 Step 1325/1563 Loss: 1.381 | Acc: 50.509% (21432/42432)\n",
      "Epoch 7 Step 1326/1563 Loss: 1.381 | Acc: 50.504% (21446/42464)\n",
      "Epoch 7 Step 1327/1563 Loss: 1.381 | Acc: 50.508% (21464/42496)\n",
      "Epoch 7 Step 1328/1563 Loss: 1.381 | Acc: 50.501% (21477/42528)\n",
      "Epoch 7 Step 1329/1563 Loss: 1.381 | Acc: 50.505% (21495/42560)\n",
      "Epoch 7 Step 1330/1563 Loss: 1.381 | Acc: 50.517% (21516/42592)\n",
      "Epoch 7 Step 1331/1563 Loss: 1.380 | Acc: 50.526% (21536/42624)\n",
      "Epoch 7 Step 1332/1563 Loss: 1.380 | Acc: 50.520% (21550/42656)\n",
      "Epoch 7 Step 1333/1563 Loss: 1.380 | Acc: 50.520% (21566/42688)\n",
      "Epoch 7 Step 1334/1563 Loss: 1.380 | Acc: 50.517% (21581/42720)\n",
      "Epoch 7 Step 1335/1563 Loss: 1.381 | Acc: 50.510% (21594/42752)\n",
      "Epoch 7 Step 1336/1563 Loss: 1.381 | Acc: 50.517% (21613/42784)\n",
      "Epoch 7 Step 1337/1563 Loss: 1.380 | Acc: 50.516% (21629/42816)\n",
      "Epoch 7 Step 1338/1563 Loss: 1.380 | Acc: 50.520% (21647/42848)\n",
      "Epoch 7 Step 1339/1563 Loss: 1.381 | Acc: 50.513% (21660/42880)\n",
      "Epoch 7 Step 1340/1563 Loss: 1.381 | Acc: 50.522% (21680/42912)\n",
      "Epoch 7 Step 1341/1563 Loss: 1.381 | Acc: 50.512% (21692/42944)\n",
      "Epoch 7 Step 1342/1563 Loss: 1.381 | Acc: 50.517% (21710/42976)\n",
      "Epoch 7 Step 1343/1563 Loss: 1.381 | Acc: 50.516% (21726/43008)\n",
      "Epoch 7 Step 1344/1563 Loss: 1.381 | Acc: 50.523% (21745/43040)\n",
      "Epoch 7 Step 1345/1563 Loss: 1.381 | Acc: 50.522% (21761/43072)\n",
      "Epoch 7 Step 1346/1563 Loss: 1.381 | Acc: 50.531% (21781/43104)\n",
      "Epoch 7 Step 1347/1563 Loss: 1.381 | Acc: 50.515% (21790/43136)\n",
      "Epoch 7 Step 1348/1563 Loss: 1.381 | Acc: 50.512% (21805/43168)\n",
      "Epoch 7 Step 1349/1563 Loss: 1.381 | Acc: 50.521% (21825/43200)\n",
      "Epoch 7 Step 1350/1563 Loss: 1.381 | Acc: 50.537% (21848/43232)\n",
      "Epoch 7 Step 1351/1563 Loss: 1.381 | Acc: 50.545% (21868/43264)\n",
      "Epoch 7 Step 1352/1563 Loss: 1.381 | Acc: 50.534% (21879/43296)\n",
      "Epoch 7 Step 1353/1563 Loss: 1.380 | Acc: 50.549% (21902/43328)\n",
      "Epoch 7 Step 1354/1563 Loss: 1.380 | Acc: 50.547% (21917/43360)\n",
      "Epoch 7 Step 1355/1563 Loss: 1.380 | Acc: 50.548% (21934/43392)\n",
      "Epoch 7 Step 1356/1563 Loss: 1.380 | Acc: 50.555% (21953/43424)\n",
      "Epoch 7 Step 1357/1563 Loss: 1.380 | Acc: 50.555% (21969/43456)\n",
      "Epoch 7 Step 1358/1563 Loss: 1.380 | Acc: 50.547% (21982/43488)\n",
      "Epoch 7 Step 1359/1563 Loss: 1.380 | Acc: 50.547% (21998/43520)\n",
      "Epoch 7 Step 1360/1563 Loss: 1.380 | Acc: 50.542% (22012/43552)\n",
      "Epoch 7 Step 1361/1563 Loss: 1.381 | Acc: 50.546% (22030/43584)\n",
      "Epoch 7 Step 1362/1563 Loss: 1.381 | Acc: 50.541% (22044/43616)\n",
      "Epoch 7 Step 1363/1563 Loss: 1.381 | Acc: 50.534% (22057/43648)\n",
      "Epoch 7 Step 1364/1563 Loss: 1.381 | Acc: 50.529% (22071/43680)\n",
      "Epoch 7 Step 1365/1563 Loss: 1.381 | Acc: 50.533% (22089/43712)\n",
      "Epoch 7 Step 1366/1563 Loss: 1.381 | Acc: 50.540% (22108/43744)\n",
      "Epoch 7 Step 1367/1563 Loss: 1.381 | Acc: 50.539% (22124/43776)\n",
      "Epoch 7 Step 1368/1563 Loss: 1.381 | Acc: 50.541% (22141/43808)\n",
      "Epoch 7 Step 1369/1563 Loss: 1.381 | Acc: 50.538% (22156/43840)\n",
      "Epoch 7 Step 1370/1563 Loss: 1.381 | Acc: 50.540% (22173/43872)\n",
      "Epoch 7 Step 1371/1563 Loss: 1.380 | Acc: 50.544% (22191/43904)\n",
      "Epoch 7 Step 1372/1563 Loss: 1.380 | Acc: 50.549% (22209/43936)\n",
      "Epoch 7 Step 1373/1563 Loss: 1.381 | Acc: 50.541% (22222/43968)\n",
      "Epoch 7 Step 1374/1563 Loss: 1.381 | Acc: 50.539% (22237/44000)\n",
      "Epoch 7 Step 1375/1563 Loss: 1.381 | Acc: 50.527% (22248/44032)\n",
      "Epoch 7 Step 1376/1563 Loss: 1.381 | Acc: 50.522% (22262/44064)\n",
      "Epoch 7 Step 1377/1563 Loss: 1.381 | Acc: 50.528% (22281/44096)\n",
      "Epoch 7 Step 1378/1563 Loss: 1.381 | Acc: 50.533% (22299/44128)\n",
      "Epoch 7 Step 1379/1563 Loss: 1.381 | Acc: 50.528% (22313/44160)\n",
      "Epoch 7 Step 1380/1563 Loss: 1.381 | Acc: 50.530% (22330/44192)\n",
      "Epoch 7 Step 1381/1563 Loss: 1.381 | Acc: 50.525% (22344/44224)\n",
      "Epoch 7 Step 1382/1563 Loss: 1.381 | Acc: 50.522% (22359/44256)\n",
      "Epoch 7 Step 1383/1563 Loss: 1.381 | Acc: 50.515% (22372/44288)\n",
      "Epoch 7 Step 1384/1563 Loss: 1.381 | Acc: 50.519% (22390/44320)\n",
      "Epoch 7 Step 1385/1563 Loss: 1.381 | Acc: 50.516% (22405/44352)\n",
      "Epoch 7 Step 1386/1563 Loss: 1.381 | Acc: 50.514% (22420/44384)\n",
      "Epoch 7 Step 1387/1563 Loss: 1.381 | Acc: 50.516% (22437/44416)\n",
      "Epoch 7 Step 1388/1563 Loss: 1.381 | Acc: 50.511% (22451/44448)\n",
      "Epoch 7 Step 1389/1563 Loss: 1.381 | Acc: 50.508% (22466/44480)\n",
      "Epoch 7 Step 1390/1563 Loss: 1.382 | Acc: 50.503% (22480/44512)\n",
      "Epoch 7 Step 1391/1563 Loss: 1.382 | Acc: 50.498% (22494/44544)\n",
      "Epoch 7 Step 1392/1563 Loss: 1.382 | Acc: 50.494% (22508/44576)\n",
      "Epoch 7 Step 1393/1563 Loss: 1.381 | Acc: 50.507% (22530/44608)\n",
      "Epoch 7 Step 1394/1563 Loss: 1.381 | Acc: 50.513% (22549/44640)\n",
      "Epoch 7 Step 1395/1563 Loss: 1.381 | Acc: 50.506% (22562/44672)\n",
      "Epoch 7 Step 1396/1563 Loss: 1.381 | Acc: 50.501% (22576/44704)\n",
      "Epoch 7 Step 1397/1563 Loss: 1.381 | Acc: 50.510% (22596/44736)\n",
      "Epoch 7 Step 1398/1563 Loss: 1.382 | Acc: 50.498% (22607/44768)\n",
      "Epoch 7 Step 1399/1563 Loss: 1.382 | Acc: 50.500% (22624/44800)\n",
      "Epoch 7 Step 1400/1563 Loss: 1.382 | Acc: 50.504% (22642/44832)\n",
      "Epoch 7 Step 1401/1563 Loss: 1.382 | Acc: 50.497% (22655/44864)\n",
      "Epoch 7 Step 1402/1563 Loss: 1.381 | Acc: 50.508% (22676/44896)\n",
      "Epoch 7 Step 1403/1563 Loss: 1.381 | Acc: 50.514% (22695/44928)\n",
      "Epoch 7 Step 1404/1563 Loss: 1.381 | Acc: 50.516% (22712/44960)\n",
      "Epoch 7 Step 1405/1563 Loss: 1.381 | Acc: 50.525% (22732/44992)\n",
      "Epoch 7 Step 1406/1563 Loss: 1.381 | Acc: 50.513% (22743/45024)\n",
      "Epoch 7 Step 1407/1563 Loss: 1.381 | Acc: 50.519% (22762/45056)\n",
      "Epoch 7 Step 1408/1563 Loss: 1.381 | Acc: 50.517% (22777/45088)\n",
      "Epoch 7 Step 1409/1563 Loss: 1.381 | Acc: 50.516% (22793/45120)\n",
      "Epoch 7 Step 1410/1563 Loss: 1.381 | Acc: 50.518% (22810/45152)\n",
      "Epoch 7 Step 1411/1563 Loss: 1.381 | Acc: 50.518% (22826/45184)\n",
      "Epoch 7 Step 1412/1563 Loss: 1.381 | Acc: 50.511% (22839/45216)\n",
      "Epoch 7 Step 1413/1563 Loss: 1.381 | Acc: 50.511% (22855/45248)\n",
      "Epoch 7 Step 1414/1563 Loss: 1.381 | Acc: 50.515% (22873/45280)\n",
      "Epoch 7 Step 1415/1563 Loss: 1.381 | Acc: 50.510% (22887/45312)\n",
      "Epoch 7 Step 1416/1563 Loss: 1.381 | Acc: 50.514% (22905/45344)\n",
      "Epoch 7 Step 1417/1563 Loss: 1.381 | Acc: 50.511% (22920/45376)\n",
      "Epoch 7 Step 1418/1563 Loss: 1.381 | Acc: 50.511% (22936/45408)\n",
      "Epoch 7 Step 1419/1563 Loss: 1.381 | Acc: 50.506% (22950/45440)\n",
      "Epoch 7 Step 1420/1563 Loss: 1.381 | Acc: 50.517% (22971/45472)\n",
      "Epoch 7 Step 1421/1563 Loss: 1.381 | Acc: 50.519% (22988/45504)\n",
      "Epoch 7 Step 1422/1563 Loss: 1.381 | Acc: 50.507% (22999/45536)\n",
      "Epoch 7 Step 1423/1563 Loss: 1.381 | Acc: 50.500% (23012/45568)\n",
      "Epoch 7 Step 1424/1563 Loss: 1.381 | Acc: 50.504% (23030/45600)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 1425/1563 Loss: 1.381 | Acc: 50.506% (23047/45632)\n",
      "Epoch 7 Step 1426/1563 Loss: 1.381 | Acc: 50.510% (23065/45664)\n",
      "Epoch 7 Step 1427/1563 Loss: 1.381 | Acc: 50.499% (23076/45696)\n",
      "Epoch 7 Step 1428/1563 Loss: 1.381 | Acc: 50.494% (23090/45728)\n",
      "Epoch 7 Step 1429/1563 Loss: 1.381 | Acc: 50.494% (23106/45760)\n",
      "Epoch 7 Step 1430/1563 Loss: 1.381 | Acc: 50.491% (23121/45792)\n",
      "Epoch 7 Step 1431/1563 Loss: 1.381 | Acc: 50.498% (23140/45824)\n",
      "Epoch 7 Step 1432/1563 Loss: 1.381 | Acc: 50.497% (23156/45856)\n",
      "Epoch 7 Step 1433/1563 Loss: 1.381 | Acc: 50.497% (23172/45888)\n",
      "Epoch 7 Step 1434/1563 Loss: 1.382 | Acc: 50.492% (23186/45920)\n",
      "Epoch 7 Step 1435/1563 Loss: 1.381 | Acc: 50.498% (23205/45952)\n",
      "Epoch 7 Step 1436/1563 Loss: 1.382 | Acc: 50.496% (23220/45984)\n",
      "Epoch 7 Step 1437/1563 Loss: 1.382 | Acc: 50.491% (23234/46016)\n",
      "Epoch 7 Step 1438/1563 Loss: 1.382 | Acc: 50.486% (23248/46048)\n",
      "Epoch 7 Step 1439/1563 Loss: 1.382 | Acc: 50.488% (23265/46080)\n",
      "Epoch 7 Step 1440/1563 Loss: 1.382 | Acc: 50.494% (23284/46112)\n",
      "Epoch 7 Step 1441/1563 Loss: 1.381 | Acc: 50.490% (23298/46144)\n",
      "Epoch 7 Step 1442/1563 Loss: 1.382 | Acc: 50.479% (23309/46176)\n",
      "Epoch 7 Step 1443/1563 Loss: 1.382 | Acc: 50.476% (23324/46208)\n",
      "Epoch 7 Step 1444/1563 Loss: 1.382 | Acc: 50.471% (23338/46240)\n",
      "Epoch 7 Step 1445/1563 Loss: 1.382 | Acc: 50.469% (23353/46272)\n",
      "Epoch 7 Step 1446/1563 Loss: 1.382 | Acc: 50.458% (23364/46304)\n",
      "Epoch 7 Step 1447/1563 Loss: 1.382 | Acc: 50.464% (23383/46336)\n",
      "Epoch 7 Step 1448/1563 Loss: 1.382 | Acc: 50.449% (23392/46368)\n",
      "Epoch 7 Step 1449/1563 Loss: 1.382 | Acc: 50.450% (23409/46400)\n",
      "Epoch 7 Step 1450/1563 Loss: 1.382 | Acc: 50.454% (23427/46432)\n",
      "Epoch 7 Step 1451/1563 Loss: 1.382 | Acc: 50.454% (23443/46464)\n",
      "Epoch 7 Step 1452/1563 Loss: 1.382 | Acc: 50.456% (23460/46496)\n",
      "Epoch 7 Step 1453/1563 Loss: 1.382 | Acc: 50.456% (23476/46528)\n",
      "Epoch 7 Step 1454/1563 Loss: 1.382 | Acc: 50.457% (23493/46560)\n",
      "Epoch 7 Step 1455/1563 Loss: 1.382 | Acc: 50.451% (23506/46592)\n",
      "Epoch 7 Step 1456/1563 Loss: 1.382 | Acc: 50.444% (23519/46624)\n",
      "Epoch 7 Step 1457/1563 Loss: 1.382 | Acc: 50.442% (23534/46656)\n",
      "Epoch 7 Step 1458/1563 Loss: 1.382 | Acc: 50.446% (23552/46688)\n",
      "Epoch 7 Step 1459/1563 Loss: 1.382 | Acc: 50.437% (23564/46720)\n",
      "Epoch 7 Step 1460/1563 Loss: 1.382 | Acc: 50.445% (23584/46752)\n",
      "Epoch 7 Step 1461/1563 Loss: 1.382 | Acc: 50.447% (23601/46784)\n",
      "Epoch 7 Step 1462/1563 Loss: 1.382 | Acc: 50.444% (23616/46816)\n",
      "Epoch 7 Step 1463/1563 Loss: 1.382 | Acc: 50.442% (23631/46848)\n",
      "Epoch 7 Step 1464/1563 Loss: 1.382 | Acc: 50.442% (23647/46880)\n",
      "Epoch 7 Step 1465/1563 Loss: 1.382 | Acc: 50.448% (23666/46912)\n",
      "Epoch 7 Step 1466/1563 Loss: 1.382 | Acc: 50.458% (23687/46944)\n",
      "Epoch 7 Step 1467/1563 Loss: 1.382 | Acc: 50.456% (23702/46976)\n",
      "Epoch 7 Step 1468/1563 Loss: 1.382 | Acc: 50.459% (23720/47008)\n",
      "Epoch 7 Step 1469/1563 Loss: 1.382 | Acc: 50.463% (23738/47040)\n",
      "Epoch 7 Step 1470/1563 Loss: 1.382 | Acc: 50.463% (23754/47072)\n",
      "Epoch 7 Step 1471/1563 Loss: 1.382 | Acc: 50.461% (23769/47104)\n",
      "Epoch 7 Step 1472/1563 Loss: 1.382 | Acc: 50.471% (23790/47136)\n",
      "Epoch 7 Step 1473/1563 Loss: 1.382 | Acc: 50.469% (23805/47168)\n",
      "Epoch 7 Step 1474/1563 Loss: 1.382 | Acc: 50.475% (23824/47200)\n",
      "Epoch 7 Step 1475/1563 Loss: 1.382 | Acc: 50.476% (23841/47232)\n",
      "Epoch 7 Step 1476/1563 Loss: 1.382 | Acc: 50.470% (23854/47264)\n",
      "Epoch 7 Step 1477/1563 Loss: 1.382 | Acc: 50.480% (23875/47296)\n",
      "Epoch 7 Step 1478/1563 Loss: 1.382 | Acc: 50.484% (23893/47328)\n",
      "Epoch 7 Step 1479/1563 Loss: 1.382 | Acc: 50.473% (23904/47360)\n",
      "Epoch 7 Step 1480/1563 Loss: 1.382 | Acc: 50.466% (23917/47392)\n",
      "Epoch 7 Step 1481/1563 Loss: 1.382 | Acc: 50.462% (23931/47424)\n",
      "Epoch 7 Step 1482/1563 Loss: 1.382 | Acc: 50.470% (23951/47456)\n",
      "Epoch 7 Step 1483/1563 Loss: 1.382 | Acc: 50.476% (23970/47488)\n",
      "Epoch 7 Step 1484/1563 Loss: 1.382 | Acc: 50.471% (23984/47520)\n",
      "Epoch 7 Step 1485/1563 Loss: 1.382 | Acc: 50.467% (23998/47552)\n",
      "Epoch 7 Step 1486/1563 Loss: 1.382 | Acc: 50.460% (24011/47584)\n",
      "Epoch 7 Step 1487/1563 Loss: 1.382 | Acc: 50.464% (24029/47616)\n",
      "Epoch 7 Step 1488/1563 Loss: 1.382 | Acc: 50.466% (24046/47648)\n",
      "Epoch 7 Step 1489/1563 Loss: 1.382 | Acc: 50.466% (24062/47680)\n",
      "Epoch 7 Step 1490/1563 Loss: 1.382 | Acc: 50.469% (24080/47712)\n",
      "Epoch 7 Step 1491/1563 Loss: 1.382 | Acc: 50.469% (24096/47744)\n",
      "Epoch 7 Step 1492/1563 Loss: 1.381 | Acc: 50.479% (24117/47776)\n",
      "Epoch 7 Step 1493/1563 Loss: 1.381 | Acc: 50.485% (24136/47808)\n",
      "Epoch 7 Step 1494/1563 Loss: 1.381 | Acc: 50.489% (24154/47840)\n",
      "Epoch 7 Step 1495/1563 Loss: 1.381 | Acc: 50.487% (24169/47872)\n",
      "Epoch 7 Step 1496/1563 Loss: 1.381 | Acc: 50.488% (24186/47904)\n",
      "Epoch 7 Step 1497/1563 Loss: 1.381 | Acc: 50.488% (24202/47936)\n",
      "Epoch 7 Step 1498/1563 Loss: 1.381 | Acc: 50.490% (24219/47968)\n",
      "Epoch 7 Step 1499/1563 Loss: 1.381 | Acc: 50.496% (24238/48000)\n",
      "Epoch 7 Step 1500/1563 Loss: 1.381 | Acc: 50.496% (24254/48032)\n",
      "Epoch 7 Step 1501/1563 Loss: 1.381 | Acc: 50.497% (24271/48064)\n",
      "Epoch 7 Step 1502/1563 Loss: 1.381 | Acc: 50.495% (24286/48096)\n",
      "Epoch 7 Step 1503/1563 Loss: 1.381 | Acc: 50.490% (24300/48128)\n",
      "Epoch 7 Step 1504/1563 Loss: 1.381 | Acc: 50.490% (24316/48160)\n",
      "Epoch 7 Step 1505/1563 Loss: 1.381 | Acc: 50.483% (24329/48192)\n",
      "Epoch 7 Step 1506/1563 Loss: 1.381 | Acc: 50.494% (24350/48224)\n",
      "Epoch 7 Step 1507/1563 Loss: 1.381 | Acc: 50.495% (24367/48256)\n",
      "Epoch 7 Step 1508/1563 Loss: 1.381 | Acc: 50.491% (24381/48288)\n",
      "Epoch 7 Step 1509/1563 Loss: 1.381 | Acc: 50.488% (24396/48320)\n",
      "Epoch 7 Step 1510/1563 Loss: 1.381 | Acc: 50.488% (24412/48352)\n",
      "Epoch 7 Step 1511/1563 Loss: 1.381 | Acc: 50.494% (24431/48384)\n",
      "Epoch 7 Step 1512/1563 Loss: 1.381 | Acc: 50.496% (24448/48416)\n",
      "Epoch 7 Step 1513/1563 Loss: 1.381 | Acc: 50.502% (24467/48448)\n",
      "Epoch 7 Step 1514/1563 Loss: 1.380 | Acc: 50.503% (24484/48480)\n",
      "Epoch 7 Step 1515/1563 Loss: 1.381 | Acc: 50.497% (24497/48512)\n",
      "Epoch 7 Step 1516/1563 Loss: 1.381 | Acc: 50.503% (24516/48544)\n",
      "Epoch 7 Step 1517/1563 Loss: 1.381 | Acc: 50.492% (24527/48576)\n",
      "Epoch 7 Step 1518/1563 Loss: 1.381 | Acc: 50.486% (24540/48608)\n",
      "Epoch 7 Step 1519/1563 Loss: 1.381 | Acc: 50.485% (24556/48640)\n",
      "Epoch 7 Step 1520/1563 Loss: 1.381 | Acc: 50.481% (24570/48672)\n",
      "Epoch 7 Step 1521/1563 Loss: 1.381 | Acc: 50.476% (24584/48704)\n",
      "Epoch 7 Step 1522/1563 Loss: 1.381 | Acc: 50.476% (24600/48736)\n",
      "Epoch 7 Step 1523/1563 Loss: 1.381 | Acc: 50.472% (24614/48768)\n",
      "Epoch 7 Step 1524/1563 Loss: 1.381 | Acc: 50.471% (24630/48800)\n",
      "Epoch 7 Step 1525/1563 Loss: 1.381 | Acc: 50.469% (24645/48832)\n",
      "Epoch 7 Step 1526/1563 Loss: 1.381 | Acc: 50.460% (24657/48864)\n",
      "Epoch 7 Step 1527/1563 Loss: 1.381 | Acc: 50.468% (24677/48896)\n",
      "Epoch 7 Step 1528/1563 Loss: 1.381 | Acc: 50.464% (24691/48928)\n",
      "Epoch 7 Step 1529/1563 Loss: 1.381 | Acc: 50.455% (24703/48960)\n",
      "Epoch 7 Step 1530/1563 Loss: 1.381 | Acc: 50.457% (24720/48992)\n",
      "Epoch 7 Step 1531/1563 Loss: 1.381 | Acc: 50.459% (24737/49024)\n",
      "Epoch 7 Step 1532/1563 Loss: 1.381 | Acc: 50.451% (24749/49056)\n",
      "Epoch 7 Step 1533/1563 Loss: 1.381 | Acc: 50.450% (24765/49088)\n",
      "Epoch 7 Step 1534/1563 Loss: 1.381 | Acc: 50.454% (24783/49120)\n",
      "Epoch 7 Step 1535/1563 Loss: 1.381 | Acc: 50.450% (24797/49152)\n",
      "Epoch 7 Step 1536/1563 Loss: 1.381 | Acc: 50.455% (24816/49184)\n",
      "Epoch 7 Step 1537/1563 Loss: 1.381 | Acc: 50.447% (24828/49216)\n",
      "Epoch 7 Step 1538/1563 Loss: 1.381 | Acc: 50.441% (24841/49248)\n",
      "Epoch 7 Step 1539/1563 Loss: 1.381 | Acc: 50.440% (24857/49280)\n",
      "Epoch 7 Step 1540/1563 Loss: 1.381 | Acc: 50.444% (24875/49312)\n",
      "Epoch 7 Step 1541/1563 Loss: 1.381 | Acc: 50.448% (24893/49344)\n",
      "Epoch 7 Step 1542/1563 Loss: 1.381 | Acc: 50.450% (24910/49376)\n",
      "Epoch 7 Step 1543/1563 Loss: 1.381 | Acc: 50.449% (24926/49408)\n",
      "Epoch 7 Step 1544/1563 Loss: 1.381 | Acc: 50.455% (24945/49440)\n",
      "Epoch 7 Step 1545/1563 Loss: 1.381 | Acc: 50.453% (24960/49472)\n",
      "Epoch 7 Step 1546/1563 Loss: 1.381 | Acc: 50.455% (24977/49504)\n",
      "Epoch 7 Step 1547/1563 Loss: 1.381 | Acc: 50.446% (24989/49536)\n",
      "Epoch 7 Step 1548/1563 Loss: 1.381 | Acc: 50.452% (25008/49568)\n",
      "Epoch 7 Step 1549/1563 Loss: 1.381 | Acc: 50.452% (25024/49600)\n",
      "Epoch 7 Step 1550/1563 Loss: 1.381 | Acc: 50.451% (25040/49632)\n",
      "Epoch 7 Step 1551/1563 Loss: 1.381 | Acc: 50.447% (25054/49664)\n",
      "Epoch 7 Step 1552/1563 Loss: 1.381 | Acc: 50.453% (25073/49696)\n",
      "Epoch 7 Step 1553/1563 Loss: 1.381 | Acc: 50.444% (25085/49728)\n",
      "Epoch 7 Step 1554/1563 Loss: 1.381 | Acc: 50.452% (25105/49760)\n",
      "Epoch 7 Step 1555/1563 Loss: 1.381 | Acc: 50.452% (25121/49792)\n",
      "Epoch 7 Step 1556/1563 Loss: 1.381 | Acc: 50.460% (25141/49824)\n",
      "Epoch 7 Step 1557/1563 Loss: 1.380 | Acc: 50.461% (25158/49856)\n",
      "Epoch 7 Step 1558/1563 Loss: 1.380 | Acc: 50.475% (25181/49888)\n",
      "Epoch 7 Step 1559/1563 Loss: 1.380 | Acc: 50.477% (25198/49920)\n",
      "Epoch 7 Step 1560/1563 Loss: 1.380 | Acc: 50.478% (25215/49952)\n",
      "Epoch 7 Step 1561/1563 Loss: 1.380 | Acc: 50.486% (25235/49984)\n",
      "Epoch 7 Step 1562/1563 Loss: 1.380 | Acc: 50.484% (25242/50000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 0/313 Test Loss: 1.013 | Test Acc: 56.250% (18/32)\n",
      "Epoch 7 Step 1/313 Test Loss: 1.207 | Test Acc: 51.562% (33/64)\n",
      "Epoch 7 Step 2/313 Test Loss: 1.223 | Test Acc: 54.167% (52/96)\n",
      "Epoch 7 Step 3/313 Test Loss: 1.248 | Test Acc: 52.344% (67/128)\n",
      "Epoch 7 Step 4/313 Test Loss: 1.293 | Test Acc: 52.500% (84/160)\n",
      "Epoch 7 Step 5/313 Test Loss: 1.317 | Test Acc: 52.083% (100/192)\n",
      "Epoch 7 Step 6/313 Test Loss: 1.376 | Test Acc: 50.000% (112/224)\n",
      "Epoch 7 Step 7/313 Test Loss: 1.356 | Test Acc: 51.953% (133/256)\n",
      "Epoch 7 Step 8/313 Test Loss: 1.362 | Test Acc: 51.042% (147/288)\n",
      "Epoch 7 Step 9/313 Test Loss: 1.349 | Test Acc: 51.562% (165/320)\n",
      "Epoch 7 Step 10/313 Test Loss: 1.340 | Test Acc: 51.420% (181/352)\n",
      "Epoch 7 Step 11/313 Test Loss: 1.373 | Test Acc: 50.260% (193/384)\n",
      "Epoch 7 Step 12/313 Test Loss: 1.373 | Test Acc: 50.481% (210/416)\n",
      "Epoch 7 Step 13/313 Test Loss: 1.381 | Test Acc: 50.223% (225/448)\n",
      "Epoch 7 Step 14/313 Test Loss: 1.377 | Test Acc: 50.000% (240/480)\n",
      "Epoch 7 Step 15/313 Test Loss: 1.363 | Test Acc: 50.781% (260/512)\n",
      "Epoch 7 Step 16/313 Test Loss: 1.357 | Test Acc: 50.919% (277/544)\n",
      "Epoch 7 Step 17/313 Test Loss: 1.345 | Test Acc: 51.562% (297/576)\n",
      "Epoch 7 Step 18/313 Test Loss: 1.351 | Test Acc: 51.316% (312/608)\n",
      "Epoch 7 Step 19/313 Test Loss: 1.328 | Test Acc: 51.719% (331/640)\n",
      "Epoch 7 Step 20/313 Test Loss: 1.318 | Test Acc: 51.339% (345/672)\n",
      "Epoch 7 Step 21/313 Test Loss: 1.339 | Test Acc: 50.284% (354/704)\n",
      "Epoch 7 Step 22/313 Test Loss: 1.337 | Test Acc: 50.272% (370/736)\n",
      "Epoch 7 Step 23/313 Test Loss: 1.339 | Test Acc: 50.391% (387/768)\n",
      "Epoch 7 Step 24/313 Test Loss: 1.346 | Test Acc: 50.125% (401/800)\n",
      "Epoch 7 Step 25/313 Test Loss: 1.340 | Test Acc: 50.601% (421/832)\n",
      "Epoch 7 Step 26/313 Test Loss: 1.342 | Test Acc: 50.810% (439/864)\n",
      "Epoch 7 Step 27/313 Test Loss: 1.336 | Test Acc: 50.781% (455/896)\n",
      "Epoch 7 Step 28/313 Test Loss: 1.332 | Test Acc: 50.862% (472/928)\n",
      "Epoch 7 Step 29/313 Test Loss: 1.321 | Test Acc: 51.146% (491/960)\n",
      "Epoch 7 Step 30/313 Test Loss: 1.315 | Test Acc: 51.411% (510/992)\n",
      "Epoch 7 Step 31/313 Test Loss: 1.305 | Test Acc: 51.953% (532/1024)\n",
      "Epoch 7 Step 32/313 Test Loss: 1.312 | Test Acc: 51.799% (547/1056)\n",
      "Epoch 7 Step 33/313 Test Loss: 1.308 | Test Acc: 51.930% (565/1088)\n",
      "Epoch 7 Step 34/313 Test Loss: 1.300 | Test Acc: 52.500% (588/1120)\n",
      "Epoch 7 Step 35/313 Test Loss: 1.307 | Test Acc: 51.997% (599/1152)\n",
      "Epoch 7 Step 36/313 Test Loss: 1.305 | Test Acc: 52.111% (617/1184)\n",
      "Epoch 7 Step 37/313 Test Loss: 1.308 | Test Acc: 52.220% (635/1216)\n",
      "Epoch 7 Step 38/313 Test Loss: 1.316 | Test Acc: 52.163% (651/1248)\n",
      "Epoch 7 Step 39/313 Test Loss: 1.315 | Test Acc: 51.953% (665/1280)\n",
      "Epoch 7 Step 40/313 Test Loss: 1.317 | Test Acc: 51.601% (677/1312)\n",
      "Epoch 7 Step 41/313 Test Loss: 1.316 | Test Acc: 51.711% (695/1344)\n",
      "Epoch 7 Step 42/313 Test Loss: 1.309 | Test Acc: 51.962% (715/1376)\n",
      "Epoch 7 Step 43/313 Test Loss: 1.312 | Test Acc: 51.918% (731/1408)\n",
      "Epoch 7 Step 44/313 Test Loss: 1.315 | Test Acc: 51.875% (747/1440)\n",
      "Epoch 7 Step 45/313 Test Loss: 1.311 | Test Acc: 52.106% (767/1472)\n",
      "Epoch 7 Step 46/313 Test Loss: 1.312 | Test Acc: 51.928% (781/1504)\n",
      "Epoch 7 Step 47/313 Test Loss: 1.312 | Test Acc: 51.888% (797/1536)\n",
      "Epoch 7 Step 48/313 Test Loss: 1.306 | Test Acc: 52.168% (818/1568)\n",
      "Epoch 7 Step 49/313 Test Loss: 1.312 | Test Acc: 52.062% (833/1600)\n",
      "Epoch 7 Step 50/313 Test Loss: 1.321 | Test Acc: 51.654% (843/1632)\n",
      "Epoch 7 Step 51/313 Test Loss: 1.317 | Test Acc: 51.923% (864/1664)\n",
      "Epoch 7 Step 52/313 Test Loss: 1.318 | Test Acc: 51.887% (880/1696)\n",
      "Epoch 7 Step 53/313 Test Loss: 1.320 | Test Acc: 51.736% (894/1728)\n",
      "Epoch 7 Step 54/313 Test Loss: 1.322 | Test Acc: 51.818% (912/1760)\n",
      "Epoch 7 Step 55/313 Test Loss: 1.319 | Test Acc: 51.953% (931/1792)\n",
      "Epoch 7 Step 56/313 Test Loss: 1.319 | Test Acc: 51.864% (946/1824)\n",
      "Epoch 7 Step 57/313 Test Loss: 1.322 | Test Acc: 51.886% (963/1856)\n",
      "Epoch 7 Step 58/313 Test Loss: 1.321 | Test Acc: 51.960% (981/1888)\n",
      "Epoch 7 Step 59/313 Test Loss: 1.325 | Test Acc: 51.875% (996/1920)\n",
      "Epoch 7 Step 60/313 Test Loss: 1.324 | Test Acc: 51.742% (1010/1952)\n",
      "Epoch 7 Step 61/313 Test Loss: 1.325 | Test Acc: 51.764% (1027/1984)\n",
      "Epoch 7 Step 62/313 Test Loss: 1.329 | Test Acc: 51.637% (1041/2016)\n",
      "Epoch 7 Step 63/313 Test Loss: 1.329 | Test Acc: 51.611% (1057/2048)\n",
      "Epoch 7 Step 64/313 Test Loss: 1.324 | Test Acc: 51.731% (1076/2080)\n",
      "Epoch 7 Step 65/313 Test Loss: 1.324 | Test Acc: 51.894% (1096/2112)\n",
      "Epoch 7 Step 66/313 Test Loss: 1.324 | Test Acc: 51.866% (1112/2144)\n",
      "Epoch 7 Step 67/313 Test Loss: 1.328 | Test Acc: 51.700% (1125/2176)\n",
      "Epoch 7 Step 68/313 Test Loss: 1.328 | Test Acc: 51.902% (1146/2208)\n",
      "Epoch 7 Step 69/313 Test Loss: 1.325 | Test Acc: 52.009% (1165/2240)\n",
      "Epoch 7 Step 70/313 Test Loss: 1.327 | Test Acc: 52.069% (1183/2272)\n",
      "Epoch 7 Step 71/313 Test Loss: 1.328 | Test Acc: 51.953% (1197/2304)\n",
      "Epoch 7 Step 72/313 Test Loss: 1.329 | Test Acc: 51.884% (1212/2336)\n",
      "Epoch 7 Step 73/313 Test Loss: 1.328 | Test Acc: 51.985% (1231/2368)\n",
      "Epoch 7 Step 74/313 Test Loss: 1.328 | Test Acc: 52.125% (1251/2400)\n",
      "Epoch 7 Step 75/313 Test Loss: 1.329 | Test Acc: 52.056% (1266/2432)\n",
      "Epoch 7 Step 76/313 Test Loss: 1.328 | Test Acc: 52.151% (1285/2464)\n",
      "Epoch 7 Step 77/313 Test Loss: 1.327 | Test Acc: 52.284% (1305/2496)\n",
      "Epoch 7 Step 78/313 Test Loss: 1.333 | Test Acc: 52.176% (1319/2528)\n",
      "Epoch 7 Step 79/313 Test Loss: 1.336 | Test Acc: 52.109% (1334/2560)\n",
      "Epoch 7 Step 80/313 Test Loss: 1.336 | Test Acc: 52.045% (1349/2592)\n",
      "Epoch 7 Step 81/313 Test Loss: 1.334 | Test Acc: 52.058% (1366/2624)\n",
      "Epoch 7 Step 82/313 Test Loss: 1.334 | Test Acc: 52.033% (1382/2656)\n",
      "Epoch 7 Step 83/313 Test Loss: 1.332 | Test Acc: 52.121% (1401/2688)\n",
      "Epoch 7 Step 84/313 Test Loss: 1.334 | Test Acc: 52.096% (1417/2720)\n",
      "Epoch 7 Step 85/313 Test Loss: 1.335 | Test Acc: 51.962% (1430/2752)\n",
      "Epoch 7 Step 86/313 Test Loss: 1.337 | Test Acc: 51.832% (1443/2784)\n",
      "Epoch 7 Step 87/313 Test Loss: 1.336 | Test Acc: 51.882% (1461/2816)\n",
      "Epoch 7 Step 88/313 Test Loss: 1.338 | Test Acc: 51.826% (1476/2848)\n",
      "Epoch 7 Step 89/313 Test Loss: 1.338 | Test Acc: 51.736% (1490/2880)\n",
      "Epoch 7 Step 90/313 Test Loss: 1.338 | Test Acc: 51.820% (1509/2912)\n",
      "Epoch 7 Step 91/313 Test Loss: 1.333 | Test Acc: 52.038% (1532/2944)\n",
      "Epoch 7 Step 92/313 Test Loss: 1.332 | Test Acc: 52.083% (1550/2976)\n",
      "Epoch 7 Step 93/313 Test Loss: 1.331 | Test Acc: 52.094% (1567/3008)\n",
      "Epoch 7 Step 94/313 Test Loss: 1.330 | Test Acc: 52.105% (1584/3040)\n",
      "Epoch 7 Step 95/313 Test Loss: 1.331 | Test Acc: 52.083% (1600/3072)\n",
      "Epoch 7 Step 96/313 Test Loss: 1.330 | Test Acc: 52.030% (1615/3104)\n",
      "Epoch 7 Step 97/313 Test Loss: 1.331 | Test Acc: 51.977% (1630/3136)\n",
      "Epoch 7 Step 98/313 Test Loss: 1.331 | Test Acc: 51.957% (1646/3168)\n",
      "Epoch 7 Step 99/313 Test Loss: 1.333 | Test Acc: 51.844% (1659/3200)\n",
      "Epoch 7 Step 100/313 Test Loss: 1.336 | Test Acc: 51.702% (1671/3232)\n",
      "Epoch 7 Step 101/313 Test Loss: 1.333 | Test Acc: 51.900% (1694/3264)\n",
      "Epoch 7 Step 102/313 Test Loss: 1.331 | Test Acc: 52.033% (1715/3296)\n",
      "Epoch 7 Step 103/313 Test Loss: 1.332 | Test Acc: 52.043% (1732/3328)\n",
      "Epoch 7 Step 104/313 Test Loss: 1.334 | Test Acc: 52.054% (1749/3360)\n",
      "Epoch 7 Step 105/313 Test Loss: 1.330 | Test Acc: 52.241% (1772/3392)\n",
      "Epoch 7 Step 106/313 Test Loss: 1.330 | Test Acc: 52.278% (1790/3424)\n",
      "Epoch 7 Step 107/313 Test Loss: 1.330 | Test Acc: 52.228% (1805/3456)\n",
      "Epoch 7 Step 108/313 Test Loss: 1.327 | Test Acc: 52.380% (1827/3488)\n",
      "Epoch 7 Step 109/313 Test Loss: 1.329 | Test Acc: 52.244% (1839/3520)\n",
      "Epoch 7 Step 110/313 Test Loss: 1.327 | Test Acc: 52.393% (1861/3552)\n",
      "Epoch 7 Step 111/313 Test Loss: 1.326 | Test Acc: 52.483% (1881/3584)\n",
      "Epoch 7 Step 112/313 Test Loss: 1.326 | Test Acc: 52.489% (1898/3616)\n",
      "Epoch 7 Step 113/313 Test Loss: 1.326 | Test Acc: 52.522% (1916/3648)\n",
      "Epoch 7 Step 114/313 Test Loss: 1.325 | Test Acc: 52.527% (1933/3680)\n",
      "Epoch 7 Step 115/313 Test Loss: 1.323 | Test Acc: 52.586% (1952/3712)\n",
      "Epoch 7 Step 116/313 Test Loss: 1.322 | Test Acc: 52.537% (1967/3744)\n",
      "Epoch 7 Step 117/313 Test Loss: 1.323 | Test Acc: 52.542% (1984/3776)\n",
      "Epoch 7 Step 118/313 Test Loss: 1.322 | Test Acc: 52.574% (2002/3808)\n",
      "Epoch 7 Step 119/313 Test Loss: 1.319 | Test Acc: 52.734% (2025/3840)\n",
      "Epoch 7 Step 120/313 Test Loss: 1.317 | Test Acc: 52.763% (2043/3872)\n",
      "Epoch 7 Step 121/313 Test Loss: 1.316 | Test Acc: 52.792% (2061/3904)\n",
      "Epoch 7 Step 122/313 Test Loss: 1.317 | Test Acc: 52.769% (2077/3936)\n",
      "Epoch 7 Step 123/313 Test Loss: 1.316 | Test Acc: 52.898% (2099/3968)\n",
      "Epoch 7 Step 124/313 Test Loss: 1.318 | Test Acc: 52.875% (2115/4000)\n",
      "Epoch 7 Step 125/313 Test Loss: 1.317 | Test Acc: 53.026% (2138/4032)\n",
      "Epoch 7 Step 126/313 Test Loss: 1.320 | Test Acc: 53.002% (2154/4064)\n",
      "Epoch 7 Step 127/313 Test Loss: 1.317 | Test Acc: 53.101% (2175/4096)\n",
      "Epoch 7 Step 128/313 Test Loss: 1.319 | Test Acc: 53.077% (2191/4128)\n",
      "Epoch 7 Step 129/313 Test Loss: 1.318 | Test Acc: 53.125% (2210/4160)\n",
      "Epoch 7 Step 130/313 Test Loss: 1.316 | Test Acc: 53.149% (2228/4192)\n",
      "Epoch 7 Step 131/313 Test Loss: 1.316 | Test Acc: 53.125% (2244/4224)\n",
      "Epoch 7 Step 132/313 Test Loss: 1.316 | Test Acc: 53.102% (2260/4256)\n",
      "Epoch 7 Step 133/313 Test Loss: 1.315 | Test Acc: 53.125% (2278/4288)\n",
      "Epoch 7 Step 134/313 Test Loss: 1.316 | Test Acc: 53.079% (2293/4320)\n",
      "Epoch 7 Step 135/313 Test Loss: 1.314 | Test Acc: 53.171% (2314/4352)\n",
      "Epoch 7 Step 136/313 Test Loss: 1.314 | Test Acc: 53.171% (2331/4384)\n",
      "Epoch 7 Step 137/313 Test Loss: 1.314 | Test Acc: 53.125% (2346/4416)\n",
      "Epoch 7 Step 138/313 Test Loss: 1.313 | Test Acc: 53.170% (2365/4448)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 139/313 Test Loss: 1.312 | Test Acc: 53.170% (2382/4480)\n",
      "Epoch 7 Step 140/313 Test Loss: 1.311 | Test Acc: 53.236% (2402/4512)\n",
      "Epoch 7 Step 141/313 Test Loss: 1.310 | Test Acc: 53.213% (2418/4544)\n",
      "Epoch 7 Step 142/313 Test Loss: 1.312 | Test Acc: 53.059% (2428/4576)\n",
      "Epoch 7 Step 143/313 Test Loss: 1.314 | Test Acc: 52.886% (2437/4608)\n",
      "Epoch 7 Step 144/313 Test Loss: 1.314 | Test Acc: 52.931% (2456/4640)\n",
      "Epoch 7 Step 145/313 Test Loss: 1.312 | Test Acc: 52.954% (2474/4672)\n",
      "Epoch 7 Step 146/313 Test Loss: 1.312 | Test Acc: 52.912% (2489/4704)\n",
      "Epoch 7 Step 147/313 Test Loss: 1.311 | Test Acc: 52.893% (2505/4736)\n",
      "Epoch 7 Step 148/313 Test Loss: 1.313 | Test Acc: 52.936% (2524/4768)\n",
      "Epoch 7 Step 149/313 Test Loss: 1.312 | Test Acc: 52.917% (2540/4800)\n",
      "Epoch 7 Step 150/313 Test Loss: 1.313 | Test Acc: 52.877% (2555/4832)\n",
      "Epoch 7 Step 151/313 Test Loss: 1.310 | Test Acc: 53.002% (2578/4864)\n",
      "Epoch 7 Step 152/313 Test Loss: 1.310 | Test Acc: 52.941% (2592/4896)\n",
      "Epoch 7 Step 153/313 Test Loss: 1.309 | Test Acc: 53.024% (2613/4928)\n",
      "Epoch 7 Step 154/313 Test Loss: 1.309 | Test Acc: 53.024% (2630/4960)\n",
      "Epoch 7 Step 155/313 Test Loss: 1.310 | Test Acc: 52.965% (2644/4992)\n",
      "Epoch 7 Step 156/313 Test Loss: 1.310 | Test Acc: 53.006% (2663/5024)\n",
      "Epoch 7 Step 157/313 Test Loss: 1.309 | Test Acc: 52.987% (2679/5056)\n",
      "Epoch 7 Step 158/313 Test Loss: 1.310 | Test Acc: 52.909% (2692/5088)\n",
      "Epoch 7 Step 159/313 Test Loss: 1.314 | Test Acc: 52.812% (2704/5120)\n",
      "Epoch 7 Step 160/313 Test Loss: 1.314 | Test Acc: 52.814% (2721/5152)\n",
      "Epoch 7 Step 161/313 Test Loss: 1.313 | Test Acc: 52.894% (2742/5184)\n",
      "Epoch 7 Step 162/313 Test Loss: 1.314 | Test Acc: 52.876% (2758/5216)\n",
      "Epoch 7 Step 163/313 Test Loss: 1.314 | Test Acc: 52.858% (2774/5248)\n",
      "Epoch 7 Step 164/313 Test Loss: 1.314 | Test Acc: 52.822% (2789/5280)\n",
      "Epoch 7 Step 165/313 Test Loss: 1.314 | Test Acc: 52.843% (2807/5312)\n",
      "Epoch 7 Step 166/313 Test Loss: 1.315 | Test Acc: 52.807% (2822/5344)\n",
      "Epoch 7 Step 167/313 Test Loss: 1.315 | Test Acc: 52.827% (2840/5376)\n",
      "Epoch 7 Step 168/313 Test Loss: 1.316 | Test Acc: 52.792% (2855/5408)\n",
      "Epoch 7 Step 169/313 Test Loss: 1.315 | Test Acc: 52.831% (2874/5440)\n",
      "Epoch 7 Step 170/313 Test Loss: 1.315 | Test Acc: 52.851% (2892/5472)\n",
      "Epoch 7 Step 171/313 Test Loss: 1.315 | Test Acc: 52.852% (2909/5504)\n",
      "Epoch 7 Step 172/313 Test Loss: 1.316 | Test Acc: 52.800% (2923/5536)\n",
      "Epoch 7 Step 173/313 Test Loss: 1.316 | Test Acc: 52.766% (2938/5568)\n",
      "Epoch 7 Step 174/313 Test Loss: 1.316 | Test Acc: 52.732% (2953/5600)\n",
      "Epoch 7 Step 175/313 Test Loss: 1.317 | Test Acc: 52.788% (2973/5632)\n",
      "Epoch 7 Step 176/313 Test Loss: 1.319 | Test Acc: 52.701% (2985/5664)\n",
      "Epoch 7 Step 177/313 Test Loss: 1.317 | Test Acc: 52.791% (3007/5696)\n",
      "Epoch 7 Step 178/313 Test Loss: 1.316 | Test Acc: 52.793% (3024/5728)\n",
      "Epoch 7 Step 179/313 Test Loss: 1.316 | Test Acc: 52.812% (3042/5760)\n",
      "Epoch 7 Step 180/313 Test Loss: 1.313 | Test Acc: 52.918% (3065/5792)\n",
      "Epoch 7 Step 181/313 Test Loss: 1.314 | Test Acc: 52.867% (3079/5824)\n",
      "Epoch 7 Step 182/313 Test Loss: 1.316 | Test Acc: 52.766% (3090/5856)\n",
      "Epoch 7 Step 183/313 Test Loss: 1.316 | Test Acc: 52.751% (3106/5888)\n",
      "Epoch 7 Step 184/313 Test Loss: 1.318 | Test Acc: 52.635% (3116/5920)\n",
      "Epoch 7 Step 185/313 Test Loss: 1.318 | Test Acc: 52.604% (3131/5952)\n",
      "Epoch 7 Step 186/313 Test Loss: 1.318 | Test Acc: 52.624% (3149/5984)\n",
      "Epoch 7 Step 187/313 Test Loss: 1.317 | Test Acc: 52.610% (3165/6016)\n",
      "Epoch 7 Step 188/313 Test Loss: 1.316 | Test Acc: 52.612% (3182/6048)\n",
      "Epoch 7 Step 189/313 Test Loss: 1.316 | Test Acc: 52.582% (3197/6080)\n",
      "Epoch 7 Step 190/313 Test Loss: 1.315 | Test Acc: 52.569% (3213/6112)\n",
      "Epoch 7 Step 191/313 Test Loss: 1.315 | Test Acc: 52.555% (3229/6144)\n",
      "Epoch 7 Step 192/313 Test Loss: 1.317 | Test Acc: 52.558% (3246/6176)\n",
      "Epoch 7 Step 193/313 Test Loss: 1.315 | Test Acc: 52.577% (3264/6208)\n",
      "Epoch 7 Step 194/313 Test Loss: 1.317 | Test Acc: 52.580% (3281/6240)\n",
      "Epoch 7 Step 195/313 Test Loss: 1.318 | Test Acc: 52.567% (3297/6272)\n",
      "Epoch 7 Step 196/313 Test Loss: 1.319 | Test Acc: 52.522% (3311/6304)\n",
      "Epoch 7 Step 197/313 Test Loss: 1.319 | Test Acc: 52.557% (3330/6336)\n",
      "Epoch 7 Step 198/313 Test Loss: 1.317 | Test Acc: 52.638% (3352/6368)\n",
      "Epoch 7 Step 199/313 Test Loss: 1.317 | Test Acc: 52.609% (3367/6400)\n",
      "Epoch 7 Step 200/313 Test Loss: 1.318 | Test Acc: 52.627% (3385/6432)\n",
      "Epoch 7 Step 201/313 Test Loss: 1.318 | Test Acc: 52.645% (3403/6464)\n",
      "Epoch 7 Step 202/313 Test Loss: 1.319 | Test Acc: 52.632% (3419/6496)\n",
      "Epoch 7 Step 203/313 Test Loss: 1.319 | Test Acc: 52.650% (3437/6528)\n",
      "Epoch 7 Step 204/313 Test Loss: 1.320 | Test Acc: 52.607% (3451/6560)\n",
      "Epoch 7 Step 205/313 Test Loss: 1.321 | Test Acc: 52.579% (3466/6592)\n",
      "Epoch 7 Step 206/313 Test Loss: 1.320 | Test Acc: 52.612% (3485/6624)\n",
      "Epoch 7 Step 207/313 Test Loss: 1.319 | Test Acc: 52.629% (3503/6656)\n",
      "Epoch 7 Step 208/313 Test Loss: 1.319 | Test Acc: 52.617% (3519/6688)\n",
      "Epoch 7 Step 209/313 Test Loss: 1.320 | Test Acc: 52.589% (3534/6720)\n",
      "Epoch 7 Step 210/313 Test Loss: 1.319 | Test Acc: 52.607% (3552/6752)\n",
      "Epoch 7 Step 211/313 Test Loss: 1.319 | Test Acc: 52.521% (3563/6784)\n",
      "Epoch 7 Step 212/313 Test Loss: 1.318 | Test Acc: 52.597% (3585/6816)\n",
      "Epoch 7 Step 213/313 Test Loss: 1.317 | Test Acc: 52.585% (3601/6848)\n",
      "Epoch 7 Step 214/313 Test Loss: 1.320 | Test Acc: 52.515% (3613/6880)\n",
      "Epoch 7 Step 215/313 Test Loss: 1.319 | Test Acc: 52.532% (3631/6912)\n",
      "Epoch 7 Step 216/313 Test Loss: 1.319 | Test Acc: 52.549% (3649/6944)\n",
      "Epoch 7 Step 217/313 Test Loss: 1.320 | Test Acc: 52.523% (3664/6976)\n",
      "Epoch 7 Step 218/313 Test Loss: 1.322 | Test Acc: 52.454% (3676/7008)\n",
      "Epoch 7 Step 219/313 Test Loss: 1.321 | Test Acc: 52.472% (3694/7040)\n",
      "Epoch 7 Step 220/313 Test Loss: 1.321 | Test Acc: 52.446% (3709/7072)\n",
      "Epoch 7 Step 221/313 Test Loss: 1.320 | Test Acc: 52.449% (3726/7104)\n",
      "Epoch 7 Step 222/313 Test Loss: 1.321 | Test Acc: 52.438% (3742/7136)\n",
      "Epoch 7 Step 223/313 Test Loss: 1.320 | Test Acc: 52.511% (3764/7168)\n",
      "Epoch 7 Step 224/313 Test Loss: 1.321 | Test Acc: 52.486% (3779/7200)\n",
      "Epoch 7 Step 225/313 Test Loss: 1.321 | Test Acc: 52.475% (3795/7232)\n",
      "Epoch 7 Step 226/313 Test Loss: 1.322 | Test Acc: 52.464% (3811/7264)\n",
      "Epoch 7 Step 227/313 Test Loss: 1.321 | Test Acc: 52.426% (3825/7296)\n",
      "Epoch 7 Step 228/313 Test Loss: 1.321 | Test Acc: 52.443% (3843/7328)\n",
      "Epoch 7 Step 229/313 Test Loss: 1.320 | Test Acc: 52.514% (3865/7360)\n",
      "Epoch 7 Step 230/313 Test Loss: 1.319 | Test Acc: 52.476% (3879/7392)\n",
      "Epoch 7 Step 231/313 Test Loss: 1.320 | Test Acc: 52.452% (3894/7424)\n",
      "Epoch 7 Step 232/313 Test Loss: 1.320 | Test Acc: 52.481% (3913/7456)\n",
      "Epoch 7 Step 233/313 Test Loss: 1.318 | Test Acc: 52.551% (3935/7488)\n",
      "Epoch 7 Step 234/313 Test Loss: 1.318 | Test Acc: 52.566% (3953/7520)\n",
      "Epoch 7 Step 235/313 Test Loss: 1.317 | Test Acc: 52.595% (3972/7552)\n",
      "Epoch 7 Step 236/313 Test Loss: 1.318 | Test Acc: 52.598% (3989/7584)\n",
      "Epoch 7 Step 237/313 Test Loss: 1.320 | Test Acc: 52.534% (4001/7616)\n",
      "Epoch 7 Step 238/313 Test Loss: 1.319 | Test Acc: 52.576% (4021/7648)\n",
      "Epoch 7 Step 239/313 Test Loss: 1.319 | Test Acc: 52.591% (4039/7680)\n",
      "Epoch 7 Step 240/313 Test Loss: 1.317 | Test Acc: 52.645% (4060/7712)\n",
      "Epoch 7 Step 241/313 Test Loss: 1.317 | Test Acc: 52.660% (4078/7744)\n",
      "Epoch 7 Step 242/313 Test Loss: 1.317 | Test Acc: 52.688% (4097/7776)\n",
      "Epoch 7 Step 243/313 Test Loss: 1.317 | Test Acc: 52.651% (4111/7808)\n",
      "Epoch 7 Step 244/313 Test Loss: 1.317 | Test Acc: 52.653% (4128/7840)\n",
      "Epoch 7 Step 245/313 Test Loss: 1.317 | Test Acc: 52.642% (4144/7872)\n",
      "Epoch 7 Step 246/313 Test Loss: 1.316 | Test Acc: 52.682% (4164/7904)\n",
      "Epoch 7 Step 247/313 Test Loss: 1.317 | Test Acc: 52.634% (4177/7936)\n",
      "Epoch 7 Step 248/313 Test Loss: 1.318 | Test Acc: 52.636% (4194/7968)\n",
      "Epoch 7 Step 249/313 Test Loss: 1.317 | Test Acc: 52.675% (4214/8000)\n",
      "Epoch 7 Step 250/313 Test Loss: 1.318 | Test Acc: 52.677% (4231/8032)\n",
      "Epoch 7 Step 251/313 Test Loss: 1.319 | Test Acc: 52.654% (4246/8064)\n",
      "Epoch 7 Step 252/313 Test Loss: 1.318 | Test Acc: 52.668% (4264/8096)\n",
      "Epoch 7 Step 253/313 Test Loss: 1.320 | Test Acc: 52.608% (4276/8128)\n",
      "Epoch 7 Step 254/313 Test Loss: 1.320 | Test Acc: 52.586% (4291/8160)\n",
      "Epoch 7 Step 255/313 Test Loss: 1.319 | Test Acc: 52.563% (4306/8192)\n",
      "Epoch 7 Step 256/313 Test Loss: 1.320 | Test Acc: 52.517% (4319/8224)\n",
      "Epoch 7 Step 257/313 Test Loss: 1.320 | Test Acc: 52.531% (4337/8256)\n",
      "Epoch 7 Step 258/313 Test Loss: 1.320 | Test Acc: 52.522% (4353/8288)\n",
      "Epoch 7 Step 259/313 Test Loss: 1.322 | Test Acc: 52.452% (4364/8320)\n",
      "Epoch 7 Step 260/313 Test Loss: 1.322 | Test Acc: 52.419% (4378/8352)\n",
      "Epoch 7 Step 261/313 Test Loss: 1.322 | Test Acc: 52.421% (4395/8384)\n",
      "Epoch 7 Step 262/313 Test Loss: 1.322 | Test Acc: 52.388% (4409/8416)\n",
      "Epoch 7 Step 263/313 Test Loss: 1.322 | Test Acc: 52.415% (4428/8448)\n",
      "Epoch 7 Step 264/313 Test Loss: 1.323 | Test Acc: 52.417% (4445/8480)\n",
      "Epoch 7 Step 265/313 Test Loss: 1.323 | Test Acc: 52.385% (4459/8512)\n",
      "Epoch 7 Step 266/313 Test Loss: 1.323 | Test Acc: 52.376% (4475/8544)\n",
      "Epoch 7 Step 267/313 Test Loss: 1.322 | Test Acc: 52.402% (4494/8576)\n",
      "Epoch 7 Step 268/313 Test Loss: 1.324 | Test Acc: 52.347% (4506/8608)\n",
      "Epoch 7 Step 269/313 Test Loss: 1.324 | Test Acc: 52.361% (4524/8640)\n",
      "Epoch 7 Step 270/313 Test Loss: 1.325 | Test Acc: 52.283% (4534/8672)\n",
      "Epoch 7 Step 271/313 Test Loss: 1.324 | Test Acc: 52.321% (4554/8704)\n",
      "Epoch 7 Step 272/313 Test Loss: 1.323 | Test Acc: 52.347% (4573/8736)\n",
      "Epoch 7 Step 273/313 Test Loss: 1.324 | Test Acc: 52.338% (4589/8768)\n",
      "Epoch 7 Step 274/313 Test Loss: 1.323 | Test Acc: 52.386% (4610/8800)\n",
      "Epoch 7 Step 275/313 Test Loss: 1.324 | Test Acc: 52.355% (4624/8832)\n",
      "Epoch 7 Step 276/313 Test Loss: 1.323 | Test Acc: 52.358% (4641/8864)\n",
      "Epoch 7 Step 277/313 Test Loss: 1.323 | Test Acc: 52.406% (4662/8896)\n",
      "Epoch 7 Step 278/313 Test Loss: 1.322 | Test Acc: 52.431% (4681/8928)\n",
      "Epoch 7 Step 279/313 Test Loss: 1.324 | Test Acc: 52.366% (4692/8960)\n",
      "Epoch 7 Step 280/313 Test Loss: 1.324 | Test Acc: 52.347% (4707/8992)\n",
      "Epoch 7 Step 281/313 Test Loss: 1.324 | Test Acc: 52.371% (4726/9024)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Step 282/313 Test Loss: 1.324 | Test Acc: 52.341% (4740/9056)\n",
      "Epoch 7 Step 283/313 Test Loss: 1.324 | Test Acc: 52.355% (4758/9088)\n",
      "Epoch 7 Step 284/313 Test Loss: 1.323 | Test Acc: 52.346% (4774/9120)\n",
      "Epoch 7 Step 285/313 Test Loss: 1.324 | Test Acc: 52.327% (4789/9152)\n",
      "Epoch 7 Step 286/313 Test Loss: 1.322 | Test Acc: 52.406% (4813/9184)\n",
      "Epoch 7 Step 287/313 Test Loss: 1.322 | Test Acc: 52.420% (4831/9216)\n",
      "Epoch 7 Step 288/313 Test Loss: 1.322 | Test Acc: 52.433% (4849/9248)\n",
      "Epoch 7 Step 289/313 Test Loss: 1.322 | Test Acc: 52.457% (4868/9280)\n",
      "Epoch 7 Step 290/313 Test Loss: 1.322 | Test Acc: 52.459% (4885/9312)\n",
      "Epoch 7 Step 291/313 Test Loss: 1.322 | Test Acc: 52.451% (4901/9344)\n",
      "Epoch 7 Step 292/313 Test Loss: 1.322 | Test Acc: 52.474% (4920/9376)\n",
      "Epoch 7 Step 293/313 Test Loss: 1.323 | Test Acc: 52.477% (4937/9408)\n",
      "Epoch 7 Step 294/313 Test Loss: 1.323 | Test Acc: 52.489% (4955/9440)\n",
      "Epoch 7 Step 295/313 Test Loss: 1.322 | Test Acc: 52.513% (4974/9472)\n",
      "Epoch 7 Step 296/313 Test Loss: 1.322 | Test Acc: 52.504% (4990/9504)\n",
      "Epoch 7 Step 297/313 Test Loss: 1.323 | Test Acc: 52.454% (5002/9536)\n",
      "Epoch 7 Step 298/313 Test Loss: 1.322 | Test Acc: 52.467% (5020/9568)\n",
      "Epoch 7 Step 299/313 Test Loss: 1.321 | Test Acc: 52.521% (5042/9600)\n",
      "Epoch 7 Step 300/313 Test Loss: 1.321 | Test Acc: 52.502% (5057/9632)\n",
      "Epoch 7 Step 301/313 Test Loss: 1.322 | Test Acc: 52.504% (5074/9664)\n",
      "Epoch 7 Step 302/313 Test Loss: 1.322 | Test Acc: 52.496% (5090/9696)\n",
      "Epoch 7 Step 303/313 Test Loss: 1.322 | Test Acc: 52.519% (5109/9728)\n",
      "Epoch 7 Step 304/313 Test Loss: 1.322 | Test Acc: 52.510% (5125/9760)\n",
      "Epoch 7 Step 305/313 Test Loss: 1.321 | Test Acc: 52.543% (5145/9792)\n",
      "Epoch 7 Step 306/313 Test Loss: 1.323 | Test Acc: 52.514% (5159/9824)\n",
      "Epoch 7 Step 307/313 Test Loss: 1.323 | Test Acc: 52.476% (5172/9856)\n",
      "Epoch 7 Step 308/313 Test Loss: 1.324 | Test Acc: 52.478% (5189/9888)\n",
      "Epoch 7 Step 309/313 Test Loss: 1.324 | Test Acc: 52.490% (5207/9920)\n",
      "Epoch 7 Step 310/313 Test Loss: 1.324 | Test Acc: 52.482% (5223/9952)\n",
      "Epoch 7 Step 311/313 Test Loss: 1.324 | Test Acc: 52.484% (5240/9984)\n",
      "Epoch 7 Step 312/313 Test Loss: 1.324 | Test Acc: 52.470% (5247/10000)\n",
      "\n",
      "Epoch: 8\n",
      "Epoch 8 Step 0/1563 Loss: 1.241 | Acc: 50.000% (16/32)\n",
      "Epoch 8 Step 1/1563 Loss: 1.326 | Acc: 51.562% (33/64)\n",
      "Epoch 8 Step 2/1563 Loss: 1.463 | Acc: 50.000% (48/96)\n",
      "Epoch 8 Step 3/1563 Loss: 1.454 | Acc: 50.000% (64/128)\n",
      "Epoch 8 Step 4/1563 Loss: 1.431 | Acc: 48.750% (78/160)\n",
      "Epoch 8 Step 5/1563 Loss: 1.428 | Acc: 48.958% (94/192)\n",
      "Epoch 8 Step 6/1563 Loss: 1.370 | Acc: 50.000% (112/224)\n",
      "Epoch 8 Step 7/1563 Loss: 1.377 | Acc: 50.000% (128/256)\n",
      "Epoch 8 Step 8/1563 Loss: 1.417 | Acc: 48.611% (140/288)\n",
      "Epoch 8 Step 9/1563 Loss: 1.437 | Acc: 47.188% (151/320)\n",
      "Epoch 8 Step 10/1563 Loss: 1.438 | Acc: 47.727% (168/352)\n",
      "Epoch 8 Step 11/1563 Loss: 1.453 | Acc: 46.875% (180/384)\n",
      "Epoch 8 Step 12/1563 Loss: 1.438 | Acc: 47.356% (197/416)\n",
      "Epoch 8 Step 13/1563 Loss: 1.434 | Acc: 47.768% (214/448)\n",
      "Epoch 8 Step 14/1563 Loss: 1.426 | Acc: 47.708% (229/480)\n",
      "Epoch 8 Step 15/1563 Loss: 1.414 | Acc: 48.633% (249/512)\n",
      "Epoch 8 Step 16/1563 Loss: 1.409 | Acc: 47.978% (261/544)\n",
      "Epoch 8 Step 17/1563 Loss: 1.394 | Acc: 47.917% (276/576)\n",
      "Epoch 8 Step 18/1563 Loss: 1.392 | Acc: 48.355% (294/608)\n",
      "Epoch 8 Step 19/1563 Loss: 1.407 | Acc: 47.969% (307/640)\n",
      "Epoch 8 Step 20/1563 Loss: 1.402 | Acc: 48.363% (325/672)\n",
      "Epoch 8 Step 21/1563 Loss: 1.406 | Acc: 48.580% (342/704)\n",
      "Epoch 8 Step 22/1563 Loss: 1.403 | Acc: 48.641% (358/736)\n",
      "Epoch 8 Step 23/1563 Loss: 1.401 | Acc: 48.828% (375/768)\n",
      "Epoch 8 Step 24/1563 Loss: 1.399 | Acc: 48.875% (391/800)\n",
      "Epoch 8 Step 25/1563 Loss: 1.396 | Acc: 48.798% (406/832)\n",
      "Epoch 8 Step 26/1563 Loss: 1.391 | Acc: 49.074% (424/864)\n",
      "Epoch 8 Step 27/1563 Loss: 1.380 | Acc: 49.330% (442/896)\n",
      "Epoch 8 Step 28/1563 Loss: 1.377 | Acc: 49.461% (459/928)\n",
      "Epoch 8 Step 29/1563 Loss: 1.376 | Acc: 49.375% (474/960)\n",
      "Epoch 8 Step 30/1563 Loss: 1.367 | Acc: 49.597% (492/992)\n",
      "Epoch 8 Step 31/1563 Loss: 1.383 | Acc: 49.023% (502/1024)\n",
      "Epoch 8 Step 32/1563 Loss: 1.377 | Acc: 49.432% (522/1056)\n",
      "Epoch 8 Step 33/1563 Loss: 1.376 | Acc: 49.540% (539/1088)\n",
      "Epoch 8 Step 34/1563 Loss: 1.376 | Acc: 49.375% (553/1120)\n",
      "Epoch 8 Step 35/1563 Loss: 1.384 | Acc: 49.219% (567/1152)\n",
      "Epoch 8 Step 36/1563 Loss: 1.393 | Acc: 48.902% (579/1184)\n",
      "Epoch 8 Step 37/1563 Loss: 1.387 | Acc: 48.931% (595/1216)\n",
      "Epoch 8 Step 38/1563 Loss: 1.380 | Acc: 49.199% (614/1248)\n",
      "Epoch 8 Step 39/1563 Loss: 1.380 | Acc: 49.141% (629/1280)\n",
      "Epoch 8 Step 40/1563 Loss: 1.379 | Acc: 49.009% (643/1312)\n",
      "Epoch 8 Step 41/1563 Loss: 1.376 | Acc: 49.182% (661/1344)\n",
      "Epoch 8 Step 42/1563 Loss: 1.379 | Acc: 48.983% (674/1376)\n",
      "Epoch 8 Step 43/1563 Loss: 1.384 | Acc: 48.722% (686/1408)\n",
      "Epoch 8 Step 44/1563 Loss: 1.381 | Acc: 48.750% (702/1440)\n",
      "Epoch 8 Step 45/1563 Loss: 1.384 | Acc: 48.777% (718/1472)\n",
      "Epoch 8 Step 46/1563 Loss: 1.379 | Acc: 49.136% (739/1504)\n",
      "Epoch 8 Step 47/1563 Loss: 1.378 | Acc: 49.154% (755/1536)\n",
      "Epoch 8 Step 48/1563 Loss: 1.385 | Acc: 49.043% (769/1568)\n",
      "Epoch 8 Step 49/1563 Loss: 1.382 | Acc: 49.312% (789/1600)\n",
      "Epoch 8 Step 50/1563 Loss: 1.382 | Acc: 49.142% (802/1632)\n",
      "Epoch 8 Step 51/1563 Loss: 1.374 | Acc: 49.339% (821/1664)\n",
      "Epoch 8 Step 52/1563 Loss: 1.375 | Acc: 49.410% (838/1696)\n",
      "Epoch 8 Step 53/1563 Loss: 1.377 | Acc: 49.306% (852/1728)\n",
      "Epoch 8 Step 54/1563 Loss: 1.382 | Acc: 49.318% (868/1760)\n",
      "Epoch 8 Step 55/1563 Loss: 1.387 | Acc: 49.163% (881/1792)\n",
      "Epoch 8 Step 56/1563 Loss: 1.387 | Acc: 49.287% (899/1824)\n",
      "Epoch 8 Step 57/1563 Loss: 1.394 | Acc: 48.976% (909/1856)\n",
      "Epoch 8 Step 58/1563 Loss: 1.393 | Acc: 49.100% (927/1888)\n",
      "Epoch 8 Step 59/1563 Loss: 1.391 | Acc: 49.115% (943/1920)\n",
      "Epoch 8 Step 60/1563 Loss: 1.393 | Acc: 49.129% (959/1952)\n",
      "Epoch 8 Step 61/1563 Loss: 1.391 | Acc: 49.294% (978/1984)\n",
      "Epoch 8 Step 62/1563 Loss: 1.389 | Acc: 49.355% (995/2016)\n",
      "Epoch 8 Step 63/1563 Loss: 1.390 | Acc: 49.365% (1011/2048)\n",
      "Epoch 8 Step 64/1563 Loss: 1.387 | Acc: 49.375% (1027/2080)\n",
      "Epoch 8 Step 65/1563 Loss: 1.384 | Acc: 49.432% (1044/2112)\n",
      "Epoch 8 Step 66/1563 Loss: 1.384 | Acc: 49.487% (1061/2144)\n",
      "Epoch 8 Step 67/1563 Loss: 1.384 | Acc: 49.449% (1076/2176)\n",
      "Epoch 8 Step 68/1563 Loss: 1.383 | Acc: 49.411% (1091/2208)\n",
      "Epoch 8 Step 69/1563 Loss: 1.381 | Acc: 49.464% (1108/2240)\n",
      "Epoch 8 Step 70/1563 Loss: 1.381 | Acc: 49.516% (1125/2272)\n",
      "Epoch 8 Step 71/1563 Loss: 1.379 | Acc: 49.566% (1142/2304)\n",
      "Epoch 8 Step 72/1563 Loss: 1.377 | Acc: 49.572% (1158/2336)\n",
      "Epoch 8 Step 73/1563 Loss: 1.376 | Acc: 49.662% (1176/2368)\n",
      "Epoch 8 Step 74/1563 Loss: 1.379 | Acc: 49.542% (1189/2400)\n",
      "Epoch 8 Step 75/1563 Loss: 1.379 | Acc: 49.424% (1202/2432)\n",
      "Epoch 8 Step 76/1563 Loss: 1.382 | Acc: 49.513% (1220/2464)\n",
      "Epoch 8 Step 77/1563 Loss: 1.381 | Acc: 49.479% (1235/2496)\n",
      "Epoch 8 Step 78/1563 Loss: 1.384 | Acc: 49.407% (1249/2528)\n",
      "Epoch 8 Step 79/1563 Loss: 1.385 | Acc: 49.336% (1263/2560)\n",
      "Epoch 8 Step 80/1563 Loss: 1.383 | Acc: 49.498% (1283/2592)\n",
      "Epoch 8 Step 81/1563 Loss: 1.379 | Acc: 49.771% (1306/2624)\n",
      "Epoch 8 Step 82/1563 Loss: 1.375 | Acc: 49.925% (1326/2656)\n",
      "Epoch 8 Step 83/1563 Loss: 1.373 | Acc: 49.963% (1343/2688)\n",
      "Epoch 8 Step 84/1563 Loss: 1.374 | Acc: 49.926% (1358/2720)\n",
      "Epoch 8 Step 85/1563 Loss: 1.373 | Acc: 49.964% (1375/2752)\n",
      "Epoch 8 Step 86/1563 Loss: 1.372 | Acc: 50.108% (1395/2784)\n",
      "Epoch 8 Step 87/1563 Loss: 1.375 | Acc: 50.071% (1410/2816)\n",
      "Epoch 8 Step 88/1563 Loss: 1.379 | Acc: 50.035% (1425/2848)\n",
      "Epoch 8 Step 89/1563 Loss: 1.378 | Acc: 50.139% (1444/2880)\n",
      "Epoch 8 Step 90/1563 Loss: 1.377 | Acc: 50.103% (1459/2912)\n",
      "Epoch 8 Step 91/1563 Loss: 1.375 | Acc: 50.306% (1481/2944)\n",
      "Epoch 8 Step 92/1563 Loss: 1.377 | Acc: 50.101% (1491/2976)\n",
      "Epoch 8 Step 93/1563 Loss: 1.374 | Acc: 50.199% (1510/3008)\n",
      "Epoch 8 Step 94/1563 Loss: 1.375 | Acc: 50.230% (1527/3040)\n",
      "Epoch 8 Step 95/1563 Loss: 1.375 | Acc: 50.195% (1542/3072)\n",
      "Epoch 8 Step 96/1563 Loss: 1.376 | Acc: 50.032% (1553/3104)\n",
      "Epoch 8 Step 97/1563 Loss: 1.374 | Acc: 50.096% (1571/3136)\n",
      "Epoch 8 Step 98/1563 Loss: 1.370 | Acc: 50.253% (1592/3168)\n",
      "Epoch 8 Step 99/1563 Loss: 1.368 | Acc: 50.500% (1616/3200)\n",
      "Epoch 8 Step 100/1563 Loss: 1.366 | Acc: 50.495% (1632/3232)\n",
      "Epoch 8 Step 101/1563 Loss: 1.364 | Acc: 50.551% (1650/3264)\n",
      "Epoch 8 Step 102/1563 Loss: 1.367 | Acc: 50.546% (1666/3296)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 103/1563 Loss: 1.365 | Acc: 50.691% (1687/3328)\n",
      "Epoch 8 Step 104/1563 Loss: 1.366 | Acc: 50.655% (1702/3360)\n",
      "Epoch 8 Step 105/1563 Loss: 1.366 | Acc: 50.678% (1719/3392)\n",
      "Epoch 8 Step 106/1563 Loss: 1.367 | Acc: 50.672% (1735/3424)\n",
      "Epoch 8 Step 107/1563 Loss: 1.366 | Acc: 50.752% (1754/3456)\n",
      "Epoch 8 Step 108/1563 Loss: 1.364 | Acc: 50.831% (1773/3488)\n",
      "Epoch 8 Step 109/1563 Loss: 1.364 | Acc: 50.739% (1786/3520)\n",
      "Epoch 8 Step 110/1563 Loss: 1.367 | Acc: 50.676% (1800/3552)\n",
      "Epoch 8 Step 111/1563 Loss: 1.366 | Acc: 50.753% (1819/3584)\n",
      "Epoch 8 Step 112/1563 Loss: 1.364 | Acc: 50.913% (1841/3616)\n",
      "Epoch 8 Step 113/1563 Loss: 1.365 | Acc: 50.932% (1858/3648)\n",
      "Epoch 8 Step 114/1563 Loss: 1.364 | Acc: 51.005% (1877/3680)\n",
      "Epoch 8 Step 115/1563 Loss: 1.364 | Acc: 51.078% (1896/3712)\n",
      "Epoch 8 Step 116/1563 Loss: 1.361 | Acc: 51.229% (1918/3744)\n",
      "Epoch 8 Step 117/1563 Loss: 1.361 | Acc: 51.192% (1933/3776)\n",
      "Epoch 8 Step 118/1563 Loss: 1.362 | Acc: 51.103% (1946/3808)\n",
      "Epoch 8 Step 119/1563 Loss: 1.362 | Acc: 51.068% (1961/3840)\n",
      "Epoch 8 Step 120/1563 Loss: 1.363 | Acc: 51.111% (1979/3872)\n",
      "Epoch 8 Step 121/1563 Loss: 1.363 | Acc: 51.153% (1997/3904)\n",
      "Epoch 8 Step 122/1563 Loss: 1.363 | Acc: 51.245% (2017/3936)\n",
      "Epoch 8 Step 123/1563 Loss: 1.364 | Acc: 51.235% (2033/3968)\n",
      "Epoch 8 Step 124/1563 Loss: 1.364 | Acc: 51.300% (2052/4000)\n",
      "Epoch 8 Step 125/1563 Loss: 1.363 | Acc: 51.314% (2069/4032)\n",
      "Epoch 8 Step 126/1563 Loss: 1.360 | Acc: 51.501% (2093/4064)\n",
      "Epoch 8 Step 127/1563 Loss: 1.360 | Acc: 51.514% (2110/4096)\n",
      "Epoch 8 Step 128/1563 Loss: 1.361 | Acc: 51.526% (2127/4128)\n",
      "Epoch 8 Step 129/1563 Loss: 1.362 | Acc: 51.490% (2142/4160)\n",
      "Epoch 8 Step 130/1563 Loss: 1.361 | Acc: 51.527% (2160/4192)\n",
      "Epoch 8 Step 131/1563 Loss: 1.363 | Acc: 51.468% (2174/4224)\n",
      "Epoch 8 Step 132/1563 Loss: 1.363 | Acc: 51.480% (2191/4256)\n",
      "Epoch 8 Step 133/1563 Loss: 1.362 | Acc: 51.446% (2206/4288)\n",
      "Epoch 8 Step 134/1563 Loss: 1.363 | Acc: 51.412% (2221/4320)\n",
      "Epoch 8 Step 135/1563 Loss: 1.362 | Acc: 51.517% (2242/4352)\n",
      "Epoch 8 Step 136/1563 Loss: 1.363 | Acc: 51.551% (2260/4384)\n",
      "Epoch 8 Step 137/1563 Loss: 1.364 | Acc: 51.517% (2275/4416)\n",
      "Epoch 8 Step 138/1563 Loss: 1.364 | Acc: 51.461% (2289/4448)\n",
      "Epoch 8 Step 139/1563 Loss: 1.364 | Acc: 51.406% (2303/4480)\n",
      "Epoch 8 Step 140/1563 Loss: 1.362 | Acc: 51.485% (2323/4512)\n",
      "Epoch 8 Step 141/1563 Loss: 1.362 | Acc: 51.540% (2342/4544)\n",
      "Epoch 8 Step 142/1563 Loss: 1.361 | Acc: 51.595% (2361/4576)\n",
      "Epoch 8 Step 143/1563 Loss: 1.361 | Acc: 51.541% (2375/4608)\n",
      "Epoch 8 Step 144/1563 Loss: 1.363 | Acc: 51.444% (2387/4640)\n",
      "Epoch 8 Step 145/1563 Loss: 1.365 | Acc: 51.370% (2400/4672)\n",
      "Epoch 8 Step 146/1563 Loss: 1.364 | Acc: 51.382% (2417/4704)\n",
      "Epoch 8 Step 147/1563 Loss: 1.365 | Acc: 51.351% (2432/4736)\n",
      "Epoch 8 Step 148/1563 Loss: 1.364 | Acc: 51.384% (2450/4768)\n",
      "Epoch 8 Step 149/1563 Loss: 1.364 | Acc: 51.375% (2466/4800)\n",
      "Epoch 8 Step 150/1563 Loss: 1.364 | Acc: 51.407% (2484/4832)\n",
      "Epoch 8 Step 151/1563 Loss: 1.361 | Acc: 51.501% (2505/4864)\n",
      "Epoch 8 Step 152/1563 Loss: 1.360 | Acc: 51.593% (2526/4896)\n",
      "Epoch 8 Step 153/1563 Loss: 1.359 | Acc: 51.603% (2543/4928)\n",
      "Epoch 8 Step 154/1563 Loss: 1.358 | Acc: 51.613% (2560/4960)\n",
      "Epoch 8 Step 155/1563 Loss: 1.357 | Acc: 51.703% (2581/4992)\n",
      "Epoch 8 Step 156/1563 Loss: 1.357 | Acc: 51.712% (2598/5024)\n",
      "Epoch 8 Step 157/1563 Loss: 1.355 | Acc: 51.760% (2617/5056)\n",
      "Epoch 8 Step 158/1563 Loss: 1.356 | Acc: 51.671% (2629/5088)\n",
      "Epoch 8 Step 159/1563 Loss: 1.356 | Acc: 51.660% (2645/5120)\n",
      "Epoch 8 Step 160/1563 Loss: 1.356 | Acc: 51.650% (2661/5152)\n",
      "Epoch 8 Step 161/1563 Loss: 1.355 | Acc: 51.601% (2675/5184)\n",
      "Epoch 8 Step 162/1563 Loss: 1.355 | Acc: 51.630% (2693/5216)\n",
      "Epoch 8 Step 163/1563 Loss: 1.354 | Acc: 51.677% (2712/5248)\n",
      "Epoch 8 Step 164/1563 Loss: 1.353 | Acc: 51.667% (2728/5280)\n",
      "Epoch 8 Step 165/1563 Loss: 1.352 | Acc: 51.694% (2746/5312)\n",
      "Epoch 8 Step 166/1563 Loss: 1.352 | Acc: 51.665% (2761/5344)\n",
      "Epoch 8 Step 167/1563 Loss: 1.351 | Acc: 51.767% (2783/5376)\n",
      "Epoch 8 Step 168/1563 Loss: 1.350 | Acc: 51.831% (2803/5408)\n",
      "Epoch 8 Step 169/1563 Loss: 1.350 | Acc: 51.820% (2819/5440)\n",
      "Epoch 8 Step 170/1563 Loss: 1.350 | Acc: 51.809% (2835/5472)\n",
      "Epoch 8 Step 171/1563 Loss: 1.349 | Acc: 51.871% (2855/5504)\n",
      "Epoch 8 Step 172/1563 Loss: 1.350 | Acc: 51.788% (2867/5536)\n",
      "Epoch 8 Step 173/1563 Loss: 1.351 | Acc: 51.742% (2881/5568)\n",
      "Epoch 8 Step 174/1563 Loss: 1.351 | Acc: 51.714% (2896/5600)\n",
      "Epoch 8 Step 175/1563 Loss: 1.351 | Acc: 51.793% (2917/5632)\n",
      "Epoch 8 Step 176/1563 Loss: 1.352 | Acc: 51.783% (2933/5664)\n",
      "Epoch 8 Step 177/1563 Loss: 1.351 | Acc: 51.826% (2952/5696)\n",
      "Epoch 8 Step 178/1563 Loss: 1.349 | Acc: 51.885% (2972/5728)\n",
      "Epoch 8 Step 179/1563 Loss: 1.349 | Acc: 51.840% (2986/5760)\n",
      "Epoch 8 Step 180/1563 Loss: 1.350 | Acc: 51.796% (3000/5792)\n",
      "Epoch 8 Step 181/1563 Loss: 1.350 | Acc: 51.803% (3017/5824)\n",
      "Epoch 8 Step 182/1563 Loss: 1.351 | Acc: 51.776% (3032/5856)\n",
      "Epoch 8 Step 183/1563 Loss: 1.350 | Acc: 51.749% (3047/5888)\n",
      "Epoch 8 Step 184/1563 Loss: 1.350 | Acc: 51.740% (3063/5920)\n",
      "Epoch 8 Step 185/1563 Loss: 1.348 | Acc: 51.781% (3082/5952)\n",
      "Epoch 8 Step 186/1563 Loss: 1.346 | Acc: 51.872% (3104/5984)\n",
      "Epoch 8 Step 187/1563 Loss: 1.347 | Acc: 51.845% (3119/6016)\n",
      "Epoch 8 Step 188/1563 Loss: 1.347 | Acc: 51.802% (3133/6048)\n",
      "Epoch 8 Step 189/1563 Loss: 1.347 | Acc: 51.842% (3152/6080)\n",
      "Epoch 8 Step 190/1563 Loss: 1.349 | Acc: 51.816% (3167/6112)\n",
      "Epoch 8 Step 191/1563 Loss: 1.348 | Acc: 51.855% (3186/6144)\n",
      "Epoch 8 Step 192/1563 Loss: 1.347 | Acc: 51.846% (3202/6176)\n",
      "Epoch 8 Step 193/1563 Loss: 1.347 | Acc: 51.804% (3216/6208)\n",
      "Epoch 8 Step 194/1563 Loss: 1.346 | Acc: 51.843% (3235/6240)\n",
      "Epoch 8 Step 195/1563 Loss: 1.346 | Acc: 51.802% (3249/6272)\n",
      "Epoch 8 Step 196/1563 Loss: 1.346 | Acc: 51.824% (3267/6304)\n",
      "Epoch 8 Step 197/1563 Loss: 1.347 | Acc: 51.768% (3280/6336)\n",
      "Epoch 8 Step 198/1563 Loss: 1.346 | Acc: 51.837% (3301/6368)\n",
      "Epoch 8 Step 199/1563 Loss: 1.347 | Acc: 51.844% (3318/6400)\n",
      "Epoch 8 Step 200/1563 Loss: 1.348 | Acc: 51.788% (3331/6432)\n",
      "Epoch 8 Step 201/1563 Loss: 1.348 | Acc: 51.764% (3346/6464)\n",
      "Epoch 8 Step 202/1563 Loss: 1.349 | Acc: 51.724% (3360/6496)\n",
      "Epoch 8 Step 203/1563 Loss: 1.351 | Acc: 51.624% (3370/6528)\n",
      "Epoch 8 Step 204/1563 Loss: 1.350 | Acc: 51.646% (3388/6560)\n",
      "Epoch 8 Step 205/1563 Loss: 1.351 | Acc: 51.654% (3405/6592)\n",
      "Epoch 8 Step 206/1563 Loss: 1.351 | Acc: 51.646% (3421/6624)\n",
      "Epoch 8 Step 207/1563 Loss: 1.351 | Acc: 51.683% (3440/6656)\n",
      "Epoch 8 Step 208/1563 Loss: 1.350 | Acc: 51.734% (3460/6688)\n",
      "Epoch 8 Step 209/1563 Loss: 1.349 | Acc: 51.726% (3476/6720)\n",
      "Epoch 8 Step 210/1563 Loss: 1.349 | Acc: 51.703% (3491/6752)\n",
      "Epoch 8 Step 211/1563 Loss: 1.348 | Acc: 51.739% (3510/6784)\n",
      "Epoch 8 Step 212/1563 Loss: 1.349 | Acc: 51.717% (3525/6816)\n",
      "Epoch 8 Step 213/1563 Loss: 1.350 | Acc: 51.621% (3535/6848)\n",
      "Epoch 8 Step 214/1563 Loss: 1.350 | Acc: 51.599% (3550/6880)\n",
      "Epoch 8 Step 215/1563 Loss: 1.350 | Acc: 51.577% (3565/6912)\n",
      "Epoch 8 Step 216/1563 Loss: 1.351 | Acc: 51.613% (3584/6944)\n",
      "Epoch 8 Step 217/1563 Loss: 1.350 | Acc: 51.677% (3605/6976)\n",
      "Epoch 8 Step 218/1563 Loss: 1.349 | Acc: 51.727% (3625/7008)\n",
      "Epoch 8 Step 219/1563 Loss: 1.347 | Acc: 51.776% (3645/7040)\n",
      "Epoch 8 Step 220/1563 Loss: 1.346 | Acc: 51.824% (3665/7072)\n",
      "Epoch 8 Step 221/1563 Loss: 1.346 | Acc: 51.731% (3675/7104)\n",
      "Epoch 8 Step 222/1563 Loss: 1.347 | Acc: 51.738% (3692/7136)\n",
      "Epoch 8 Step 223/1563 Loss: 1.347 | Acc: 51.744% (3709/7168)\n",
      "Epoch 8 Step 224/1563 Loss: 1.347 | Acc: 51.778% (3728/7200)\n",
      "Epoch 8 Step 225/1563 Loss: 1.346 | Acc: 51.798% (3746/7232)\n",
      "Epoch 8 Step 226/1563 Loss: 1.348 | Acc: 51.748% (3759/7264)\n",
      "Epoch 8 Step 227/1563 Loss: 1.347 | Acc: 51.741% (3775/7296)\n",
      "Epoch 8 Step 228/1563 Loss: 1.348 | Acc: 51.774% (3794/7328)\n",
      "Epoch 8 Step 229/1563 Loss: 1.348 | Acc: 51.780% (3811/7360)\n",
      "Epoch 8 Step 230/1563 Loss: 1.348 | Acc: 51.732% (3824/7392)\n",
      "Epoch 8 Step 231/1563 Loss: 1.348 | Acc: 51.751% (3842/7424)\n",
      "Epoch 8 Step 232/1563 Loss: 1.348 | Acc: 51.730% (3857/7456)\n",
      "Epoch 8 Step 233/1563 Loss: 1.349 | Acc: 51.643% (3867/7488)\n",
      "Epoch 8 Step 234/1563 Loss: 1.349 | Acc: 51.676% (3886/7520)\n",
      "Epoch 8 Step 235/1563 Loss: 1.350 | Acc: 51.629% (3899/7552)\n",
      "Epoch 8 Step 236/1563 Loss: 1.349 | Acc: 51.648% (3917/7584)\n",
      "Epoch 8 Step 237/1563 Loss: 1.349 | Acc: 51.668% (3935/7616)\n",
      "Epoch 8 Step 238/1563 Loss: 1.349 | Acc: 51.700% (3954/7648)\n",
      "Epoch 8 Step 239/1563 Loss: 1.348 | Acc: 51.732% (3973/7680)\n",
      "Epoch 8 Step 240/1563 Loss: 1.348 | Acc: 51.738% (3990/7712)\n",
      "Epoch 8 Step 241/1563 Loss: 1.348 | Acc: 51.769% (4009/7744)\n",
      "Epoch 8 Step 242/1563 Loss: 1.349 | Acc: 51.800% (4028/7776)\n",
      "Epoch 8 Step 243/1563 Loss: 1.347 | Acc: 51.857% (4049/7808)\n",
      "Epoch 8 Step 244/1563 Loss: 1.348 | Acc: 51.824% (4063/7840)\n",
      "Epoch 8 Step 245/1563 Loss: 1.347 | Acc: 51.893% (4085/7872)\n",
      "Epoch 8 Step 246/1563 Loss: 1.347 | Acc: 51.872% (4100/7904)\n",
      "Epoch 8 Step 247/1563 Loss: 1.347 | Acc: 51.878% (4117/7936)\n",
      "Epoch 8 Step 248/1563 Loss: 1.347 | Acc: 51.857% (4132/7968)\n",
      "Epoch 8 Step 249/1563 Loss: 1.348 | Acc: 51.800% (4144/8000)\n",
      "Epoch 8 Step 250/1563 Loss: 1.348 | Acc: 51.780% (4159/8032)\n",
      "Epoch 8 Step 251/1563 Loss: 1.347 | Acc: 51.773% (4175/8064)\n",
      "Epoch 8 Step 252/1563 Loss: 1.348 | Acc: 51.791% (4193/8096)\n",
      "Epoch 8 Step 253/1563 Loss: 1.348 | Acc: 51.735% (4205/8128)\n",
      "Epoch 8 Step 254/1563 Loss: 1.349 | Acc: 51.789% (4226/8160)\n",
      "Epoch 8 Step 255/1563 Loss: 1.350 | Acc: 51.782% (4242/8192)\n",
      "Epoch 8 Step 256/1563 Loss: 1.349 | Acc: 51.775% (4258/8224)\n",
      "Epoch 8 Step 257/1563 Loss: 1.349 | Acc: 51.744% (4272/8256)\n",
      "Epoch 8 Step 258/1563 Loss: 1.350 | Acc: 51.725% (4287/8288)\n",
      "Epoch 8 Step 259/1563 Loss: 1.350 | Acc: 51.707% (4302/8320)\n",
      "Epoch 8 Step 260/1563 Loss: 1.350 | Acc: 51.736% (4321/8352)\n",
      "Epoch 8 Step 261/1563 Loss: 1.350 | Acc: 51.741% (4338/8384)\n",
      "Epoch 8 Step 262/1563 Loss: 1.350 | Acc: 51.735% (4354/8416)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 263/1563 Loss: 1.349 | Acc: 51.776% (4374/8448)\n",
      "Epoch 8 Step 264/1563 Loss: 1.348 | Acc: 51.792% (4392/8480)\n",
      "Epoch 8 Step 265/1563 Loss: 1.347 | Acc: 51.821% (4411/8512)\n",
      "Epoch 8 Step 266/1563 Loss: 1.346 | Acc: 51.884% (4433/8544)\n",
      "Epoch 8 Step 267/1563 Loss: 1.345 | Acc: 51.936% (4454/8576)\n",
      "Epoch 8 Step 268/1563 Loss: 1.345 | Acc: 51.928% (4470/8608)\n",
      "Epoch 8 Step 269/1563 Loss: 1.345 | Acc: 51.933% (4487/8640)\n",
      "Epoch 8 Step 270/1563 Loss: 1.345 | Acc: 51.914% (4502/8672)\n",
      "Epoch 8 Step 271/1563 Loss: 1.344 | Acc: 51.896% (4517/8704)\n",
      "Epoch 8 Step 272/1563 Loss: 1.344 | Acc: 51.900% (4534/8736)\n",
      "Epoch 8 Step 273/1563 Loss: 1.343 | Acc: 51.939% (4554/8768)\n",
      "Epoch 8 Step 274/1563 Loss: 1.344 | Acc: 51.920% (4569/8800)\n",
      "Epoch 8 Step 275/1563 Loss: 1.345 | Acc: 51.902% (4584/8832)\n",
      "Epoch 8 Step 276/1563 Loss: 1.344 | Acc: 51.929% (4603/8864)\n",
      "Epoch 8 Step 277/1563 Loss: 1.345 | Acc: 51.911% (4618/8896)\n",
      "Epoch 8 Step 278/1563 Loss: 1.345 | Acc: 51.915% (4635/8928)\n",
      "Epoch 8 Step 279/1563 Loss: 1.344 | Acc: 51.975% (4657/8960)\n",
      "Epoch 8 Step 280/1563 Loss: 1.343 | Acc: 51.991% (4675/8992)\n",
      "Epoch 8 Step 281/1563 Loss: 1.344 | Acc: 51.995% (4692/9024)\n",
      "Epoch 8 Step 282/1563 Loss: 1.343 | Acc: 52.032% (4712/9056)\n",
      "Epoch 8 Step 283/1563 Loss: 1.344 | Acc: 52.014% (4727/9088)\n",
      "Epoch 8 Step 284/1563 Loss: 1.345 | Acc: 51.952% (4738/9120)\n",
      "Epoch 8 Step 285/1563 Loss: 1.346 | Acc: 51.912% (4751/9152)\n",
      "Epoch 8 Step 286/1563 Loss: 1.346 | Acc: 51.905% (4767/9184)\n",
      "Epoch 8 Step 287/1563 Loss: 1.348 | Acc: 51.812% (4775/9216)\n",
      "Epoch 8 Step 288/1563 Loss: 1.348 | Acc: 51.784% (4789/9248)\n",
      "Epoch 8 Step 289/1563 Loss: 1.348 | Acc: 51.778% (4805/9280)\n",
      "Epoch 8 Step 290/1563 Loss: 1.349 | Acc: 51.750% (4819/9312)\n",
      "Epoch 8 Step 291/1563 Loss: 1.348 | Acc: 51.798% (4840/9344)\n",
      "Epoch 8 Step 292/1563 Loss: 1.349 | Acc: 51.781% (4855/9376)\n",
      "Epoch 8 Step 293/1563 Loss: 1.348 | Acc: 51.828% (4876/9408)\n",
      "Epoch 8 Step 294/1563 Loss: 1.348 | Acc: 51.833% (4893/9440)\n",
      "Epoch 8 Step 295/1563 Loss: 1.348 | Acc: 51.805% (4907/9472)\n",
      "Epoch 8 Step 296/1563 Loss: 1.349 | Acc: 51.810% (4924/9504)\n",
      "Epoch 8 Step 297/1563 Loss: 1.349 | Acc: 51.772% (4937/9536)\n",
      "Epoch 8 Step 298/1563 Loss: 1.350 | Acc: 51.766% (4953/9568)\n",
      "Epoch 8 Step 299/1563 Loss: 1.350 | Acc: 51.740% (4967/9600)\n",
      "Epoch 8 Step 300/1563 Loss: 1.349 | Acc: 51.765% (4986/9632)\n",
      "Epoch 8 Step 301/1563 Loss: 1.349 | Acc: 51.749% (5001/9664)\n",
      "Epoch 8 Step 302/1563 Loss: 1.349 | Acc: 51.712% (5014/9696)\n",
      "Epoch 8 Step 303/1563 Loss: 1.350 | Acc: 51.645% (5024/9728)\n",
      "Epoch 8 Step 304/1563 Loss: 1.349 | Acc: 51.711% (5047/9760)\n",
      "Epoch 8 Step 305/1563 Loss: 1.349 | Acc: 51.726% (5065/9792)\n",
      "Epoch 8 Step 306/1563 Loss: 1.350 | Acc: 51.700% (5079/9824)\n",
      "Epoch 8 Step 307/1563 Loss: 1.350 | Acc: 51.684% (5094/9856)\n",
      "Epoch 8 Step 308/1563 Loss: 1.351 | Acc: 51.618% (5104/9888)\n",
      "Epoch 8 Step 309/1563 Loss: 1.351 | Acc: 51.613% (5120/9920)\n",
      "Epoch 8 Step 310/1563 Loss: 1.352 | Acc: 51.588% (5134/9952)\n",
      "Epoch 8 Step 311/1563 Loss: 1.352 | Acc: 51.593% (5151/9984)\n",
      "Epoch 8 Step 312/1563 Loss: 1.352 | Acc: 51.597% (5168/10016)\n",
      "Epoch 8 Step 313/1563 Loss: 1.352 | Acc: 51.622% (5187/10048)\n",
      "Epoch 8 Step 314/1563 Loss: 1.352 | Acc: 51.627% (5204/10080)\n",
      "Epoch 8 Step 315/1563 Loss: 1.352 | Acc: 51.642% (5222/10112)\n",
      "Epoch 8 Step 316/1563 Loss: 1.352 | Acc: 51.656% (5240/10144)\n",
      "Epoch 8 Step 317/1563 Loss: 1.352 | Acc: 51.641% (5255/10176)\n",
      "Epoch 8 Step 318/1563 Loss: 1.352 | Acc: 51.636% (5271/10208)\n",
      "Epoch 8 Step 319/1563 Loss: 1.353 | Acc: 51.621% (5286/10240)\n",
      "Epoch 8 Step 320/1563 Loss: 1.352 | Acc: 51.626% (5303/10272)\n",
      "Epoch 8 Step 321/1563 Loss: 1.352 | Acc: 51.621% (5319/10304)\n",
      "Epoch 8 Step 322/1563 Loss: 1.352 | Acc: 51.616% (5335/10336)\n",
      "Epoch 8 Step 323/1563 Loss: 1.351 | Acc: 51.659% (5356/10368)\n",
      "Epoch 8 Step 324/1563 Loss: 1.350 | Acc: 51.654% (5372/10400)\n",
      "Epoch 8 Step 325/1563 Loss: 1.350 | Acc: 51.658% (5389/10432)\n",
      "Epoch 8 Step 326/1563 Loss: 1.351 | Acc: 51.644% (5404/10464)\n",
      "Epoch 8 Step 327/1563 Loss: 1.351 | Acc: 51.639% (5420/10496)\n",
      "Epoch 8 Step 328/1563 Loss: 1.353 | Acc: 51.586% (5431/10528)\n",
      "Epoch 8 Step 329/1563 Loss: 1.353 | Acc: 51.534% (5442/10560)\n",
      "Epoch 8 Step 330/1563 Loss: 1.354 | Acc: 51.548% (5460/10592)\n",
      "Epoch 8 Step 331/1563 Loss: 1.355 | Acc: 51.506% (5472/10624)\n",
      "Epoch 8 Step 332/1563 Loss: 1.356 | Acc: 51.464% (5484/10656)\n",
      "Epoch 8 Step 333/1563 Loss: 1.356 | Acc: 51.478% (5502/10688)\n",
      "Epoch 8 Step 334/1563 Loss: 1.356 | Acc: 51.493% (5520/10720)\n",
      "Epoch 8 Step 335/1563 Loss: 1.357 | Acc: 51.469% (5534/10752)\n",
      "Epoch 8 Step 336/1563 Loss: 1.357 | Acc: 51.465% (5550/10784)\n",
      "Epoch 8 Step 337/1563 Loss: 1.358 | Acc: 51.452% (5565/10816)\n",
      "Epoch 8 Step 338/1563 Loss: 1.359 | Acc: 51.383% (5574/10848)\n",
      "Epoch 8 Step 339/1563 Loss: 1.359 | Acc: 51.379% (5590/10880)\n",
      "Epoch 8 Step 340/1563 Loss: 1.358 | Acc: 51.420% (5611/10912)\n",
      "Epoch 8 Step 341/1563 Loss: 1.358 | Acc: 51.425% (5628/10944)\n",
      "Epoch 8 Step 342/1563 Loss: 1.358 | Acc: 51.412% (5643/10976)\n",
      "Epoch 8 Step 343/1563 Loss: 1.358 | Acc: 51.399% (5658/11008)\n",
      "Epoch 8 Step 344/1563 Loss: 1.357 | Acc: 51.440% (5679/11040)\n",
      "Epoch 8 Step 345/1563 Loss: 1.357 | Acc: 51.436% (5695/11072)\n",
      "Epoch 8 Step 346/1563 Loss: 1.357 | Acc: 51.423% (5710/11104)\n",
      "Epoch 8 Step 347/1563 Loss: 1.357 | Acc: 51.374% (5721/11136)\n",
      "Epoch 8 Step 348/1563 Loss: 1.358 | Acc: 51.343% (5734/11168)\n",
      "Epoch 8 Step 349/1563 Loss: 1.359 | Acc: 51.321% (5748/11200)\n",
      "Epoch 8 Step 350/1563 Loss: 1.360 | Acc: 51.273% (5759/11232)\n",
      "Epoch 8 Step 351/1563 Loss: 1.360 | Acc: 51.287% (5777/11264)\n",
      "Epoch 8 Step 352/1563 Loss: 1.360 | Acc: 51.310% (5796/11296)\n",
      "Epoch 8 Step 353/1563 Loss: 1.359 | Acc: 51.315% (5813/11328)\n",
      "Epoch 8 Step 354/1563 Loss: 1.360 | Acc: 51.276% (5825/11360)\n",
      "Epoch 8 Step 355/1563 Loss: 1.360 | Acc: 51.255% (5839/11392)\n",
      "Epoch 8 Step 356/1563 Loss: 1.360 | Acc: 51.225% (5852/11424)\n",
      "Epoch 8 Step 357/1563 Loss: 1.361 | Acc: 51.196% (5865/11456)\n",
      "Epoch 8 Step 358/1563 Loss: 1.361 | Acc: 51.175% (5879/11488)\n",
      "Epoch 8 Step 359/1563 Loss: 1.360 | Acc: 51.233% (5902/11520)\n",
      "Epoch 8 Step 360/1563 Loss: 1.360 | Acc: 51.264% (5922/11552)\n",
      "Epoch 8 Step 361/1563 Loss: 1.360 | Acc: 51.269% (5939/11584)\n",
      "Epoch 8 Step 362/1563 Loss: 1.360 | Acc: 51.248% (5953/11616)\n",
      "Epoch 8 Step 363/1563 Loss: 1.361 | Acc: 51.219% (5966/11648)\n",
      "Epoch 8 Step 364/1563 Loss: 1.361 | Acc: 51.224% (5983/11680)\n",
      "Epoch 8 Step 365/1563 Loss: 1.361 | Acc: 51.238% (6001/11712)\n",
      "Epoch 8 Step 366/1563 Loss: 1.361 | Acc: 51.243% (6018/11744)\n",
      "Epoch 8 Step 367/1563 Loss: 1.360 | Acc: 51.265% (6037/11776)\n",
      "Epoch 8 Step 368/1563 Loss: 1.361 | Acc: 51.253% (6052/11808)\n",
      "Epoch 8 Step 369/1563 Loss: 1.362 | Acc: 51.225% (6065/11840)\n",
      "Epoch 8 Step 370/1563 Loss: 1.361 | Acc: 51.272% (6087/11872)\n",
      "Epoch 8 Step 371/1563 Loss: 1.361 | Acc: 51.268% (6103/11904)\n",
      "Epoch 8 Step 372/1563 Loss: 1.361 | Acc: 51.265% (6119/11936)\n",
      "Epoch 8 Step 373/1563 Loss: 1.361 | Acc: 51.270% (6136/11968)\n",
      "Epoch 8 Step 374/1563 Loss: 1.361 | Acc: 51.283% (6154/12000)\n",
      "Epoch 8 Step 375/1563 Loss: 1.362 | Acc: 51.222% (6163/12032)\n",
      "Epoch 8 Step 376/1563 Loss: 1.363 | Acc: 51.219% (6179/12064)\n",
      "Epoch 8 Step 377/1563 Loss: 1.363 | Acc: 51.240% (6198/12096)\n",
      "Epoch 8 Step 378/1563 Loss: 1.363 | Acc: 51.212% (6211/12128)\n",
      "Epoch 8 Step 379/1563 Loss: 1.362 | Acc: 51.225% (6229/12160)\n",
      "Epoch 8 Step 380/1563 Loss: 1.363 | Acc: 51.181% (6240/12192)\n",
      "Epoch 8 Step 381/1563 Loss: 1.363 | Acc: 51.162% (6254/12224)\n",
      "Epoch 8 Step 382/1563 Loss: 1.363 | Acc: 51.167% (6271/12256)\n",
      "Epoch 8 Step 383/1563 Loss: 1.363 | Acc: 51.156% (6286/12288)\n",
      "Epoch 8 Step 384/1563 Loss: 1.363 | Acc: 51.128% (6299/12320)\n",
      "Epoch 8 Step 385/1563 Loss: 1.363 | Acc: 51.109% (6313/12352)\n",
      "Epoch 8 Step 386/1563 Loss: 1.364 | Acc: 51.098% (6328/12384)\n",
      "Epoch 8 Step 387/1563 Loss: 1.364 | Acc: 51.120% (6347/12416)\n",
      "Epoch 8 Step 388/1563 Loss: 1.364 | Acc: 51.149% (6367/12448)\n",
      "Epoch 8 Step 389/1563 Loss: 1.364 | Acc: 51.122% (6380/12480)\n",
      "Epoch 8 Step 390/1563 Loss: 1.364 | Acc: 51.135% (6398/12512)\n",
      "Epoch 8 Step 391/1563 Loss: 1.364 | Acc: 51.140% (6415/12544)\n",
      "Epoch 8 Step 392/1563 Loss: 1.364 | Acc: 51.129% (6430/12576)\n",
      "Epoch 8 Step 393/1563 Loss: 1.365 | Acc: 51.118% (6445/12608)\n",
      "Epoch 8 Step 394/1563 Loss: 1.365 | Acc: 51.131% (6463/12640)\n",
      "Epoch 8 Step 395/1563 Loss: 1.364 | Acc: 51.121% (6478/12672)\n",
      "Epoch 8 Step 396/1563 Loss: 1.364 | Acc: 51.141% (6497/12704)\n",
      "Epoch 8 Step 397/1563 Loss: 1.365 | Acc: 51.123% (6511/12736)\n",
      "Epoch 8 Step 398/1563 Loss: 1.365 | Acc: 51.096% (6524/12768)\n",
      "Epoch 8 Step 399/1563 Loss: 1.365 | Acc: 51.086% (6539/12800)\n",
      "Epoch 8 Step 400/1563 Loss: 1.366 | Acc: 51.075% (6554/12832)\n",
      "Epoch 8 Step 401/1563 Loss: 1.366 | Acc: 51.042% (6566/12864)\n",
      "Epoch 8 Step 402/1563 Loss: 1.366 | Acc: 51.039% (6582/12896)\n",
      "Epoch 8 Step 403/1563 Loss: 1.366 | Acc: 51.060% (6601/12928)\n",
      "Epoch 8 Step 404/1563 Loss: 1.367 | Acc: 51.026% (6613/12960)\n",
      "Epoch 8 Step 405/1563 Loss: 1.368 | Acc: 50.993% (6625/12992)\n",
      "Epoch 8 Step 406/1563 Loss: 1.368 | Acc: 50.998% (6642/13024)\n",
      "Epoch 8 Step 407/1563 Loss: 1.367 | Acc: 51.003% (6659/13056)\n",
      "Epoch 8 Step 408/1563 Loss: 1.367 | Acc: 51.001% (6675/13088)\n",
      "Epoch 8 Step 409/1563 Loss: 1.367 | Acc: 51.029% (6695/13120)\n",
      "Epoch 8 Step 410/1563 Loss: 1.367 | Acc: 51.019% (6710/13152)\n",
      "Epoch 8 Step 411/1563 Loss: 1.366 | Acc: 51.047% (6730/13184)\n",
      "Epoch 8 Step 412/1563 Loss: 1.367 | Acc: 51.006% (6741/13216)\n",
      "Epoch 8 Step 413/1563 Loss: 1.367 | Acc: 51.011% (6758/13248)\n",
      "Epoch 8 Step 414/1563 Loss: 1.367 | Acc: 50.986% (6771/13280)\n",
      "Epoch 8 Step 415/1563 Loss: 1.367 | Acc: 51.007% (6790/13312)\n",
      "Epoch 8 Step 416/1563 Loss: 1.367 | Acc: 51.034% (6810/13344)\n",
      "Epoch 8 Step 417/1563 Loss: 1.367 | Acc: 51.032% (6826/13376)\n",
      "Epoch 8 Step 418/1563 Loss: 1.366 | Acc: 51.044% (6844/13408)\n",
      "Epoch 8 Step 419/1563 Loss: 1.367 | Acc: 51.034% (6859/13440)\n",
      "Epoch 8 Step 420/1563 Loss: 1.366 | Acc: 51.039% (6876/13472)\n",
      "Epoch 8 Step 421/1563 Loss: 1.366 | Acc: 51.029% (6891/13504)\n",
      "Epoch 8 Step 422/1563 Loss: 1.366 | Acc: 51.071% (6913/13536)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 423/1563 Loss: 1.366 | Acc: 51.032% (6924/13568)\n",
      "Epoch 8 Step 424/1563 Loss: 1.366 | Acc: 51.037% (6941/13600)\n",
      "Epoch 8 Step 425/1563 Loss: 1.366 | Acc: 51.034% (6957/13632)\n",
      "Epoch 8 Step 426/1563 Loss: 1.366 | Acc: 51.003% (6969/13664)\n",
      "Epoch 8 Step 427/1563 Loss: 1.366 | Acc: 50.993% (6984/13696)\n",
      "Epoch 8 Step 428/1563 Loss: 1.367 | Acc: 50.983% (6999/13728)\n",
      "Epoch 8 Step 429/1563 Loss: 1.368 | Acc: 50.967% (7013/13760)\n",
      "Epoch 8 Step 430/1563 Loss: 1.368 | Acc: 50.964% (7029/13792)\n",
      "Epoch 8 Step 431/1563 Loss: 1.368 | Acc: 50.991% (7049/13824)\n",
      "Epoch 8 Step 432/1563 Loss: 1.368 | Acc: 50.974% (7063/13856)\n",
      "Epoch 8 Step 433/1563 Loss: 1.367 | Acc: 51.001% (7083/13888)\n",
      "Epoch 8 Step 434/1563 Loss: 1.367 | Acc: 51.006% (7100/13920)\n",
      "Epoch 8 Step 435/1563 Loss: 1.367 | Acc: 51.018% (7118/13952)\n",
      "Epoch 8 Step 436/1563 Loss: 1.367 | Acc: 51.008% (7133/13984)\n",
      "Epoch 8 Step 437/1563 Loss: 1.367 | Acc: 51.013% (7150/14016)\n",
      "Epoch 8 Step 438/1563 Loss: 1.367 | Acc: 51.054% (7172/14048)\n",
      "Epoch 8 Step 439/1563 Loss: 1.366 | Acc: 51.108% (7196/14080)\n",
      "Epoch 8 Step 440/1563 Loss: 1.366 | Acc: 51.113% (7213/14112)\n",
      "Epoch 8 Step 441/1563 Loss: 1.365 | Acc: 51.117% (7230/14144)\n",
      "Epoch 8 Step 442/1563 Loss: 1.365 | Acc: 51.143% (7250/14176)\n",
      "Epoch 8 Step 443/1563 Loss: 1.365 | Acc: 51.154% (7268/14208)\n",
      "Epoch 8 Step 444/1563 Loss: 1.365 | Acc: 51.152% (7284/14240)\n",
      "Epoch 8 Step 445/1563 Loss: 1.365 | Acc: 51.163% (7302/14272)\n",
      "Epoch 8 Step 446/1563 Loss: 1.364 | Acc: 51.188% (7322/14304)\n",
      "Epoch 8 Step 447/1563 Loss: 1.365 | Acc: 51.151% (7333/14336)\n",
      "Epoch 8 Step 448/1563 Loss: 1.365 | Acc: 51.134% (7347/14368)\n",
      "Epoch 8 Step 449/1563 Loss: 1.365 | Acc: 51.132% (7363/14400)\n",
      "Epoch 8 Step 450/1563 Loss: 1.366 | Acc: 51.116% (7377/14432)\n",
      "Epoch 8 Step 451/1563 Loss: 1.366 | Acc: 51.113% (7393/14464)\n",
      "Epoch 8 Step 452/1563 Loss: 1.366 | Acc: 51.097% (7407/14496)\n",
      "Epoch 8 Step 453/1563 Loss: 1.366 | Acc: 51.094% (7423/14528)\n",
      "Epoch 8 Step 454/1563 Loss: 1.366 | Acc: 51.071% (7436/14560)\n",
      "Epoch 8 Step 455/1563 Loss: 1.366 | Acc: 51.076% (7453/14592)\n",
      "Epoch 8 Step 456/1563 Loss: 1.366 | Acc: 51.074% (7469/14624)\n",
      "Epoch 8 Step 457/1563 Loss: 1.366 | Acc: 51.071% (7485/14656)\n",
      "Epoch 8 Step 458/1563 Loss: 1.366 | Acc: 51.048% (7498/14688)\n",
      "Epoch 8 Step 459/1563 Loss: 1.366 | Acc: 51.046% (7514/14720)\n",
      "Epoch 8 Step 460/1563 Loss: 1.366 | Acc: 51.030% (7528/14752)\n",
      "Epoch 8 Step 461/1563 Loss: 1.366 | Acc: 51.021% (7543/14784)\n",
      "Epoch 8 Step 462/1563 Loss: 1.366 | Acc: 51.033% (7561/14816)\n",
      "Epoch 8 Step 463/1563 Loss: 1.366 | Acc: 51.057% (7581/14848)\n",
      "Epoch 8 Step 464/1563 Loss: 1.367 | Acc: 51.075% (7600/14880)\n",
      "Epoch 8 Step 465/1563 Loss: 1.366 | Acc: 51.080% (7617/14912)\n",
      "Epoch 8 Step 466/1563 Loss: 1.366 | Acc: 51.071% (7632/14944)\n",
      "Epoch 8 Step 467/1563 Loss: 1.366 | Acc: 51.102% (7653/14976)\n",
      "Epoch 8 Step 468/1563 Loss: 1.366 | Acc: 51.093% (7668/15008)\n",
      "Epoch 8 Step 469/1563 Loss: 1.366 | Acc: 51.064% (7680/15040)\n",
      "Epoch 8 Step 470/1563 Loss: 1.366 | Acc: 51.101% (7702/15072)\n",
      "Epoch 8 Step 471/1563 Loss: 1.366 | Acc: 51.092% (7717/15104)\n",
      "Epoch 8 Step 472/1563 Loss: 1.366 | Acc: 51.090% (7733/15136)\n",
      "Epoch 8 Step 473/1563 Loss: 1.366 | Acc: 51.114% (7753/15168)\n",
      "Epoch 8 Step 474/1563 Loss: 1.366 | Acc: 51.099% (7767/15200)\n",
      "Epoch 8 Step 475/1563 Loss: 1.366 | Acc: 51.110% (7785/15232)\n",
      "Epoch 8 Step 476/1563 Loss: 1.366 | Acc: 51.107% (7801/15264)\n",
      "Epoch 8 Step 477/1563 Loss: 1.366 | Acc: 51.118% (7819/15296)\n",
      "Epoch 8 Step 478/1563 Loss: 1.365 | Acc: 51.122% (7836/15328)\n",
      "Epoch 8 Step 479/1563 Loss: 1.365 | Acc: 51.133% (7854/15360)\n",
      "Epoch 8 Step 480/1563 Loss: 1.365 | Acc: 51.130% (7870/15392)\n",
      "Epoch 8 Step 481/1563 Loss: 1.364 | Acc: 51.148% (7889/15424)\n",
      "Epoch 8 Step 482/1563 Loss: 1.364 | Acc: 51.171% (7909/15456)\n",
      "Epoch 8 Step 483/1563 Loss: 1.364 | Acc: 51.169% (7925/15488)\n",
      "Epoch 8 Step 484/1563 Loss: 1.363 | Acc: 51.179% (7943/15520)\n",
      "Epoch 8 Step 485/1563 Loss: 1.363 | Acc: 51.177% (7959/15552)\n",
      "Epoch 8 Step 486/1563 Loss: 1.363 | Acc: 51.168% (7974/15584)\n",
      "Epoch 8 Step 487/1563 Loss: 1.362 | Acc: 51.204% (7996/15616)\n",
      "Epoch 8 Step 488/1563 Loss: 1.361 | Acc: 51.227% (8016/15648)\n",
      "Epoch 8 Step 489/1563 Loss: 1.362 | Acc: 51.224% (8032/15680)\n",
      "Epoch 8 Step 490/1563 Loss: 1.361 | Acc: 51.260% (8054/15712)\n",
      "Epoch 8 Step 491/1563 Loss: 1.362 | Acc: 51.239% (8067/15744)\n",
      "Epoch 8 Step 492/1563 Loss: 1.362 | Acc: 51.223% (8081/15776)\n",
      "Epoch 8 Step 493/1563 Loss: 1.362 | Acc: 51.221% (8097/15808)\n",
      "Epoch 8 Step 494/1563 Loss: 1.361 | Acc: 51.237% (8116/15840)\n",
      "Epoch 8 Step 495/1563 Loss: 1.361 | Acc: 51.241% (8133/15872)\n",
      "Epoch 8 Step 496/1563 Loss: 1.361 | Acc: 51.245% (8150/15904)\n",
      "Epoch 8 Step 497/1563 Loss: 1.361 | Acc: 51.230% (8164/15936)\n",
      "Epoch 8 Step 498/1563 Loss: 1.361 | Acc: 51.234% (8181/15968)\n",
      "Epoch 8 Step 499/1563 Loss: 1.361 | Acc: 51.231% (8197/16000)\n",
      "Epoch 8 Step 500/1563 Loss: 1.361 | Acc: 51.223% (8212/16032)\n",
      "Epoch 8 Step 501/1563 Loss: 1.362 | Acc: 51.195% (8224/16064)\n",
      "Epoch 8 Step 502/1563 Loss: 1.362 | Acc: 51.187% (8239/16096)\n",
      "Epoch 8 Step 503/1563 Loss: 1.362 | Acc: 51.178% (8254/16128)\n",
      "Epoch 8 Step 504/1563 Loss: 1.362 | Acc: 51.176% (8270/16160)\n",
      "Epoch 8 Step 505/1563 Loss: 1.363 | Acc: 51.155% (8283/16192)\n",
      "Epoch 8 Step 506/1563 Loss: 1.363 | Acc: 51.153% (8299/16224)\n",
      "Epoch 8 Step 507/1563 Loss: 1.363 | Acc: 51.150% (8315/16256)\n",
      "Epoch 8 Step 508/1563 Loss: 1.363 | Acc: 51.179% (8336/16288)\n",
      "Epoch 8 Step 509/1563 Loss: 1.363 | Acc: 51.201% (8356/16320)\n",
      "Epoch 8 Step 510/1563 Loss: 1.363 | Acc: 51.211% (8374/16352)\n",
      "Epoch 8 Step 511/1563 Loss: 1.364 | Acc: 51.172% (8384/16384)\n",
      "Epoch 8 Step 512/1563 Loss: 1.364 | Acc: 51.170% (8400/16416)\n",
      "Epoch 8 Step 513/1563 Loss: 1.364 | Acc: 51.173% (8417/16448)\n",
      "Epoch 8 Step 514/1563 Loss: 1.365 | Acc: 51.171% (8433/16480)\n",
      "Epoch 8 Step 515/1563 Loss: 1.365 | Acc: 51.145% (8445/16512)\n",
      "Epoch 8 Step 516/1563 Loss: 1.365 | Acc: 51.142% (8461/16544)\n",
      "Epoch 8 Step 517/1563 Loss: 1.365 | Acc: 51.152% (8479/16576)\n",
      "Epoch 8 Step 518/1563 Loss: 1.365 | Acc: 51.150% (8495/16608)\n",
      "Epoch 8 Step 519/1563 Loss: 1.364 | Acc: 51.178% (8516/16640)\n",
      "Epoch 8 Step 520/1563 Loss: 1.364 | Acc: 51.188% (8534/16672)\n",
      "Epoch 8 Step 521/1563 Loss: 1.364 | Acc: 51.173% (8548/16704)\n",
      "Epoch 8 Step 522/1563 Loss: 1.364 | Acc: 51.171% (8564/16736)\n",
      "Epoch 8 Step 523/1563 Loss: 1.364 | Acc: 51.187% (8583/16768)\n",
      "Epoch 8 Step 524/1563 Loss: 1.364 | Acc: 51.179% (8598/16800)\n",
      "Epoch 8 Step 525/1563 Loss: 1.364 | Acc: 51.182% (8615/16832)\n",
      "Epoch 8 Step 526/1563 Loss: 1.364 | Acc: 51.139% (8624/16864)\n",
      "Epoch 8 Step 527/1563 Loss: 1.364 | Acc: 51.130% (8639/16896)\n",
      "Epoch 8 Step 528/1563 Loss: 1.365 | Acc: 51.128% (8655/16928)\n",
      "Epoch 8 Step 529/1563 Loss: 1.365 | Acc: 51.126% (8671/16960)\n",
      "Epoch 8 Step 530/1563 Loss: 1.365 | Acc: 51.124% (8687/16992)\n",
      "Epoch 8 Step 531/1563 Loss: 1.364 | Acc: 51.134% (8705/17024)\n",
      "Epoch 8 Step 532/1563 Loss: 1.364 | Acc: 51.126% (8720/17056)\n",
      "Epoch 8 Step 533/1563 Loss: 1.364 | Acc: 51.118% (8735/17088)\n",
      "Epoch 8 Step 534/1563 Loss: 1.365 | Acc: 51.098% (8748/17120)\n",
      "Epoch 8 Step 535/1563 Loss: 1.365 | Acc: 51.108% (8766/17152)\n",
      "Epoch 8 Step 536/1563 Loss: 1.365 | Acc: 51.135% (8787/17184)\n",
      "Epoch 8 Step 537/1563 Loss: 1.365 | Acc: 51.121% (8801/17216)\n",
      "Epoch 8 Step 538/1563 Loss: 1.365 | Acc: 51.102% (8814/17248)\n",
      "Epoch 8 Step 539/1563 Loss: 1.367 | Acc: 51.065% (8824/17280)\n",
      "Epoch 8 Step 540/1563 Loss: 1.366 | Acc: 51.098% (8846/17312)\n",
      "Epoch 8 Step 541/1563 Loss: 1.366 | Acc: 51.124% (8867/17344)\n",
      "Epoch 8 Step 542/1563 Loss: 1.365 | Acc: 51.140% (8886/17376)\n",
      "Epoch 8 Step 543/1563 Loss: 1.365 | Acc: 51.137% (8902/17408)\n",
      "Epoch 8 Step 544/1563 Loss: 1.365 | Acc: 51.112% (8914/17440)\n",
      "Epoch 8 Step 545/1563 Loss: 1.365 | Acc: 51.122% (8932/17472)\n",
      "Epoch 8 Step 546/1563 Loss: 1.365 | Acc: 51.120% (8948/17504)\n",
      "Epoch 8 Step 547/1563 Loss: 1.365 | Acc: 51.118% (8964/17536)\n",
      "Epoch 8 Step 548/1563 Loss: 1.366 | Acc: 51.116% (8980/17568)\n",
      "Epoch 8 Step 549/1563 Loss: 1.365 | Acc: 51.114% (8996/17600)\n",
      "Epoch 8 Step 550/1563 Loss: 1.365 | Acc: 51.106% (9011/17632)\n",
      "Epoch 8 Step 551/1563 Loss: 1.366 | Acc: 51.110% (9028/17664)\n",
      "Epoch 8 Step 552/1563 Loss: 1.366 | Acc: 51.091% (9041/17696)\n",
      "Epoch 8 Step 553/1563 Loss: 1.366 | Acc: 51.094% (9058/17728)\n",
      "Epoch 8 Step 554/1563 Loss: 1.366 | Acc: 51.087% (9073/17760)\n",
      "Epoch 8 Step 555/1563 Loss: 1.365 | Acc: 51.096% (9091/17792)\n",
      "Epoch 8 Step 556/1563 Loss: 1.365 | Acc: 51.128% (9113/17824)\n",
      "Epoch 8 Step 557/1563 Loss: 1.365 | Acc: 51.103% (9125/17856)\n",
      "Epoch 8 Step 558/1563 Loss: 1.365 | Acc: 51.124% (9145/17888)\n",
      "Epoch 8 Step 559/1563 Loss: 1.365 | Acc: 51.133% (9163/17920)\n",
      "Epoch 8 Step 560/1563 Loss: 1.365 | Acc: 51.153% (9183/17952)\n",
      "Epoch 8 Step 561/1563 Loss: 1.365 | Acc: 51.162% (9201/17984)\n",
      "Epoch 8 Step 562/1563 Loss: 1.364 | Acc: 51.182% (9221/18016)\n",
      "Epoch 8 Step 563/1563 Loss: 1.364 | Acc: 51.191% (9239/18048)\n",
      "Epoch 8 Step 564/1563 Loss: 1.364 | Acc: 51.217% (9260/18080)\n",
      "Epoch 8 Step 565/1563 Loss: 1.364 | Acc: 51.204% (9274/18112)\n",
      "Epoch 8 Step 566/1563 Loss: 1.364 | Acc: 51.218% (9293/18144)\n",
      "Epoch 8 Step 567/1563 Loss: 1.364 | Acc: 51.210% (9308/18176)\n",
      "Epoch 8 Step 568/1563 Loss: 1.365 | Acc: 51.197% (9322/18208)\n",
      "Epoch 8 Step 569/1563 Loss: 1.365 | Acc: 51.212% (9341/18240)\n",
      "Epoch 8 Step 570/1563 Loss: 1.365 | Acc: 51.193% (9354/18272)\n",
      "Epoch 8 Step 571/1563 Loss: 1.365 | Acc: 51.191% (9370/18304)\n",
      "Epoch 8 Step 572/1563 Loss: 1.365 | Acc: 51.211% (9390/18336)\n",
      "Epoch 8 Step 573/1563 Loss: 1.365 | Acc: 51.203% (9405/18368)\n",
      "Epoch 8 Step 574/1563 Loss: 1.365 | Acc: 51.196% (9420/18400)\n",
      "Epoch 8 Step 575/1563 Loss: 1.366 | Acc: 51.177% (9433/18432)\n",
      "Epoch 8 Step 576/1563 Loss: 1.365 | Acc: 51.170% (9448/18464)\n",
      "Epoch 8 Step 577/1563 Loss: 1.365 | Acc: 51.195% (9469/18496)\n",
      "Epoch 8 Step 578/1563 Loss: 1.365 | Acc: 51.214% (9489/18528)\n",
      "Epoch 8 Step 579/1563 Loss: 1.365 | Acc: 51.228% (9508/18560)\n",
      "Epoch 8 Step 580/1563 Loss: 1.365 | Acc: 51.248% (9528/18592)\n",
      "Epoch 8 Step 581/1563 Loss: 1.365 | Acc: 51.230% (9541/18624)\n",
      "Epoch 8 Step 582/1563 Loss: 1.365 | Acc: 51.217% (9555/18656)\n",
      "Epoch 8 Step 583/1563 Loss: 1.365 | Acc: 51.231% (9574/18688)\n",
      "Epoch 8 Step 584/1563 Loss: 1.365 | Acc: 51.239% (9592/18720)\n",
      "Epoch 8 Step 585/1563 Loss: 1.364 | Acc: 51.248% (9610/18752)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 586/1563 Loss: 1.364 | Acc: 51.256% (9628/18784)\n",
      "Epoch 8 Step 587/1563 Loss: 1.365 | Acc: 51.233% (9640/18816)\n",
      "Epoch 8 Step 588/1563 Loss: 1.365 | Acc: 51.231% (9656/18848)\n",
      "Epoch 8 Step 589/1563 Loss: 1.366 | Acc: 51.245% (9675/18880)\n",
      "Epoch 8 Step 590/1563 Loss: 1.366 | Acc: 51.248% (9692/18912)\n",
      "Epoch 8 Step 591/1563 Loss: 1.366 | Acc: 51.230% (9705/18944)\n",
      "Epoch 8 Step 592/1563 Loss: 1.366 | Acc: 51.217% (9719/18976)\n",
      "Epoch 8 Step 593/1563 Loss: 1.366 | Acc: 51.199% (9732/19008)\n",
      "Epoch 8 Step 594/1563 Loss: 1.366 | Acc: 51.224% (9753/19040)\n",
      "Epoch 8 Step 595/1563 Loss: 1.365 | Acc: 51.243% (9773/19072)\n",
      "Epoch 8 Step 596/1563 Loss: 1.365 | Acc: 51.251% (9791/19104)\n",
      "Epoch 8 Step 597/1563 Loss: 1.366 | Acc: 51.233% (9804/19136)\n",
      "Epoch 8 Step 598/1563 Loss: 1.366 | Acc: 51.216% (9817/19168)\n",
      "Epoch 8 Step 599/1563 Loss: 1.367 | Acc: 51.203% (9831/19200)\n",
      "Epoch 8 Step 600/1563 Loss: 1.367 | Acc: 51.196% (9846/19232)\n",
      "Epoch 8 Step 601/1563 Loss: 1.367 | Acc: 51.204% (9864/19264)\n",
      "Epoch 8 Step 602/1563 Loss: 1.367 | Acc: 51.208% (9881/19296)\n",
      "Epoch 8 Step 603/1563 Loss: 1.366 | Acc: 51.211% (9898/19328)\n",
      "Epoch 8 Step 604/1563 Loss: 1.366 | Acc: 51.193% (9911/19360)\n",
      "Epoch 8 Step 605/1563 Loss: 1.366 | Acc: 51.181% (9925/19392)\n",
      "Epoch 8 Step 606/1563 Loss: 1.366 | Acc: 51.200% (9945/19424)\n",
      "Epoch 8 Step 607/1563 Loss: 1.366 | Acc: 51.187% (9959/19456)\n",
      "Epoch 8 Step 608/1563 Loss: 1.366 | Acc: 51.175% (9973/19488)\n",
      "Epoch 8 Step 609/1563 Loss: 1.366 | Acc: 51.158% (9986/19520)\n",
      "Epoch 8 Step 610/1563 Loss: 1.367 | Acc: 51.125% (9996/19552)\n",
      "Epoch 8 Step 611/1563 Loss: 1.367 | Acc: 51.118% (10011/19584)\n",
      "Epoch 8 Step 612/1563 Loss: 1.367 | Acc: 51.111% (10026/19616)\n",
      "Epoch 8 Step 613/1563 Loss: 1.367 | Acc: 51.120% (10044/19648)\n",
      "Epoch 8 Step 614/1563 Loss: 1.367 | Acc: 51.118% (10060/19680)\n",
      "Epoch 8 Step 615/1563 Loss: 1.367 | Acc: 51.116% (10076/19712)\n",
      "Epoch 8 Step 616/1563 Loss: 1.367 | Acc: 51.124% (10094/19744)\n",
      "Epoch 8 Step 617/1563 Loss: 1.367 | Acc: 51.107% (10107/19776)\n",
      "Epoch 8 Step 618/1563 Loss: 1.367 | Acc: 51.080% (10118/19808)\n",
      "Epoch 8 Step 619/1563 Loss: 1.368 | Acc: 51.058% (10130/19840)\n",
      "Epoch 8 Step 620/1563 Loss: 1.367 | Acc: 51.072% (10149/19872)\n",
      "Epoch 8 Step 621/1563 Loss: 1.367 | Acc: 51.065% (10164/19904)\n",
      "Epoch 8 Step 622/1563 Loss: 1.367 | Acc: 51.048% (10177/19936)\n",
      "Epoch 8 Step 623/1563 Loss: 1.368 | Acc: 51.022% (10188/19968)\n",
      "Epoch 8 Step 624/1563 Loss: 1.369 | Acc: 51.010% (10202/20000)\n",
      "Epoch 8 Step 625/1563 Loss: 1.369 | Acc: 51.023% (10221/20032)\n",
      "Epoch 8 Step 626/1563 Loss: 1.369 | Acc: 51.032% (10239/20064)\n",
      "Epoch 8 Step 627/1563 Loss: 1.369 | Acc: 51.030% (10255/20096)\n",
      "Epoch 8 Step 628/1563 Loss: 1.369 | Acc: 51.014% (10268/20128)\n",
      "Epoch 8 Step 629/1563 Loss: 1.369 | Acc: 51.012% (10284/20160)\n",
      "Epoch 8 Step 630/1563 Loss: 1.368 | Acc: 51.030% (10304/20192)\n",
      "Epoch 8 Step 631/1563 Loss: 1.369 | Acc: 51.019% (10318/20224)\n",
      "Epoch 8 Step 632/1563 Loss: 1.369 | Acc: 51.012% (10333/20256)\n",
      "Epoch 8 Step 633/1563 Loss: 1.369 | Acc: 51.020% (10351/20288)\n",
      "Epoch 8 Step 634/1563 Loss: 1.369 | Acc: 51.024% (10368/20320)\n",
      "Epoch 8 Step 635/1563 Loss: 1.369 | Acc: 51.022% (10384/20352)\n",
      "Epoch 8 Step 636/1563 Loss: 1.369 | Acc: 51.030% (10402/20384)\n",
      "Epoch 8 Step 637/1563 Loss: 1.369 | Acc: 51.024% (10417/20416)\n",
      "Epoch 8 Step 638/1563 Loss: 1.369 | Acc: 51.017% (10432/20448)\n",
      "Epoch 8 Step 639/1563 Loss: 1.369 | Acc: 51.021% (10449/20480)\n",
      "Epoch 8 Step 640/1563 Loss: 1.369 | Acc: 51.024% (10466/20512)\n",
      "Epoch 8 Step 641/1563 Loss: 1.369 | Acc: 51.017% (10481/20544)\n",
      "Epoch 8 Step 642/1563 Loss: 1.369 | Acc: 51.030% (10500/20576)\n",
      "Epoch 8 Step 643/1563 Loss: 1.369 | Acc: 51.029% (10516/20608)\n",
      "Epoch 8 Step 644/1563 Loss: 1.368 | Acc: 51.047% (10536/20640)\n",
      "Epoch 8 Step 645/1563 Loss: 1.369 | Acc: 51.026% (10548/20672)\n",
      "Epoch 8 Step 646/1563 Loss: 1.369 | Acc: 51.034% (10566/20704)\n",
      "Epoch 8 Step 647/1563 Loss: 1.369 | Acc: 51.032% (10582/20736)\n",
      "Epoch 8 Step 648/1563 Loss: 1.369 | Acc: 51.030% (10598/20768)\n",
      "Epoch 8 Step 649/1563 Loss: 1.369 | Acc: 51.043% (10617/20800)\n",
      "Epoch 8 Step 650/1563 Loss: 1.369 | Acc: 51.037% (10632/20832)\n",
      "Epoch 8 Step 651/1563 Loss: 1.368 | Acc: 51.054% (10652/20864)\n",
      "Epoch 8 Step 652/1563 Loss: 1.368 | Acc: 51.082% (10674/20896)\n",
      "Epoch 8 Step 653/1563 Loss: 1.368 | Acc: 51.094% (10693/20928)\n",
      "Epoch 8 Step 654/1563 Loss: 1.368 | Acc: 51.097% (10710/20960)\n",
      "Epoch 8 Step 655/1563 Loss: 1.368 | Acc: 51.100% (10727/20992)\n",
      "Epoch 8 Step 656/1563 Loss: 1.368 | Acc: 51.104% (10744/21024)\n",
      "Epoch 8 Step 657/1563 Loss: 1.368 | Acc: 51.111% (10762/21056)\n",
      "Epoch 8 Step 658/1563 Loss: 1.367 | Acc: 51.110% (10778/21088)\n",
      "Epoch 8 Step 659/1563 Loss: 1.367 | Acc: 51.117% (10796/21120)\n",
      "Epoch 8 Step 660/1563 Loss: 1.368 | Acc: 51.102% (10809/21152)\n",
      "Epoch 8 Step 661/1563 Loss: 1.367 | Acc: 51.123% (10830/21184)\n",
      "Epoch 8 Step 662/1563 Loss: 1.367 | Acc: 51.131% (10848/21216)\n",
      "Epoch 8 Step 663/1563 Loss: 1.368 | Acc: 51.097% (10857/21248)\n",
      "Epoch 8 Step 664/1563 Loss: 1.368 | Acc: 51.104% (10875/21280)\n",
      "Epoch 8 Step 665/1563 Loss: 1.368 | Acc: 51.107% (10892/21312)\n",
      "Epoch 8 Step 666/1563 Loss: 1.368 | Acc: 51.106% (10908/21344)\n",
      "Epoch 8 Step 667/1563 Loss: 1.368 | Acc: 51.123% (10928/21376)\n",
      "Epoch 8 Step 668/1563 Loss: 1.368 | Acc: 51.093% (10938/21408)\n",
      "Epoch 8 Step 669/1563 Loss: 1.368 | Acc: 51.091% (10954/21440)\n",
      "Epoch 8 Step 670/1563 Loss: 1.368 | Acc: 51.094% (10971/21472)\n",
      "Epoch 8 Step 671/1563 Loss: 1.368 | Acc: 51.102% (10989/21504)\n",
      "Epoch 8 Step 672/1563 Loss: 1.368 | Acc: 51.082% (11001/21536)\n",
      "Epoch 8 Step 673/1563 Loss: 1.368 | Acc: 51.076% (11016/21568)\n",
      "Epoch 8 Step 674/1563 Loss: 1.368 | Acc: 51.083% (11034/21600)\n",
      "Epoch 8 Step 675/1563 Loss: 1.368 | Acc: 51.091% (11052/21632)\n",
      "Epoch 8 Step 676/1563 Loss: 1.368 | Acc: 51.076% (11065/21664)\n",
      "Epoch 8 Step 677/1563 Loss: 1.367 | Acc: 51.097% (11086/21696)\n",
      "Epoch 8 Step 678/1563 Loss: 1.368 | Acc: 51.086% (11100/21728)\n",
      "Epoch 8 Step 679/1563 Loss: 1.368 | Acc: 51.080% (11115/21760)\n",
      "Epoch 8 Step 680/1563 Loss: 1.368 | Acc: 51.060% (11127/21792)\n",
      "Epoch 8 Step 681/1563 Loss: 1.368 | Acc: 51.045% (11140/21824)\n",
      "Epoch 8 Step 682/1563 Loss: 1.368 | Acc: 51.034% (11154/21856)\n",
      "Epoch 8 Step 683/1563 Loss: 1.367 | Acc: 51.033% (11170/21888)\n",
      "Epoch 8 Step 684/1563 Loss: 1.367 | Acc: 51.072% (11195/21920)\n",
      "Epoch 8 Step 685/1563 Loss: 1.367 | Acc: 51.071% (11211/21952)\n",
      "Epoch 8 Step 686/1563 Loss: 1.367 | Acc: 51.064% (11226/21984)\n",
      "Epoch 8 Step 687/1563 Loss: 1.367 | Acc: 51.058% (11241/22016)\n",
      "Epoch 8 Step 688/1563 Loss: 1.367 | Acc: 51.066% (11259/22048)\n",
      "Epoch 8 Step 689/1563 Loss: 1.367 | Acc: 51.069% (11276/22080)\n",
      "Epoch 8 Step 690/1563 Loss: 1.366 | Acc: 51.085% (11296/22112)\n",
      "Epoch 8 Step 691/1563 Loss: 1.367 | Acc: 51.079% (11311/22144)\n",
      "Epoch 8 Step 692/1563 Loss: 1.367 | Acc: 51.096% (11331/22176)\n",
      "Epoch 8 Step 693/1563 Loss: 1.367 | Acc: 51.099% (11348/22208)\n",
      "Epoch 8 Step 694/1563 Loss: 1.367 | Acc: 51.084% (11361/22240)\n",
      "Epoch 8 Step 695/1563 Loss: 1.367 | Acc: 51.082% (11377/22272)\n",
      "Epoch 8 Step 696/1563 Loss: 1.366 | Acc: 51.094% (11396/22304)\n",
      "Epoch 8 Step 697/1563 Loss: 1.366 | Acc: 51.092% (11412/22336)\n",
      "Epoch 8 Step 698/1563 Loss: 1.366 | Acc: 51.100% (11430/22368)\n",
      "Epoch 8 Step 699/1563 Loss: 1.366 | Acc: 51.116% (11450/22400)\n",
      "Epoch 8 Step 700/1563 Loss: 1.365 | Acc: 51.123% (11468/22432)\n",
      "Epoch 8 Step 701/1563 Loss: 1.366 | Acc: 51.113% (11482/22464)\n",
      "Epoch 8 Step 702/1563 Loss: 1.365 | Acc: 51.125% (11501/22496)\n",
      "Epoch 8 Step 703/1563 Loss: 1.365 | Acc: 51.127% (11518/22528)\n",
      "Epoch 8 Step 704/1563 Loss: 1.365 | Acc: 51.130% (11535/22560)\n",
      "Epoch 8 Step 705/1563 Loss: 1.365 | Acc: 51.142% (11554/22592)\n",
      "Epoch 8 Step 706/1563 Loss: 1.365 | Acc: 51.136% (11569/22624)\n",
      "Epoch 8 Step 707/1563 Loss: 1.365 | Acc: 51.148% (11588/22656)\n",
      "Epoch 8 Step 708/1563 Loss: 1.364 | Acc: 51.155% (11606/22688)\n",
      "Epoch 8 Step 709/1563 Loss: 1.364 | Acc: 51.171% (11626/22720)\n",
      "Epoch 8 Step 710/1563 Loss: 1.364 | Acc: 51.178% (11644/22752)\n",
      "Epoch 8 Step 711/1563 Loss: 1.364 | Acc: 51.172% (11659/22784)\n",
      "Epoch 8 Step 712/1563 Loss: 1.364 | Acc: 51.170% (11675/22816)\n",
      "Epoch 8 Step 713/1563 Loss: 1.364 | Acc: 51.173% (11692/22848)\n",
      "Epoch 8 Step 714/1563 Loss: 1.363 | Acc: 51.189% (11712/22880)\n",
      "Epoch 8 Step 715/1563 Loss: 1.364 | Acc: 51.200% (11731/22912)\n",
      "Epoch 8 Step 716/1563 Loss: 1.363 | Acc: 51.216% (11751/22944)\n",
      "Epoch 8 Step 717/1563 Loss: 1.363 | Acc: 51.210% (11766/22976)\n",
      "Epoch 8 Step 718/1563 Loss: 1.363 | Acc: 51.217% (11784/23008)\n",
      "Epoch 8 Step 719/1563 Loss: 1.363 | Acc: 51.215% (11800/23040)\n",
      "Epoch 8 Step 720/1563 Loss: 1.363 | Acc: 51.231% (11820/23072)\n",
      "Epoch 8 Step 721/1563 Loss: 1.363 | Acc: 51.242% (11839/23104)\n",
      "Epoch 8 Step 722/1563 Loss: 1.363 | Acc: 51.228% (11852/23136)\n",
      "Epoch 8 Step 723/1563 Loss: 1.363 | Acc: 51.243% (11872/23168)\n",
      "Epoch 8 Step 724/1563 Loss: 1.362 | Acc: 51.246% (11889/23200)\n",
      "Epoch 8 Step 725/1563 Loss: 1.362 | Acc: 51.248% (11906/23232)\n",
      "Epoch 8 Step 726/1563 Loss: 1.362 | Acc: 51.259% (11925/23264)\n",
      "Epoch 8 Step 727/1563 Loss: 1.362 | Acc: 51.275% (11945/23296)\n",
      "Epoch 8 Step 728/1563 Loss: 1.362 | Acc: 51.277% (11962/23328)\n",
      "Epoch 8 Step 729/1563 Loss: 1.362 | Acc: 51.271% (11977/23360)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 730/1563 Loss: 1.362 | Acc: 51.270% (11993/23392)\n",
      "Epoch 8 Step 731/1563 Loss: 1.362 | Acc: 51.268% (12009/23424)\n",
      "Epoch 8 Step 732/1563 Loss: 1.361 | Acc: 51.275% (12027/23456)\n",
      "Epoch 8 Step 733/1563 Loss: 1.361 | Acc: 51.294% (12048/23488)\n",
      "Epoch 8 Step 734/1563 Loss: 1.361 | Acc: 51.301% (12066/23520)\n",
      "Epoch 8 Step 735/1563 Loss: 1.361 | Acc: 51.303% (12083/23552)\n",
      "Epoch 8 Step 736/1563 Loss: 1.361 | Acc: 51.297% (12098/23584)\n",
      "Epoch 8 Step 737/1563 Loss: 1.360 | Acc: 51.313% (12118/23616)\n",
      "Epoch 8 Step 738/1563 Loss: 1.360 | Acc: 51.302% (12132/23648)\n",
      "Epoch 8 Step 739/1563 Loss: 1.360 | Acc: 51.301% (12148/23680)\n",
      "Epoch 8 Step 740/1563 Loss: 1.360 | Acc: 51.295% (12163/23712)\n",
      "Epoch 8 Step 741/1563 Loss: 1.361 | Acc: 51.297% (12180/23744)\n",
      "Epoch 8 Step 742/1563 Loss: 1.361 | Acc: 51.308% (12199/23776)\n",
      "Epoch 8 Step 743/1563 Loss: 1.361 | Acc: 51.277% (12208/23808)\n",
      "Epoch 8 Step 744/1563 Loss: 1.361 | Acc: 51.275% (12224/23840)\n",
      "Epoch 8 Step 745/1563 Loss: 1.361 | Acc: 51.282% (12242/23872)\n",
      "Epoch 8 Step 746/1563 Loss: 1.361 | Acc: 51.284% (12259/23904)\n",
      "Epoch 8 Step 747/1563 Loss: 1.361 | Acc: 51.287% (12276/23936)\n",
      "Epoch 8 Step 748/1563 Loss: 1.360 | Acc: 51.289% (12293/23968)\n",
      "Epoch 8 Step 749/1563 Loss: 1.360 | Acc: 51.304% (12313/24000)\n",
      "Epoch 8 Step 750/1563 Loss: 1.360 | Acc: 51.298% (12328/24032)\n",
      "Epoch 8 Step 751/1563 Loss: 1.360 | Acc: 51.301% (12345/24064)\n",
      "Epoch 8 Step 752/1563 Loss: 1.360 | Acc: 51.299% (12361/24096)\n",
      "Epoch 8 Step 753/1563 Loss: 1.360 | Acc: 51.310% (12380/24128)\n",
      "Epoch 8 Step 754/1563 Loss: 1.360 | Acc: 51.304% (12395/24160)\n",
      "Epoch 8 Step 755/1563 Loss: 1.360 | Acc: 51.294% (12409/24192)\n",
      "Epoch 8 Step 756/1563 Loss: 1.361 | Acc: 51.284% (12423/24224)\n",
      "Epoch 8 Step 757/1563 Loss: 1.360 | Acc: 51.299% (12443/24256)\n",
      "Epoch 8 Step 758/1563 Loss: 1.360 | Acc: 51.301% (12460/24288)\n",
      "Epoch 8 Step 759/1563 Loss: 1.360 | Acc: 51.299% (12476/24320)\n",
      "Epoch 8 Step 760/1563 Loss: 1.361 | Acc: 51.285% (12489/24352)\n",
      "Epoch 8 Step 761/1563 Loss: 1.361 | Acc: 51.267% (12501/24384)\n",
      "Epoch 8 Step 762/1563 Loss: 1.362 | Acc: 51.249% (12513/24416)\n",
      "Epoch 8 Step 763/1563 Loss: 1.362 | Acc: 51.248% (12529/24448)\n",
      "Epoch 8 Step 764/1563 Loss: 1.362 | Acc: 51.250% (12546/24480)\n",
      "Epoch 8 Step 765/1563 Loss: 1.362 | Acc: 51.236% (12559/24512)\n",
      "Epoch 8 Step 766/1563 Loss: 1.362 | Acc: 51.222% (12572/24544)\n",
      "Epoch 8 Step 767/1563 Loss: 1.362 | Acc: 51.225% (12589/24576)\n",
      "Epoch 8 Step 768/1563 Loss: 1.361 | Acc: 51.239% (12609/24608)\n",
      "Epoch 8 Step 769/1563 Loss: 1.361 | Acc: 51.238% (12625/24640)\n",
      "Epoch 8 Step 770/1563 Loss: 1.361 | Acc: 51.252% (12645/24672)\n",
      "Epoch 8 Step 771/1563 Loss: 1.361 | Acc: 51.255% (12662/24704)\n",
      "Epoch 8 Step 772/1563 Loss: 1.361 | Acc: 51.257% (12679/24736)\n",
      "Epoch 8 Step 773/1563 Loss: 1.361 | Acc: 51.264% (12697/24768)\n",
      "Epoch 8 Step 774/1563 Loss: 1.361 | Acc: 51.266% (12714/24800)\n",
      "Epoch 8 Step 775/1563 Loss: 1.361 | Acc: 51.260% (12729/24832)\n",
      "Epoch 8 Step 776/1563 Loss: 1.361 | Acc: 51.279% (12750/24864)\n",
      "Epoch 8 Step 777/1563 Loss: 1.361 | Acc: 51.273% (12765/24896)\n",
      "Epoch 8 Step 778/1563 Loss: 1.361 | Acc: 51.264% (12779/24928)\n",
      "Epoch 8 Step 779/1563 Loss: 1.361 | Acc: 51.270% (12797/24960)\n",
      "Epoch 8 Step 780/1563 Loss: 1.361 | Acc: 51.264% (12812/24992)\n",
      "Epoch 8 Step 781/1563 Loss: 1.361 | Acc: 51.263% (12828/25024)\n",
      "Epoch 8 Step 782/1563 Loss: 1.361 | Acc: 51.289% (12851/25056)\n",
      "Epoch 8 Step 783/1563 Loss: 1.361 | Acc: 51.291% (12868/25088)\n",
      "Epoch 8 Step 784/1563 Loss: 1.361 | Acc: 51.310% (12889/25120)\n",
      "Epoch 8 Step 785/1563 Loss: 1.361 | Acc: 51.300% (12903/25152)\n",
      "Epoch 8 Step 786/1563 Loss: 1.360 | Acc: 51.314% (12923/25184)\n",
      "Epoch 8 Step 787/1563 Loss: 1.360 | Acc: 51.325% (12942/25216)\n",
      "Epoch 8 Step 788/1563 Loss: 1.360 | Acc: 51.335% (12961/25248)\n",
      "Epoch 8 Step 789/1563 Loss: 1.360 | Acc: 51.333% (12977/25280)\n",
      "Epoch 8 Step 790/1563 Loss: 1.360 | Acc: 51.339% (12995/25312)\n",
      "Epoch 8 Step 791/1563 Loss: 1.360 | Acc: 51.345% (13013/25344)\n",
      "Epoch 8 Step 792/1563 Loss: 1.360 | Acc: 51.352% (13031/25376)\n",
      "Epoch 8 Step 793/1563 Loss: 1.359 | Acc: 51.366% (13051/25408)\n",
      "Epoch 8 Step 794/1563 Loss: 1.360 | Acc: 51.340% (13061/25440)\n",
      "Epoch 8 Step 795/1563 Loss: 1.360 | Acc: 51.331% (13075/25472)\n",
      "Epoch 8 Step 796/1563 Loss: 1.360 | Acc: 51.329% (13091/25504)\n",
      "Epoch 8 Step 797/1563 Loss: 1.360 | Acc: 51.324% (13106/25536)\n",
      "Epoch 8 Step 798/1563 Loss: 1.360 | Acc: 51.322% (13122/25568)\n",
      "Epoch 8 Step 799/1563 Loss: 1.360 | Acc: 51.328% (13140/25600)\n",
      "Epoch 8 Step 800/1563 Loss: 1.360 | Acc: 51.311% (13152/25632)\n",
      "Epoch 8 Step 801/1563 Loss: 1.361 | Acc: 51.294% (13164/25664)\n",
      "Epoch 8 Step 802/1563 Loss: 1.361 | Acc: 51.284% (13178/25696)\n",
      "Epoch 8 Step 803/1563 Loss: 1.361 | Acc: 51.287% (13195/25728)\n",
      "Epoch 8 Step 804/1563 Loss: 1.361 | Acc: 51.266% (13206/25760)\n",
      "Epoch 8 Step 805/1563 Loss: 1.361 | Acc: 51.272% (13224/25792)\n",
      "Epoch 8 Step 806/1563 Loss: 1.361 | Acc: 51.262% (13238/25824)\n",
      "Epoch 8 Step 807/1563 Loss: 1.361 | Acc: 51.269% (13256/25856)\n",
      "Epoch 8 Step 808/1563 Loss: 1.361 | Acc: 51.259% (13270/25888)\n",
      "Epoch 8 Step 809/1563 Loss: 1.361 | Acc: 51.250% (13284/25920)\n",
      "Epoch 8 Step 810/1563 Loss: 1.361 | Acc: 51.260% (13303/25952)\n",
      "Epoch 8 Step 811/1563 Loss: 1.361 | Acc: 51.262% (13320/25984)\n",
      "Epoch 8 Step 812/1563 Loss: 1.360 | Acc: 51.280% (13341/26016)\n",
      "Epoch 8 Step 813/1563 Loss: 1.360 | Acc: 51.286% (13359/26048)\n",
      "Epoch 8 Step 814/1563 Loss: 1.360 | Acc: 51.285% (13375/26080)\n",
      "Epoch 8 Step 815/1563 Loss: 1.360 | Acc: 51.302% (13396/26112)\n",
      "Epoch 8 Step 816/1563 Loss: 1.360 | Acc: 51.293% (13410/26144)\n",
      "Epoch 8 Step 817/1563 Loss: 1.360 | Acc: 51.291% (13426/26176)\n",
      "Epoch 8 Step 818/1563 Loss: 1.360 | Acc: 51.290% (13442/26208)\n",
      "Epoch 8 Step 819/1563 Loss: 1.360 | Acc: 51.296% (13460/26240)\n",
      "Epoch 8 Step 820/1563 Loss: 1.360 | Acc: 51.294% (13476/26272)\n",
      "Epoch 8 Step 821/1563 Loss: 1.360 | Acc: 51.304% (13495/26304)\n",
      "Epoch 8 Step 822/1563 Loss: 1.360 | Acc: 51.314% (13514/26336)\n",
      "Epoch 8 Step 823/1563 Loss: 1.359 | Acc: 51.343% (13538/26368)\n",
      "Epoch 8 Step 824/1563 Loss: 1.360 | Acc: 51.322% (13549/26400)\n",
      "Epoch 8 Step 825/1563 Loss: 1.360 | Acc: 51.313% (13563/26432)\n",
      "Epoch 8 Step 826/1563 Loss: 1.360 | Acc: 51.307% (13578/26464)\n",
      "Epoch 8 Step 827/1563 Loss: 1.359 | Acc: 51.317% (13597/26496)\n",
      "Epoch 8 Step 828/1563 Loss: 1.359 | Acc: 51.319% (13614/26528)\n",
      "Epoch 8 Step 829/1563 Loss: 1.359 | Acc: 51.329% (13633/26560)\n",
      "Epoch 8 Step 830/1563 Loss: 1.359 | Acc: 51.324% (13648/26592)\n",
      "Epoch 8 Step 831/1563 Loss: 1.359 | Acc: 51.341% (13669/26624)\n",
      "Epoch 8 Step 832/1563 Loss: 1.359 | Acc: 51.336% (13684/26656)\n",
      "Epoch 8 Step 833/1563 Loss: 1.359 | Acc: 51.311% (13694/26688)\n",
      "Epoch 8 Step 834/1563 Loss: 1.359 | Acc: 51.306% (13709/26720)\n",
      "Epoch 8 Step 835/1563 Loss: 1.359 | Acc: 51.320% (13729/26752)\n",
      "Epoch 8 Step 836/1563 Loss: 1.359 | Acc: 51.322% (13746/26784)\n",
      "Epoch 8 Step 837/1563 Loss: 1.359 | Acc: 51.313% (13760/26816)\n",
      "Epoch 8 Step 838/1563 Loss: 1.359 | Acc: 51.322% (13779/26848)\n",
      "Epoch 8 Step 839/1563 Loss: 1.359 | Acc: 51.332% (13798/26880)\n",
      "Epoch 8 Step 840/1563 Loss: 1.359 | Acc: 51.338% (13816/26912)\n",
      "Epoch 8 Step 841/1563 Loss: 1.359 | Acc: 51.344% (13834/26944)\n",
      "Epoch 8 Step 842/1563 Loss: 1.359 | Acc: 51.335% (13848/26976)\n",
      "Epoch 8 Step 843/1563 Loss: 1.359 | Acc: 51.318% (13860/27008)\n",
      "Epoch 8 Step 844/1563 Loss: 1.359 | Acc: 51.313% (13875/27040)\n",
      "Epoch 8 Step 845/1563 Loss: 1.360 | Acc: 51.289% (13885/27072)\n",
      "Epoch 8 Step 846/1563 Loss: 1.360 | Acc: 51.295% (13903/27104)\n",
      "Epoch 8 Step 847/1563 Loss: 1.359 | Acc: 51.301% (13921/27136)\n",
      "Epoch 8 Step 848/1563 Loss: 1.359 | Acc: 51.296% (13936/27168)\n",
      "Epoch 8 Step 849/1563 Loss: 1.360 | Acc: 51.279% (13948/27200)\n",
      "Epoch 8 Step 850/1563 Loss: 1.360 | Acc: 51.274% (13963/27232)\n",
      "Epoch 8 Step 851/1563 Loss: 1.360 | Acc: 51.280% (13981/27264)\n",
      "Epoch 8 Step 852/1563 Loss: 1.360 | Acc: 51.279% (13997/27296)\n",
      "Epoch 8 Step 853/1563 Loss: 1.360 | Acc: 51.288% (14016/27328)\n",
      "Epoch 8 Step 854/1563 Loss: 1.360 | Acc: 51.294% (14034/27360)\n",
      "Epoch 8 Step 855/1563 Loss: 1.360 | Acc: 51.278% (14046/27392)\n",
      "Epoch 8 Step 856/1563 Loss: 1.360 | Acc: 51.269% (14060/27424)\n",
      "Epoch 8 Step 857/1563 Loss: 1.360 | Acc: 51.267% (14076/27456)\n",
      "Epoch 8 Step 858/1563 Loss: 1.360 | Acc: 51.248% (14087/27488)\n",
      "Epoch 8 Step 859/1563 Loss: 1.360 | Acc: 51.257% (14106/27520)\n",
      "Epoch 8 Step 860/1563 Loss: 1.360 | Acc: 51.249% (14120/27552)\n",
      "Epoch 8 Step 861/1563 Loss: 1.360 | Acc: 51.243% (14135/27584)\n",
      "Epoch 8 Step 862/1563 Loss: 1.361 | Acc: 51.238% (14150/27616)\n",
      "Epoch 8 Step 863/1563 Loss: 1.360 | Acc: 51.241% (14167/27648)\n",
      "Epoch 8 Step 864/1563 Loss: 1.360 | Acc: 51.254% (14187/27680)\n",
      "Epoch 8 Step 865/1563 Loss: 1.361 | Acc: 51.252% (14203/27712)\n",
      "Epoch 8 Step 866/1563 Loss: 1.361 | Acc: 51.244% (14217/27744)\n",
      "Epoch 8 Step 867/1563 Loss: 1.361 | Acc: 51.231% (14230/27776)\n",
      "Epoch 8 Step 868/1563 Loss: 1.361 | Acc: 51.219% (14243/27808)\n",
      "Epoch 8 Step 869/1563 Loss: 1.361 | Acc: 51.225% (14261/27840)\n",
      "Epoch 8 Step 870/1563 Loss: 1.361 | Acc: 51.252% (14285/27872)\n",
      "Epoch 8 Step 871/1563 Loss: 1.361 | Acc: 51.251% (14301/27904)\n",
      "Epoch 8 Step 872/1563 Loss: 1.361 | Acc: 51.249% (14317/27936)\n",
      "Epoch 8 Step 873/1563 Loss: 1.361 | Acc: 51.248% (14333/27968)\n",
      "Epoch 8 Step 874/1563 Loss: 1.361 | Acc: 51.254% (14351/28000)\n",
      "Epoch 8 Step 875/1563 Loss: 1.361 | Acc: 51.245% (14365/28032)\n",
      "Epoch 8 Step 876/1563 Loss: 1.362 | Acc: 51.240% (14380/28064)\n",
      "Epoch 8 Step 877/1563 Loss: 1.362 | Acc: 51.246% (14398/28096)\n",
      "Epoch 8 Step 878/1563 Loss: 1.361 | Acc: 51.255% (14417/28128)\n",
      "Epoch 8 Step 879/1563 Loss: 1.362 | Acc: 51.236% (14428/28160)\n",
      "Epoch 8 Step 880/1563 Loss: 1.361 | Acc: 51.238% (14445/28192)\n",
      "Epoch 8 Step 881/1563 Loss: 1.361 | Acc: 51.240% (14462/28224)\n",
      "Epoch 8 Step 882/1563 Loss: 1.361 | Acc: 51.239% (14478/28256)\n",
      "Epoch 8 Step 883/1563 Loss: 1.361 | Acc: 51.244% (14496/28288)\n",
      "Epoch 8 Step 884/1563 Loss: 1.361 | Acc: 51.236% (14510/28320)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 885/1563 Loss: 1.361 | Acc: 51.245% (14529/28352)\n",
      "Epoch 8 Step 886/1563 Loss: 1.361 | Acc: 51.244% (14545/28384)\n",
      "Epoch 8 Step 887/1563 Loss: 1.361 | Acc: 51.232% (14558/28416)\n",
      "Epoch 8 Step 888/1563 Loss: 1.361 | Acc: 51.227% (14573/28448)\n",
      "Epoch 8 Step 889/1563 Loss: 1.361 | Acc: 51.232% (14591/28480)\n",
      "Epoch 8 Step 890/1563 Loss: 1.362 | Acc: 51.210% (14601/28512)\n",
      "Epoch 8 Step 891/1563 Loss: 1.362 | Acc: 51.219% (14620/28544)\n",
      "Epoch 8 Step 892/1563 Loss: 1.362 | Acc: 51.207% (14633/28576)\n",
      "Epoch 8 Step 893/1563 Loss: 1.362 | Acc: 51.202% (14648/28608)\n",
      "Epoch 8 Step 894/1563 Loss: 1.361 | Acc: 51.219% (14669/28640)\n",
      "Epoch 8 Step 895/1563 Loss: 1.361 | Acc: 51.217% (14685/28672)\n",
      "Epoch 8 Step 896/1563 Loss: 1.361 | Acc: 51.230% (14705/28704)\n",
      "Epoch 8 Step 897/1563 Loss: 1.361 | Acc: 51.228% (14721/28736)\n",
      "Epoch 8 Step 898/1563 Loss: 1.361 | Acc: 51.237% (14740/28768)\n",
      "Epoch 8 Step 899/1563 Loss: 1.361 | Acc: 51.247% (14759/28800)\n",
      "Epoch 8 Step 900/1563 Loss: 1.361 | Acc: 51.238% (14773/28832)\n",
      "Epoch 8 Step 901/1563 Loss: 1.361 | Acc: 51.233% (14788/28864)\n",
      "Epoch 8 Step 902/1563 Loss: 1.361 | Acc: 51.235% (14805/28896)\n",
      "Epoch 8 Step 903/1563 Loss: 1.361 | Acc: 51.234% (14821/28928)\n",
      "Epoch 8 Step 904/1563 Loss: 1.361 | Acc: 51.240% (14839/28960)\n",
      "Epoch 8 Step 905/1563 Loss: 1.361 | Acc: 51.242% (14856/28992)\n",
      "Epoch 8 Step 906/1563 Loss: 1.361 | Acc: 51.230% (14869/29024)\n",
      "Epoch 8 Step 907/1563 Loss: 1.361 | Acc: 51.236% (14887/29056)\n",
      "Epoch 8 Step 908/1563 Loss: 1.361 | Acc: 51.224% (14900/29088)\n",
      "Epoch 8 Step 909/1563 Loss: 1.361 | Acc: 51.229% (14918/29120)\n",
      "Epoch 8 Step 910/1563 Loss: 1.362 | Acc: 51.238% (14937/29152)\n",
      "Epoch 8 Step 911/1563 Loss: 1.361 | Acc: 51.258% (14959/29184)\n",
      "Epoch 8 Step 912/1563 Loss: 1.361 | Acc: 51.260% (14976/29216)\n",
      "Epoch 8 Step 913/1563 Loss: 1.361 | Acc: 51.251% (14990/29248)\n",
      "Epoch 8 Step 914/1563 Loss: 1.361 | Acc: 51.243% (15004/29280)\n",
      "Epoch 8 Step 915/1563 Loss: 1.361 | Acc: 51.232% (15017/29312)\n",
      "Epoch 8 Step 916/1563 Loss: 1.361 | Acc: 51.244% (15037/29344)\n",
      "Epoch 8 Step 917/1563 Loss: 1.361 | Acc: 51.249% (15055/29376)\n",
      "Epoch 8 Step 918/1563 Loss: 1.361 | Acc: 51.248% (15071/29408)\n",
      "Epoch 8 Step 919/1563 Loss: 1.361 | Acc: 51.219% (15079/29440)\n",
      "Epoch 8 Step 920/1563 Loss: 1.361 | Acc: 51.225% (15097/29472)\n",
      "Epoch 8 Step 921/1563 Loss: 1.361 | Acc: 51.227% (15114/29504)\n",
      "Epoch 8 Step 922/1563 Loss: 1.361 | Acc: 51.222% (15129/29536)\n",
      "Epoch 8 Step 923/1563 Loss: 1.361 | Acc: 51.218% (15144/29568)\n",
      "Epoch 8 Step 924/1563 Loss: 1.361 | Acc: 51.206% (15157/29600)\n",
      "Epoch 8 Step 925/1563 Loss: 1.361 | Acc: 51.201% (15172/29632)\n",
      "Epoch 8 Step 926/1563 Loss: 1.361 | Acc: 51.200% (15188/29664)\n",
      "Epoch 8 Step 927/1563 Loss: 1.361 | Acc: 51.206% (15206/29696)\n",
      "Epoch 8 Step 928/1563 Loss: 1.361 | Acc: 51.208% (15223/29728)\n",
      "Epoch 8 Step 929/1563 Loss: 1.361 | Acc: 51.220% (15243/29760)\n",
      "Epoch 8 Step 930/1563 Loss: 1.361 | Acc: 51.222% (15260/29792)\n",
      "Epoch 8 Step 931/1563 Loss: 1.361 | Acc: 51.220% (15276/29824)\n",
      "Epoch 8 Step 932/1563 Loss: 1.361 | Acc: 51.219% (15292/29856)\n",
      "Epoch 8 Step 933/1563 Loss: 1.361 | Acc: 51.215% (15307/29888)\n",
      "Epoch 8 Step 934/1563 Loss: 1.361 | Acc: 51.213% (15323/29920)\n",
      "Epoch 8 Step 935/1563 Loss: 1.361 | Acc: 51.222% (15342/29952)\n",
      "Epoch 8 Step 936/1563 Loss: 1.361 | Acc: 51.211% (15355/29984)\n",
      "Epoch 8 Step 937/1563 Loss: 1.361 | Acc: 51.209% (15371/30016)\n",
      "Epoch 8 Step 938/1563 Loss: 1.361 | Acc: 51.218% (15390/30048)\n",
      "Epoch 8 Step 939/1563 Loss: 1.361 | Acc: 51.217% (15406/30080)\n",
      "Epoch 8 Step 940/1563 Loss: 1.361 | Acc: 51.212% (15421/30112)\n",
      "Epoch 8 Step 941/1563 Loss: 1.361 | Acc: 51.204% (15435/30144)\n",
      "Epoch 8 Step 942/1563 Loss: 1.361 | Acc: 51.206% (15452/30176)\n",
      "Epoch 8 Step 943/1563 Loss: 1.361 | Acc: 51.205% (15468/30208)\n",
      "Epoch 8 Step 944/1563 Loss: 1.361 | Acc: 51.197% (15482/30240)\n",
      "Epoch 8 Step 945/1563 Loss: 1.361 | Acc: 51.186% (15495/30272)\n",
      "Epoch 8 Step 946/1563 Loss: 1.361 | Acc: 51.181% (15510/30304)\n",
      "Epoch 8 Step 947/1563 Loss: 1.361 | Acc: 51.160% (15520/30336)\n",
      "Epoch 8 Step 948/1563 Loss: 1.362 | Acc: 51.146% (15532/30368)\n",
      "Epoch 8 Step 949/1563 Loss: 1.362 | Acc: 51.151% (15550/30400)\n",
      "Epoch 8 Step 950/1563 Loss: 1.361 | Acc: 51.167% (15571/30432)\n",
      "Epoch 8 Step 951/1563 Loss: 1.361 | Acc: 51.165% (15587/30464)\n",
      "Epoch 8 Step 952/1563 Loss: 1.361 | Acc: 51.167% (15604/30496)\n",
      "Epoch 8 Step 953/1563 Loss: 1.361 | Acc: 51.173% (15622/30528)\n",
      "Epoch 8 Step 954/1563 Loss: 1.361 | Acc: 51.175% (15639/30560)\n",
      "Epoch 8 Step 955/1563 Loss: 1.361 | Acc: 51.164% (15652/30592)\n",
      "Epoch 8 Step 956/1563 Loss: 1.362 | Acc: 51.166% (15669/30624)\n",
      "Epoch 8 Step 957/1563 Loss: 1.361 | Acc: 51.171% (15687/30656)\n",
      "Epoch 8 Step 958/1563 Loss: 1.361 | Acc: 51.180% (15706/30688)\n",
      "Epoch 8 Step 959/1563 Loss: 1.361 | Acc: 51.182% (15723/30720)\n",
      "Epoch 8 Step 960/1563 Loss: 1.361 | Acc: 51.174% (15737/30752)\n",
      "Epoch 8 Step 961/1563 Loss: 1.362 | Acc: 51.160% (15749/30784)\n",
      "Epoch 8 Step 962/1563 Loss: 1.362 | Acc: 51.158% (15765/30816)\n",
      "Epoch 8 Step 963/1563 Loss: 1.362 | Acc: 51.144% (15777/30848)\n",
      "Epoch 8 Step 964/1563 Loss: 1.362 | Acc: 51.137% (15791/30880)\n",
      "Epoch 8 Step 965/1563 Loss: 1.362 | Acc: 51.129% (15805/30912)\n",
      "Epoch 8 Step 966/1563 Loss: 1.362 | Acc: 51.115% (15817/30944)\n",
      "Epoch 8 Step 967/1563 Loss: 1.362 | Acc: 51.107% (15831/30976)\n",
      "Epoch 8 Step 968/1563 Loss: 1.362 | Acc: 51.126% (15853/31008)\n",
      "Epoch 8 Step 969/1563 Loss: 1.362 | Acc: 51.108% (15864/31040)\n",
      "Epoch 8 Step 970/1563 Loss: 1.362 | Acc: 51.101% (15878/31072)\n",
      "Epoch 8 Step 971/1563 Loss: 1.362 | Acc: 51.093% (15892/31104)\n",
      "Epoch 8 Step 972/1563 Loss: 1.362 | Acc: 51.105% (15912/31136)\n",
      "Epoch 8 Step 973/1563 Loss: 1.362 | Acc: 51.104% (15928/31168)\n",
      "Epoch 8 Step 974/1563 Loss: 1.362 | Acc: 51.109% (15946/31200)\n",
      "Epoch 8 Step 975/1563 Loss: 1.362 | Acc: 51.105% (15961/31232)\n",
      "Epoch 8 Step 976/1563 Loss: 1.363 | Acc: 51.088% (15972/31264)\n",
      "Epoch 8 Step 977/1563 Loss: 1.363 | Acc: 51.086% (15988/31296)\n",
      "Epoch 8 Step 978/1563 Loss: 1.363 | Acc: 51.085% (16004/31328)\n",
      "Epoch 8 Step 979/1563 Loss: 1.363 | Acc: 51.094% (16023/31360)\n",
      "Epoch 8 Step 980/1563 Loss: 1.363 | Acc: 51.096% (16040/31392)\n",
      "Epoch 8 Step 981/1563 Loss: 1.363 | Acc: 51.082% (16052/31424)\n",
      "Epoch 8 Step 982/1563 Loss: 1.363 | Acc: 51.081% (16068/31456)\n",
      "Epoch 8 Step 983/1563 Loss: 1.363 | Acc: 51.073% (16082/31488)\n",
      "Epoch 8 Step 984/1563 Loss: 1.362 | Acc: 51.085% (16102/31520)\n",
      "Epoch 8 Step 985/1563 Loss: 1.362 | Acc: 51.090% (16120/31552)\n",
      "Epoch 8 Step 986/1563 Loss: 1.362 | Acc: 51.099% (16139/31584)\n",
      "Epoch 8 Step 987/1563 Loss: 1.362 | Acc: 51.094% (16154/31616)\n",
      "Epoch 8 Step 988/1563 Loss: 1.362 | Acc: 51.093% (16170/31648)\n",
      "Epoch 8 Step 989/1563 Loss: 1.362 | Acc: 51.098% (16188/31680)\n",
      "Epoch 8 Step 990/1563 Loss: 1.362 | Acc: 51.094% (16203/31712)\n",
      "Epoch 8 Step 991/1563 Loss: 1.362 | Acc: 51.103% (16222/31744)\n",
      "Epoch 8 Step 992/1563 Loss: 1.362 | Acc: 51.101% (16238/31776)\n",
      "Epoch 8 Step 993/1563 Loss: 1.361 | Acc: 51.094% (16252/31808)\n",
      "Epoch 8 Step 994/1563 Loss: 1.361 | Acc: 51.109% (16273/31840)\n",
      "Epoch 8 Step 995/1563 Loss: 1.361 | Acc: 51.108% (16289/31872)\n",
      "Epoch 8 Step 996/1563 Loss: 1.361 | Acc: 51.106% (16305/31904)\n",
      "Epoch 8 Step 997/1563 Loss: 1.361 | Acc: 51.112% (16323/31936)\n",
      "Epoch 8 Step 998/1563 Loss: 1.361 | Acc: 51.114% (16340/31968)\n",
      "Epoch 8 Step 999/1563 Loss: 1.361 | Acc: 51.109% (16355/32000)\n",
      "Epoch 8 Step 1000/1563 Loss: 1.361 | Acc: 51.108% (16371/32032)\n",
      "Epoch 8 Step 1001/1563 Loss: 1.361 | Acc: 51.098% (16384/32064)\n",
      "Epoch 8 Step 1002/1563 Loss: 1.361 | Acc: 51.103% (16402/32096)\n",
      "Epoch 8 Step 1003/1563 Loss: 1.361 | Acc: 51.127% (16426/32128)\n",
      "Epoch 8 Step 1004/1563 Loss: 1.361 | Acc: 51.123% (16441/32160)\n",
      "Epoch 8 Step 1005/1563 Loss: 1.360 | Acc: 51.128% (16459/32192)\n",
      "Epoch 8 Step 1006/1563 Loss: 1.360 | Acc: 51.142% (16480/32224)\n",
      "Epoch 8 Step 1007/1563 Loss: 1.360 | Acc: 51.144% (16497/32256)\n",
      "Epoch 8 Step 1008/1563 Loss: 1.360 | Acc: 51.146% (16514/32288)\n",
      "Epoch 8 Step 1009/1563 Loss: 1.360 | Acc: 51.139% (16528/32320)\n",
      "Epoch 8 Step 1010/1563 Loss: 1.360 | Acc: 51.137% (16544/32352)\n",
      "Epoch 8 Step 1011/1563 Loss: 1.360 | Acc: 51.152% (16565/32384)\n",
      "Epoch 8 Step 1012/1563 Loss: 1.360 | Acc: 51.138% (16577/32416)\n",
      "Epoch 8 Step 1013/1563 Loss: 1.360 | Acc: 51.140% (16594/32448)\n",
      "Epoch 8 Step 1014/1563 Loss: 1.360 | Acc: 51.121% (16604/32480)\n",
      "Epoch 8 Step 1015/1563 Loss: 1.360 | Acc: 51.129% (16623/32512)\n",
      "Epoch 8 Step 1016/1563 Loss: 1.360 | Acc: 51.137% (16642/32544)\n",
      "Epoch 8 Step 1017/1563 Loss: 1.361 | Acc: 51.130% (16656/32576)\n",
      "Epoch 8 Step 1018/1563 Loss: 1.361 | Acc: 51.129% (16672/32608)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 1019/1563 Loss: 1.361 | Acc: 51.118% (16685/32640)\n",
      "Epoch 8 Step 1020/1563 Loss: 1.361 | Acc: 51.120% (16702/32672)\n",
      "Epoch 8 Step 1021/1563 Loss: 1.361 | Acc: 51.110% (16715/32704)\n",
      "Epoch 8 Step 1022/1563 Loss: 1.361 | Acc: 51.109% (16731/32736)\n",
      "Epoch 8 Step 1023/1563 Loss: 1.361 | Acc: 51.114% (16749/32768)\n",
      "Epoch 8 Step 1024/1563 Loss: 1.361 | Acc: 51.125% (16769/32800)\n",
      "Epoch 8 Step 1025/1563 Loss: 1.361 | Acc: 51.127% (16786/32832)\n",
      "Epoch 8 Step 1026/1563 Loss: 1.361 | Acc: 51.129% (16803/32864)\n",
      "Epoch 8 Step 1027/1563 Loss: 1.361 | Acc: 51.128% (16819/32896)\n",
      "Epoch 8 Step 1028/1563 Loss: 1.361 | Acc: 51.127% (16835/32928)\n",
      "Epoch 8 Step 1029/1563 Loss: 1.361 | Acc: 51.123% (16850/32960)\n",
      "Epoch 8 Step 1030/1563 Loss: 1.361 | Acc: 51.128% (16868/32992)\n",
      "Epoch 8 Step 1031/1563 Loss: 1.361 | Acc: 51.126% (16884/33024)\n",
      "Epoch 8 Step 1032/1563 Loss: 1.361 | Acc: 51.134% (16903/33056)\n",
      "Epoch 8 Step 1033/1563 Loss: 1.361 | Acc: 51.148% (16924/33088)\n",
      "Epoch 8 Step 1034/1563 Loss: 1.361 | Acc: 51.153% (16942/33120)\n",
      "Epoch 8 Step 1035/1563 Loss: 1.361 | Acc: 51.143% (16955/33152)\n",
      "Epoch 8 Step 1036/1563 Loss: 1.361 | Acc: 51.151% (16974/33184)\n",
      "Epoch 8 Step 1037/1563 Loss: 1.361 | Acc: 51.147% (16989/33216)\n",
      "Epoch 8 Step 1038/1563 Loss: 1.361 | Acc: 51.146% (17005/33248)\n",
      "Epoch 8 Step 1039/1563 Loss: 1.361 | Acc: 51.136% (17018/33280)\n",
      "Epoch 8 Step 1040/1563 Loss: 1.361 | Acc: 51.147% (17038/33312)\n",
      "Epoch 8 Step 1041/1563 Loss: 1.360 | Acc: 51.161% (17059/33344)\n",
      "Epoch 8 Step 1042/1563 Loss: 1.360 | Acc: 51.163% (17076/33376)\n",
      "Epoch 8 Step 1043/1563 Loss: 1.360 | Acc: 51.170% (17095/33408)\n",
      "Epoch 8 Step 1044/1563 Loss: 1.360 | Acc: 51.166% (17110/33440)\n",
      "Epoch 8 Step 1045/1563 Loss: 1.360 | Acc: 51.150% (17121/33472)\n",
      "Epoch 8 Step 1046/1563 Loss: 1.360 | Acc: 51.152% (17138/33504)\n",
      "Epoch 8 Step 1047/1563 Loss: 1.360 | Acc: 51.154% (17155/33536)\n",
      "Epoch 8 Step 1048/1563 Loss: 1.360 | Acc: 51.150% (17170/33568)\n",
      "Epoch 8 Step 1049/1563 Loss: 1.360 | Acc: 51.146% (17185/33600)\n",
      "Epoch 8 Step 1050/1563 Loss: 1.360 | Acc: 51.154% (17204/33632)\n",
      "Epoch 8 Step 1051/1563 Loss: 1.360 | Acc: 51.156% (17221/33664)\n",
      "Epoch 8 Step 1052/1563 Loss: 1.360 | Acc: 51.146% (17234/33696)\n",
      "Epoch 8 Step 1053/1563 Loss: 1.360 | Acc: 51.147% (17251/33728)\n",
      "Epoch 8 Step 1054/1563 Loss: 1.360 | Acc: 51.149% (17268/33760)\n",
      "Epoch 8 Step 1055/1563 Loss: 1.360 | Acc: 51.160% (17288/33792)\n",
      "Epoch 8 Step 1056/1563 Loss: 1.359 | Acc: 51.174% (17309/33824)\n",
      "Epoch 8 Step 1057/1563 Loss: 1.359 | Acc: 51.170% (17324/33856)\n",
      "Epoch 8 Step 1058/1563 Loss: 1.359 | Acc: 51.160% (17337/33888)\n",
      "Epoch 8 Step 1059/1563 Loss: 1.359 | Acc: 51.162% (17354/33920)\n",
      "Epoch 8 Step 1060/1563 Loss: 1.359 | Acc: 51.152% (17367/33952)\n",
      "Epoch 8 Step 1061/1563 Loss: 1.359 | Acc: 51.151% (17383/33984)\n",
      "Epoch 8 Step 1062/1563 Loss: 1.359 | Acc: 51.149% (17399/34016)\n",
      "Epoch 8 Step 1063/1563 Loss: 1.360 | Acc: 51.137% (17411/34048)\n",
      "Epoch 8 Step 1064/1563 Loss: 1.360 | Acc: 51.138% (17428/34080)\n",
      "Epoch 8 Step 1065/1563 Loss: 1.360 | Acc: 51.140% (17445/34112)\n",
      "Epoch 8 Step 1066/1563 Loss: 1.360 | Acc: 51.136% (17460/34144)\n",
      "Epoch 8 Step 1067/1563 Loss: 1.360 | Acc: 51.138% (17477/34176)\n",
      "Epoch 8 Step 1068/1563 Loss: 1.360 | Acc: 51.134% (17492/34208)\n",
      "Epoch 8 Step 1069/1563 Loss: 1.359 | Acc: 51.145% (17512/34240)\n",
      "Epoch 8 Step 1070/1563 Loss: 1.360 | Acc: 51.147% (17529/34272)\n",
      "Epoch 8 Step 1071/1563 Loss: 1.360 | Acc: 51.146% (17545/34304)\n",
      "Epoch 8 Step 1072/1563 Loss: 1.360 | Acc: 51.147% (17562/34336)\n",
      "Epoch 8 Step 1073/1563 Loss: 1.359 | Acc: 51.158% (17582/34368)\n",
      "Epoch 8 Step 1074/1563 Loss: 1.360 | Acc: 51.148% (17595/34400)\n",
      "Epoch 8 Step 1075/1563 Loss: 1.360 | Acc: 51.150% (17612/34432)\n",
      "Epoch 8 Step 1076/1563 Loss: 1.360 | Acc: 51.158% (17631/34464)\n",
      "Epoch 8 Step 1077/1563 Loss: 1.359 | Acc: 51.157% (17647/34496)\n",
      "Epoch 8 Step 1078/1563 Loss: 1.360 | Acc: 51.147% (17660/34528)\n",
      "Epoch 8 Step 1079/1563 Loss: 1.359 | Acc: 51.157% (17680/34560)\n",
      "Epoch 8 Step 1080/1563 Loss: 1.359 | Acc: 51.153% (17695/34592)\n",
      "Epoch 8 Step 1081/1563 Loss: 1.359 | Acc: 51.161% (17714/34624)\n",
      "Epoch 8 Step 1082/1563 Loss: 1.359 | Acc: 51.160% (17730/34656)\n",
      "Epoch 8 Step 1083/1563 Loss: 1.359 | Acc: 51.165% (17748/34688)\n",
      "Epoch 8 Step 1084/1563 Loss: 1.359 | Acc: 51.161% (17763/34720)\n",
      "Epoch 8 Step 1085/1563 Loss: 1.359 | Acc: 51.151% (17776/34752)\n",
      "Epoch 8 Step 1086/1563 Loss: 1.359 | Acc: 51.138% (17788/34784)\n",
      "Epoch 8 Step 1087/1563 Loss: 1.360 | Acc: 51.126% (17800/34816)\n",
      "Epoch 8 Step 1088/1563 Loss: 1.359 | Acc: 51.133% (17819/34848)\n",
      "Epoch 8 Step 1089/1563 Loss: 1.359 | Acc: 51.132% (17835/34880)\n",
      "Epoch 8 Step 1090/1563 Loss: 1.360 | Acc: 51.114% (17845/34912)\n",
      "Epoch 8 Step 1091/1563 Loss: 1.360 | Acc: 51.119% (17863/34944)\n",
      "Epoch 8 Step 1092/1563 Loss: 1.360 | Acc: 51.109% (17876/34976)\n",
      "Epoch 8 Step 1093/1563 Loss: 1.360 | Acc: 51.100% (17889/35008)\n",
      "Epoch 8 Step 1094/1563 Loss: 1.360 | Acc: 51.104% (17907/35040)\n",
      "Epoch 8 Step 1095/1563 Loss: 1.360 | Acc: 51.121% (17929/35072)\n",
      "Epoch 8 Step 1096/1563 Loss: 1.360 | Acc: 51.131% (17949/35104)\n",
      "Epoch 8 Step 1097/1563 Loss: 1.360 | Acc: 51.136% (17967/35136)\n",
      "Epoch 8 Step 1098/1563 Loss: 1.360 | Acc: 51.135% (17983/35168)\n",
      "Epoch 8 Step 1099/1563 Loss: 1.360 | Acc: 51.134% (17999/35200)\n",
      "Epoch 8 Step 1100/1563 Loss: 1.360 | Acc: 51.130% (18014/35232)\n",
      "Epoch 8 Step 1101/1563 Loss: 1.360 | Acc: 51.134% (18032/35264)\n",
      "Epoch 8 Step 1102/1563 Loss: 1.360 | Acc: 51.128% (18046/35296)\n",
      "Epoch 8 Step 1103/1563 Loss: 1.360 | Acc: 51.127% (18062/35328)\n",
      "Epoch 8 Step 1104/1563 Loss: 1.360 | Acc: 51.126% (18078/35360)\n",
      "Epoch 8 Step 1105/1563 Loss: 1.360 | Acc: 51.119% (18092/35392)\n",
      "Epoch 8 Step 1106/1563 Loss: 1.360 | Acc: 51.129% (18112/35424)\n",
      "Epoch 8 Step 1107/1563 Loss: 1.359 | Acc: 51.137% (18131/35456)\n",
      "Epoch 8 Step 1108/1563 Loss: 1.359 | Acc: 51.130% (18145/35488)\n",
      "Epoch 8 Step 1109/1563 Loss: 1.360 | Acc: 51.123% (18159/35520)\n",
      "Epoch 8 Step 1110/1563 Loss: 1.360 | Acc: 51.134% (18179/35552)\n",
      "Epoch 8 Step 1111/1563 Loss: 1.359 | Acc: 51.133% (18195/35584)\n",
      "Epoch 8 Step 1112/1563 Loss: 1.359 | Acc: 51.148% (18217/35616)\n",
      "Epoch 8 Step 1113/1563 Loss: 1.360 | Acc: 51.153% (18235/35648)\n",
      "Epoch 8 Step 1114/1563 Loss: 1.360 | Acc: 51.143% (18248/35680)\n",
      "Epoch 8 Step 1115/1563 Loss: 1.360 | Acc: 51.137% (18262/35712)\n",
      "Epoch 8 Step 1116/1563 Loss: 1.360 | Acc: 51.147% (18282/35744)\n",
      "Epoch 8 Step 1117/1563 Loss: 1.360 | Acc: 51.143% (18297/35776)\n",
      "Epoch 8 Step 1118/1563 Loss: 1.360 | Acc: 51.139% (18312/35808)\n",
      "Epoch 8 Step 1119/1563 Loss: 1.360 | Acc: 51.138% (18328/35840)\n",
      "Epoch 8 Step 1120/1563 Loss: 1.360 | Acc: 51.129% (18341/35872)\n",
      "Epoch 8 Step 1121/1563 Loss: 1.360 | Acc: 51.136% (18360/35904)\n",
      "Epoch 8 Step 1122/1563 Loss: 1.360 | Acc: 51.130% (18374/35936)\n",
      "Epoch 8 Step 1123/1563 Loss: 1.360 | Acc: 51.120% (18387/35968)\n",
      "Epoch 8 Step 1124/1563 Loss: 1.360 | Acc: 51.111% (18400/36000)\n",
      "Epoch 8 Step 1125/1563 Loss: 1.361 | Acc: 51.113% (18417/36032)\n",
      "Epoch 8 Step 1126/1563 Loss: 1.361 | Acc: 51.106% (18431/36064)\n",
      "Epoch 8 Step 1127/1563 Loss: 1.360 | Acc: 51.122% (18453/36096)\n",
      "Epoch 8 Step 1128/1563 Loss: 1.361 | Acc: 51.113% (18466/36128)\n",
      "Epoch 8 Step 1129/1563 Loss: 1.360 | Acc: 51.114% (18483/36160)\n",
      "Epoch 8 Step 1130/1563 Loss: 1.360 | Acc: 51.130% (18505/36192)\n",
      "Epoch 8 Step 1131/1563 Loss: 1.360 | Acc: 51.137% (18524/36224)\n",
      "Epoch 8 Step 1132/1563 Loss: 1.360 | Acc: 51.128% (18537/36256)\n",
      "Epoch 8 Step 1133/1563 Loss: 1.361 | Acc: 51.119% (18550/36288)\n",
      "Epoch 8 Step 1134/1563 Loss: 1.361 | Acc: 51.112% (18564/36320)\n",
      "Epoch 8 Step 1135/1563 Loss: 1.361 | Acc: 51.106% (18578/36352)\n",
      "Epoch 8 Step 1136/1563 Loss: 1.361 | Acc: 51.110% (18596/36384)\n",
      "Epoch 8 Step 1137/1563 Loss: 1.360 | Acc: 51.126% (18618/36416)\n",
      "Epoch 8 Step 1138/1563 Loss: 1.361 | Acc: 51.119% (18632/36448)\n",
      "Epoch 8 Step 1139/1563 Loss: 1.360 | Acc: 51.116% (18647/36480)\n",
      "Epoch 8 Step 1140/1563 Loss: 1.361 | Acc: 51.117% (18664/36512)\n",
      "Epoch 8 Step 1141/1563 Loss: 1.361 | Acc: 51.114% (18679/36544)\n",
      "Epoch 8 Step 1142/1563 Loss: 1.360 | Acc: 51.121% (18698/36576)\n",
      "Epoch 8 Step 1143/1563 Loss: 1.361 | Acc: 51.123% (18715/36608)\n",
      "Epoch 8 Step 1144/1563 Loss: 1.361 | Acc: 51.119% (18730/36640)\n",
      "Epoch 8 Step 1145/1563 Loss: 1.361 | Acc: 51.099% (18739/36672)\n",
      "Epoch 8 Step 1146/1563 Loss: 1.361 | Acc: 51.095% (18754/36704)\n",
      "Epoch 8 Step 1147/1563 Loss: 1.361 | Acc: 51.100% (18772/36736)\n",
      "Epoch 8 Step 1148/1563 Loss: 1.361 | Acc: 51.099% (18788/36768)\n",
      "Epoch 8 Step 1149/1563 Loss: 1.361 | Acc: 51.098% (18804/36800)\n",
      "Epoch 8 Step 1150/1563 Loss: 1.361 | Acc: 51.097% (18820/36832)\n",
      "Epoch 8 Step 1151/1563 Loss: 1.361 | Acc: 51.096% (18836/36864)\n",
      "Epoch 8 Step 1152/1563 Loss: 1.361 | Acc: 51.084% (18848/36896)\n",
      "Epoch 8 Step 1153/1563 Loss: 1.361 | Acc: 51.099% (18870/36928)\n",
      "Epoch 8 Step 1154/1563 Loss: 1.361 | Acc: 51.101% (18887/36960)\n",
      "Epoch 8 Step 1155/1563 Loss: 1.361 | Acc: 51.103% (18904/36992)\n",
      "Epoch 8 Step 1156/1563 Loss: 1.361 | Acc: 51.115% (18925/37024)\n",
      "Epoch 8 Step 1157/1563 Loss: 1.361 | Acc: 51.125% (18945/37056)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 1158/1563 Loss: 1.361 | Acc: 51.122% (18960/37088)\n",
      "Epoch 8 Step 1159/1563 Loss: 1.361 | Acc: 51.126% (18978/37120)\n",
      "Epoch 8 Step 1160/1563 Loss: 1.361 | Acc: 51.136% (18998/37152)\n",
      "Epoch 8 Step 1161/1563 Loss: 1.361 | Acc: 51.146% (19018/37184)\n",
      "Epoch 8 Step 1162/1563 Loss: 1.361 | Acc: 51.142% (19033/37216)\n",
      "Epoch 8 Step 1163/1563 Loss: 1.361 | Acc: 51.122% (19042/37248)\n",
      "Epoch 8 Step 1164/1563 Loss: 1.361 | Acc: 51.124% (19059/37280)\n",
      "Epoch 8 Step 1165/1563 Loss: 1.361 | Acc: 51.131% (19078/37312)\n",
      "Epoch 8 Step 1166/1563 Loss: 1.361 | Acc: 51.130% (19094/37344)\n",
      "Epoch 8 Step 1167/1563 Loss: 1.361 | Acc: 51.132% (19111/37376)\n",
      "Epoch 8 Step 1168/1563 Loss: 1.361 | Acc: 51.133% (19128/37408)\n",
      "Epoch 8 Step 1169/1563 Loss: 1.360 | Acc: 51.140% (19147/37440)\n",
      "Epoch 8 Step 1170/1563 Loss: 1.360 | Acc: 51.142% (19164/37472)\n",
      "Epoch 8 Step 1171/1563 Loss: 1.360 | Acc: 51.149% (19183/37504)\n",
      "Epoch 8 Step 1172/1563 Loss: 1.360 | Acc: 51.159% (19203/37536)\n",
      "Epoch 8 Step 1173/1563 Loss: 1.360 | Acc: 51.169% (19223/37568)\n",
      "Epoch 8 Step 1174/1563 Loss: 1.360 | Acc: 51.168% (19239/37600)\n",
      "Epoch 8 Step 1175/1563 Loss: 1.360 | Acc: 51.172% (19257/37632)\n",
      "Epoch 8 Step 1176/1563 Loss: 1.360 | Acc: 51.160% (19269/37664)\n",
      "Epoch 8 Step 1177/1563 Loss: 1.360 | Acc: 51.149% (19281/37696)\n",
      "Epoch 8 Step 1178/1563 Loss: 1.360 | Acc: 51.140% (19294/37728)\n",
      "Epoch 8 Step 1179/1563 Loss: 1.360 | Acc: 51.136% (19309/37760)\n",
      "Epoch 8 Step 1180/1563 Loss: 1.360 | Acc: 51.127% (19322/37792)\n",
      "Epoch 8 Step 1181/1563 Loss: 1.360 | Acc: 51.126% (19338/37824)\n",
      "Epoch 8 Step 1182/1563 Loss: 1.360 | Acc: 51.123% (19353/37856)\n",
      "Epoch 8 Step 1183/1563 Loss: 1.360 | Acc: 51.114% (19366/37888)\n",
      "Epoch 8 Step 1184/1563 Loss: 1.360 | Acc: 51.121% (19385/37920)\n",
      "Epoch 8 Step 1185/1563 Loss: 1.360 | Acc: 51.115% (19399/37952)\n",
      "Epoch 8 Step 1186/1563 Loss: 1.360 | Acc: 51.116% (19416/37984)\n",
      "Epoch 8 Step 1187/1563 Loss: 1.360 | Acc: 51.110% (19430/38016)\n",
      "Epoch 8 Step 1188/1563 Loss: 1.360 | Acc: 51.125% (19452/38048)\n",
      "Epoch 8 Step 1189/1563 Loss: 1.360 | Acc: 51.127% (19469/38080)\n",
      "Epoch 8 Step 1190/1563 Loss: 1.360 | Acc: 51.128% (19486/38112)\n",
      "Epoch 8 Step 1191/1563 Loss: 1.360 | Acc: 51.114% (19497/38144)\n",
      "Epoch 8 Step 1192/1563 Loss: 1.361 | Acc: 51.108% (19511/38176)\n",
      "Epoch 8 Step 1193/1563 Loss: 1.361 | Acc: 51.104% (19526/38208)\n",
      "Epoch 8 Step 1194/1563 Loss: 1.361 | Acc: 51.096% (19539/38240)\n",
      "Epoch 8 Step 1195/1563 Loss: 1.361 | Acc: 51.095% (19555/38272)\n",
      "Epoch 8 Step 1196/1563 Loss: 1.361 | Acc: 51.102% (19574/38304)\n",
      "Epoch 8 Step 1197/1563 Loss: 1.361 | Acc: 51.103% (19591/38336)\n",
      "Epoch 8 Step 1198/1563 Loss: 1.361 | Acc: 51.087% (19601/38368)\n",
      "Epoch 8 Step 1199/1563 Loss: 1.361 | Acc: 51.091% (19619/38400)\n",
      "Epoch 8 Step 1200/1563 Loss: 1.361 | Acc: 51.077% (19630/38432)\n",
      "Epoch 8 Step 1201/1563 Loss: 1.361 | Acc: 51.076% (19646/38464)\n",
      "Epoch 8 Step 1202/1563 Loss: 1.361 | Acc: 51.062% (19657/38496)\n",
      "Epoch 8 Step 1203/1563 Loss: 1.361 | Acc: 51.067% (19675/38528)\n",
      "Epoch 8 Step 1204/1563 Loss: 1.361 | Acc: 51.074% (19694/38560)\n",
      "Epoch 8 Step 1205/1563 Loss: 1.361 | Acc: 51.057% (19704/38592)\n",
      "Epoch 8 Step 1206/1563 Loss: 1.361 | Acc: 51.067% (19724/38624)\n",
      "Epoch 8 Step 1207/1563 Loss: 1.361 | Acc: 51.079% (19745/38656)\n",
      "Epoch 8 Step 1208/1563 Loss: 1.360 | Acc: 51.091% (19766/38688)\n",
      "Epoch 8 Step 1209/1563 Loss: 1.360 | Acc: 51.092% (19783/38720)\n",
      "Epoch 8 Step 1210/1563 Loss: 1.360 | Acc: 51.107% (19805/38752)\n",
      "Epoch 8 Step 1211/1563 Loss: 1.361 | Acc: 51.101% (19819/38784)\n",
      "Epoch 8 Step 1212/1563 Loss: 1.361 | Acc: 51.092% (19832/38816)\n",
      "Epoch 8 Step 1213/1563 Loss: 1.361 | Acc: 51.073% (19841/38848)\n",
      "Epoch 8 Step 1214/1563 Loss: 1.361 | Acc: 51.078% (19859/38880)\n",
      "Epoch 8 Step 1215/1563 Loss: 1.361 | Acc: 51.079% (19876/38912)\n",
      "Epoch 8 Step 1216/1563 Loss: 1.361 | Acc: 51.078% (19892/38944)\n",
      "Epoch 8 Step 1217/1563 Loss: 1.361 | Acc: 51.078% (19908/38976)\n",
      "Epoch 8 Step 1218/1563 Loss: 1.361 | Acc: 51.064% (19919/39008)\n",
      "Epoch 8 Step 1219/1563 Loss: 1.361 | Acc: 51.053% (19931/39040)\n",
      "Epoch 8 Step 1220/1563 Loss: 1.361 | Acc: 51.065% (19952/39072)\n",
      "Epoch 8 Step 1221/1563 Loss: 1.361 | Acc: 51.069% (19970/39104)\n",
      "Epoch 8 Step 1222/1563 Loss: 1.361 | Acc: 51.078% (19990/39136)\n",
      "Epoch 8 Step 1223/1563 Loss: 1.361 | Acc: 51.080% (20007/39168)\n",
      "Epoch 8 Step 1224/1563 Loss: 1.361 | Acc: 51.089% (20027/39200)\n",
      "Epoch 8 Step 1225/1563 Loss: 1.361 | Acc: 51.099% (20047/39232)\n",
      "Epoch 8 Step 1226/1563 Loss: 1.361 | Acc: 51.093% (20061/39264)\n",
      "Epoch 8 Step 1227/1563 Loss: 1.361 | Acc: 51.104% (20082/39296)\n",
      "Epoch 8 Step 1228/1563 Loss: 1.361 | Acc: 51.109% (20100/39328)\n",
      "Epoch 8 Step 1229/1563 Loss: 1.361 | Acc: 51.113% (20118/39360)\n",
      "Epoch 8 Step 1230/1563 Loss: 1.361 | Acc: 51.114% (20135/39392)\n",
      "Epoch 8 Step 1231/1563 Loss: 1.361 | Acc: 51.111% (20150/39424)\n",
      "Epoch 8 Step 1232/1563 Loss: 1.361 | Acc: 51.110% (20166/39456)\n",
      "Epoch 8 Step 1233/1563 Loss: 1.361 | Acc: 51.091% (20175/39488)\n",
      "Epoch 8 Step 1234/1563 Loss: 1.361 | Acc: 51.091% (20191/39520)\n",
      "Epoch 8 Step 1235/1563 Loss: 1.361 | Acc: 51.097% (20210/39552)\n",
      "Epoch 8 Step 1236/1563 Loss: 1.361 | Acc: 51.089% (20223/39584)\n",
      "Epoch 8 Step 1237/1563 Loss: 1.361 | Acc: 51.096% (20242/39616)\n",
      "Epoch 8 Step 1238/1563 Loss: 1.361 | Acc: 51.105% (20262/39648)\n",
      "Epoch 8 Step 1239/1563 Loss: 1.360 | Acc: 51.121% (20285/39680)\n",
      "Epoch 8 Step 1240/1563 Loss: 1.360 | Acc: 51.128% (20304/39712)\n",
      "Epoch 8 Step 1241/1563 Loss: 1.360 | Acc: 51.127% (20320/39744)\n",
      "Epoch 8 Step 1242/1563 Loss: 1.360 | Acc: 51.134% (20339/39776)\n",
      "Epoch 8 Step 1243/1563 Loss: 1.360 | Acc: 51.140% (20358/39808)\n",
      "Epoch 8 Step 1244/1563 Loss: 1.360 | Acc: 51.142% (20375/39840)\n",
      "Epoch 8 Step 1245/1563 Loss: 1.360 | Acc: 51.139% (20390/39872)\n",
      "Epoch 8 Step 1246/1563 Loss: 1.360 | Acc: 51.135% (20405/39904)\n",
      "Epoch 8 Step 1247/1563 Loss: 1.360 | Acc: 51.129% (20419/39936)\n",
      "Epoch 8 Step 1248/1563 Loss: 1.360 | Acc: 51.128% (20435/39968)\n",
      "Epoch 8 Step 1249/1563 Loss: 1.361 | Acc: 51.117% (20447/40000)\n",
      "Epoch 8 Step 1250/1563 Loss: 1.361 | Acc: 51.114% (20462/40032)\n",
      "Epoch 8 Step 1251/1563 Loss: 1.361 | Acc: 51.111% (20477/40064)\n",
      "Epoch 8 Step 1252/1563 Loss: 1.361 | Acc: 51.115% (20495/40096)\n",
      "Epoch 8 Step 1253/1563 Loss: 1.361 | Acc: 51.109% (20509/40128)\n",
      "Epoch 8 Step 1254/1563 Loss: 1.361 | Acc: 51.108% (20525/40160)\n",
      "Epoch 8 Step 1255/1563 Loss: 1.361 | Acc: 51.112% (20543/40192)\n",
      "Epoch 8 Step 1256/1563 Loss: 1.361 | Acc: 51.109% (20558/40224)\n",
      "Epoch 8 Step 1257/1563 Loss: 1.361 | Acc: 51.110% (20575/40256)\n",
      "Epoch 8 Step 1258/1563 Loss: 1.361 | Acc: 51.124% (20597/40288)\n",
      "Epoch 8 Step 1259/1563 Loss: 1.361 | Acc: 51.116% (20610/40320)\n",
      "Epoch 8 Step 1260/1563 Loss: 1.361 | Acc: 51.115% (20626/40352)\n",
      "Epoch 8 Step 1261/1563 Loss: 1.361 | Acc: 51.099% (20636/40384)\n",
      "Epoch 8 Step 1262/1563 Loss: 1.361 | Acc: 51.104% (20654/40416)\n",
      "Epoch 8 Step 1263/1563 Loss: 1.361 | Acc: 51.100% (20669/40448)\n",
      "Epoch 8 Step 1264/1563 Loss: 1.361 | Acc: 51.097% (20684/40480)\n",
      "Epoch 8 Step 1265/1563 Loss: 1.361 | Acc: 51.094% (20699/40512)\n",
      "Epoch 8 Step 1266/1563 Loss: 1.361 | Acc: 51.090% (20714/40544)\n",
      "Epoch 8 Step 1267/1563 Loss: 1.361 | Acc: 51.084% (20728/40576)\n",
      "Epoch 8 Step 1268/1563 Loss: 1.361 | Acc: 51.076% (20741/40608)\n",
      "Epoch 8 Step 1269/1563 Loss: 1.361 | Acc: 51.075% (20757/40640)\n",
      "Epoch 8 Step 1270/1563 Loss: 1.361 | Acc: 51.072% (20772/40672)\n",
      "Epoch 8 Step 1271/1563 Loss: 1.361 | Acc: 51.071% (20788/40704)\n",
      "Epoch 8 Step 1272/1563 Loss: 1.361 | Acc: 51.080% (20808/40736)\n",
      "Epoch 8 Step 1273/1563 Loss: 1.361 | Acc: 51.082% (20825/40768)\n",
      "Epoch 8 Step 1274/1563 Loss: 1.361 | Acc: 51.083% (20842/40800)\n",
      "Epoch 8 Step 1275/1563 Loss: 1.361 | Acc: 51.078% (20856/40832)\n",
      "Epoch 8 Step 1276/1563 Loss: 1.361 | Acc: 51.082% (20874/40864)\n",
      "Epoch 8 Step 1277/1563 Loss: 1.361 | Acc: 51.071% (20886/40896)\n",
      "Epoch 8 Step 1278/1563 Loss: 1.361 | Acc: 51.073% (20903/40928)\n",
      "Epoch 8 Step 1279/1563 Loss: 1.362 | Acc: 51.072% (20919/40960)\n",
      "Epoch 8 Step 1280/1563 Loss: 1.361 | Acc: 51.086% (20941/40992)\n",
      "Epoch 8 Step 1281/1563 Loss: 1.361 | Acc: 51.075% (20953/41024)\n",
      "Epoch 8 Step 1282/1563 Loss: 1.361 | Acc: 51.074% (20969/41056)\n",
      "Epoch 8 Step 1283/1563 Loss: 1.361 | Acc: 51.076% (20986/41088)\n",
      "Epoch 8 Step 1284/1563 Loss: 1.362 | Acc: 51.063% (20997/41120)\n",
      "Epoch 8 Step 1285/1563 Loss: 1.362 | Acc: 51.069% (21016/41152)\n",
      "Epoch 8 Step 1286/1563 Loss: 1.362 | Acc: 51.061% (21029/41184)\n",
      "Epoch 8 Step 1287/1563 Loss: 1.362 | Acc: 51.065% (21047/41216)\n",
      "Epoch 8 Step 1288/1563 Loss: 1.362 | Acc: 51.062% (21062/41248)\n",
      "Epoch 8 Step 1289/1563 Loss: 1.362 | Acc: 51.061% (21078/41280)\n",
      "Epoch 8 Step 1290/1563 Loss: 1.362 | Acc: 51.072% (21099/41312)\n",
      "Epoch 8 Step 1291/1563 Loss: 1.362 | Acc: 51.069% (21114/41344)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 1292/1563 Loss: 1.362 | Acc: 51.068% (21130/41376)\n",
      "Epoch 8 Step 1293/1563 Loss: 1.362 | Acc: 51.060% (21143/41408)\n",
      "Epoch 8 Step 1294/1563 Loss: 1.362 | Acc: 51.042% (21152/41440)\n",
      "Epoch 8 Step 1295/1563 Loss: 1.362 | Acc: 51.042% (21168/41472)\n",
      "Epoch 8 Step 1296/1563 Loss: 1.362 | Acc: 51.036% (21182/41504)\n",
      "Epoch 8 Step 1297/1563 Loss: 1.362 | Acc: 51.038% (21199/41536)\n",
      "Epoch 8 Step 1298/1563 Loss: 1.362 | Acc: 51.034% (21214/41568)\n",
      "Epoch 8 Step 1299/1563 Loss: 1.362 | Acc: 51.036% (21231/41600)\n",
      "Epoch 8 Step 1300/1563 Loss: 1.362 | Acc: 51.035% (21247/41632)\n",
      "Epoch 8 Step 1301/1563 Loss: 1.362 | Acc: 51.034% (21263/41664)\n",
      "Epoch 8 Step 1302/1563 Loss: 1.362 | Acc: 51.036% (21280/41696)\n",
      "Epoch 8 Step 1303/1563 Loss: 1.362 | Acc: 51.045% (21300/41728)\n",
      "Epoch 8 Step 1304/1563 Loss: 1.362 | Acc: 51.046% (21317/41760)\n",
      "Epoch 8 Step 1305/1563 Loss: 1.362 | Acc: 51.065% (21341/41792)\n",
      "Epoch 8 Step 1306/1563 Loss: 1.362 | Acc: 51.057% (21354/41824)\n",
      "Epoch 8 Step 1307/1563 Loss: 1.362 | Acc: 51.056% (21370/41856)\n",
      "Epoch 8 Step 1308/1563 Loss: 1.362 | Acc: 51.053% (21385/41888)\n",
      "Epoch 8 Step 1309/1563 Loss: 1.362 | Acc: 51.050% (21400/41920)\n",
      "Epoch 8 Step 1310/1563 Loss: 1.362 | Acc: 51.051% (21417/41952)\n",
      "Epoch 8 Step 1311/1563 Loss: 1.362 | Acc: 51.050% (21433/41984)\n",
      "Epoch 8 Step 1312/1563 Loss: 1.362 | Acc: 51.052% (21450/42016)\n",
      "Epoch 8 Step 1313/1563 Loss: 1.362 | Acc: 51.042% (21462/42048)\n",
      "Epoch 8 Step 1314/1563 Loss: 1.362 | Acc: 51.043% (21479/42080)\n",
      "Epoch 8 Step 1315/1563 Loss: 1.362 | Acc: 51.040% (21494/42112)\n",
      "Epoch 8 Step 1316/1563 Loss: 1.362 | Acc: 51.032% (21507/42144)\n",
      "Epoch 8 Step 1317/1563 Loss: 1.362 | Acc: 51.034% (21524/42176)\n",
      "Epoch 8 Step 1318/1563 Loss: 1.362 | Acc: 51.033% (21540/42208)\n",
      "Epoch 8 Step 1319/1563 Loss: 1.362 | Acc: 51.023% (21552/42240)\n",
      "Epoch 8 Step 1320/1563 Loss: 1.362 | Acc: 51.008% (21562/42272)\n",
      "Epoch 8 Step 1321/1563 Loss: 1.362 | Acc: 51.019% (21583/42304)\n",
      "Epoch 8 Step 1322/1563 Loss: 1.362 | Acc: 51.023% (21601/42336)\n",
      "Epoch 8 Step 1323/1563 Loss: 1.362 | Acc: 51.027% (21619/42368)\n",
      "Epoch 8 Step 1324/1563 Loss: 1.362 | Acc: 51.033% (21638/42400)\n",
      "Epoch 8 Step 1325/1563 Loss: 1.362 | Acc: 51.028% (21652/42432)\n",
      "Epoch 8 Step 1326/1563 Loss: 1.362 | Acc: 51.015% (21663/42464)\n",
      "Epoch 8 Step 1327/1563 Loss: 1.362 | Acc: 51.019% (21681/42496)\n",
      "Epoch 8 Step 1328/1563 Loss: 1.362 | Acc: 51.004% (21691/42528)\n",
      "Epoch 8 Step 1329/1563 Loss: 1.362 | Acc: 51.003% (21707/42560)\n",
      "Epoch 8 Step 1330/1563 Loss: 1.362 | Acc: 51.000% (21722/42592)\n",
      "Epoch 8 Step 1331/1563 Loss: 1.362 | Acc: 51.011% (21743/42624)\n",
      "Epoch 8 Step 1332/1563 Loss: 1.362 | Acc: 51.015% (21761/42656)\n",
      "Epoch 8 Step 1333/1563 Loss: 1.362 | Acc: 51.007% (21774/42688)\n",
      "Epoch 8 Step 1334/1563 Loss: 1.362 | Acc: 50.993% (21784/42720)\n",
      "Epoch 8 Step 1335/1563 Loss: 1.362 | Acc: 50.992% (21800/42752)\n",
      "Epoch 8 Step 1336/1563 Loss: 1.362 | Acc: 51.000% (21820/42784)\n",
      "Epoch 8 Step 1337/1563 Loss: 1.362 | Acc: 50.993% (21833/42816)\n",
      "Epoch 8 Step 1338/1563 Loss: 1.362 | Acc: 50.990% (21848/42848)\n",
      "Epoch 8 Step 1339/1563 Loss: 1.362 | Acc: 50.991% (21865/42880)\n",
      "Epoch 8 Step 1340/1563 Loss: 1.362 | Acc: 51.002% (21886/42912)\n",
      "Epoch 8 Step 1341/1563 Loss: 1.362 | Acc: 51.011% (21906/42944)\n",
      "Epoch 8 Step 1342/1563 Loss: 1.362 | Acc: 51.005% (21920/42976)\n",
      "Epoch 8 Step 1343/1563 Loss: 1.362 | Acc: 51.004% (21936/43008)\n",
      "Epoch 8 Step 1344/1563 Loss: 1.362 | Acc: 51.011% (21955/43040)\n",
      "Epoch 8 Step 1345/1563 Loss: 1.362 | Acc: 51.005% (21969/43072)\n",
      "Epoch 8 Step 1346/1563 Loss: 1.361 | Acc: 51.012% (21988/43104)\n",
      "Epoch 8 Step 1347/1563 Loss: 1.362 | Acc: 51.006% (22002/43136)\n",
      "Epoch 8 Step 1348/1563 Loss: 1.362 | Acc: 51.003% (22017/43168)\n",
      "Epoch 8 Step 1349/1563 Loss: 1.362 | Acc: 50.995% (22030/43200)\n",
      "Epoch 8 Step 1350/1563 Loss: 1.362 | Acc: 50.995% (22046/43232)\n",
      "Epoch 8 Step 1351/1563 Loss: 1.362 | Acc: 50.989% (22060/43264)\n",
      "Epoch 8 Step 1352/1563 Loss: 1.362 | Acc: 50.986% (22075/43296)\n",
      "Epoch 8 Step 1353/1563 Loss: 1.362 | Acc: 50.995% (22095/43328)\n",
      "Epoch 8 Step 1354/1563 Loss: 1.361 | Acc: 51.006% (22116/43360)\n",
      "Epoch 8 Step 1355/1563 Loss: 1.361 | Acc: 51.007% (22133/43392)\n",
      "Epoch 8 Step 1356/1563 Loss: 1.361 | Acc: 50.993% (22143/43424)\n",
      "Epoch 8 Step 1357/1563 Loss: 1.362 | Acc: 50.983% (22155/43456)\n",
      "Epoch 8 Step 1358/1563 Loss: 1.362 | Acc: 50.986% (22173/43488)\n",
      "Epoch 8 Step 1359/1563 Loss: 1.362 | Acc: 50.983% (22188/43520)\n",
      "Epoch 8 Step 1360/1563 Loss: 1.362 | Acc: 50.971% (22199/43552)\n",
      "Epoch 8 Step 1361/1563 Loss: 1.362 | Acc: 50.961% (22211/43584)\n",
      "Epoch 8 Step 1362/1563 Loss: 1.362 | Acc: 50.961% (22227/43616)\n",
      "Epoch 8 Step 1363/1563 Loss: 1.362 | Acc: 50.958% (22242/43648)\n",
      "Epoch 8 Step 1364/1563 Loss: 1.362 | Acc: 50.952% (22256/43680)\n",
      "Epoch 8 Step 1365/1563 Loss: 1.362 | Acc: 50.956% (22274/43712)\n",
      "Epoch 8 Step 1366/1563 Loss: 1.362 | Acc: 50.951% (22288/43744)\n",
      "Epoch 8 Step 1367/1563 Loss: 1.362 | Acc: 50.946% (22302/43776)\n",
      "Epoch 8 Step 1368/1563 Loss: 1.363 | Acc: 50.943% (22317/43808)\n",
      "Epoch 8 Step 1369/1563 Loss: 1.363 | Acc: 50.942% (22333/43840)\n",
      "Epoch 8 Step 1370/1563 Loss: 1.362 | Acc: 50.946% (22351/43872)\n",
      "Epoch 8 Step 1371/1563 Loss: 1.363 | Acc: 50.943% (22366/43904)\n",
      "Epoch 8 Step 1372/1563 Loss: 1.363 | Acc: 50.947% (22384/43936)\n",
      "Epoch 8 Step 1373/1563 Loss: 1.363 | Acc: 50.942% (22398/43968)\n",
      "Epoch 8 Step 1374/1563 Loss: 1.363 | Acc: 50.950% (22418/44000)\n",
      "Epoch 8 Step 1375/1563 Loss: 1.363 | Acc: 50.942% (22431/44032)\n",
      "Epoch 8 Step 1376/1563 Loss: 1.363 | Acc: 50.942% (22447/44064)\n",
      "Epoch 8 Step 1377/1563 Loss: 1.363 | Acc: 50.934% (22460/44096)\n",
      "Epoch 8 Step 1378/1563 Loss: 1.363 | Acc: 50.920% (22470/44128)\n",
      "Epoch 8 Step 1379/1563 Loss: 1.363 | Acc: 50.922% (22487/44160)\n",
      "Epoch 8 Step 1380/1563 Loss: 1.363 | Acc: 50.916% (22501/44192)\n",
      "Epoch 8 Step 1381/1563 Loss: 1.363 | Acc: 50.914% (22516/44224)\n",
      "Epoch 8 Step 1382/1563 Loss: 1.363 | Acc: 50.915% (22533/44256)\n",
      "Epoch 8 Step 1383/1563 Loss: 1.363 | Acc: 50.912% (22548/44288)\n",
      "Epoch 8 Step 1384/1563 Loss: 1.363 | Acc: 50.907% (22562/44320)\n",
      "Epoch 8 Step 1385/1563 Loss: 1.363 | Acc: 50.902% (22576/44352)\n",
      "Epoch 8 Step 1386/1563 Loss: 1.363 | Acc: 50.915% (22598/44384)\n",
      "Epoch 8 Step 1387/1563 Loss: 1.363 | Acc: 50.910% (22612/44416)\n",
      "Epoch 8 Step 1388/1563 Loss: 1.363 | Acc: 50.909% (22628/44448)\n",
      "Epoch 8 Step 1389/1563 Loss: 1.363 | Acc: 50.917% (22648/44480)\n",
      "Epoch 8 Step 1390/1563 Loss: 1.363 | Acc: 50.914% (22663/44512)\n",
      "Epoch 8 Step 1391/1563 Loss: 1.363 | Acc: 50.900% (22673/44544)\n",
      "Epoch 8 Step 1392/1563 Loss: 1.363 | Acc: 50.900% (22689/44576)\n",
      "Epoch 8 Step 1393/1563 Loss: 1.363 | Acc: 50.906% (22708/44608)\n",
      "Epoch 8 Step 1394/1563 Loss: 1.363 | Acc: 50.896% (22720/44640)\n",
      "Epoch 8 Step 1395/1563 Loss: 1.363 | Acc: 50.904% (22740/44672)\n",
      "Epoch 8 Step 1396/1563 Loss: 1.363 | Acc: 50.906% (22757/44704)\n",
      "Epoch 8 Step 1397/1563 Loss: 1.363 | Acc: 50.910% (22775/44736)\n",
      "Epoch 8 Step 1398/1563 Loss: 1.363 | Acc: 50.905% (22789/44768)\n",
      "Epoch 8 Step 1399/1563 Loss: 1.364 | Acc: 50.897% (22802/44800)\n",
      "Epoch 8 Step 1400/1563 Loss: 1.364 | Acc: 50.899% (22819/44832)\n",
      "Epoch 8 Step 1401/1563 Loss: 1.364 | Acc: 50.903% (22837/44864)\n",
      "Epoch 8 Step 1402/1563 Loss: 1.363 | Acc: 50.907% (22855/44896)\n",
      "Epoch 8 Step 1403/1563 Loss: 1.363 | Acc: 50.901% (22869/44928)\n",
      "Epoch 8 Step 1404/1563 Loss: 1.363 | Acc: 50.896% (22883/44960)\n",
      "Epoch 8 Step 1405/1563 Loss: 1.363 | Acc: 50.893% (22898/44992)\n",
      "Epoch 8 Step 1406/1563 Loss: 1.363 | Acc: 50.906% (22920/45024)\n",
      "Epoch 8 Step 1407/1563 Loss: 1.363 | Acc: 50.910% (22938/45056)\n",
      "Epoch 8 Step 1408/1563 Loss: 1.363 | Acc: 50.907% (22953/45088)\n",
      "Epoch 8 Step 1409/1563 Loss: 1.363 | Acc: 50.913% (22972/45120)\n",
      "Epoch 8 Step 1410/1563 Loss: 1.363 | Acc: 50.919% (22991/45152)\n",
      "Epoch 8 Step 1411/1563 Loss: 1.363 | Acc: 50.925% (23010/45184)\n",
      "Epoch 8 Step 1412/1563 Loss: 1.363 | Acc: 50.927% (23027/45216)\n",
      "Epoch 8 Step 1413/1563 Loss: 1.363 | Acc: 50.930% (23045/45248)\n",
      "Epoch 8 Step 1414/1563 Loss: 1.363 | Acc: 50.939% (23065/45280)\n",
      "Epoch 8 Step 1415/1563 Loss: 1.363 | Acc: 50.953% (23088/45312)\n",
      "Epoch 8 Step 1416/1563 Loss: 1.362 | Acc: 50.955% (23105/45344)\n",
      "Epoch 8 Step 1417/1563 Loss: 1.363 | Acc: 50.954% (23121/45376)\n",
      "Epoch 8 Step 1418/1563 Loss: 1.363 | Acc: 50.951% (23136/45408)\n",
      "Epoch 8 Step 1419/1563 Loss: 1.363 | Acc: 50.953% (23153/45440)\n",
      "Epoch 8 Step 1420/1563 Loss: 1.363 | Acc: 50.941% (23164/45472)\n",
      "Epoch 8 Step 1421/1563 Loss: 1.363 | Acc: 50.923% (23172/45504)\n",
      "Epoch 8 Step 1422/1563 Loss: 1.363 | Acc: 50.925% (23189/45536)\n",
      "Epoch 8 Step 1423/1563 Loss: 1.363 | Acc: 50.926% (23206/45568)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 1424/1563 Loss: 1.363 | Acc: 50.919% (23219/45600)\n",
      "Epoch 8 Step 1425/1563 Loss: 1.364 | Acc: 50.914% (23233/45632)\n",
      "Epoch 8 Step 1426/1563 Loss: 1.363 | Acc: 50.918% (23251/45664)\n",
      "Epoch 8 Step 1427/1563 Loss: 1.363 | Acc: 50.917% (23267/45696)\n",
      "Epoch 8 Step 1428/1563 Loss: 1.364 | Acc: 50.916% (23283/45728)\n",
      "Epoch 8 Step 1429/1563 Loss: 1.364 | Acc: 50.922% (23302/45760)\n",
      "Epoch 8 Step 1430/1563 Loss: 1.364 | Acc: 50.930% (23322/45792)\n",
      "Epoch 8 Step 1431/1563 Loss: 1.364 | Acc: 50.932% (23339/45824)\n",
      "Epoch 8 Step 1432/1563 Loss: 1.364 | Acc: 50.927% (23353/45856)\n",
      "Epoch 8 Step 1433/1563 Loss: 1.364 | Acc: 50.939% (23375/45888)\n",
      "Epoch 8 Step 1434/1563 Loss: 1.363 | Acc: 50.939% (23391/45920)\n",
      "Epoch 8 Step 1435/1563 Loss: 1.363 | Acc: 50.938% (23407/45952)\n",
      "Epoch 8 Step 1436/1563 Loss: 1.363 | Acc: 50.935% (23422/45984)\n",
      "Epoch 8 Step 1437/1563 Loss: 1.363 | Acc: 50.932% (23437/46016)\n",
      "Epoch 8 Step 1438/1563 Loss: 1.363 | Acc: 50.934% (23454/46048)\n",
      "Epoch 8 Step 1439/1563 Loss: 1.363 | Acc: 50.931% (23469/46080)\n",
      "Epoch 8 Step 1440/1563 Loss: 1.363 | Acc: 50.935% (23487/46112)\n",
      "Epoch 8 Step 1441/1563 Loss: 1.363 | Acc: 50.932% (23502/46144)\n",
      "Epoch 8 Step 1442/1563 Loss: 1.363 | Acc: 50.933% (23519/46176)\n",
      "Epoch 8 Step 1443/1563 Loss: 1.363 | Acc: 50.928% (23533/46208)\n",
      "Epoch 8 Step 1444/1563 Loss: 1.363 | Acc: 50.947% (23558/46240)\n",
      "Epoch 8 Step 1445/1563 Loss: 1.363 | Acc: 50.949% (23575/46272)\n",
      "Epoch 8 Step 1446/1563 Loss: 1.363 | Acc: 50.948% (23591/46304)\n",
      "Epoch 8 Step 1447/1563 Loss: 1.363 | Acc: 50.943% (23605/46336)\n",
      "Epoch 8 Step 1448/1563 Loss: 1.363 | Acc: 50.953% (23626/46368)\n",
      "Epoch 8 Step 1449/1563 Loss: 1.363 | Acc: 50.963% (23647/46400)\n",
      "Epoch 8 Step 1450/1563 Loss: 1.363 | Acc: 50.963% (23663/46432)\n",
      "Epoch 8 Step 1451/1563 Loss: 1.363 | Acc: 50.962% (23679/46464)\n",
      "Epoch 8 Step 1452/1563 Loss: 1.363 | Acc: 50.951% (23690/46496)\n",
      "Epoch 8 Step 1453/1563 Loss: 1.363 | Acc: 50.952% (23707/46528)\n",
      "Epoch 8 Step 1454/1563 Loss: 1.363 | Acc: 50.951% (23723/46560)\n",
      "Epoch 8 Step 1455/1563 Loss: 1.363 | Acc: 50.953% (23740/46592)\n",
      "Epoch 8 Step 1456/1563 Loss: 1.363 | Acc: 50.952% (23756/46624)\n",
      "Epoch 8 Step 1457/1563 Loss: 1.363 | Acc: 50.954% (23773/46656)\n",
      "Epoch 8 Step 1458/1563 Loss: 1.363 | Acc: 50.966% (23795/46688)\n",
      "Epoch 8 Step 1459/1563 Loss: 1.363 | Acc: 50.963% (23810/46720)\n",
      "Epoch 8 Step 1460/1563 Loss: 1.363 | Acc: 50.960% (23825/46752)\n",
      "Epoch 8 Step 1461/1563 Loss: 1.363 | Acc: 50.955% (23839/46784)\n",
      "Epoch 8 Step 1462/1563 Loss: 1.363 | Acc: 50.953% (23854/46816)\n",
      "Epoch 8 Step 1463/1563 Loss: 1.363 | Acc: 50.952% (23870/46848)\n",
      "Epoch 8 Step 1464/1563 Loss: 1.363 | Acc: 50.947% (23884/46880)\n",
      "Epoch 8 Step 1465/1563 Loss: 1.363 | Acc: 50.944% (23899/46912)\n",
      "Epoch 8 Step 1466/1563 Loss: 1.363 | Acc: 50.946% (23916/46944)\n",
      "Epoch 8 Step 1467/1563 Loss: 1.363 | Acc: 50.949% (23934/46976)\n",
      "Epoch 8 Step 1468/1563 Loss: 1.363 | Acc: 50.951% (23951/47008)\n",
      "Epoch 8 Step 1469/1563 Loss: 1.363 | Acc: 50.955% (23969/47040)\n",
      "Epoch 8 Step 1470/1563 Loss: 1.363 | Acc: 50.952% (23984/47072)\n",
      "Epoch 8 Step 1471/1563 Loss: 1.363 | Acc: 50.960% (24004/47104)\n",
      "Epoch 8 Step 1472/1563 Loss: 1.363 | Acc: 50.963% (24022/47136)\n",
      "Epoch 8 Step 1473/1563 Loss: 1.363 | Acc: 50.969% (24041/47168)\n",
      "Epoch 8 Step 1474/1563 Loss: 1.363 | Acc: 50.970% (24058/47200)\n",
      "Epoch 8 Step 1475/1563 Loss: 1.363 | Acc: 50.980% (24079/47232)\n",
      "Epoch 8 Step 1476/1563 Loss: 1.363 | Acc: 50.988% (24099/47264)\n",
      "Epoch 8 Step 1477/1563 Loss: 1.363 | Acc: 50.992% (24117/47296)\n",
      "Epoch 8 Step 1478/1563 Loss: 1.362 | Acc: 51.002% (24138/47328)\n",
      "Epoch 8 Step 1479/1563 Loss: 1.363 | Acc: 50.990% (24149/47360)\n",
      "Epoch 8 Step 1480/1563 Loss: 1.363 | Acc: 50.996% (24168/47392)\n",
      "Epoch 8 Step 1481/1563 Loss: 1.362 | Acc: 50.999% (24186/47424)\n",
      "Epoch 8 Step 1482/1563 Loss: 1.362 | Acc: 50.999% (24202/47456)\n",
      "Epoch 8 Step 1483/1563 Loss: 1.362 | Acc: 51.004% (24221/47488)\n",
      "Epoch 8 Step 1484/1563 Loss: 1.362 | Acc: 51.012% (24241/47520)\n",
      "Epoch 8 Step 1485/1563 Loss: 1.362 | Acc: 51.007% (24255/47552)\n",
      "Epoch 8 Step 1486/1563 Loss: 1.362 | Acc: 51.019% (24277/47584)\n",
      "Epoch 8 Step 1487/1563 Loss: 1.362 | Acc: 51.023% (24295/47616)\n",
      "Epoch 8 Step 1488/1563 Loss: 1.362 | Acc: 51.022% (24311/47648)\n",
      "Epoch 8 Step 1489/1563 Loss: 1.362 | Acc: 51.015% (24324/47680)\n",
      "Epoch 8 Step 1490/1563 Loss: 1.362 | Acc: 51.010% (24338/47712)\n",
      "Epoch 8 Step 1491/1563 Loss: 1.362 | Acc: 51.012% (24355/47744)\n",
      "Epoch 8 Step 1492/1563 Loss: 1.362 | Acc: 51.013% (24372/47776)\n",
      "Epoch 8 Step 1493/1563 Loss: 1.362 | Acc: 51.019% (24391/47808)\n",
      "Epoch 8 Step 1494/1563 Loss: 1.362 | Acc: 51.008% (24402/47840)\n",
      "Epoch 8 Step 1495/1563 Loss: 1.363 | Acc: 51.003% (24416/47872)\n",
      "Epoch 8 Step 1496/1563 Loss: 1.362 | Acc: 50.994% (24428/47904)\n",
      "Epoch 8 Step 1497/1563 Loss: 1.362 | Acc: 51.006% (24450/47936)\n",
      "Epoch 8 Step 1498/1563 Loss: 1.362 | Acc: 51.009% (24468/47968)\n",
      "Epoch 8 Step 1499/1563 Loss: 1.362 | Acc: 51.010% (24485/48000)\n",
      "Epoch 8 Step 1500/1563 Loss: 1.362 | Acc: 51.014% (24503/48032)\n",
      "Epoch 8 Step 1501/1563 Loss: 1.362 | Acc: 51.013% (24519/48064)\n",
      "Epoch 8 Step 1502/1563 Loss: 1.362 | Acc: 51.017% (24537/48096)\n",
      "Epoch 8 Step 1503/1563 Loss: 1.362 | Acc: 51.022% (24556/48128)\n",
      "Epoch 8 Step 1504/1563 Loss: 1.362 | Acc: 51.034% (24578/48160)\n",
      "Epoch 8 Step 1505/1563 Loss: 1.361 | Acc: 51.029% (24592/48192)\n",
      "Epoch 8 Step 1506/1563 Loss: 1.361 | Acc: 51.029% (24608/48224)\n",
      "Epoch 8 Step 1507/1563 Loss: 1.361 | Acc: 51.028% (24624/48256)\n",
      "Epoch 8 Step 1508/1563 Loss: 1.361 | Acc: 51.035% (24644/48288)\n",
      "Epoch 8 Step 1509/1563 Loss: 1.361 | Acc: 51.029% (24657/48320)\n",
      "Epoch 8 Step 1510/1563 Loss: 1.361 | Acc: 51.030% (24674/48352)\n",
      "Epoch 8 Step 1511/1563 Loss: 1.361 | Acc: 51.029% (24690/48384)\n",
      "Epoch 8 Step 1512/1563 Loss: 1.361 | Acc: 51.029% (24706/48416)\n",
      "Epoch 8 Step 1513/1563 Loss: 1.361 | Acc: 51.026% (24721/48448)\n",
      "Epoch 8 Step 1514/1563 Loss: 1.361 | Acc: 51.033% (24741/48480)\n",
      "Epoch 8 Step 1515/1563 Loss: 1.361 | Acc: 51.037% (24759/48512)\n",
      "Epoch 8 Step 1516/1563 Loss: 1.361 | Acc: 51.030% (24772/48544)\n",
      "Epoch 8 Step 1517/1563 Loss: 1.361 | Acc: 51.031% (24789/48576)\n",
      "Epoch 8 Step 1518/1563 Loss: 1.361 | Acc: 51.025% (24802/48608)\n",
      "Epoch 8 Step 1519/1563 Loss: 1.361 | Acc: 51.018% (24815/48640)\n",
      "Epoch 8 Step 1520/1563 Loss: 1.361 | Acc: 51.021% (24833/48672)\n",
      "Epoch 8 Step 1521/1563 Loss: 1.361 | Acc: 51.027% (24852/48704)\n",
      "Epoch 8 Step 1522/1563 Loss: 1.361 | Acc: 51.020% (24865/48736)\n",
      "Epoch 8 Step 1523/1563 Loss: 1.361 | Acc: 51.023% (24883/48768)\n",
      "Epoch 8 Step 1524/1563 Loss: 1.361 | Acc: 51.027% (24901/48800)\n",
      "Epoch 8 Step 1525/1563 Loss: 1.361 | Acc: 51.028% (24918/48832)\n",
      "Epoch 8 Step 1526/1563 Loss: 1.361 | Acc: 51.019% (24930/48864)\n",
      "Epoch 8 Step 1527/1563 Loss: 1.361 | Acc: 51.031% (24952/48896)\n",
      "Epoch 8 Step 1528/1563 Loss: 1.361 | Acc: 51.022% (24964/48928)\n",
      "Epoch 8 Step 1529/1563 Loss: 1.361 | Acc: 51.029% (24984/48960)\n",
      "Epoch 8 Step 1530/1563 Loss: 1.361 | Acc: 51.027% (24999/48992)\n",
      "Epoch 8 Step 1531/1563 Loss: 1.361 | Acc: 51.026% (25015/49024)\n",
      "Epoch 8 Step 1532/1563 Loss: 1.361 | Acc: 51.019% (25028/49056)\n",
      "Epoch 8 Step 1533/1563 Loss: 1.361 | Acc: 51.025% (25047/49088)\n",
      "Epoch 8 Step 1534/1563 Loss: 1.361 | Acc: 51.028% (25065/49120)\n",
      "Epoch 8 Step 1535/1563 Loss: 1.361 | Acc: 51.027% (25081/49152)\n",
      "Epoch 8 Step 1536/1563 Loss: 1.361 | Acc: 51.035% (25101/49184)\n",
      "Epoch 8 Step 1537/1563 Loss: 1.361 | Acc: 51.040% (25120/49216)\n",
      "Epoch 8 Step 1538/1563 Loss: 1.361 | Acc: 51.036% (25134/49248)\n",
      "Epoch 8 Step 1539/1563 Loss: 1.361 | Acc: 51.031% (25148/49280)\n",
      "Epoch 8 Step 1540/1563 Loss: 1.361 | Acc: 51.034% (25166/49312)\n",
      "Epoch 8 Step 1541/1563 Loss: 1.361 | Acc: 51.025% (25178/49344)\n",
      "Epoch 8 Step 1542/1563 Loss: 1.361 | Acc: 51.033% (25198/49376)\n",
      "Epoch 8 Step 1543/1563 Loss: 1.361 | Acc: 51.032% (25214/49408)\n",
      "Epoch 8 Step 1544/1563 Loss: 1.362 | Acc: 51.032% (25230/49440)\n",
      "Epoch 8 Step 1545/1563 Loss: 1.361 | Acc: 51.043% (25252/49472)\n",
      "Epoch 8 Step 1546/1563 Loss: 1.361 | Acc: 51.044% (25269/49504)\n",
      "Epoch 8 Step 1547/1563 Loss: 1.361 | Acc: 51.038% (25282/49536)\n",
      "Epoch 8 Step 1548/1563 Loss: 1.361 | Acc: 51.035% (25297/49568)\n",
      "Epoch 8 Step 1549/1563 Loss: 1.362 | Acc: 51.032% (25312/49600)\n",
      "Epoch 8 Step 1550/1563 Loss: 1.361 | Acc: 51.038% (25331/49632)\n",
      "Epoch 8 Step 1551/1563 Loss: 1.361 | Acc: 51.037% (25347/49664)\n",
      "Epoch 8 Step 1552/1563 Loss: 1.361 | Acc: 51.040% (25365/49696)\n",
      "Epoch 8 Step 1553/1563 Loss: 1.361 | Acc: 51.036% (25379/49728)\n",
      "Epoch 8 Step 1554/1563 Loss: 1.361 | Acc: 51.045% (25400/49760)\n",
      "Epoch 8 Step 1555/1563 Loss: 1.361 | Acc: 51.036% (25412/49792)\n",
      "Epoch 8 Step 1556/1563 Loss: 1.361 | Acc: 51.042% (25431/49824)\n",
      "Epoch 8 Step 1557/1563 Loss: 1.361 | Acc: 51.037% (25445/49856)\n",
      "Epoch 8 Step 1558/1563 Loss: 1.361 | Acc: 51.048% (25467/49888)\n",
      "Epoch 8 Step 1559/1563 Loss: 1.361 | Acc: 51.048% (25483/49920)\n",
      "Epoch 8 Step 1560/1563 Loss: 1.361 | Acc: 51.051% (25501/49952)\n",
      "Epoch 8 Step 1561/1563 Loss: 1.361 | Acc: 51.050% (25517/49984)\n",
      "Epoch 8 Step 1562/1563 Loss: 1.361 | Acc: 51.046% (25523/50000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 0/313 Test Loss: 1.008 | Test Acc: 62.500% (20/32)\n",
      "Epoch 8 Step 1/313 Test Loss: 1.181 | Test Acc: 57.812% (37/64)\n",
      "Epoch 8 Step 2/313 Test Loss: 1.161 | Test Acc: 60.417% (58/96)\n",
      "Epoch 8 Step 3/313 Test Loss: 1.180 | Test Acc: 59.375% (76/128)\n",
      "Epoch 8 Step 4/313 Test Loss: 1.221 | Test Acc: 58.125% (93/160)\n",
      "Epoch 8 Step 5/313 Test Loss: 1.236 | Test Acc: 56.250% (108/192)\n",
      "Epoch 8 Step 6/313 Test Loss: 1.296 | Test Acc: 54.018% (121/224)\n",
      "Epoch 8 Step 7/313 Test Loss: 1.297 | Test Acc: 55.078% (141/256)\n",
      "Epoch 8 Step 8/313 Test Loss: 1.298 | Test Acc: 54.167% (156/288)\n",
      "Epoch 8 Step 9/313 Test Loss: 1.277 | Test Acc: 55.938% (179/320)\n",
      "Epoch 8 Step 10/313 Test Loss: 1.276 | Test Acc: 55.682% (196/352)\n",
      "Epoch 8 Step 11/313 Test Loss: 1.288 | Test Acc: 55.469% (213/384)\n",
      "Epoch 8 Step 12/313 Test Loss: 1.285 | Test Acc: 55.529% (231/416)\n",
      "Epoch 8 Step 13/313 Test Loss: 1.299 | Test Acc: 55.134% (247/448)\n",
      "Epoch 8 Step 14/313 Test Loss: 1.310 | Test Acc: 54.375% (261/480)\n",
      "Epoch 8 Step 15/313 Test Loss: 1.301 | Test Acc: 54.297% (278/512)\n",
      "Epoch 8 Step 16/313 Test Loss: 1.284 | Test Acc: 54.596% (297/544)\n",
      "Epoch 8 Step 17/313 Test Loss: 1.274 | Test Acc: 55.208% (318/576)\n",
      "Epoch 8 Step 18/313 Test Loss: 1.282 | Test Acc: 54.770% (333/608)\n",
      "Epoch 8 Step 19/313 Test Loss: 1.262 | Test Acc: 55.469% (355/640)\n",
      "Epoch 8 Step 20/313 Test Loss: 1.251 | Test Acc: 55.506% (373/672)\n",
      "Epoch 8 Step 21/313 Test Loss: 1.270 | Test Acc: 54.688% (385/704)\n",
      "Epoch 8 Step 22/313 Test Loss: 1.270 | Test Acc: 54.620% (402/736)\n",
      "Epoch 8 Step 23/313 Test Loss: 1.269 | Test Acc: 54.557% (419/768)\n",
      "Epoch 8 Step 24/313 Test Loss: 1.276 | Test Acc: 54.250% (434/800)\n",
      "Epoch 8 Step 25/313 Test Loss: 1.274 | Test Acc: 54.688% (455/832)\n",
      "Epoch 8 Step 26/313 Test Loss: 1.277 | Test Acc: 54.630% (472/864)\n",
      "Epoch 8 Step 27/313 Test Loss: 1.269 | Test Acc: 54.911% (492/896)\n",
      "Epoch 8 Step 28/313 Test Loss: 1.263 | Test Acc: 55.172% (512/928)\n",
      "Epoch 8 Step 29/313 Test Loss: 1.254 | Test Acc: 55.000% (528/960)\n",
      "Epoch 8 Step 30/313 Test Loss: 1.248 | Test Acc: 55.343% (549/992)\n",
      "Epoch 8 Step 31/313 Test Loss: 1.240 | Test Acc: 55.566% (569/1024)\n",
      "Epoch 8 Step 32/313 Test Loss: 1.245 | Test Acc: 55.587% (587/1056)\n",
      "Epoch 8 Step 33/313 Test Loss: 1.240 | Test Acc: 55.699% (606/1088)\n",
      "Epoch 8 Step 34/313 Test Loss: 1.231 | Test Acc: 55.893% (626/1120)\n",
      "Epoch 8 Step 35/313 Test Loss: 1.237 | Test Acc: 55.382% (638/1152)\n",
      "Epoch 8 Step 36/313 Test Loss: 1.232 | Test Acc: 55.405% (656/1184)\n",
      "Epoch 8 Step 37/313 Test Loss: 1.234 | Test Acc: 55.592% (676/1216)\n",
      "Epoch 8 Step 38/313 Test Loss: 1.243 | Test Acc: 55.288% (690/1248)\n",
      "Epoch 8 Step 39/313 Test Loss: 1.243 | Test Acc: 55.078% (705/1280)\n",
      "Epoch 8 Step 40/313 Test Loss: 1.247 | Test Acc: 54.726% (718/1312)\n",
      "Epoch 8 Step 41/313 Test Loss: 1.249 | Test Acc: 54.836% (737/1344)\n",
      "Epoch 8 Step 42/313 Test Loss: 1.244 | Test Acc: 54.869% (755/1376)\n",
      "Epoch 8 Step 43/313 Test Loss: 1.249 | Test Acc: 54.688% (770/1408)\n",
      "Epoch 8 Step 44/313 Test Loss: 1.253 | Test Acc: 54.514% (785/1440)\n",
      "Epoch 8 Step 45/313 Test Loss: 1.248 | Test Acc: 54.620% (804/1472)\n",
      "Epoch 8 Step 46/313 Test Loss: 1.251 | Test Acc: 54.521% (820/1504)\n",
      "Epoch 8 Step 47/313 Test Loss: 1.249 | Test Acc: 54.622% (839/1536)\n",
      "Epoch 8 Step 48/313 Test Loss: 1.247 | Test Acc: 54.719% (858/1568)\n",
      "Epoch 8 Step 49/313 Test Loss: 1.258 | Test Acc: 54.500% (872/1600)\n",
      "Epoch 8 Step 50/313 Test Loss: 1.266 | Test Acc: 54.228% (885/1632)\n",
      "Epoch 8 Step 51/313 Test Loss: 1.263 | Test Acc: 54.567% (908/1664)\n",
      "Epoch 8 Step 52/313 Test Loss: 1.265 | Test Acc: 54.599% (926/1696)\n",
      "Epoch 8 Step 53/313 Test Loss: 1.270 | Test Acc: 54.456% (941/1728)\n",
      "Epoch 8 Step 54/313 Test Loss: 1.271 | Test Acc: 54.375% (957/1760)\n",
      "Epoch 8 Step 55/313 Test Loss: 1.268 | Test Acc: 54.464% (976/1792)\n",
      "Epoch 8 Step 56/313 Test Loss: 1.268 | Test Acc: 54.496% (994/1824)\n",
      "Epoch 8 Step 57/313 Test Loss: 1.271 | Test Acc: 54.634% (1014/1856)\n",
      "Epoch 8 Step 58/313 Test Loss: 1.273 | Test Acc: 54.714% (1033/1888)\n",
      "Epoch 8 Step 59/313 Test Loss: 1.276 | Test Acc: 54.635% (1049/1920)\n",
      "Epoch 8 Step 60/313 Test Loss: 1.277 | Test Acc: 54.406% (1062/1952)\n",
      "Epoch 8 Step 61/313 Test Loss: 1.278 | Test Acc: 54.435% (1080/1984)\n",
      "Epoch 8 Step 62/313 Test Loss: 1.284 | Test Acc: 54.216% (1093/2016)\n",
      "Epoch 8 Step 63/313 Test Loss: 1.283 | Test Acc: 54.053% (1107/2048)\n",
      "Epoch 8 Step 64/313 Test Loss: 1.281 | Test Acc: 54.087% (1125/2080)\n",
      "Epoch 8 Step 65/313 Test Loss: 1.278 | Test Acc: 54.214% (1145/2112)\n",
      "Epoch 8 Step 66/313 Test Loss: 1.279 | Test Acc: 54.151% (1161/2144)\n",
      "Epoch 8 Step 67/313 Test Loss: 1.281 | Test Acc: 54.090% (1177/2176)\n",
      "Epoch 8 Step 68/313 Test Loss: 1.282 | Test Acc: 54.167% (1196/2208)\n",
      "Epoch 8 Step 69/313 Test Loss: 1.282 | Test Acc: 54.196% (1214/2240)\n",
      "Epoch 8 Step 70/313 Test Loss: 1.282 | Test Acc: 54.269% (1233/2272)\n",
      "Epoch 8 Step 71/313 Test Loss: 1.283 | Test Acc: 54.167% (1248/2304)\n",
      "Epoch 8 Step 72/313 Test Loss: 1.285 | Test Acc: 54.152% (1265/2336)\n",
      "Epoch 8 Step 73/313 Test Loss: 1.283 | Test Acc: 54.265% (1285/2368)\n",
      "Epoch 8 Step 74/313 Test Loss: 1.283 | Test Acc: 54.333% (1304/2400)\n",
      "Epoch 8 Step 75/313 Test Loss: 1.283 | Test Acc: 54.359% (1322/2432)\n",
      "Epoch 8 Step 76/313 Test Loss: 1.283 | Test Acc: 54.464% (1342/2464)\n",
      "Epoch 8 Step 77/313 Test Loss: 1.283 | Test Acc: 54.527% (1361/2496)\n",
      "Epoch 8 Step 78/313 Test Loss: 1.288 | Test Acc: 54.233% (1371/2528)\n",
      "Epoch 8 Step 79/313 Test Loss: 1.292 | Test Acc: 54.102% (1385/2560)\n",
      "Epoch 8 Step 80/313 Test Loss: 1.292 | Test Acc: 54.012% (1400/2592)\n",
      "Epoch 8 Step 81/313 Test Loss: 1.291 | Test Acc: 54.040% (1418/2624)\n",
      "Epoch 8 Step 82/313 Test Loss: 1.292 | Test Acc: 54.029% (1435/2656)\n",
      "Epoch 8 Step 83/313 Test Loss: 1.289 | Test Acc: 54.129% (1455/2688)\n",
      "Epoch 8 Step 84/313 Test Loss: 1.292 | Test Acc: 54.044% (1470/2720)\n",
      "Epoch 8 Step 85/313 Test Loss: 1.293 | Test Acc: 53.888% (1483/2752)\n",
      "Epoch 8 Step 86/313 Test Loss: 1.293 | Test Acc: 53.772% (1497/2784)\n",
      "Epoch 8 Step 87/313 Test Loss: 1.292 | Test Acc: 53.800% (1515/2816)\n",
      "Epoch 8 Step 88/313 Test Loss: 1.292 | Test Acc: 53.862% (1534/2848)\n",
      "Epoch 8 Step 89/313 Test Loss: 1.293 | Test Acc: 53.681% (1546/2880)\n",
      "Epoch 8 Step 90/313 Test Loss: 1.291 | Test Acc: 53.812% (1567/2912)\n",
      "Epoch 8 Step 91/313 Test Loss: 1.286 | Test Acc: 53.974% (1589/2944)\n",
      "Epoch 8 Step 92/313 Test Loss: 1.286 | Test Acc: 54.032% (1608/2976)\n",
      "Epoch 8 Step 93/313 Test Loss: 1.285 | Test Acc: 54.122% (1628/3008)\n",
      "Epoch 8 Step 94/313 Test Loss: 1.284 | Test Acc: 54.145% (1646/3040)\n",
      "Epoch 8 Step 95/313 Test Loss: 1.284 | Test Acc: 54.102% (1662/3072)\n",
      "Epoch 8 Step 96/313 Test Loss: 1.282 | Test Acc: 54.188% (1682/3104)\n",
      "Epoch 8 Step 97/313 Test Loss: 1.283 | Test Acc: 54.082% (1696/3136)\n",
      "Epoch 8 Step 98/313 Test Loss: 1.282 | Test Acc: 54.040% (1712/3168)\n",
      "Epoch 8 Step 99/313 Test Loss: 1.284 | Test Acc: 54.062% (1730/3200)\n",
      "Epoch 8 Step 100/313 Test Loss: 1.286 | Test Acc: 54.022% (1746/3232)\n",
      "Epoch 8 Step 101/313 Test Loss: 1.284 | Test Acc: 54.075% (1765/3264)\n",
      "Epoch 8 Step 102/313 Test Loss: 1.283 | Test Acc: 54.217% (1787/3296)\n",
      "Epoch 8 Step 103/313 Test Loss: 1.284 | Test Acc: 54.237% (1805/3328)\n",
      "Epoch 8 Step 104/313 Test Loss: 1.283 | Test Acc: 54.286% (1824/3360)\n",
      "Epoch 8 Step 105/313 Test Loss: 1.281 | Test Acc: 54.363% (1844/3392)\n",
      "Epoch 8 Step 106/313 Test Loss: 1.281 | Test Acc: 54.264% (1858/3424)\n",
      "Epoch 8 Step 107/313 Test Loss: 1.281 | Test Acc: 54.311% (1877/3456)\n",
      "Epoch 8 Step 108/313 Test Loss: 1.278 | Test Acc: 54.386% (1897/3488)\n",
      "Epoch 8 Step 109/313 Test Loss: 1.281 | Test Acc: 54.375% (1914/3520)\n",
      "Epoch 8 Step 110/313 Test Loss: 1.279 | Test Acc: 54.476% (1935/3552)\n",
      "Epoch 8 Step 111/313 Test Loss: 1.277 | Test Acc: 54.548% (1955/3584)\n",
      "Epoch 8 Step 112/313 Test Loss: 1.277 | Test Acc: 54.508% (1971/3616)\n",
      "Epoch 8 Step 113/313 Test Loss: 1.277 | Test Acc: 54.550% (1990/3648)\n",
      "Epoch 8 Step 114/313 Test Loss: 1.276 | Test Acc: 54.592% (2009/3680)\n",
      "Epoch 8 Step 115/313 Test Loss: 1.275 | Test Acc: 54.580% (2026/3712)\n",
      "Epoch 8 Step 116/313 Test Loss: 1.275 | Test Acc: 54.541% (2042/3744)\n",
      "Epoch 8 Step 117/313 Test Loss: 1.277 | Test Acc: 54.502% (2058/3776)\n",
      "Epoch 8 Step 118/313 Test Loss: 1.276 | Test Acc: 54.491% (2075/3808)\n",
      "Epoch 8 Step 119/313 Test Loss: 1.273 | Test Acc: 54.661% (2099/3840)\n",
      "Epoch 8 Step 120/313 Test Loss: 1.270 | Test Acc: 54.778% (2121/3872)\n",
      "Epoch 8 Step 121/313 Test Loss: 1.270 | Test Acc: 54.662% (2134/3904)\n",
      "Epoch 8 Step 122/313 Test Loss: 1.271 | Test Acc: 54.573% (2148/3936)\n",
      "Epoch 8 Step 123/313 Test Loss: 1.269 | Test Acc: 54.637% (2168/3968)\n",
      "Epoch 8 Step 124/313 Test Loss: 1.271 | Test Acc: 54.525% (2181/4000)\n",
      "Epoch 8 Step 125/313 Test Loss: 1.271 | Test Acc: 54.588% (2201/4032)\n",
      "Epoch 8 Step 126/313 Test Loss: 1.274 | Test Acc: 54.601% (2219/4064)\n",
      "Epoch 8 Step 127/313 Test Loss: 1.271 | Test Acc: 54.688% (2240/4096)\n",
      "Epoch 8 Step 128/313 Test Loss: 1.274 | Test Acc: 54.627% (2255/4128)\n",
      "Epoch 8 Step 129/313 Test Loss: 1.273 | Test Acc: 54.688% (2275/4160)\n",
      "Epoch 8 Step 130/313 Test Loss: 1.271 | Test Acc: 54.795% (2297/4192)\n",
      "Epoch 8 Step 131/313 Test Loss: 1.271 | Test Acc: 54.759% (2313/4224)\n",
      "Epoch 8 Step 132/313 Test Loss: 1.272 | Test Acc: 54.723% (2329/4256)\n",
      "Epoch 8 Step 133/313 Test Loss: 1.272 | Test Acc: 54.711% (2346/4288)\n",
      "Epoch 8 Step 134/313 Test Loss: 1.273 | Test Acc: 54.653% (2361/4320)\n",
      "Epoch 8 Step 135/313 Test Loss: 1.271 | Test Acc: 54.756% (2383/4352)\n",
      "Epoch 8 Step 136/313 Test Loss: 1.270 | Test Acc: 54.745% (2400/4384)\n",
      "Epoch 8 Step 137/313 Test Loss: 1.269 | Test Acc: 54.778% (2419/4416)\n",
      "Epoch 8 Step 138/313 Test Loss: 1.268 | Test Acc: 54.789% (2437/4448)\n",
      "Epoch 8 Step 139/313 Test Loss: 1.268 | Test Acc: 54.710% (2451/4480)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 140/313 Test Loss: 1.267 | Test Acc: 54.787% (2472/4512)\n",
      "Epoch 8 Step 141/313 Test Loss: 1.267 | Test Acc: 54.776% (2489/4544)\n",
      "Epoch 8 Step 142/313 Test Loss: 1.268 | Test Acc: 54.633% (2500/4576)\n",
      "Epoch 8 Step 143/313 Test Loss: 1.270 | Test Acc: 54.579% (2515/4608)\n",
      "Epoch 8 Step 144/313 Test Loss: 1.271 | Test Acc: 54.612% (2534/4640)\n",
      "Epoch 8 Step 145/313 Test Loss: 1.268 | Test Acc: 54.730% (2557/4672)\n",
      "Epoch 8 Step 146/313 Test Loss: 1.268 | Test Acc: 54.656% (2571/4704)\n",
      "Epoch 8 Step 147/313 Test Loss: 1.268 | Test Acc: 54.624% (2587/4736)\n",
      "Epoch 8 Step 148/313 Test Loss: 1.269 | Test Acc: 54.614% (2604/4768)\n",
      "Epoch 8 Step 149/313 Test Loss: 1.269 | Test Acc: 54.583% (2620/4800)\n",
      "Epoch 8 Step 150/313 Test Loss: 1.272 | Test Acc: 54.512% (2634/4832)\n",
      "Epoch 8 Step 151/313 Test Loss: 1.269 | Test Acc: 54.605% (2656/4864)\n",
      "Epoch 8 Step 152/313 Test Loss: 1.269 | Test Acc: 54.575% (2672/4896)\n",
      "Epoch 8 Step 153/313 Test Loss: 1.268 | Test Acc: 54.627% (2692/4928)\n",
      "Epoch 8 Step 154/313 Test Loss: 1.268 | Test Acc: 54.657% (2711/4960)\n",
      "Epoch 8 Step 155/313 Test Loss: 1.268 | Test Acc: 54.607% (2726/4992)\n",
      "Epoch 8 Step 156/313 Test Loss: 1.269 | Test Acc: 54.618% (2744/5024)\n",
      "Epoch 8 Step 157/313 Test Loss: 1.268 | Test Acc: 54.608% (2761/5056)\n",
      "Epoch 8 Step 158/313 Test Loss: 1.269 | Test Acc: 54.540% (2775/5088)\n",
      "Epoch 8 Step 159/313 Test Loss: 1.271 | Test Acc: 54.492% (2790/5120)\n",
      "Epoch 8 Step 160/313 Test Loss: 1.271 | Test Acc: 54.523% (2809/5152)\n",
      "Epoch 8 Step 161/313 Test Loss: 1.271 | Test Acc: 54.610% (2831/5184)\n",
      "Epoch 8 Step 162/313 Test Loss: 1.272 | Test Acc: 54.601% (2848/5216)\n",
      "Epoch 8 Step 163/313 Test Loss: 1.273 | Test Acc: 54.554% (2863/5248)\n",
      "Epoch 8 Step 164/313 Test Loss: 1.273 | Test Acc: 54.545% (2880/5280)\n",
      "Epoch 8 Step 165/313 Test Loss: 1.274 | Test Acc: 54.537% (2897/5312)\n",
      "Epoch 8 Step 166/313 Test Loss: 1.275 | Test Acc: 54.510% (2913/5344)\n",
      "Epoch 8 Step 167/313 Test Loss: 1.275 | Test Acc: 54.501% (2930/5376)\n",
      "Epoch 8 Step 168/313 Test Loss: 1.276 | Test Acc: 54.512% (2948/5408)\n",
      "Epoch 8 Step 169/313 Test Loss: 1.276 | Test Acc: 54.485% (2964/5440)\n",
      "Epoch 8 Step 170/313 Test Loss: 1.275 | Test Acc: 54.532% (2984/5472)\n",
      "Epoch 8 Step 171/313 Test Loss: 1.275 | Test Acc: 54.560% (3003/5504)\n",
      "Epoch 8 Step 172/313 Test Loss: 1.276 | Test Acc: 54.552% (3020/5536)\n",
      "Epoch 8 Step 173/313 Test Loss: 1.277 | Test Acc: 54.454% (3032/5568)\n",
      "Epoch 8 Step 174/313 Test Loss: 1.276 | Test Acc: 54.446% (3049/5600)\n",
      "Epoch 8 Step 175/313 Test Loss: 1.277 | Test Acc: 54.439% (3066/5632)\n",
      "Epoch 8 Step 176/313 Test Loss: 1.278 | Test Acc: 54.273% (3074/5664)\n",
      "Epoch 8 Step 177/313 Test Loss: 1.278 | Test Acc: 54.319% (3094/5696)\n",
      "Epoch 8 Step 178/313 Test Loss: 1.276 | Test Acc: 54.312% (3111/5728)\n",
      "Epoch 8 Step 179/313 Test Loss: 1.276 | Test Acc: 54.253% (3125/5760)\n",
      "Epoch 8 Step 180/313 Test Loss: 1.274 | Test Acc: 54.368% (3149/5792)\n",
      "Epoch 8 Step 181/313 Test Loss: 1.275 | Test Acc: 54.327% (3164/5824)\n",
      "Epoch 8 Step 182/313 Test Loss: 1.278 | Test Acc: 54.218% (3175/5856)\n",
      "Epoch 8 Step 183/313 Test Loss: 1.279 | Test Acc: 54.195% (3191/5888)\n",
      "Epoch 8 Step 184/313 Test Loss: 1.281 | Test Acc: 54.155% (3206/5920)\n",
      "Epoch 8 Step 185/313 Test Loss: 1.281 | Test Acc: 54.150% (3223/5952)\n",
      "Epoch 8 Step 186/313 Test Loss: 1.281 | Test Acc: 54.178% (3242/5984)\n",
      "Epoch 8 Step 187/313 Test Loss: 1.280 | Test Acc: 54.189% (3260/6016)\n",
      "Epoch 8 Step 188/313 Test Loss: 1.280 | Test Acc: 54.200% (3278/6048)\n",
      "Epoch 8 Step 189/313 Test Loss: 1.281 | Test Acc: 54.161% (3293/6080)\n",
      "Epoch 8 Step 190/313 Test Loss: 1.280 | Test Acc: 54.139% (3309/6112)\n",
      "Epoch 8 Step 191/313 Test Loss: 1.280 | Test Acc: 54.134% (3326/6144)\n",
      "Epoch 8 Step 192/313 Test Loss: 1.281 | Test Acc: 54.097% (3341/6176)\n",
      "Epoch 8 Step 193/313 Test Loss: 1.280 | Test Acc: 54.108% (3359/6208)\n",
      "Epoch 8 Step 194/313 Test Loss: 1.280 | Test Acc: 54.071% (3374/6240)\n",
      "Epoch 8 Step 195/313 Test Loss: 1.282 | Test Acc: 54.018% (3388/6272)\n",
      "Epoch 8 Step 196/313 Test Loss: 1.282 | Test Acc: 53.982% (3403/6304)\n",
      "Epoch 8 Step 197/313 Test Loss: 1.282 | Test Acc: 54.025% (3423/6336)\n",
      "Epoch 8 Step 198/313 Test Loss: 1.280 | Test Acc: 54.067% (3443/6368)\n",
      "Epoch 8 Step 199/313 Test Loss: 1.281 | Test Acc: 54.000% (3456/6400)\n",
      "Epoch 8 Step 200/313 Test Loss: 1.282 | Test Acc: 53.996% (3473/6432)\n",
      "Epoch 8 Step 201/313 Test Loss: 1.282 | Test Acc: 53.960% (3488/6464)\n",
      "Epoch 8 Step 202/313 Test Loss: 1.284 | Test Acc: 53.925% (3503/6496)\n",
      "Epoch 8 Step 203/313 Test Loss: 1.284 | Test Acc: 53.876% (3517/6528)\n",
      "Epoch 8 Step 204/313 Test Loss: 1.286 | Test Acc: 53.811% (3530/6560)\n",
      "Epoch 8 Step 205/313 Test Loss: 1.286 | Test Acc: 53.777% (3545/6592)\n",
      "Epoch 8 Step 206/313 Test Loss: 1.286 | Test Acc: 53.804% (3564/6624)\n",
      "Epoch 8 Step 207/313 Test Loss: 1.285 | Test Acc: 53.846% (3584/6656)\n",
      "Epoch 8 Step 208/313 Test Loss: 1.285 | Test Acc: 53.798% (3598/6688)\n",
      "Epoch 8 Step 209/313 Test Loss: 1.285 | Test Acc: 53.839% (3618/6720)\n",
      "Epoch 8 Step 210/313 Test Loss: 1.285 | Test Acc: 53.821% (3634/6752)\n",
      "Epoch 8 Step 211/313 Test Loss: 1.285 | Test Acc: 53.774% (3648/6784)\n",
      "Epoch 8 Step 212/313 Test Loss: 1.284 | Test Acc: 53.873% (3672/6816)\n",
      "Epoch 8 Step 213/313 Test Loss: 1.284 | Test Acc: 53.855% (3688/6848)\n",
      "Epoch 8 Step 214/313 Test Loss: 1.286 | Test Acc: 53.808% (3702/6880)\n",
      "Epoch 8 Step 215/313 Test Loss: 1.285 | Test Acc: 53.834% (3721/6912)\n",
      "Epoch 8 Step 216/313 Test Loss: 1.285 | Test Acc: 53.787% (3735/6944)\n",
      "Epoch 8 Step 217/313 Test Loss: 1.287 | Test Acc: 53.756% (3750/6976)\n",
      "Epoch 8 Step 218/313 Test Loss: 1.288 | Test Acc: 53.710% (3764/7008)\n",
      "Epoch 8 Step 219/313 Test Loss: 1.287 | Test Acc: 53.736% (3783/7040)\n",
      "Epoch 8 Step 220/313 Test Loss: 1.287 | Test Acc: 53.747% (3801/7072)\n",
      "Epoch 8 Step 221/313 Test Loss: 1.286 | Test Acc: 53.744% (3818/7104)\n",
      "Epoch 8 Step 222/313 Test Loss: 1.287 | Test Acc: 53.756% (3836/7136)\n",
      "Epoch 8 Step 223/313 Test Loss: 1.286 | Test Acc: 53.795% (3856/7168)\n",
      "Epoch 8 Step 224/313 Test Loss: 1.287 | Test Acc: 53.764% (3871/7200)\n",
      "Epoch 8 Step 225/313 Test Loss: 1.287 | Test Acc: 53.733% (3886/7232)\n",
      "Epoch 8 Step 226/313 Test Loss: 1.288 | Test Acc: 53.717% (3902/7264)\n",
      "Epoch 8 Step 227/313 Test Loss: 1.287 | Test Acc: 53.701% (3918/7296)\n",
      "Epoch 8 Step 228/313 Test Loss: 1.286 | Test Acc: 53.780% (3941/7328)\n",
      "Epoch 8 Step 229/313 Test Loss: 1.285 | Test Acc: 53.832% (3962/7360)\n",
      "Epoch 8 Step 230/313 Test Loss: 1.284 | Test Acc: 53.801% (3977/7392)\n",
      "Epoch 8 Step 231/313 Test Loss: 1.285 | Test Acc: 53.785% (3993/7424)\n",
      "Epoch 8 Step 232/313 Test Loss: 1.286 | Test Acc: 53.769% (4009/7456)\n",
      "Epoch 8 Step 233/313 Test Loss: 1.284 | Test Acc: 53.873% (4034/7488)\n",
      "Epoch 8 Step 234/313 Test Loss: 1.284 | Test Acc: 53.856% (4050/7520)\n",
      "Epoch 8 Step 235/313 Test Loss: 1.283 | Test Acc: 53.880% (4069/7552)\n",
      "Epoch 8 Step 236/313 Test Loss: 1.283 | Test Acc: 53.850% (4084/7584)\n",
      "Epoch 8 Step 237/313 Test Loss: 1.285 | Test Acc: 53.795% (4097/7616)\n",
      "Epoch 8 Step 238/313 Test Loss: 1.285 | Test Acc: 53.831% (4117/7648)\n",
      "Epoch 8 Step 239/313 Test Loss: 1.285 | Test Acc: 53.854% (4136/7680)\n",
      "Epoch 8 Step 240/313 Test Loss: 1.283 | Test Acc: 53.877% (4155/7712)\n",
      "Epoch 8 Step 241/313 Test Loss: 1.283 | Test Acc: 53.900% (4174/7744)\n",
      "Epoch 8 Step 242/313 Test Loss: 1.283 | Test Acc: 53.909% (4192/7776)\n",
      "Epoch 8 Step 243/313 Test Loss: 1.284 | Test Acc: 53.906% (4209/7808)\n",
      "Epoch 8 Step 244/313 Test Loss: 1.284 | Test Acc: 53.903% (4226/7840)\n",
      "Epoch 8 Step 245/313 Test Loss: 1.284 | Test Acc: 53.925% (4245/7872)\n",
      "Epoch 8 Step 246/313 Test Loss: 1.284 | Test Acc: 53.960% (4265/7904)\n",
      "Epoch 8 Step 247/313 Test Loss: 1.284 | Test Acc: 53.919% (4279/7936)\n",
      "Epoch 8 Step 248/313 Test Loss: 1.285 | Test Acc: 53.903% (4295/7968)\n",
      "Epoch 8 Step 249/313 Test Loss: 1.285 | Test Acc: 53.975% (4318/8000)\n",
      "Epoch 8 Step 250/313 Test Loss: 1.285 | Test Acc: 53.959% (4334/8032)\n",
      "Epoch 8 Step 251/313 Test Loss: 1.286 | Test Acc: 53.956% (4351/8064)\n",
      "Epoch 8 Step 252/313 Test Loss: 1.286 | Test Acc: 53.953% (4368/8096)\n",
      "Epoch 8 Step 253/313 Test Loss: 1.286 | Test Acc: 53.962% (4386/8128)\n",
      "Epoch 8 Step 254/313 Test Loss: 1.286 | Test Acc: 53.922% (4400/8160)\n",
      "Epoch 8 Step 255/313 Test Loss: 1.286 | Test Acc: 53.955% (4420/8192)\n",
      "Epoch 8 Step 256/313 Test Loss: 1.286 | Test Acc: 53.928% (4435/8224)\n",
      "Epoch 8 Step 257/313 Test Loss: 1.286 | Test Acc: 53.924% (4452/8256)\n",
      "Epoch 8 Step 258/313 Test Loss: 1.287 | Test Acc: 53.897% (4467/8288)\n",
      "Epoch 8 Step 259/313 Test Loss: 1.288 | Test Acc: 53.810% (4477/8320)\n",
      "Epoch 8 Step 260/313 Test Loss: 1.288 | Test Acc: 53.795% (4493/8352)\n",
      "Epoch 8 Step 261/313 Test Loss: 1.288 | Test Acc: 53.805% (4511/8384)\n",
      "Epoch 8 Step 262/313 Test Loss: 1.288 | Test Acc: 53.802% (4528/8416)\n",
      "Epoch 8 Step 263/313 Test Loss: 1.288 | Test Acc: 53.800% (4545/8448)\n",
      "Epoch 8 Step 264/313 Test Loss: 1.288 | Test Acc: 53.797% (4562/8480)\n",
      "Epoch 8 Step 265/313 Test Loss: 1.288 | Test Acc: 53.795% (4579/8512)\n",
      "Epoch 8 Step 266/313 Test Loss: 1.288 | Test Acc: 53.804% (4597/8544)\n",
      "Epoch 8 Step 267/313 Test Loss: 1.287 | Test Acc: 53.825% (4616/8576)\n",
      "Epoch 8 Step 268/313 Test Loss: 1.288 | Test Acc: 53.729% (4625/8608)\n",
      "Epoch 8 Step 269/313 Test Loss: 1.288 | Test Acc: 53.750% (4644/8640)\n",
      "Epoch 8 Step 270/313 Test Loss: 1.289 | Test Acc: 53.713% (4658/8672)\n",
      "Epoch 8 Step 271/313 Test Loss: 1.289 | Test Acc: 53.757% (4679/8704)\n",
      "Epoch 8 Step 272/313 Test Loss: 1.288 | Test Acc: 53.789% (4699/8736)\n",
      "Epoch 8 Step 273/313 Test Loss: 1.288 | Test Acc: 53.764% (4714/8768)\n",
      "Epoch 8 Step 274/313 Test Loss: 1.288 | Test Acc: 53.795% (4734/8800)\n",
      "Epoch 8 Step 275/313 Test Loss: 1.289 | Test Acc: 53.770% (4749/8832)\n",
      "Epoch 8 Step 276/313 Test Loss: 1.289 | Test Acc: 53.745% (4764/8864)\n",
      "Epoch 8 Step 277/313 Test Loss: 1.289 | Test Acc: 53.777% (4784/8896)\n",
      "Epoch 8 Step 278/313 Test Loss: 1.287 | Test Acc: 53.819% (4805/8928)\n",
      "Epoch 8 Step 279/313 Test Loss: 1.288 | Test Acc: 53.772% (4818/8960)\n",
      "Epoch 8 Step 280/313 Test Loss: 1.289 | Test Acc: 53.770% (4835/8992)\n",
      "Epoch 8 Step 281/313 Test Loss: 1.288 | Test Acc: 53.790% (4854/9024)\n",
      "Epoch 8 Step 282/313 Test Loss: 1.288 | Test Acc: 53.799% (4872/9056)\n",
      "Epoch 8 Step 283/313 Test Loss: 1.288 | Test Acc: 53.840% (4893/9088)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Step 284/313 Test Loss: 1.287 | Test Acc: 53.849% (4911/9120)\n",
      "Epoch 8 Step 285/313 Test Loss: 1.288 | Test Acc: 53.835% (4927/9152)\n",
      "Epoch 8 Step 286/313 Test Loss: 1.287 | Test Acc: 53.887% (4949/9184)\n",
      "Epoch 8 Step 287/313 Test Loss: 1.286 | Test Acc: 53.906% (4968/9216)\n",
      "Epoch 8 Step 288/313 Test Loss: 1.286 | Test Acc: 53.925% (4987/9248)\n",
      "Epoch 8 Step 289/313 Test Loss: 1.286 | Test Acc: 53.955% (5007/9280)\n",
      "Epoch 8 Step 290/313 Test Loss: 1.287 | Test Acc: 53.930% (5022/9312)\n",
      "Epoch 8 Step 291/313 Test Loss: 1.286 | Test Acc: 53.960% (5042/9344)\n",
      "Epoch 8 Step 292/313 Test Loss: 1.286 | Test Acc: 54.010% (5064/9376)\n",
      "Epoch 8 Step 293/313 Test Loss: 1.286 | Test Acc: 54.007% (5081/9408)\n",
      "Epoch 8 Step 294/313 Test Loss: 1.286 | Test Acc: 54.015% (5099/9440)\n",
      "Epoch 8 Step 295/313 Test Loss: 1.286 | Test Acc: 54.012% (5116/9472)\n",
      "Epoch 8 Step 296/313 Test Loss: 1.285 | Test Acc: 54.072% (5139/9504)\n",
      "Epoch 8 Step 297/313 Test Loss: 1.286 | Test Acc: 54.048% (5154/9536)\n",
      "Epoch 8 Step 298/313 Test Loss: 1.286 | Test Acc: 54.076% (5174/9568)\n",
      "Epoch 8 Step 299/313 Test Loss: 1.284 | Test Acc: 54.104% (5194/9600)\n",
      "Epoch 8 Step 300/313 Test Loss: 1.285 | Test Acc: 54.091% (5210/9632)\n",
      "Epoch 8 Step 301/313 Test Loss: 1.285 | Test Acc: 54.046% (5223/9664)\n",
      "Epoch 8 Step 302/313 Test Loss: 1.285 | Test Acc: 54.064% (5242/9696)\n",
      "Epoch 8 Step 303/313 Test Loss: 1.285 | Test Acc: 54.102% (5263/9728)\n",
      "Epoch 8 Step 304/313 Test Loss: 1.285 | Test Acc: 54.088% (5279/9760)\n",
      "Epoch 8 Step 305/313 Test Loss: 1.285 | Test Acc: 54.105% (5298/9792)\n",
      "Epoch 8 Step 306/313 Test Loss: 1.286 | Test Acc: 54.092% (5314/9824)\n",
      "Epoch 8 Step 307/313 Test Loss: 1.287 | Test Acc: 54.089% (5331/9856)\n",
      "Epoch 8 Step 308/313 Test Loss: 1.287 | Test Acc: 54.086% (5348/9888)\n",
      "Epoch 8 Step 309/313 Test Loss: 1.287 | Test Acc: 54.113% (5368/9920)\n",
      "Epoch 8 Step 310/313 Test Loss: 1.287 | Test Acc: 54.100% (5384/9952)\n",
      "Epoch 8 Step 311/313 Test Loss: 1.287 | Test Acc: 54.107% (5402/9984)\n",
      "Epoch 8 Step 312/313 Test Loss: 1.287 | Test Acc: 54.090% (5409/10000)\n",
      "Saving..\n",
      "\n",
      "Epoch: 9\n",
      "Epoch 9 Step 0/1563 Loss: 0.954 | Acc: 62.500% (20/32)\n",
      "Epoch 9 Step 1/1563 Loss: 1.035 | Acc: 65.625% (42/64)\n",
      "Epoch 9 Step 2/1563 Loss: 1.180 | Acc: 63.542% (61/96)\n",
      "Epoch 9 Step 3/1563 Loss: 1.221 | Acc: 59.375% (76/128)\n",
      "Epoch 9 Step 4/1563 Loss: 1.240 | Acc: 57.500% (92/160)\n",
      "Epoch 9 Step 5/1563 Loss: 1.247 | Acc: 58.854% (113/192)\n",
      "Epoch 9 Step 6/1563 Loss: 1.236 | Acc: 59.375% (133/224)\n",
      "Epoch 9 Step 7/1563 Loss: 1.286 | Acc: 57.031% (146/256)\n",
      "Epoch 9 Step 8/1563 Loss: 1.280 | Acc: 56.597% (163/288)\n",
      "Epoch 9 Step 9/1563 Loss: 1.269 | Acc: 56.250% (180/320)\n",
      "Epoch 9 Step 10/1563 Loss: 1.301 | Acc: 54.545% (192/352)\n",
      "Epoch 9 Step 11/1563 Loss: 1.334 | Acc: 52.865% (203/384)\n",
      "Epoch 9 Step 12/1563 Loss: 1.330 | Acc: 53.125% (221/416)\n",
      "Epoch 9 Step 13/1563 Loss: 1.331 | Acc: 53.571% (240/448)\n",
      "Epoch 9 Step 14/1563 Loss: 1.310 | Acc: 53.750% (258/480)\n",
      "Epoch 9 Step 15/1563 Loss: 1.299 | Acc: 54.492% (279/512)\n",
      "Epoch 9 Step 16/1563 Loss: 1.321 | Acc: 54.228% (295/544)\n",
      "Epoch 9 Step 17/1563 Loss: 1.329 | Acc: 53.472% (308/576)\n",
      "Epoch 9 Step 18/1563 Loss: 1.356 | Acc: 52.961% (322/608)\n",
      "Epoch 9 Step 19/1563 Loss: 1.346 | Acc: 53.125% (340/640)\n",
      "Epoch 9 Step 20/1563 Loss: 1.346 | Acc: 52.976% (356/672)\n",
      "Epoch 9 Step 21/1563 Loss: 1.339 | Acc: 53.551% (377/704)\n",
      "Epoch 9 Step 22/1563 Loss: 1.335 | Acc: 53.533% (394/736)\n",
      "Epoch 9 Step 23/1563 Loss: 1.347 | Acc: 53.255% (409/768)\n",
      "Epoch 9 Step 24/1563 Loss: 1.349 | Acc: 53.000% (424/800)\n",
      "Epoch 9 Step 25/1563 Loss: 1.351 | Acc: 53.125% (442/832)\n",
      "Epoch 9 Step 26/1563 Loss: 1.350 | Acc: 53.009% (458/864)\n",
      "Epoch 9 Step 27/1563 Loss: 1.344 | Acc: 53.237% (477/896)\n",
      "Epoch 9 Step 28/1563 Loss: 1.339 | Acc: 53.664% (498/928)\n",
      "Epoch 9 Step 29/1563 Loss: 1.330 | Acc: 53.854% (517/960)\n",
      "Epoch 9 Step 30/1563 Loss: 1.323 | Acc: 54.133% (537/992)\n",
      "Epoch 9 Step 31/1563 Loss: 1.335 | Acc: 53.613% (549/1024)\n",
      "Epoch 9 Step 32/1563 Loss: 1.326 | Acc: 53.977% (570/1056)\n",
      "Epoch 9 Step 33/1563 Loss: 1.314 | Acc: 54.688% (595/1088)\n",
      "Epoch 9 Step 34/1563 Loss: 1.314 | Acc: 54.911% (615/1120)\n",
      "Epoch 9 Step 35/1563 Loss: 1.321 | Acc: 54.688% (630/1152)\n",
      "Epoch 9 Step 36/1563 Loss: 1.323 | Acc: 54.561% (646/1184)\n",
      "Epoch 9 Step 37/1563 Loss: 1.327 | Acc: 54.359% (661/1216)\n",
      "Epoch 9 Step 38/1563 Loss: 1.329 | Acc: 54.167% (676/1248)\n",
      "Epoch 9 Step 39/1563 Loss: 1.326 | Acc: 54.141% (693/1280)\n",
      "Epoch 9 Step 40/1563 Loss: 1.326 | Acc: 54.116% (710/1312)\n",
      "Epoch 9 Step 41/1563 Loss: 1.329 | Acc: 53.795% (723/1344)\n",
      "Epoch 9 Step 42/1563 Loss: 1.321 | Acc: 53.924% (742/1376)\n",
      "Epoch 9 Step 43/1563 Loss: 1.327 | Acc: 53.622% (755/1408)\n",
      "Epoch 9 Step 44/1563 Loss: 1.324 | Acc: 53.750% (774/1440)\n",
      "Epoch 9 Step 45/1563 Loss: 1.334 | Acc: 53.329% (785/1472)\n",
      "Epoch 9 Step 46/1563 Loss: 1.327 | Acc: 53.590% (806/1504)\n",
      "Epoch 9 Step 47/1563 Loss: 1.327 | Acc: 53.646% (824/1536)\n",
      "Epoch 9 Step 48/1563 Loss: 1.324 | Acc: 53.699% (842/1568)\n",
      "Epoch 9 Step 49/1563 Loss: 1.322 | Acc: 53.625% (858/1600)\n",
      "Epoch 9 Step 50/1563 Loss: 1.323 | Acc: 53.431% (872/1632)\n",
      "Epoch 9 Step 51/1563 Loss: 1.321 | Acc: 53.546% (891/1664)\n",
      "Epoch 9 Step 52/1563 Loss: 1.323 | Acc: 53.597% (909/1696)\n",
      "Epoch 9 Step 53/1563 Loss: 1.323 | Acc: 53.588% (926/1728)\n",
      "Epoch 9 Step 54/1563 Loss: 1.327 | Acc: 53.409% (940/1760)\n",
      "Epoch 9 Step 55/1563 Loss: 1.325 | Acc: 53.683% (962/1792)\n",
      "Epoch 9 Step 56/1563 Loss: 1.324 | Acc: 53.509% (976/1824)\n",
      "Epoch 9 Step 57/1563 Loss: 1.328 | Acc: 53.233% (988/1856)\n",
      "Epoch 9 Step 58/1563 Loss: 1.328 | Acc: 53.125% (1003/1888)\n",
      "Epoch 9 Step 59/1563 Loss: 1.327 | Acc: 53.229% (1022/1920)\n",
      "Epoch 9 Step 60/1563 Loss: 1.324 | Acc: 53.227% (1039/1952)\n",
      "Epoch 9 Step 61/1563 Loss: 1.327 | Acc: 53.125% (1054/1984)\n",
      "Epoch 9 Step 62/1563 Loss: 1.326 | Acc: 53.175% (1072/2016)\n",
      "Epoch 9 Step 63/1563 Loss: 1.322 | Acc: 53.418% (1094/2048)\n",
      "Epoch 9 Step 64/1563 Loss: 1.328 | Acc: 53.221% (1107/2080)\n",
      "Epoch 9 Step 65/1563 Loss: 1.330 | Acc: 53.078% (1121/2112)\n",
      "Epoch 9 Step 66/1563 Loss: 1.327 | Acc: 53.218% (1141/2144)\n",
      "Epoch 9 Step 67/1563 Loss: 1.329 | Acc: 53.217% (1158/2176)\n",
      "Epoch 9 Step 68/1563 Loss: 1.331 | Acc: 53.216% (1175/2208)\n",
      "Epoch 9 Step 69/1563 Loss: 1.330 | Acc: 53.170% (1191/2240)\n",
      "Epoch 9 Step 70/1563 Loss: 1.330 | Acc: 52.993% (1204/2272)\n",
      "Epoch 9 Step 71/1563 Loss: 1.328 | Acc: 52.995% (1221/2304)\n",
      "Epoch 9 Step 72/1563 Loss: 1.329 | Acc: 52.868% (1235/2336)\n",
      "Epoch 9 Step 73/1563 Loss: 1.329 | Acc: 52.787% (1250/2368)\n",
      "Epoch 9 Step 74/1563 Loss: 1.327 | Acc: 52.792% (1267/2400)\n",
      "Epoch 9 Step 75/1563 Loss: 1.330 | Acc: 52.632% (1280/2432)\n",
      "Epoch 9 Step 76/1563 Loss: 1.334 | Acc: 52.557% (1295/2464)\n",
      "Epoch 9 Step 77/1563 Loss: 1.333 | Acc: 52.604% (1313/2496)\n",
      "Epoch 9 Step 78/1563 Loss: 1.336 | Acc: 52.492% (1327/2528)\n",
      "Epoch 9 Step 79/1563 Loss: 1.337 | Acc: 52.500% (1344/2560)\n",
      "Epoch 9 Step 80/1563 Loss: 1.341 | Acc: 52.469% (1360/2592)\n",
      "Epoch 9 Step 81/1563 Loss: 1.341 | Acc: 52.363% (1374/2624)\n",
      "Epoch 9 Step 82/1563 Loss: 1.339 | Acc: 52.410% (1392/2656)\n",
      "Epoch 9 Step 83/1563 Loss: 1.338 | Acc: 52.344% (1407/2688)\n",
      "Epoch 9 Step 84/1563 Loss: 1.340 | Acc: 52.316% (1423/2720)\n",
      "Epoch 9 Step 85/1563 Loss: 1.344 | Acc: 52.108% (1434/2752)\n",
      "Epoch 9 Step 86/1563 Loss: 1.343 | Acc: 52.047% (1449/2784)\n",
      "Epoch 9 Step 87/1563 Loss: 1.343 | Acc: 51.918% (1462/2816)\n",
      "Epoch 9 Step 88/1563 Loss: 1.346 | Acc: 51.756% (1474/2848)\n",
      "Epoch 9 Step 89/1563 Loss: 1.346 | Acc: 51.701% (1489/2880)\n",
      "Epoch 9 Step 90/1563 Loss: 1.348 | Acc: 51.580% (1502/2912)\n",
      "Epoch 9 Step 91/1563 Loss: 1.350 | Acc: 51.495% (1516/2944)\n",
      "Epoch 9 Step 92/1563 Loss: 1.351 | Acc: 51.512% (1533/2976)\n",
      "Epoch 9 Step 93/1563 Loss: 1.353 | Acc: 51.363% (1545/3008)\n",
      "Epoch 9 Step 94/1563 Loss: 1.351 | Acc: 51.382% (1562/3040)\n",
      "Epoch 9 Step 95/1563 Loss: 1.355 | Acc: 51.237% (1574/3072)\n",
      "Epoch 9 Step 96/1563 Loss: 1.356 | Acc: 51.160% (1588/3104)\n",
      "Epoch 9 Step 97/1563 Loss: 1.354 | Acc: 51.244% (1607/3136)\n",
      "Epoch 9 Step 98/1563 Loss: 1.354 | Acc: 51.199% (1622/3168)\n",
      "Epoch 9 Step 99/1563 Loss: 1.358 | Acc: 51.188% (1638/3200)\n",
      "Epoch 9 Step 100/1563 Loss: 1.359 | Acc: 51.114% (1652/3232)\n",
      "Epoch 9 Step 101/1563 Loss: 1.361 | Acc: 51.103% (1668/3264)\n",
      "Epoch 9 Step 102/1563 Loss: 1.361 | Acc: 51.092% (1684/3296)\n",
      "Epoch 9 Step 103/1563 Loss: 1.362 | Acc: 51.112% (1701/3328)\n",
      "Epoch 9 Step 104/1563 Loss: 1.361 | Acc: 51.190% (1720/3360)\n",
      "Epoch 9 Step 105/1563 Loss: 1.364 | Acc: 50.973% (1729/3392)\n",
      "Epoch 9 Step 106/1563 Loss: 1.362 | Acc: 51.022% (1747/3424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 107/1563 Loss: 1.362 | Acc: 51.042% (1764/3456)\n",
      "Epoch 9 Step 108/1563 Loss: 1.363 | Acc: 51.003% (1779/3488)\n",
      "Epoch 9 Step 109/1563 Loss: 1.363 | Acc: 50.994% (1795/3520)\n",
      "Epoch 9 Step 110/1563 Loss: 1.360 | Acc: 50.957% (1810/3552)\n",
      "Epoch 9 Step 111/1563 Loss: 1.358 | Acc: 51.032% (1829/3584)\n",
      "Epoch 9 Step 112/1563 Loss: 1.357 | Acc: 51.023% (1845/3616)\n",
      "Epoch 9 Step 113/1563 Loss: 1.357 | Acc: 50.959% (1859/3648)\n",
      "Epoch 9 Step 114/1563 Loss: 1.358 | Acc: 50.978% (1876/3680)\n",
      "Epoch 9 Step 115/1563 Loss: 1.358 | Acc: 50.862% (1888/3712)\n",
      "Epoch 9 Step 116/1563 Loss: 1.356 | Acc: 50.908% (1906/3744)\n",
      "Epoch 9 Step 117/1563 Loss: 1.358 | Acc: 50.874% (1921/3776)\n",
      "Epoch 9 Step 118/1563 Loss: 1.358 | Acc: 50.867% (1937/3808)\n",
      "Epoch 9 Step 119/1563 Loss: 1.357 | Acc: 50.911% (1955/3840)\n",
      "Epoch 9 Step 120/1563 Loss: 1.359 | Acc: 50.878% (1970/3872)\n",
      "Epoch 9 Step 121/1563 Loss: 1.359 | Acc: 50.871% (1986/3904)\n",
      "Epoch 9 Step 122/1563 Loss: 1.360 | Acc: 50.762% (1998/3936)\n",
      "Epoch 9 Step 123/1563 Loss: 1.361 | Acc: 50.680% (2011/3968)\n",
      "Epoch 9 Step 124/1563 Loss: 1.361 | Acc: 50.700% (2028/4000)\n",
      "Epoch 9 Step 125/1563 Loss: 1.359 | Acc: 50.794% (2048/4032)\n",
      "Epoch 9 Step 126/1563 Loss: 1.359 | Acc: 50.763% (2063/4064)\n",
      "Epoch 9 Step 127/1563 Loss: 1.357 | Acc: 50.854% (2083/4096)\n",
      "Epoch 9 Step 128/1563 Loss: 1.359 | Acc: 50.751% (2095/4128)\n",
      "Epoch 9 Step 129/1563 Loss: 1.360 | Acc: 50.673% (2108/4160)\n",
      "Epoch 9 Step 130/1563 Loss: 1.361 | Acc: 50.644% (2123/4192)\n",
      "Epoch 9 Step 131/1563 Loss: 1.362 | Acc: 50.616% (2138/4224)\n",
      "Epoch 9 Step 132/1563 Loss: 1.361 | Acc: 50.634% (2155/4256)\n",
      "Epoch 9 Step 133/1563 Loss: 1.360 | Acc: 50.700% (2174/4288)\n",
      "Epoch 9 Step 134/1563 Loss: 1.360 | Acc: 50.741% (2192/4320)\n",
      "Epoch 9 Step 135/1563 Loss: 1.362 | Acc: 50.620% (2203/4352)\n",
      "Epoch 9 Step 136/1563 Loss: 1.362 | Acc: 50.661% (2221/4384)\n",
      "Epoch 9 Step 137/1563 Loss: 1.365 | Acc: 50.543% (2232/4416)\n",
      "Epoch 9 Step 138/1563 Loss: 1.364 | Acc: 50.585% (2250/4448)\n",
      "Epoch 9 Step 139/1563 Loss: 1.363 | Acc: 50.625% (2268/4480)\n",
      "Epoch 9 Step 140/1563 Loss: 1.363 | Acc: 50.598% (2283/4512)\n",
      "Epoch 9 Step 141/1563 Loss: 1.362 | Acc: 50.594% (2299/4544)\n",
      "Epoch 9 Step 142/1563 Loss: 1.361 | Acc: 50.590% (2315/4576)\n",
      "Epoch 9 Step 143/1563 Loss: 1.361 | Acc: 50.586% (2331/4608)\n",
      "Epoch 9 Step 144/1563 Loss: 1.359 | Acc: 50.603% (2348/4640)\n",
      "Epoch 9 Step 145/1563 Loss: 1.358 | Acc: 50.621% (2365/4672)\n",
      "Epoch 9 Step 146/1563 Loss: 1.357 | Acc: 50.702% (2385/4704)\n",
      "Epoch 9 Step 147/1563 Loss: 1.354 | Acc: 50.866% (2409/4736)\n",
      "Epoch 9 Step 148/1563 Loss: 1.355 | Acc: 50.797% (2422/4768)\n",
      "Epoch 9 Step 149/1563 Loss: 1.356 | Acc: 50.771% (2437/4800)\n",
      "Epoch 9 Step 150/1563 Loss: 1.355 | Acc: 50.869% (2458/4832)\n",
      "Epoch 9 Step 151/1563 Loss: 1.354 | Acc: 50.863% (2474/4864)\n",
      "Epoch 9 Step 152/1563 Loss: 1.354 | Acc: 50.776% (2486/4896)\n",
      "Epoch 9 Step 153/1563 Loss: 1.355 | Acc: 50.791% (2503/4928)\n",
      "Epoch 9 Step 154/1563 Loss: 1.351 | Acc: 50.907% (2525/4960)\n",
      "Epoch 9 Step 155/1563 Loss: 1.350 | Acc: 50.942% (2543/4992)\n",
      "Epoch 9 Step 156/1563 Loss: 1.351 | Acc: 50.955% (2560/5024)\n",
      "Epoch 9 Step 157/1563 Loss: 1.350 | Acc: 50.989% (2578/5056)\n",
      "Epoch 9 Step 158/1563 Loss: 1.349 | Acc: 50.983% (2594/5088)\n",
      "Epoch 9 Step 159/1563 Loss: 1.348 | Acc: 50.977% (2610/5120)\n",
      "Epoch 9 Step 160/1563 Loss: 1.347 | Acc: 51.029% (2629/5152)\n",
      "Epoch 9 Step 161/1563 Loss: 1.349 | Acc: 50.965% (2642/5184)\n",
      "Epoch 9 Step 162/1563 Loss: 1.348 | Acc: 50.978% (2659/5216)\n",
      "Epoch 9 Step 163/1563 Loss: 1.348 | Acc: 50.915% (2672/5248)\n",
      "Epoch 9 Step 164/1563 Loss: 1.347 | Acc: 50.966% (2691/5280)\n",
      "Epoch 9 Step 165/1563 Loss: 1.348 | Acc: 50.960% (2707/5312)\n",
      "Epoch 9 Step 166/1563 Loss: 1.347 | Acc: 51.048% (2728/5344)\n",
      "Epoch 9 Step 167/1563 Loss: 1.347 | Acc: 51.079% (2746/5376)\n",
      "Epoch 9 Step 168/1563 Loss: 1.346 | Acc: 51.054% (2761/5408)\n",
      "Epoch 9 Step 169/1563 Loss: 1.346 | Acc: 51.048% (2777/5440)\n",
      "Epoch 9 Step 170/1563 Loss: 1.344 | Acc: 51.115% (2797/5472)\n",
      "Epoch 9 Step 171/1563 Loss: 1.343 | Acc: 51.163% (2816/5504)\n",
      "Epoch 9 Step 172/1563 Loss: 1.343 | Acc: 51.192% (2834/5536)\n",
      "Epoch 9 Step 173/1563 Loss: 1.341 | Acc: 51.239% (2853/5568)\n",
      "Epoch 9 Step 174/1563 Loss: 1.342 | Acc: 51.214% (2868/5600)\n",
      "Epoch 9 Step 175/1563 Loss: 1.342 | Acc: 51.225% (2885/5632)\n",
      "Epoch 9 Step 176/1563 Loss: 1.343 | Acc: 51.201% (2900/5664)\n",
      "Epoch 9 Step 177/1563 Loss: 1.344 | Acc: 51.159% (2914/5696)\n",
      "Epoch 9 Step 178/1563 Loss: 1.342 | Acc: 51.205% (2933/5728)\n",
      "Epoch 9 Step 179/1563 Loss: 1.342 | Acc: 51.198% (2949/5760)\n",
      "Epoch 9 Step 180/1563 Loss: 1.342 | Acc: 51.191% (2965/5792)\n",
      "Epoch 9 Step 181/1563 Loss: 1.340 | Acc: 51.236% (2984/5824)\n",
      "Epoch 9 Step 182/1563 Loss: 1.339 | Acc: 51.298% (3004/5856)\n",
      "Epoch 9 Step 183/1563 Loss: 1.338 | Acc: 51.325% (3022/5888)\n",
      "Epoch 9 Step 184/1563 Loss: 1.338 | Acc: 51.368% (3041/5920)\n",
      "Epoch 9 Step 185/1563 Loss: 1.339 | Acc: 51.344% (3056/5952)\n",
      "Epoch 9 Step 186/1563 Loss: 1.337 | Acc: 51.437% (3078/5984)\n",
      "Epoch 9 Step 187/1563 Loss: 1.339 | Acc: 51.380% (3091/6016)\n",
      "Epoch 9 Step 188/1563 Loss: 1.339 | Acc: 51.405% (3109/6048)\n",
      "Epoch 9 Step 189/1563 Loss: 1.339 | Acc: 51.464% (3129/6080)\n",
      "Epoch 9 Step 190/1563 Loss: 1.338 | Acc: 51.538% (3150/6112)\n",
      "Epoch 9 Step 191/1563 Loss: 1.337 | Acc: 51.579% (3169/6144)\n",
      "Epoch 9 Step 192/1563 Loss: 1.337 | Acc: 51.587% (3186/6176)\n",
      "Epoch 9 Step 193/1563 Loss: 1.338 | Acc: 51.579% (3202/6208)\n",
      "Epoch 9 Step 194/1563 Loss: 1.338 | Acc: 51.571% (3218/6240)\n",
      "Epoch 9 Step 195/1563 Loss: 1.340 | Acc: 51.499% (3230/6272)\n",
      "Epoch 9 Step 196/1563 Loss: 1.340 | Acc: 51.555% (3250/6304)\n",
      "Epoch 9 Step 197/1563 Loss: 1.340 | Acc: 51.578% (3268/6336)\n",
      "Epoch 9 Step 198/1563 Loss: 1.341 | Acc: 51.523% (3281/6368)\n",
      "Epoch 9 Step 199/1563 Loss: 1.341 | Acc: 51.547% (3299/6400)\n",
      "Epoch 9 Step 200/1563 Loss: 1.341 | Acc: 51.555% (3316/6432)\n",
      "Epoch 9 Step 201/1563 Loss: 1.340 | Acc: 51.562% (3333/6464)\n",
      "Epoch 9 Step 202/1563 Loss: 1.339 | Acc: 51.616% (3353/6496)\n",
      "Epoch 9 Step 203/1563 Loss: 1.337 | Acc: 51.670% (3373/6528)\n",
      "Epoch 9 Step 204/1563 Loss: 1.338 | Acc: 51.662% (3389/6560)\n",
      "Epoch 9 Step 205/1563 Loss: 1.338 | Acc: 51.654% (3405/6592)\n",
      "Epoch 9 Step 206/1563 Loss: 1.339 | Acc: 51.676% (3423/6624)\n",
      "Epoch 9 Step 207/1563 Loss: 1.339 | Acc: 51.653% (3438/6656)\n",
      "Epoch 9 Step 208/1563 Loss: 1.341 | Acc: 51.660% (3455/6688)\n",
      "Epoch 9 Step 209/1563 Loss: 1.340 | Acc: 51.652% (3471/6720)\n",
      "Epoch 9 Step 210/1563 Loss: 1.339 | Acc: 51.644% (3487/6752)\n",
      "Epoch 9 Step 211/1563 Loss: 1.340 | Acc: 51.607% (3501/6784)\n",
      "Epoch 9 Step 212/1563 Loss: 1.339 | Acc: 51.643% (3520/6816)\n",
      "Epoch 9 Step 213/1563 Loss: 1.340 | Acc: 51.621% (3535/6848)\n",
      "Epoch 9 Step 214/1563 Loss: 1.340 | Acc: 51.613% (3551/6880)\n",
      "Epoch 9 Step 215/1563 Loss: 1.340 | Acc: 51.635% (3569/6912)\n",
      "Epoch 9 Step 216/1563 Loss: 1.339 | Acc: 51.656% (3587/6944)\n",
      "Epoch 9 Step 217/1563 Loss: 1.338 | Acc: 51.606% (3600/6976)\n",
      "Epoch 9 Step 218/1563 Loss: 1.337 | Acc: 51.670% (3621/7008)\n",
      "Epoch 9 Step 219/1563 Loss: 1.338 | Acc: 51.634% (3635/7040)\n",
      "Epoch 9 Step 220/1563 Loss: 1.337 | Acc: 51.669% (3654/7072)\n",
      "Epoch 9 Step 221/1563 Loss: 1.336 | Acc: 51.717% (3674/7104)\n",
      "Epoch 9 Step 222/1563 Loss: 1.336 | Acc: 51.696% (3689/7136)\n",
      "Epoch 9 Step 223/1563 Loss: 1.337 | Acc: 51.702% (3706/7168)\n",
      "Epoch 9 Step 224/1563 Loss: 1.338 | Acc: 51.667% (3720/7200)\n",
      "Epoch 9 Step 225/1563 Loss: 1.339 | Acc: 51.687% (3738/7232)\n",
      "Epoch 9 Step 226/1563 Loss: 1.340 | Acc: 51.652% (3752/7264)\n",
      "Epoch 9 Step 227/1563 Loss: 1.341 | Acc: 51.590% (3764/7296)\n",
      "Epoch 9 Step 228/1563 Loss: 1.342 | Acc: 51.542% (3777/7328)\n",
      "Epoch 9 Step 229/1563 Loss: 1.342 | Acc: 51.508% (3791/7360)\n",
      "Epoch 9 Step 230/1563 Loss: 1.341 | Acc: 51.583% (3813/7392)\n",
      "Epoch 9 Step 231/1563 Loss: 1.341 | Acc: 51.562% (3828/7424)\n",
      "Epoch 9 Step 232/1563 Loss: 1.341 | Acc: 51.596% (3847/7456)\n",
      "Epoch 9 Step 233/1563 Loss: 1.342 | Acc: 51.576% (3862/7488)\n",
      "Epoch 9 Step 234/1563 Loss: 1.343 | Acc: 51.556% (3877/7520)\n",
      "Epoch 9 Step 235/1563 Loss: 1.342 | Acc: 51.576% (3895/7552)\n",
      "Epoch 9 Step 236/1563 Loss: 1.342 | Acc: 51.530% (3908/7584)\n",
      "Epoch 9 Step 237/1563 Loss: 1.340 | Acc: 51.615% (3931/7616)\n",
      "Epoch 9 Step 238/1563 Loss: 1.341 | Acc: 51.569% (3944/7648)\n",
      "Epoch 9 Step 239/1563 Loss: 1.341 | Acc: 51.576% (3961/7680)\n",
      "Epoch 9 Step 240/1563 Loss: 1.340 | Acc: 51.647% (3983/7712)\n",
      "Epoch 9 Step 241/1563 Loss: 1.341 | Acc: 51.653% (4000/7744)\n",
      "Epoch 9 Step 242/1563 Loss: 1.342 | Acc: 51.633% (4015/7776)\n",
      "Epoch 9 Step 243/1563 Loss: 1.344 | Acc: 51.588% (4028/7808)\n",
      "Epoch 9 Step 244/1563 Loss: 1.344 | Acc: 51.569% (4043/7840)\n",
      "Epoch 9 Step 245/1563 Loss: 1.345 | Acc: 51.562% (4059/7872)\n",
      "Epoch 9 Step 246/1563 Loss: 1.347 | Acc: 51.455% (4067/7904)\n",
      "Epoch 9 Step 247/1563 Loss: 1.346 | Acc: 51.487% (4086/7936)\n",
      "Epoch 9 Step 248/1563 Loss: 1.347 | Acc: 51.481% (4102/7968)\n",
      "Epoch 9 Step 249/1563 Loss: 1.346 | Acc: 51.487% (4119/8000)\n",
      "Epoch 9 Step 250/1563 Loss: 1.344 | Acc: 51.581% (4143/8032)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 251/1563 Loss: 1.344 | Acc: 51.625% (4163/8064)\n",
      "Epoch 9 Step 252/1563 Loss: 1.345 | Acc: 51.606% (4178/8096)\n",
      "Epoch 9 Step 253/1563 Loss: 1.345 | Acc: 51.636% (4197/8128)\n",
      "Epoch 9 Step 254/1563 Loss: 1.344 | Acc: 51.691% (4218/8160)\n",
      "Epoch 9 Step 255/1563 Loss: 1.344 | Acc: 51.648% (4231/8192)\n",
      "Epoch 9 Step 256/1563 Loss: 1.345 | Acc: 51.605% (4244/8224)\n",
      "Epoch 9 Step 257/1563 Loss: 1.345 | Acc: 51.623% (4262/8256)\n",
      "Epoch 9 Step 258/1563 Loss: 1.345 | Acc: 51.605% (4277/8288)\n",
      "Epoch 9 Step 259/1563 Loss: 1.345 | Acc: 51.599% (4293/8320)\n",
      "Epoch 9 Step 260/1563 Loss: 1.344 | Acc: 51.628% (4312/8352)\n",
      "Epoch 9 Step 261/1563 Loss: 1.343 | Acc: 51.670% (4332/8384)\n",
      "Epoch 9 Step 262/1563 Loss: 1.343 | Acc: 51.652% (4347/8416)\n",
      "Epoch 9 Step 263/1563 Loss: 1.343 | Acc: 51.645% (4363/8448)\n",
      "Epoch 9 Step 264/1563 Loss: 1.342 | Acc: 51.675% (4382/8480)\n",
      "Epoch 9 Step 265/1563 Loss: 1.342 | Acc: 51.668% (4398/8512)\n",
      "Epoch 9 Step 266/1563 Loss: 1.342 | Acc: 51.685% (4416/8544)\n",
      "Epoch 9 Step 267/1563 Loss: 1.341 | Acc: 51.702% (4434/8576)\n",
      "Epoch 9 Step 268/1563 Loss: 1.342 | Acc: 51.661% (4447/8608)\n",
      "Epoch 9 Step 269/1563 Loss: 1.342 | Acc: 51.690% (4466/8640)\n",
      "Epoch 9 Step 270/1563 Loss: 1.341 | Acc: 51.730% (4486/8672)\n",
      "Epoch 9 Step 271/1563 Loss: 1.341 | Acc: 51.723% (4502/8704)\n",
      "Epoch 9 Step 272/1563 Loss: 1.342 | Acc: 51.740% (4520/8736)\n",
      "Epoch 9 Step 273/1563 Loss: 1.340 | Acc: 51.768% (4539/8768)\n",
      "Epoch 9 Step 274/1563 Loss: 1.340 | Acc: 51.807% (4559/8800)\n",
      "Epoch 9 Step 275/1563 Loss: 1.341 | Acc: 51.823% (4577/8832)\n",
      "Epoch 9 Step 276/1563 Loss: 1.340 | Acc: 51.805% (4592/8864)\n",
      "Epoch 9 Step 277/1563 Loss: 1.340 | Acc: 51.821% (4610/8896)\n",
      "Epoch 9 Step 278/1563 Loss: 1.341 | Acc: 51.837% (4628/8928)\n",
      "Epoch 9 Step 279/1563 Loss: 1.341 | Acc: 51.853% (4646/8960)\n",
      "Epoch 9 Step 280/1563 Loss: 1.340 | Acc: 51.857% (4663/8992)\n",
      "Epoch 9 Step 281/1563 Loss: 1.340 | Acc: 51.840% (4678/9024)\n",
      "Epoch 9 Step 282/1563 Loss: 1.339 | Acc: 51.833% (4694/9056)\n",
      "Epoch 9 Step 283/1563 Loss: 1.340 | Acc: 51.805% (4708/9088)\n",
      "Epoch 9 Step 284/1563 Loss: 1.339 | Acc: 51.809% (4725/9120)\n",
      "Epoch 9 Step 285/1563 Loss: 1.340 | Acc: 51.825% (4743/9152)\n",
      "Epoch 9 Step 286/1563 Loss: 1.339 | Acc: 51.862% (4763/9184)\n",
      "Epoch 9 Step 287/1563 Loss: 1.339 | Acc: 51.823% (4776/9216)\n",
      "Epoch 9 Step 288/1563 Loss: 1.338 | Acc: 51.871% (4797/9248)\n",
      "Epoch 9 Step 289/1563 Loss: 1.338 | Acc: 51.886% (4815/9280)\n",
      "Epoch 9 Step 290/1563 Loss: 1.337 | Acc: 51.965% (4839/9312)\n",
      "Epoch 9 Step 291/1563 Loss: 1.337 | Acc: 51.948% (4854/9344)\n",
      "Epoch 9 Step 292/1563 Loss: 1.336 | Acc: 51.941% (4870/9376)\n",
      "Epoch 9 Step 293/1563 Loss: 1.335 | Acc: 51.935% (4886/9408)\n",
      "Epoch 9 Step 294/1563 Loss: 1.336 | Acc: 51.886% (4898/9440)\n",
      "Epoch 9 Step 295/1563 Loss: 1.336 | Acc: 51.890% (4915/9472)\n",
      "Epoch 9 Step 296/1563 Loss: 1.336 | Acc: 51.926% (4935/9504)\n",
      "Epoch 9 Step 297/1563 Loss: 1.337 | Acc: 51.888% (4948/9536)\n",
      "Epoch 9 Step 298/1563 Loss: 1.337 | Acc: 51.839% (4960/9568)\n",
      "Epoch 9 Step 299/1563 Loss: 1.337 | Acc: 51.896% (4982/9600)\n",
      "Epoch 9 Step 300/1563 Loss: 1.338 | Acc: 51.900% (4999/9632)\n",
      "Epoch 9 Step 301/1563 Loss: 1.339 | Acc: 51.894% (5015/9664)\n",
      "Epoch 9 Step 302/1563 Loss: 1.338 | Acc: 51.918% (5034/9696)\n",
      "Epoch 9 Step 303/1563 Loss: 1.338 | Acc: 51.891% (5048/9728)\n",
      "Epoch 9 Step 304/1563 Loss: 1.338 | Acc: 51.875% (5063/9760)\n",
      "Epoch 9 Step 305/1563 Loss: 1.339 | Acc: 51.828% (5075/9792)\n",
      "Epoch 9 Step 306/1563 Loss: 1.339 | Acc: 51.842% (5093/9824)\n",
      "Epoch 9 Step 307/1563 Loss: 1.339 | Acc: 51.836% (5109/9856)\n",
      "Epoch 9 Step 308/1563 Loss: 1.338 | Acc: 51.851% (5127/9888)\n",
      "Epoch 9 Step 309/1563 Loss: 1.338 | Acc: 51.865% (5145/9920)\n",
      "Epoch 9 Step 310/1563 Loss: 1.337 | Acc: 51.889% (5164/9952)\n",
      "Epoch 9 Step 311/1563 Loss: 1.338 | Acc: 51.873% (5179/9984)\n",
      "Epoch 9 Step 312/1563 Loss: 1.339 | Acc: 51.857% (5194/10016)\n",
      "Epoch 9 Step 313/1563 Loss: 1.340 | Acc: 51.801% (5205/10048)\n",
      "Epoch 9 Step 314/1563 Loss: 1.341 | Acc: 51.756% (5217/10080)\n",
      "Epoch 9 Step 315/1563 Loss: 1.341 | Acc: 51.721% (5230/10112)\n",
      "Epoch 9 Step 316/1563 Loss: 1.341 | Acc: 51.755% (5250/10144)\n",
      "Epoch 9 Step 317/1563 Loss: 1.341 | Acc: 51.798% (5271/10176)\n",
      "Epoch 9 Step 318/1563 Loss: 1.340 | Acc: 51.812% (5289/10208)\n",
      "Epoch 9 Step 319/1563 Loss: 1.340 | Acc: 51.826% (5307/10240)\n",
      "Epoch 9 Step 320/1563 Loss: 1.340 | Acc: 51.840% (5325/10272)\n",
      "Epoch 9 Step 321/1563 Loss: 1.341 | Acc: 51.766% (5334/10304)\n",
      "Epoch 9 Step 322/1563 Loss: 1.341 | Acc: 51.771% (5351/10336)\n",
      "Epoch 9 Step 323/1563 Loss: 1.341 | Acc: 51.755% (5366/10368)\n",
      "Epoch 9 Step 324/1563 Loss: 1.342 | Acc: 51.702% (5377/10400)\n",
      "Epoch 9 Step 325/1563 Loss: 1.342 | Acc: 51.697% (5393/10432)\n",
      "Epoch 9 Step 326/1563 Loss: 1.342 | Acc: 51.692% (5409/10464)\n",
      "Epoch 9 Step 327/1563 Loss: 1.342 | Acc: 51.696% (5426/10496)\n",
      "Epoch 9 Step 328/1563 Loss: 1.343 | Acc: 51.643% (5437/10528)\n",
      "Epoch 9 Step 329/1563 Loss: 1.343 | Acc: 51.676% (5457/10560)\n",
      "Epoch 9 Step 330/1563 Loss: 1.343 | Acc: 51.699% (5476/10592)\n",
      "Epoch 9 Step 331/1563 Loss: 1.345 | Acc: 51.647% (5487/10624)\n",
      "Epoch 9 Step 332/1563 Loss: 1.344 | Acc: 51.652% (5504/10656)\n",
      "Epoch 9 Step 333/1563 Loss: 1.344 | Acc: 51.647% (5520/10688)\n",
      "Epoch 9 Step 334/1563 Loss: 1.344 | Acc: 51.679% (5540/10720)\n",
      "Epoch 9 Step 335/1563 Loss: 1.344 | Acc: 51.683% (5557/10752)\n",
      "Epoch 9 Step 336/1563 Loss: 1.344 | Acc: 51.651% (5570/10784)\n",
      "Epoch 9 Step 337/1563 Loss: 1.344 | Acc: 51.655% (5587/10816)\n",
      "Epoch 9 Step 338/1563 Loss: 1.344 | Acc: 51.678% (5606/10848)\n",
      "Epoch 9 Step 339/1563 Loss: 1.343 | Acc: 51.673% (5622/10880)\n",
      "Epoch 9 Step 340/1563 Loss: 1.343 | Acc: 51.659% (5637/10912)\n",
      "Epoch 9 Step 341/1563 Loss: 1.345 | Acc: 51.636% (5651/10944)\n",
      "Epoch 9 Step 342/1563 Loss: 1.345 | Acc: 51.649% (5669/10976)\n",
      "Epoch 9 Step 343/1563 Loss: 1.346 | Acc: 51.617% (5682/11008)\n",
      "Epoch 9 Step 344/1563 Loss: 1.346 | Acc: 51.639% (5701/11040)\n",
      "Epoch 9 Step 345/1563 Loss: 1.347 | Acc: 51.599% (5713/11072)\n",
      "Epoch 9 Step 346/1563 Loss: 1.347 | Acc: 51.576% (5727/11104)\n",
      "Epoch 9 Step 347/1563 Loss: 1.347 | Acc: 51.571% (5743/11136)\n",
      "Epoch 9 Step 348/1563 Loss: 1.348 | Acc: 51.540% (5756/11168)\n",
      "Epoch 9 Step 349/1563 Loss: 1.349 | Acc: 51.491% (5767/11200)\n",
      "Epoch 9 Step 350/1563 Loss: 1.348 | Acc: 51.514% (5786/11232)\n",
      "Epoch 9 Step 351/1563 Loss: 1.348 | Acc: 51.545% (5806/11264)\n",
      "Epoch 9 Step 352/1563 Loss: 1.347 | Acc: 51.593% (5828/11296)\n",
      "Epoch 9 Step 353/1563 Loss: 1.347 | Acc: 51.598% (5845/11328)\n",
      "Epoch 9 Step 354/1563 Loss: 1.346 | Acc: 51.646% (5867/11360)\n",
      "Epoch 9 Step 355/1563 Loss: 1.346 | Acc: 51.606% (5879/11392)\n",
      "Epoch 9 Step 356/1563 Loss: 1.346 | Acc: 51.584% (5893/11424)\n",
      "Epoch 9 Step 357/1563 Loss: 1.346 | Acc: 51.554% (5906/11456)\n",
      "Epoch 9 Step 358/1563 Loss: 1.346 | Acc: 51.549% (5922/11488)\n",
      "Epoch 9 Step 359/1563 Loss: 1.346 | Acc: 51.571% (5941/11520)\n",
      "Epoch 9 Step 360/1563 Loss: 1.346 | Acc: 51.567% (5957/11552)\n",
      "Epoch 9 Step 361/1563 Loss: 1.346 | Acc: 51.545% (5971/11584)\n",
      "Epoch 9 Step 362/1563 Loss: 1.346 | Acc: 51.532% (5986/11616)\n",
      "Epoch 9 Step 363/1563 Loss: 1.347 | Acc: 51.477% (5996/11648)\n",
      "Epoch 9 Step 364/1563 Loss: 1.347 | Acc: 51.473% (6012/11680)\n",
      "Epoch 9 Step 365/1563 Loss: 1.346 | Acc: 51.503% (6032/11712)\n",
      "Epoch 9 Step 366/1563 Loss: 1.346 | Acc: 51.516% (6050/11744)\n",
      "Epoch 9 Step 367/1563 Loss: 1.347 | Acc: 51.486% (6063/11776)\n",
      "Epoch 9 Step 368/1563 Loss: 1.346 | Acc: 51.482% (6079/11808)\n",
      "Epoch 9 Step 369/1563 Loss: 1.346 | Acc: 51.495% (6097/11840)\n",
      "Epoch 9 Step 370/1563 Loss: 1.347 | Acc: 51.491% (6113/11872)\n",
      "Epoch 9 Step 371/1563 Loss: 1.347 | Acc: 51.487% (6129/11904)\n",
      "Epoch 9 Step 372/1563 Loss: 1.348 | Acc: 51.466% (6143/11936)\n",
      "Epoch 9 Step 373/1563 Loss: 1.348 | Acc: 51.437% (6156/11968)\n",
      "Epoch 9 Step 374/1563 Loss: 1.347 | Acc: 51.467% (6176/12000)\n",
      "Epoch 9 Step 375/1563 Loss: 1.347 | Acc: 51.463% (6192/12032)\n",
      "Epoch 9 Step 376/1563 Loss: 1.346 | Acc: 51.484% (6211/12064)\n",
      "Epoch 9 Step 377/1563 Loss: 1.346 | Acc: 51.463% (6225/12096)\n",
      "Epoch 9 Step 378/1563 Loss: 1.346 | Acc: 51.509% (6247/12128)\n",
      "Epoch 9 Step 379/1563 Loss: 1.347 | Acc: 51.488% (6261/12160)\n",
      "Epoch 9 Step 380/1563 Loss: 1.346 | Acc: 51.509% (6280/12192)\n",
      "Epoch 9 Step 381/1563 Loss: 1.347 | Acc: 51.489% (6294/12224)\n",
      "Epoch 9 Step 382/1563 Loss: 1.347 | Acc: 51.469% (6308/12256)\n",
      "Epoch 9 Step 383/1563 Loss: 1.347 | Acc: 51.473% (6325/12288)\n",
      "Epoch 9 Step 384/1563 Loss: 1.347 | Acc: 51.445% (6338/12320)\n",
      "Epoch 9 Step 385/1563 Loss: 1.348 | Acc: 51.384% (6347/12352)\n",
      "Epoch 9 Step 386/1563 Loss: 1.348 | Acc: 51.357% (6360/12384)\n",
      "Epoch 9 Step 387/1563 Loss: 1.348 | Acc: 51.369% (6378/12416)\n",
      "Epoch 9 Step 388/1563 Loss: 1.348 | Acc: 51.406% (6399/12448)\n",
      "Epoch 9 Step 389/1563 Loss: 1.348 | Acc: 51.418% (6417/12480)\n",
      "Epoch 9 Step 390/1563 Loss: 1.347 | Acc: 51.423% (6434/12512)\n",
      "Epoch 9 Step 391/1563 Loss: 1.347 | Acc: 51.403% (6448/12544)\n",
      "Epoch 9 Step 392/1563 Loss: 1.347 | Acc: 51.415% (6466/12576)\n",
      "Epoch 9 Step 393/1563 Loss: 1.348 | Acc: 51.420% (6483/12608)\n",
      "Epoch 9 Step 394/1563 Loss: 1.347 | Acc: 51.432% (6501/12640)\n",
      "Epoch 9 Step 395/1563 Loss: 1.346 | Acc: 51.436% (6518/12672)\n",
      "Epoch 9 Step 396/1563 Loss: 1.346 | Acc: 51.417% (6532/12704)\n",
      "Epoch 9 Step 397/1563 Loss: 1.346 | Acc: 51.429% (6550/12736)\n",
      "Epoch 9 Step 398/1563 Loss: 1.347 | Acc: 51.425% (6566/12768)\n",
      "Epoch 9 Step 399/1563 Loss: 1.346 | Acc: 51.445% (6585/12800)\n",
      "Epoch 9 Step 400/1563 Loss: 1.346 | Acc: 51.450% (6602/12832)\n",
      "Epoch 9 Step 401/1563 Loss: 1.346 | Acc: 51.454% (6619/12864)\n",
      "Epoch 9 Step 402/1563 Loss: 1.347 | Acc: 51.442% (6634/12896)\n",
      "Epoch 9 Step 403/1563 Loss: 1.346 | Acc: 51.446% (6651/12928)\n",
      "Epoch 9 Step 404/1563 Loss: 1.346 | Acc: 51.451% (6668/12960)\n",
      "Epoch 9 Step 405/1563 Loss: 1.346 | Acc: 51.462% (6686/12992)\n",
      "Epoch 9 Step 406/1563 Loss: 1.346 | Acc: 51.413% (6696/13024)\n",
      "Epoch 9 Step 407/1563 Loss: 1.348 | Acc: 51.371% (6707/13056)\n",
      "Epoch 9 Step 408/1563 Loss: 1.348 | Acc: 51.383% (6725/13088)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 409/1563 Loss: 1.348 | Acc: 51.380% (6741/13120)\n",
      "Epoch 9 Step 410/1563 Loss: 1.348 | Acc: 51.399% (6760/13152)\n",
      "Epoch 9 Step 411/1563 Loss: 1.348 | Acc: 51.388% (6775/13184)\n",
      "Epoch 9 Step 412/1563 Loss: 1.348 | Acc: 51.392% (6792/13216)\n",
      "Epoch 9 Step 413/1563 Loss: 1.348 | Acc: 51.389% (6808/13248)\n",
      "Epoch 9 Step 414/1563 Loss: 1.348 | Acc: 51.416% (6828/13280)\n",
      "Epoch 9 Step 415/1563 Loss: 1.348 | Acc: 51.412% (6844/13312)\n",
      "Epoch 9 Step 416/1563 Loss: 1.347 | Acc: 51.454% (6866/13344)\n",
      "Epoch 9 Step 417/1563 Loss: 1.347 | Acc: 51.450% (6882/13376)\n",
      "Epoch 9 Step 418/1563 Loss: 1.347 | Acc: 51.439% (6897/13408)\n",
      "Epoch 9 Step 419/1563 Loss: 1.347 | Acc: 51.421% (6911/13440)\n",
      "Epoch 9 Step 420/1563 Loss: 1.347 | Acc: 51.403% (6925/13472)\n",
      "Epoch 9 Step 421/1563 Loss: 1.347 | Acc: 51.422% (6944/13504)\n",
      "Epoch 9 Step 422/1563 Loss: 1.346 | Acc: 51.433% (6962/13536)\n",
      "Epoch 9 Step 423/1563 Loss: 1.347 | Acc: 51.415% (6976/13568)\n",
      "Epoch 9 Step 424/1563 Loss: 1.347 | Acc: 51.419% (6993/13600)\n",
      "Epoch 9 Step 425/1563 Loss: 1.347 | Acc: 51.430% (7011/13632)\n",
      "Epoch 9 Step 426/1563 Loss: 1.347 | Acc: 51.398% (7023/13664)\n",
      "Epoch 9 Step 427/1563 Loss: 1.347 | Acc: 51.402% (7040/13696)\n",
      "Epoch 9 Step 428/1563 Loss: 1.347 | Acc: 51.399% (7056/13728)\n",
      "Epoch 9 Step 429/1563 Loss: 1.347 | Acc: 51.366% (7068/13760)\n",
      "Epoch 9 Step 430/1563 Loss: 1.347 | Acc: 51.363% (7084/13792)\n",
      "Epoch 9 Step 431/1563 Loss: 1.347 | Acc: 51.360% (7100/13824)\n",
      "Epoch 9 Step 432/1563 Loss: 1.347 | Acc: 51.357% (7116/13856)\n",
      "Epoch 9 Step 433/1563 Loss: 1.348 | Acc: 51.325% (7128/13888)\n",
      "Epoch 9 Step 434/1563 Loss: 1.348 | Acc: 51.300% (7141/13920)\n",
      "Epoch 9 Step 435/1563 Loss: 1.348 | Acc: 51.290% (7156/13952)\n",
      "Epoch 9 Step 436/1563 Loss: 1.348 | Acc: 51.287% (7172/13984)\n",
      "Epoch 9 Step 437/1563 Loss: 1.348 | Acc: 51.291% (7189/14016)\n",
      "Epoch 9 Step 438/1563 Loss: 1.348 | Acc: 51.281% (7204/14048)\n",
      "Epoch 9 Step 439/1563 Loss: 1.348 | Acc: 51.271% (7219/14080)\n",
      "Epoch 9 Step 440/1563 Loss: 1.349 | Acc: 51.276% (7236/14112)\n",
      "Epoch 9 Step 441/1563 Loss: 1.349 | Acc: 51.287% (7254/14144)\n",
      "Epoch 9 Step 442/1563 Loss: 1.349 | Acc: 51.291% (7271/14176)\n",
      "Epoch 9 Step 443/1563 Loss: 1.349 | Acc: 51.274% (7285/14208)\n",
      "Epoch 9 Step 444/1563 Loss: 1.349 | Acc: 51.257% (7299/14240)\n",
      "Epoch 9 Step 445/1563 Loss: 1.350 | Acc: 51.254% (7315/14272)\n",
      "Epoch 9 Step 446/1563 Loss: 1.349 | Acc: 51.272% (7334/14304)\n",
      "Epoch 9 Step 447/1563 Loss: 1.350 | Acc: 51.263% (7349/14336)\n",
      "Epoch 9 Step 448/1563 Loss: 1.349 | Acc: 51.274% (7367/14368)\n",
      "Epoch 9 Step 449/1563 Loss: 1.349 | Acc: 51.278% (7384/14400)\n",
      "Epoch 9 Step 450/1563 Loss: 1.349 | Acc: 51.289% (7402/14432)\n",
      "Epoch 9 Step 451/1563 Loss: 1.349 | Acc: 51.286% (7418/14464)\n",
      "Epoch 9 Step 452/1563 Loss: 1.349 | Acc: 51.269% (7432/14496)\n",
      "Epoch 9 Step 453/1563 Loss: 1.349 | Acc: 51.267% (7448/14528)\n",
      "Epoch 9 Step 454/1563 Loss: 1.348 | Acc: 51.277% (7466/14560)\n",
      "Epoch 9 Step 455/1563 Loss: 1.348 | Acc: 51.275% (7482/14592)\n",
      "Epoch 9 Step 456/1563 Loss: 1.349 | Acc: 51.258% (7496/14624)\n",
      "Epoch 9 Step 457/1563 Loss: 1.349 | Acc: 51.242% (7510/14656)\n",
      "Epoch 9 Step 458/1563 Loss: 1.349 | Acc: 51.239% (7526/14688)\n",
      "Epoch 9 Step 459/1563 Loss: 1.348 | Acc: 51.284% (7549/14720)\n",
      "Epoch 9 Step 460/1563 Loss: 1.348 | Acc: 51.281% (7565/14752)\n",
      "Epoch 9 Step 461/1563 Loss: 1.348 | Acc: 51.272% (7580/14784)\n",
      "Epoch 9 Step 462/1563 Loss: 1.348 | Acc: 51.289% (7599/14816)\n",
      "Epoch 9 Step 463/1563 Loss: 1.348 | Acc: 51.273% (7613/14848)\n",
      "Epoch 9 Step 464/1563 Loss: 1.348 | Acc: 51.257% (7627/14880)\n",
      "Epoch 9 Step 465/1563 Loss: 1.348 | Acc: 51.267% (7645/14912)\n",
      "Epoch 9 Step 466/1563 Loss: 1.349 | Acc: 51.245% (7658/14944)\n",
      "Epoch 9 Step 467/1563 Loss: 1.348 | Acc: 51.282% (7680/14976)\n",
      "Epoch 9 Step 468/1563 Loss: 1.349 | Acc: 51.246% (7691/15008)\n",
      "Epoch 9 Step 469/1563 Loss: 1.350 | Acc: 51.237% (7706/15040)\n",
      "Epoch 9 Step 470/1563 Loss: 1.349 | Acc: 51.221% (7720/15072)\n",
      "Epoch 9 Step 471/1563 Loss: 1.350 | Acc: 51.198% (7733/15104)\n",
      "Epoch 9 Step 472/1563 Loss: 1.350 | Acc: 51.216% (7752/15136)\n",
      "Epoch 9 Step 473/1563 Loss: 1.350 | Acc: 51.206% (7767/15168)\n",
      "Epoch 9 Step 474/1563 Loss: 1.349 | Acc: 51.224% (7786/15200)\n",
      "Epoch 9 Step 475/1563 Loss: 1.350 | Acc: 51.208% (7800/15232)\n",
      "Epoch 9 Step 476/1563 Loss: 1.350 | Acc: 51.212% (7817/15264)\n",
      "Epoch 9 Step 477/1563 Loss: 1.349 | Acc: 51.229% (7836/15296)\n",
      "Epoch 9 Step 478/1563 Loss: 1.349 | Acc: 51.227% (7852/15328)\n",
      "Epoch 9 Step 479/1563 Loss: 1.349 | Acc: 51.243% (7871/15360)\n",
      "Epoch 9 Step 480/1563 Loss: 1.348 | Acc: 51.254% (7889/15392)\n",
      "Epoch 9 Step 481/1563 Loss: 1.348 | Acc: 51.264% (7907/15424)\n",
      "Epoch 9 Step 482/1563 Loss: 1.348 | Acc: 51.313% (7931/15456)\n",
      "Epoch 9 Step 483/1563 Loss: 1.348 | Acc: 51.291% (7944/15488)\n",
      "Epoch 9 Step 484/1563 Loss: 1.348 | Acc: 51.302% (7962/15520)\n",
      "Epoch 9 Step 485/1563 Loss: 1.348 | Acc: 51.305% (7979/15552)\n",
      "Epoch 9 Step 486/1563 Loss: 1.349 | Acc: 51.309% (7996/15584)\n",
      "Epoch 9 Step 487/1563 Loss: 1.349 | Acc: 51.313% (8013/15616)\n",
      "Epoch 9 Step 488/1563 Loss: 1.348 | Acc: 51.355% (8036/15648)\n",
      "Epoch 9 Step 489/1563 Loss: 1.349 | Acc: 51.346% (8051/15680)\n",
      "Epoch 9 Step 490/1563 Loss: 1.349 | Acc: 51.330% (8065/15712)\n",
      "Epoch 9 Step 491/1563 Loss: 1.349 | Acc: 51.327% (8081/15744)\n",
      "Epoch 9 Step 492/1563 Loss: 1.349 | Acc: 51.312% (8095/15776)\n",
      "Epoch 9 Step 493/1563 Loss: 1.349 | Acc: 51.322% (8113/15808)\n",
      "Epoch 9 Step 494/1563 Loss: 1.349 | Acc: 51.338% (8132/15840)\n",
      "Epoch 9 Step 495/1563 Loss: 1.349 | Acc: 51.323% (8146/15872)\n",
      "Epoch 9 Step 496/1563 Loss: 1.348 | Acc: 51.327% (8163/15904)\n",
      "Epoch 9 Step 497/1563 Loss: 1.348 | Acc: 51.330% (8180/15936)\n",
      "Epoch 9 Step 498/1563 Loss: 1.348 | Acc: 51.346% (8199/15968)\n",
      "Epoch 9 Step 499/1563 Loss: 1.348 | Acc: 51.306% (8209/16000)\n",
      "Epoch 9 Step 500/1563 Loss: 1.348 | Acc: 51.297% (8224/16032)\n",
      "Epoch 9 Step 501/1563 Loss: 1.348 | Acc: 51.295% (8240/16064)\n",
      "Epoch 9 Step 502/1563 Loss: 1.348 | Acc: 51.292% (8256/16096)\n",
      "Epoch 9 Step 503/1563 Loss: 1.349 | Acc: 51.283% (8271/16128)\n",
      "Epoch 9 Step 504/1563 Loss: 1.349 | Acc: 51.287% (8288/16160)\n",
      "Epoch 9 Step 505/1563 Loss: 1.349 | Acc: 51.303% (8307/16192)\n",
      "Epoch 9 Step 506/1563 Loss: 1.349 | Acc: 51.288% (8321/16224)\n",
      "Epoch 9 Step 507/1563 Loss: 1.348 | Acc: 51.292% (8338/16256)\n",
      "Epoch 9 Step 508/1563 Loss: 1.348 | Acc: 51.320% (8359/16288)\n",
      "Epoch 9 Step 509/1563 Loss: 1.347 | Acc: 51.336% (8378/16320)\n",
      "Epoch 9 Step 510/1563 Loss: 1.347 | Acc: 51.352% (8397/16352)\n",
      "Epoch 9 Step 511/1563 Loss: 1.348 | Acc: 51.331% (8410/16384)\n",
      "Epoch 9 Step 512/1563 Loss: 1.347 | Acc: 51.322% (8425/16416)\n",
      "Epoch 9 Step 513/1563 Loss: 1.348 | Acc: 51.331% (8443/16448)\n",
      "Epoch 9 Step 514/1563 Loss: 1.348 | Acc: 51.323% (8458/16480)\n",
      "Epoch 9 Step 515/1563 Loss: 1.348 | Acc: 51.326% (8475/16512)\n",
      "Epoch 9 Step 516/1563 Loss: 1.347 | Acc: 51.336% (8493/16544)\n",
      "Epoch 9 Step 517/1563 Loss: 1.347 | Acc: 51.345% (8511/16576)\n",
      "Epoch 9 Step 518/1563 Loss: 1.347 | Acc: 51.337% (8526/16608)\n",
      "Epoch 9 Step 519/1563 Loss: 1.347 | Acc: 51.346% (8544/16640)\n",
      "Epoch 9 Step 520/1563 Loss: 1.347 | Acc: 51.332% (8558/16672)\n",
      "Epoch 9 Step 521/1563 Loss: 1.348 | Acc: 51.323% (8573/16704)\n",
      "Epoch 9 Step 522/1563 Loss: 1.348 | Acc: 51.321% (8589/16736)\n",
      "Epoch 9 Step 523/1563 Loss: 1.348 | Acc: 51.312% (8604/16768)\n",
      "Epoch 9 Step 524/1563 Loss: 1.348 | Acc: 51.310% (8620/16800)\n",
      "Epoch 9 Step 525/1563 Loss: 1.348 | Acc: 51.295% (8634/16832)\n",
      "Epoch 9 Step 526/1563 Loss: 1.348 | Acc: 51.293% (8650/16864)\n",
      "Epoch 9 Step 527/1563 Loss: 1.349 | Acc: 51.284% (8665/16896)\n",
      "Epoch 9 Step 528/1563 Loss: 1.349 | Acc: 51.282% (8681/16928)\n",
      "Epoch 9 Step 529/1563 Loss: 1.349 | Acc: 51.274% (8696/16960)\n",
      "Epoch 9 Step 530/1563 Loss: 1.349 | Acc: 51.248% (8708/16992)\n",
      "Epoch 9 Step 531/1563 Loss: 1.348 | Acc: 51.257% (8726/17024)\n",
      "Epoch 9 Step 532/1563 Loss: 1.348 | Acc: 51.284% (8747/17056)\n",
      "Epoch 9 Step 533/1563 Loss: 1.348 | Acc: 51.299% (8766/17088)\n",
      "Epoch 9 Step 534/1563 Loss: 1.348 | Acc: 51.303% (8783/17120)\n",
      "Epoch 9 Step 535/1563 Loss: 1.348 | Acc: 51.283% (8796/17152)\n",
      "Epoch 9 Step 536/1563 Loss: 1.348 | Acc: 51.298% (8815/17184)\n",
      "Epoch 9 Step 537/1563 Loss: 1.348 | Acc: 51.278% (8828/17216)\n",
      "Epoch 9 Step 538/1563 Loss: 1.348 | Acc: 51.270% (8843/17248)\n",
      "Epoch 9 Step 539/1563 Loss: 1.349 | Acc: 51.267% (8859/17280)\n",
      "Epoch 9 Step 540/1563 Loss: 1.349 | Acc: 51.294% (8880/17312)\n",
      "Epoch 9 Step 541/1563 Loss: 1.348 | Acc: 51.315% (8900/17344)\n",
      "Epoch 9 Step 542/1563 Loss: 1.349 | Acc: 51.318% (8917/17376)\n",
      "Epoch 9 Step 543/1563 Loss: 1.348 | Acc: 51.315% (8933/17408)\n",
      "Epoch 9 Step 544/1563 Loss: 1.349 | Acc: 51.302% (8947/17440)\n",
      "Epoch 9 Step 545/1563 Loss: 1.349 | Acc: 51.299% (8963/17472)\n",
      "Epoch 9 Step 546/1563 Loss: 1.349 | Acc: 51.308% (8981/17504)\n",
      "Epoch 9 Step 547/1563 Loss: 1.349 | Acc: 51.323% (9000/17536)\n",
      "Epoch 9 Step 548/1563 Loss: 1.348 | Acc: 51.326% (9017/17568)\n",
      "Epoch 9 Step 549/1563 Loss: 1.348 | Acc: 51.352% (9038/17600)\n",
      "Epoch 9 Step 550/1563 Loss: 1.347 | Acc: 51.361% (9056/17632)\n",
      "Epoch 9 Step 551/1563 Loss: 1.347 | Acc: 51.342% (9069/17664)\n",
      "Epoch 9 Step 552/1563 Loss: 1.347 | Acc: 51.345% (9086/17696)\n",
      "Epoch 9 Step 553/1563 Loss: 1.347 | Acc: 51.343% (9102/17728)\n",
      "Epoch 9 Step 554/1563 Loss: 1.347 | Acc: 51.346% (9119/17760)\n",
      "Epoch 9 Step 555/1563 Loss: 1.347 | Acc: 51.349% (9136/17792)\n",
      "Epoch 9 Step 556/1563 Loss: 1.347 | Acc: 51.369% (9156/17824)\n",
      "Epoch 9 Step 557/1563 Loss: 1.348 | Acc: 51.350% (9169/17856)\n",
      "Epoch 9 Step 558/1563 Loss: 1.348 | Acc: 51.336% (9183/17888)\n",
      "Epoch 9 Step 559/1563 Loss: 1.348 | Acc: 51.306% (9194/17920)\n",
      "Epoch 9 Step 560/1563 Loss: 1.348 | Acc: 51.309% (9211/17952)\n",
      "Epoch 9 Step 561/1563 Loss: 1.348 | Acc: 51.301% (9226/17984)\n",
      "Epoch 9 Step 562/1563 Loss: 1.348 | Acc: 51.288% (9240/18016)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 563/1563 Loss: 1.349 | Acc: 51.280% (9255/18048)\n",
      "Epoch 9 Step 564/1563 Loss: 1.349 | Acc: 51.272% (9270/18080)\n",
      "Epoch 9 Step 565/1563 Loss: 1.349 | Acc: 51.270% (9286/18112)\n",
      "Epoch 9 Step 566/1563 Loss: 1.348 | Acc: 51.290% (9306/18144)\n",
      "Epoch 9 Step 567/1563 Loss: 1.348 | Acc: 51.298% (9324/18176)\n",
      "Epoch 9 Step 568/1563 Loss: 1.348 | Acc: 51.302% (9341/18208)\n",
      "Epoch 9 Step 569/1563 Loss: 1.349 | Acc: 51.310% (9359/18240)\n",
      "Epoch 9 Step 570/1563 Loss: 1.348 | Acc: 51.341% (9381/18272)\n",
      "Epoch 9 Step 571/1563 Loss: 1.349 | Acc: 51.311% (9392/18304)\n",
      "Epoch 9 Step 572/1563 Loss: 1.349 | Acc: 51.331% (9412/18336)\n",
      "Epoch 9 Step 573/1563 Loss: 1.348 | Acc: 51.334% (9429/18368)\n",
      "Epoch 9 Step 574/1563 Loss: 1.349 | Acc: 51.315% (9442/18400)\n",
      "Epoch 9 Step 575/1563 Loss: 1.348 | Acc: 51.356% (9466/18432)\n",
      "Epoch 9 Step 576/1563 Loss: 1.349 | Acc: 51.338% (9479/18464)\n",
      "Epoch 9 Step 577/1563 Loss: 1.349 | Acc: 51.346% (9497/18496)\n",
      "Epoch 9 Step 578/1563 Loss: 1.349 | Acc: 51.328% (9510/18528)\n",
      "Epoch 9 Step 579/1563 Loss: 1.349 | Acc: 51.336% (9528/18560)\n",
      "Epoch 9 Step 580/1563 Loss: 1.348 | Acc: 51.355% (9548/18592)\n",
      "Epoch 9 Step 581/1563 Loss: 1.349 | Acc: 51.348% (9563/18624)\n",
      "Epoch 9 Step 582/1563 Loss: 1.349 | Acc: 51.324% (9575/18656)\n",
      "Epoch 9 Step 583/1563 Loss: 1.349 | Acc: 51.322% (9591/18688)\n",
      "Epoch 9 Step 584/1563 Loss: 1.349 | Acc: 51.303% (9604/18720)\n",
      "Epoch 9 Step 585/1563 Loss: 1.349 | Acc: 51.296% (9619/18752)\n",
      "Epoch 9 Step 586/1563 Loss: 1.350 | Acc: 51.288% (9634/18784)\n",
      "Epoch 9 Step 587/1563 Loss: 1.350 | Acc: 51.281% (9649/18816)\n",
      "Epoch 9 Step 588/1563 Loss: 1.349 | Acc: 51.321% (9673/18848)\n",
      "Epoch 9 Step 589/1563 Loss: 1.350 | Acc: 51.298% (9685/18880)\n",
      "Epoch 9 Step 590/1563 Loss: 1.350 | Acc: 51.290% (9700/18912)\n",
      "Epoch 9 Step 591/1563 Loss: 1.349 | Acc: 51.293% (9717/18944)\n",
      "Epoch 9 Step 592/1563 Loss: 1.349 | Acc: 51.281% (9731/18976)\n",
      "Epoch 9 Step 593/1563 Loss: 1.349 | Acc: 51.263% (9744/19008)\n",
      "Epoch 9 Step 594/1563 Loss: 1.349 | Acc: 51.271% (9762/19040)\n",
      "Epoch 9 Step 595/1563 Loss: 1.349 | Acc: 51.274% (9779/19072)\n",
      "Epoch 9 Step 596/1563 Loss: 1.349 | Acc: 51.262% (9793/19104)\n",
      "Epoch 9 Step 597/1563 Loss: 1.349 | Acc: 51.275% (9812/19136)\n",
      "Epoch 9 Step 598/1563 Loss: 1.349 | Acc: 51.273% (9828/19168)\n",
      "Epoch 9 Step 599/1563 Loss: 1.348 | Acc: 51.292% (9848/19200)\n",
      "Epoch 9 Step 600/1563 Loss: 1.348 | Acc: 51.295% (9865/19232)\n",
      "Epoch 9 Step 601/1563 Loss: 1.348 | Acc: 51.287% (9880/19264)\n",
      "Epoch 9 Step 602/1563 Loss: 1.348 | Acc: 51.290% (9897/19296)\n",
      "Epoch 9 Step 603/1563 Loss: 1.348 | Acc: 51.273% (9910/19328)\n",
      "Epoch 9 Step 604/1563 Loss: 1.348 | Acc: 51.302% (9932/19360)\n",
      "Epoch 9 Step 605/1563 Loss: 1.349 | Acc: 51.300% (9948/19392)\n",
      "Epoch 9 Step 606/1563 Loss: 1.349 | Acc: 51.287% (9962/19424)\n",
      "Epoch 9 Step 607/1563 Loss: 1.349 | Acc: 51.280% (9977/19456)\n",
      "Epoch 9 Step 608/1563 Loss: 1.349 | Acc: 51.293% (9996/19488)\n",
      "Epoch 9 Step 609/1563 Loss: 1.349 | Acc: 51.301% (10014/19520)\n",
      "Epoch 9 Step 610/1563 Loss: 1.348 | Acc: 51.304% (10031/19552)\n",
      "Epoch 9 Step 611/1563 Loss: 1.348 | Acc: 51.292% (10045/19584)\n",
      "Epoch 9 Step 612/1563 Loss: 1.348 | Acc: 51.300% (10063/19616)\n",
      "Epoch 9 Step 613/1563 Loss: 1.347 | Acc: 51.333% (10086/19648)\n",
      "Epoch 9 Step 614/1563 Loss: 1.347 | Acc: 51.347% (10105/19680)\n",
      "Epoch 9 Step 615/1563 Loss: 1.347 | Acc: 51.349% (10122/19712)\n",
      "Epoch 9 Step 616/1563 Loss: 1.347 | Acc: 51.347% (10138/19744)\n",
      "Epoch 9 Step 617/1563 Loss: 1.346 | Acc: 51.360% (10157/19776)\n",
      "Epoch 9 Step 618/1563 Loss: 1.347 | Acc: 51.328% (10167/19808)\n",
      "Epoch 9 Step 619/1563 Loss: 1.347 | Acc: 51.316% (10181/19840)\n",
      "Epoch 9 Step 620/1563 Loss: 1.347 | Acc: 51.313% (10197/19872)\n",
      "Epoch 9 Step 621/1563 Loss: 1.346 | Acc: 51.321% (10215/19904)\n",
      "Epoch 9 Step 622/1563 Loss: 1.346 | Acc: 51.339% (10235/19936)\n",
      "Epoch 9 Step 623/1563 Loss: 1.347 | Acc: 51.327% (10249/19968)\n",
      "Epoch 9 Step 624/1563 Loss: 1.347 | Acc: 51.320% (10264/20000)\n",
      "Epoch 9 Step 625/1563 Loss: 1.347 | Acc: 51.308% (10278/20032)\n",
      "Epoch 9 Step 626/1563 Loss: 1.347 | Acc: 51.306% (10294/20064)\n",
      "Epoch 9 Step 627/1563 Loss: 1.347 | Acc: 51.299% (10309/20096)\n",
      "Epoch 9 Step 628/1563 Loss: 1.347 | Acc: 51.302% (10326/20128)\n",
      "Epoch 9 Step 629/1563 Loss: 1.347 | Acc: 51.310% (10344/20160)\n",
      "Epoch 9 Step 630/1563 Loss: 1.346 | Acc: 51.332% (10365/20192)\n",
      "Epoch 9 Step 631/1563 Loss: 1.347 | Acc: 51.345% (10384/20224)\n",
      "Epoch 9 Step 632/1563 Loss: 1.347 | Acc: 51.343% (10400/20256)\n",
      "Epoch 9 Step 633/1563 Loss: 1.347 | Acc: 51.365% (10421/20288)\n",
      "Epoch 9 Step 634/1563 Loss: 1.346 | Acc: 51.353% (10435/20320)\n",
      "Epoch 9 Step 635/1563 Loss: 1.346 | Acc: 51.351% (10451/20352)\n",
      "Epoch 9 Step 636/1563 Loss: 1.346 | Acc: 51.359% (10469/20384)\n",
      "Epoch 9 Step 637/1563 Loss: 1.346 | Acc: 51.367% (10487/20416)\n",
      "Epoch 9 Step 638/1563 Loss: 1.346 | Acc: 51.369% (10504/20448)\n",
      "Epoch 9 Step 639/1563 Loss: 1.346 | Acc: 51.382% (10523/20480)\n",
      "Epoch 9 Step 640/1563 Loss: 1.346 | Acc: 51.375% (10538/20512)\n",
      "Epoch 9 Step 641/1563 Loss: 1.346 | Acc: 51.363% (10552/20544)\n",
      "Epoch 9 Step 642/1563 Loss: 1.346 | Acc: 51.356% (10567/20576)\n",
      "Epoch 9 Step 643/1563 Loss: 1.346 | Acc: 51.349% (10582/20608)\n",
      "Epoch 9 Step 644/1563 Loss: 1.346 | Acc: 51.352% (10599/20640)\n",
      "Epoch 9 Step 645/1563 Loss: 1.346 | Acc: 51.340% (10613/20672)\n",
      "Epoch 9 Step 646/1563 Loss: 1.346 | Acc: 51.357% (10633/20704)\n",
      "Epoch 9 Step 647/1563 Loss: 1.346 | Acc: 51.355% (10649/20736)\n",
      "Epoch 9 Step 648/1563 Loss: 1.346 | Acc: 51.372% (10669/20768)\n",
      "Epoch 9 Step 649/1563 Loss: 1.346 | Acc: 51.351% (10681/20800)\n",
      "Epoch 9 Step 650/1563 Loss: 1.346 | Acc: 51.354% (10698/20832)\n",
      "Epoch 9 Step 651/1563 Loss: 1.346 | Acc: 51.332% (10710/20864)\n",
      "Epoch 9 Step 652/1563 Loss: 1.346 | Acc: 51.335% (10727/20896)\n",
      "Epoch 9 Step 653/1563 Loss: 1.347 | Acc: 51.324% (10741/20928)\n",
      "Epoch 9 Step 654/1563 Loss: 1.347 | Acc: 51.326% (10758/20960)\n",
      "Epoch 9 Step 655/1563 Loss: 1.347 | Acc: 51.315% (10772/20992)\n",
      "Epoch 9 Step 656/1563 Loss: 1.347 | Acc: 51.313% (10788/21024)\n",
      "Epoch 9 Step 657/1563 Loss: 1.347 | Acc: 51.320% (10806/21056)\n",
      "Epoch 9 Step 658/1563 Loss: 1.348 | Acc: 51.314% (10821/21088)\n",
      "Epoch 9 Step 659/1563 Loss: 1.348 | Acc: 51.302% (10835/21120)\n",
      "Epoch 9 Step 660/1563 Loss: 1.348 | Acc: 51.300% (10851/21152)\n",
      "Epoch 9 Step 661/1563 Loss: 1.348 | Acc: 51.298% (10867/21184)\n",
      "Epoch 9 Step 662/1563 Loss: 1.348 | Acc: 51.306% (10885/21216)\n",
      "Epoch 9 Step 663/1563 Loss: 1.348 | Acc: 51.308% (10902/21248)\n",
      "Epoch 9 Step 664/1563 Loss: 1.349 | Acc: 51.302% (10917/21280)\n",
      "Epoch 9 Step 665/1563 Loss: 1.348 | Acc: 51.304% (10934/21312)\n",
      "Epoch 9 Step 666/1563 Loss: 1.348 | Acc: 51.307% (10951/21344)\n",
      "Epoch 9 Step 667/1563 Loss: 1.348 | Acc: 51.286% (10963/21376)\n",
      "Epoch 9 Step 668/1563 Loss: 1.349 | Acc: 51.275% (10977/21408)\n",
      "Epoch 9 Step 669/1563 Loss: 1.349 | Acc: 51.283% (10995/21440)\n",
      "Epoch 9 Step 670/1563 Loss: 1.349 | Acc: 51.285% (11012/21472)\n",
      "Epoch 9 Step 671/1563 Loss: 1.349 | Acc: 51.297% (11031/21504)\n",
      "Epoch 9 Step 672/1563 Loss: 1.349 | Acc: 51.277% (11043/21536)\n",
      "Epoch 9 Step 673/1563 Loss: 1.349 | Acc: 51.275% (11059/21568)\n",
      "Epoch 9 Step 674/1563 Loss: 1.349 | Acc: 51.269% (11074/21600)\n",
      "Epoch 9 Step 675/1563 Loss: 1.349 | Acc: 51.271% (11091/21632)\n",
      "Epoch 9 Step 676/1563 Loss: 1.349 | Acc: 51.279% (11109/21664)\n",
      "Epoch 9 Step 677/1563 Loss: 1.350 | Acc: 51.263% (11122/21696)\n",
      "Epoch 9 Step 678/1563 Loss: 1.349 | Acc: 51.270% (11140/21728)\n",
      "Epoch 9 Step 679/1563 Loss: 1.349 | Acc: 51.273% (11157/21760)\n",
      "Epoch 9 Step 680/1563 Loss: 1.349 | Acc: 51.285% (11176/21792)\n",
      "Epoch 9 Step 681/1563 Loss: 1.349 | Acc: 51.269% (11189/21824)\n",
      "Epoch 9 Step 682/1563 Loss: 1.349 | Acc: 51.245% (11200/21856)\n",
      "Epoch 9 Step 683/1563 Loss: 1.349 | Acc: 51.234% (11214/21888)\n",
      "Epoch 9 Step 684/1563 Loss: 1.349 | Acc: 51.241% (11232/21920)\n",
      "Epoch 9 Step 685/1563 Loss: 1.349 | Acc: 51.221% (11244/21952)\n",
      "Epoch 9 Step 686/1563 Loss: 1.349 | Acc: 51.224% (11261/21984)\n",
      "Epoch 9 Step 687/1563 Loss: 1.349 | Acc: 51.254% (11284/22016)\n",
      "Epoch 9 Step 688/1563 Loss: 1.348 | Acc: 51.261% (11302/22048)\n",
      "Epoch 9 Step 689/1563 Loss: 1.348 | Acc: 51.255% (11317/22080)\n",
      "Epoch 9 Step 690/1563 Loss: 1.349 | Acc: 51.239% (11330/22112)\n",
      "Epoch 9 Step 691/1563 Loss: 1.349 | Acc: 51.242% (11347/22144)\n",
      "Epoch 9 Step 692/1563 Loss: 1.349 | Acc: 51.231% (11361/22176)\n",
      "Epoch 9 Step 693/1563 Loss: 1.349 | Acc: 51.229% (11377/22208)\n",
      "Epoch 9 Step 694/1563 Loss: 1.350 | Acc: 51.228% (11393/22240)\n",
      "Epoch 9 Step 695/1563 Loss: 1.349 | Acc: 51.239% (11412/22272)\n",
      "Epoch 9 Step 696/1563 Loss: 1.349 | Acc: 51.264% (11434/22304)\n",
      "Epoch 9 Step 697/1563 Loss: 1.349 | Acc: 51.280% (11454/22336)\n",
      "Epoch 9 Step 698/1563 Loss: 1.348 | Acc: 51.292% (11473/22368)\n",
      "Epoch 9 Step 699/1563 Loss: 1.348 | Acc: 51.290% (11489/22400)\n",
      "Epoch 9 Step 700/1563 Loss: 1.348 | Acc: 51.293% (11506/22432)\n",
      "Epoch 9 Step 701/1563 Loss: 1.348 | Acc: 51.304% (11525/22464)\n",
      "Epoch 9 Step 702/1563 Loss: 1.348 | Acc: 51.311% (11543/22496)\n",
      "Epoch 9 Step 703/1563 Loss: 1.348 | Acc: 51.305% (11558/22528)\n",
      "Epoch 9 Step 704/1563 Loss: 1.349 | Acc: 51.299% (11573/22560)\n",
      "Epoch 9 Step 705/1563 Loss: 1.348 | Acc: 51.328% (11596/22592)\n",
      "Epoch 9 Step 706/1563 Loss: 1.348 | Acc: 51.317% (11610/22624)\n",
      "Epoch 9 Step 707/1563 Loss: 1.348 | Acc: 51.324% (11628/22656)\n",
      "Epoch 9 Step 708/1563 Loss: 1.348 | Acc: 51.309% (11641/22688)\n",
      "Epoch 9 Step 709/1563 Loss: 1.348 | Acc: 51.312% (11658/22720)\n",
      "Epoch 9 Step 710/1563 Loss: 1.348 | Acc: 51.292% (11670/22752)\n",
      "Epoch 9 Step 711/1563 Loss: 1.348 | Acc: 51.304% (11689/22784)\n",
      "Epoch 9 Step 712/1563 Loss: 1.348 | Acc: 51.310% (11707/22816)\n",
      "Epoch 9 Step 713/1563 Loss: 1.348 | Acc: 51.322% (11726/22848)\n",
      "Epoch 9 Step 714/1563 Loss: 1.348 | Acc: 51.302% (11738/22880)\n",
      "Epoch 9 Step 715/1563 Loss: 1.348 | Acc: 51.274% (11748/22912)\n",
      "Epoch 9 Step 716/1563 Loss: 1.348 | Acc: 51.286% (11767/22944)\n",
      "Epoch 9 Step 717/1563 Loss: 1.348 | Acc: 51.297% (11786/22976)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 718/1563 Loss: 1.348 | Acc: 51.308% (11805/23008)\n",
      "Epoch 9 Step 719/1563 Loss: 1.348 | Acc: 51.293% (11818/23040)\n",
      "Epoch 9 Step 720/1563 Loss: 1.348 | Acc: 51.292% (11834/23072)\n",
      "Epoch 9 Step 721/1563 Loss: 1.348 | Acc: 51.285% (11849/23104)\n",
      "Epoch 9 Step 722/1563 Loss: 1.348 | Acc: 51.284% (11865/23136)\n",
      "Epoch 9 Step 723/1563 Loss: 1.348 | Acc: 51.282% (11881/23168)\n",
      "Epoch 9 Step 724/1563 Loss: 1.348 | Acc: 51.306% (11903/23200)\n",
      "Epoch 9 Step 725/1563 Loss: 1.348 | Acc: 51.313% (11921/23232)\n",
      "Epoch 9 Step 726/1563 Loss: 1.348 | Acc: 51.307% (11936/23264)\n",
      "Epoch 9 Step 727/1563 Loss: 1.348 | Acc: 51.318% (11955/23296)\n",
      "Epoch 9 Step 728/1563 Loss: 1.347 | Acc: 51.320% (11972/23328)\n",
      "Epoch 9 Step 729/1563 Loss: 1.348 | Acc: 51.314% (11987/23360)\n",
      "Epoch 9 Step 730/1563 Loss: 1.348 | Acc: 51.304% (12001/23392)\n",
      "Epoch 9 Step 731/1563 Loss: 1.348 | Acc: 51.298% (12016/23424)\n",
      "Epoch 9 Step 732/1563 Loss: 1.348 | Acc: 51.292% (12031/23456)\n",
      "Epoch 9 Step 733/1563 Loss: 1.348 | Acc: 51.282% (12045/23488)\n",
      "Epoch 9 Step 734/1563 Loss: 1.348 | Acc: 51.305% (12067/23520)\n",
      "Epoch 9 Step 735/1563 Loss: 1.348 | Acc: 51.316% (12086/23552)\n",
      "Epoch 9 Step 736/1563 Loss: 1.347 | Acc: 51.340% (12108/23584)\n",
      "Epoch 9 Step 737/1563 Loss: 1.347 | Acc: 51.351% (12127/23616)\n",
      "Epoch 9 Step 738/1563 Loss: 1.347 | Acc: 51.353% (12144/23648)\n",
      "Epoch 9 Step 739/1563 Loss: 1.347 | Acc: 51.330% (12155/23680)\n",
      "Epoch 9 Step 740/1563 Loss: 1.348 | Acc: 51.316% (12168/23712)\n",
      "Epoch 9 Step 741/1563 Loss: 1.348 | Acc: 51.327% (12187/23744)\n",
      "Epoch 9 Step 742/1563 Loss: 1.348 | Acc: 51.321% (12202/23776)\n",
      "Epoch 9 Step 743/1563 Loss: 1.348 | Acc: 51.310% (12216/23808)\n",
      "Epoch 9 Step 744/1563 Loss: 1.348 | Acc: 51.305% (12231/23840)\n",
      "Epoch 9 Step 745/1563 Loss: 1.348 | Acc: 51.303% (12247/23872)\n",
      "Epoch 9 Step 746/1563 Loss: 1.348 | Acc: 51.305% (12264/23904)\n",
      "Epoch 9 Step 747/1563 Loss: 1.348 | Acc: 51.295% (12278/23936)\n",
      "Epoch 9 Step 748/1563 Loss: 1.348 | Acc: 51.302% (12296/23968)\n",
      "Epoch 9 Step 749/1563 Loss: 1.348 | Acc: 51.292% (12310/24000)\n",
      "Epoch 9 Step 750/1563 Loss: 1.348 | Acc: 51.302% (12329/24032)\n",
      "Epoch 9 Step 751/1563 Loss: 1.348 | Acc: 51.301% (12345/24064)\n",
      "Epoch 9 Step 752/1563 Loss: 1.348 | Acc: 51.295% (12360/24096)\n",
      "Epoch 9 Step 753/1563 Loss: 1.348 | Acc: 51.318% (12382/24128)\n",
      "Epoch 9 Step 754/1563 Loss: 1.348 | Acc: 51.329% (12401/24160)\n",
      "Epoch 9 Step 755/1563 Loss: 1.348 | Acc: 51.319% (12415/24192)\n",
      "Epoch 9 Step 756/1563 Loss: 1.348 | Acc: 51.338% (12436/24224)\n",
      "Epoch 9 Step 757/1563 Loss: 1.348 | Acc: 51.352% (12456/24256)\n",
      "Epoch 9 Step 758/1563 Loss: 1.348 | Acc: 51.334% (12468/24288)\n",
      "Epoch 9 Step 759/1563 Loss: 1.348 | Acc: 51.308% (12478/24320)\n",
      "Epoch 9 Step 760/1563 Loss: 1.348 | Acc: 51.298% (12492/24352)\n",
      "Epoch 9 Step 761/1563 Loss: 1.348 | Acc: 51.300% (12509/24384)\n",
      "Epoch 9 Step 762/1563 Loss: 1.348 | Acc: 51.298% (12525/24416)\n",
      "Epoch 9 Step 763/1563 Loss: 1.349 | Acc: 51.288% (12539/24448)\n",
      "Epoch 9 Step 764/1563 Loss: 1.349 | Acc: 51.279% (12553/24480)\n",
      "Epoch 9 Step 765/1563 Loss: 1.349 | Acc: 51.285% (12571/24512)\n",
      "Epoch 9 Step 766/1563 Loss: 1.349 | Acc: 51.275% (12585/24544)\n",
      "Epoch 9 Step 767/1563 Loss: 1.349 | Acc: 51.274% (12601/24576)\n",
      "Epoch 9 Step 768/1563 Loss: 1.349 | Acc: 51.260% (12614/24608)\n",
      "Epoch 9 Step 769/1563 Loss: 1.349 | Acc: 51.246% (12627/24640)\n",
      "Epoch 9 Step 770/1563 Loss: 1.350 | Acc: 51.220% (12637/24672)\n",
      "Epoch 9 Step 771/1563 Loss: 1.350 | Acc: 51.214% (12652/24704)\n",
      "Epoch 9 Step 772/1563 Loss: 1.350 | Acc: 51.221% (12670/24736)\n",
      "Epoch 9 Step 773/1563 Loss: 1.350 | Acc: 51.211% (12684/24768)\n",
      "Epoch 9 Step 774/1563 Loss: 1.350 | Acc: 51.210% (12700/24800)\n",
      "Epoch 9 Step 775/1563 Loss: 1.350 | Acc: 51.200% (12714/24832)\n",
      "Epoch 9 Step 776/1563 Loss: 1.350 | Acc: 51.219% (12735/24864)\n",
      "Epoch 9 Step 777/1563 Loss: 1.350 | Acc: 51.229% (12754/24896)\n",
      "Epoch 9 Step 778/1563 Loss: 1.350 | Acc: 51.232% (12771/24928)\n",
      "Epoch 9 Step 779/1563 Loss: 1.350 | Acc: 51.198% (12779/24960)\n",
      "Epoch 9 Step 780/1563 Loss: 1.350 | Acc: 51.188% (12793/24992)\n",
      "Epoch 9 Step 781/1563 Loss: 1.350 | Acc: 51.183% (12808/25024)\n",
      "Epoch 9 Step 782/1563 Loss: 1.350 | Acc: 51.189% (12826/25056)\n",
      "Epoch 9 Step 783/1563 Loss: 1.350 | Acc: 51.180% (12840/25088)\n",
      "Epoch 9 Step 784/1563 Loss: 1.351 | Acc: 51.182% (12857/25120)\n",
      "Epoch 9 Step 785/1563 Loss: 1.351 | Acc: 51.185% (12874/25152)\n",
      "Epoch 9 Step 786/1563 Loss: 1.351 | Acc: 51.191% (12892/25184)\n",
      "Epoch 9 Step 787/1563 Loss: 1.350 | Acc: 51.202% (12911/25216)\n",
      "Epoch 9 Step 788/1563 Loss: 1.351 | Acc: 51.188% (12924/25248)\n",
      "Epoch 9 Step 789/1563 Loss: 1.351 | Acc: 51.187% (12940/25280)\n",
      "Epoch 9 Step 790/1563 Loss: 1.351 | Acc: 51.189% (12957/25312)\n",
      "Epoch 9 Step 791/1563 Loss: 1.351 | Acc: 51.192% (12974/25344)\n",
      "Epoch 9 Step 792/1563 Loss: 1.351 | Acc: 51.194% (12991/25376)\n",
      "Epoch 9 Step 793/1563 Loss: 1.351 | Acc: 51.204% (13010/25408)\n",
      "Epoch 9 Step 794/1563 Loss: 1.351 | Acc: 51.203% (13026/25440)\n",
      "Epoch 9 Step 795/1563 Loss: 1.350 | Acc: 51.217% (13046/25472)\n",
      "Epoch 9 Step 796/1563 Loss: 1.350 | Acc: 51.227% (13065/25504)\n",
      "Epoch 9 Step 797/1563 Loss: 1.350 | Acc: 51.249% (13087/25536)\n",
      "Epoch 9 Step 798/1563 Loss: 1.350 | Acc: 51.255% (13105/25568)\n",
      "Epoch 9 Step 799/1563 Loss: 1.350 | Acc: 51.258% (13122/25600)\n",
      "Epoch 9 Step 800/1563 Loss: 1.350 | Acc: 51.272% (13142/25632)\n",
      "Epoch 9 Step 801/1563 Loss: 1.350 | Acc: 51.286% (13162/25664)\n",
      "Epoch 9 Step 802/1563 Loss: 1.350 | Acc: 51.276% (13176/25696)\n",
      "Epoch 9 Step 803/1563 Loss: 1.350 | Acc: 51.283% (13194/25728)\n",
      "Epoch 9 Step 804/1563 Loss: 1.349 | Acc: 51.300% (13215/25760)\n",
      "Epoch 9 Step 805/1563 Loss: 1.349 | Acc: 51.326% (13238/25792)\n",
      "Epoch 9 Step 806/1563 Loss: 1.349 | Acc: 51.348% (13260/25824)\n",
      "Epoch 9 Step 807/1563 Loss: 1.349 | Acc: 51.346% (13276/25856)\n",
      "Epoch 9 Step 808/1563 Loss: 1.349 | Acc: 51.340% (13291/25888)\n",
      "Epoch 9 Step 809/1563 Loss: 1.349 | Acc: 51.335% (13306/25920)\n",
      "Epoch 9 Step 810/1563 Loss: 1.349 | Acc: 51.329% (13321/25952)\n",
      "Epoch 9 Step 811/1563 Loss: 1.349 | Acc: 51.332% (13338/25984)\n",
      "Epoch 9 Step 812/1563 Loss: 1.349 | Acc: 51.334% (13355/26016)\n",
      "Epoch 9 Step 813/1563 Loss: 1.349 | Acc: 51.317% (13367/26048)\n",
      "Epoch 9 Step 814/1563 Loss: 1.350 | Acc: 51.300% (13379/26080)\n",
      "Epoch 9 Step 815/1563 Loss: 1.350 | Acc: 51.306% (13397/26112)\n",
      "Epoch 9 Step 816/1563 Loss: 1.349 | Acc: 51.327% (13419/26144)\n",
      "Epoch 9 Step 817/1563 Loss: 1.349 | Acc: 51.341% (13439/26176)\n",
      "Epoch 9 Step 818/1563 Loss: 1.349 | Acc: 51.339% (13455/26208)\n",
      "Epoch 9 Step 819/1563 Loss: 1.349 | Acc: 51.341% (13472/26240)\n",
      "Epoch 9 Step 820/1563 Loss: 1.349 | Acc: 51.344% (13489/26272)\n",
      "Epoch 9 Step 821/1563 Loss: 1.349 | Acc: 51.346% (13506/26304)\n",
      "Epoch 9 Step 822/1563 Loss: 1.349 | Acc: 51.348% (13523/26336)\n",
      "Epoch 9 Step 823/1563 Loss: 1.349 | Acc: 51.350% (13540/26368)\n",
      "Epoch 9 Step 824/1563 Loss: 1.350 | Acc: 51.348% (13556/26400)\n",
      "Epoch 9 Step 825/1563 Loss: 1.350 | Acc: 51.339% (13570/26432)\n",
      "Epoch 9 Step 826/1563 Loss: 1.350 | Acc: 51.341% (13587/26464)\n",
      "Epoch 9 Step 827/1563 Loss: 1.349 | Acc: 51.347% (13605/26496)\n",
      "Epoch 9 Step 828/1563 Loss: 1.350 | Acc: 51.342% (13620/26528)\n",
      "Epoch 9 Step 829/1563 Loss: 1.350 | Acc: 51.337% (13635/26560)\n",
      "Epoch 9 Step 830/1563 Loss: 1.349 | Acc: 51.339% (13652/26592)\n",
      "Epoch 9 Step 831/1563 Loss: 1.350 | Acc: 51.333% (13667/26624)\n",
      "Epoch 9 Step 832/1563 Loss: 1.350 | Acc: 51.313% (13678/26656)\n",
      "Epoch 9 Step 833/1563 Loss: 1.350 | Acc: 51.304% (13692/26688)\n",
      "Epoch 9 Step 834/1563 Loss: 1.350 | Acc: 51.310% (13710/26720)\n",
      "Epoch 9 Step 835/1563 Loss: 1.350 | Acc: 51.301% (13724/26752)\n",
      "Epoch 9 Step 836/1563 Loss: 1.350 | Acc: 51.299% (13740/26784)\n",
      "Epoch 9 Step 837/1563 Loss: 1.350 | Acc: 51.287% (13753/26816)\n",
      "Epoch 9 Step 838/1563 Loss: 1.350 | Acc: 51.300% (13773/26848)\n",
      "Epoch 9 Step 839/1563 Loss: 1.350 | Acc: 51.283% (13785/26880)\n",
      "Epoch 9 Step 840/1563 Loss: 1.350 | Acc: 51.271% (13798/26912)\n",
      "Epoch 9 Step 841/1563 Loss: 1.350 | Acc: 51.277% (13816/26944)\n",
      "Epoch 9 Step 842/1563 Loss: 1.350 | Acc: 51.275% (13832/26976)\n",
      "Epoch 9 Step 843/1563 Loss: 1.351 | Acc: 51.251% (13842/27008)\n",
      "Epoch 9 Step 844/1563 Loss: 1.351 | Acc: 51.250% (13858/27040)\n",
      "Epoch 9 Step 845/1563 Loss: 1.351 | Acc: 51.249% (13874/27072)\n",
      "Epoch 9 Step 846/1563 Loss: 1.351 | Acc: 51.258% (13893/27104)\n",
      "Epoch 9 Step 847/1563 Loss: 1.351 | Acc: 51.260% (13910/27136)\n",
      "Epoch 9 Step 848/1563 Loss: 1.351 | Acc: 51.266% (13928/27168)\n",
      "Epoch 9 Step 849/1563 Loss: 1.351 | Acc: 51.257% (13942/27200)\n",
      "Epoch 9 Step 850/1563 Loss: 1.351 | Acc: 51.267% (13961/27232)\n",
      "Epoch 9 Step 851/1563 Loss: 1.351 | Acc: 51.254% (13974/27264)\n",
      "Epoch 9 Step 852/1563 Loss: 1.351 | Acc: 51.246% (13988/27296)\n",
      "Epoch 9 Step 853/1563 Loss: 1.351 | Acc: 51.259% (14008/27328)\n",
      "Epoch 9 Step 854/1563 Loss: 1.351 | Acc: 51.268% (14027/27360)\n",
      "Epoch 9 Step 855/1563 Loss: 1.351 | Acc: 51.274% (14045/27392)\n",
      "Epoch 9 Step 856/1563 Loss: 1.350 | Acc: 51.284% (14064/27424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 857/1563 Loss: 1.351 | Acc: 51.286% (14081/27456)\n",
      "Epoch 9 Step 858/1563 Loss: 1.351 | Acc: 51.281% (14096/27488)\n",
      "Epoch 9 Step 859/1563 Loss: 1.351 | Acc: 51.268% (14109/27520)\n",
      "Epoch 9 Step 860/1563 Loss: 1.351 | Acc: 51.263% (14124/27552)\n",
      "Epoch 9 Step 861/1563 Loss: 1.351 | Acc: 51.254% (14138/27584)\n",
      "Epoch 9 Step 862/1563 Loss: 1.352 | Acc: 51.257% (14155/27616)\n",
      "Epoch 9 Step 863/1563 Loss: 1.351 | Acc: 51.266% (14174/27648)\n",
      "Epoch 9 Step 864/1563 Loss: 1.351 | Acc: 51.275% (14193/27680)\n",
      "Epoch 9 Step 865/1563 Loss: 1.351 | Acc: 51.256% (14204/27712)\n",
      "Epoch 9 Step 866/1563 Loss: 1.351 | Acc: 51.276% (14226/27744)\n",
      "Epoch 9 Step 867/1563 Loss: 1.351 | Acc: 51.271% (14241/27776)\n",
      "Epoch 9 Step 868/1563 Loss: 1.351 | Acc: 51.273% (14258/27808)\n",
      "Epoch 9 Step 869/1563 Loss: 1.351 | Acc: 51.286% (14278/27840)\n",
      "Epoch 9 Step 870/1563 Loss: 1.351 | Acc: 51.274% (14291/27872)\n",
      "Epoch 9 Step 871/1563 Loss: 1.351 | Acc: 51.261% (14304/27904)\n",
      "Epoch 9 Step 872/1563 Loss: 1.351 | Acc: 51.260% (14320/27936)\n",
      "Epoch 9 Step 873/1563 Loss: 1.351 | Acc: 51.273% (14340/27968)\n",
      "Epoch 9 Step 874/1563 Loss: 1.351 | Acc: 51.279% (14358/28000)\n",
      "Epoch 9 Step 875/1563 Loss: 1.351 | Acc: 51.288% (14377/28032)\n",
      "Epoch 9 Step 876/1563 Loss: 1.351 | Acc: 51.279% (14391/28064)\n",
      "Epoch 9 Step 877/1563 Loss: 1.351 | Acc: 51.278% (14407/28096)\n",
      "Epoch 9 Step 878/1563 Loss: 1.351 | Acc: 51.273% (14422/28128)\n",
      "Epoch 9 Step 879/1563 Loss: 1.351 | Acc: 51.278% (14440/28160)\n",
      "Epoch 9 Step 880/1563 Loss: 1.352 | Acc: 51.273% (14455/28192)\n",
      "Epoch 9 Step 881/1563 Loss: 1.351 | Acc: 51.276% (14472/28224)\n",
      "Epoch 9 Step 882/1563 Loss: 1.352 | Acc: 51.278% (14489/28256)\n",
      "Epoch 9 Step 883/1563 Loss: 1.352 | Acc: 51.283% (14507/28288)\n",
      "Epoch 9 Step 884/1563 Loss: 1.352 | Acc: 51.296% (14527/28320)\n",
      "Epoch 9 Step 885/1563 Loss: 1.352 | Acc: 51.301% (14545/28352)\n",
      "Epoch 9 Step 886/1563 Loss: 1.352 | Acc: 51.297% (14560/28384)\n",
      "Epoch 9 Step 887/1563 Loss: 1.351 | Acc: 51.302% (14578/28416)\n",
      "Epoch 9 Step 888/1563 Loss: 1.352 | Acc: 51.304% (14595/28448)\n",
      "Epoch 9 Step 889/1563 Loss: 1.352 | Acc: 51.299% (14610/28480)\n",
      "Epoch 9 Step 890/1563 Loss: 1.352 | Acc: 51.312% (14630/28512)\n",
      "Epoch 9 Step 891/1563 Loss: 1.352 | Acc: 51.310% (14646/28544)\n",
      "Epoch 9 Step 892/1563 Loss: 1.352 | Acc: 51.295% (14658/28576)\n",
      "Epoch 9 Step 893/1563 Loss: 1.352 | Acc: 51.269% (14667/28608)\n",
      "Epoch 9 Step 894/1563 Loss: 1.352 | Acc: 51.274% (14685/28640)\n",
      "Epoch 9 Step 895/1563 Loss: 1.352 | Acc: 51.280% (14703/28672)\n",
      "Epoch 9 Step 896/1563 Loss: 1.352 | Acc: 51.299% (14725/28704)\n",
      "Epoch 9 Step 897/1563 Loss: 1.352 | Acc: 51.302% (14742/28736)\n",
      "Epoch 9 Step 898/1563 Loss: 1.352 | Acc: 51.307% (14760/28768)\n",
      "Epoch 9 Step 899/1563 Loss: 1.352 | Acc: 51.302% (14775/28800)\n",
      "Epoch 9 Step 900/1563 Loss: 1.352 | Acc: 51.304% (14792/28832)\n",
      "Epoch 9 Step 901/1563 Loss: 1.353 | Acc: 51.289% (14804/28864)\n",
      "Epoch 9 Step 902/1563 Loss: 1.352 | Acc: 51.305% (14825/28896)\n",
      "Epoch 9 Step 903/1563 Loss: 1.352 | Acc: 51.310% (14843/28928)\n",
      "Epoch 9 Step 904/1563 Loss: 1.352 | Acc: 51.305% (14858/28960)\n",
      "Epoch 9 Step 905/1563 Loss: 1.352 | Acc: 51.300% (14873/28992)\n",
      "Epoch 9 Step 906/1563 Loss: 1.352 | Acc: 51.302% (14890/29024)\n",
      "Epoch 9 Step 907/1563 Loss: 1.352 | Acc: 51.322% (14912/29056)\n",
      "Epoch 9 Step 908/1563 Loss: 1.352 | Acc: 51.324% (14929/29088)\n",
      "Epoch 9 Step 909/1563 Loss: 1.352 | Acc: 51.312% (14942/29120)\n",
      "Epoch 9 Step 910/1563 Loss: 1.352 | Acc: 51.317% (14960/29152)\n",
      "Epoch 9 Step 911/1563 Loss: 1.352 | Acc: 51.326% (14979/29184)\n",
      "Epoch 9 Step 912/1563 Loss: 1.352 | Acc: 51.328% (14996/29216)\n",
      "Epoch 9 Step 913/1563 Loss: 1.352 | Acc: 51.340% (15016/29248)\n",
      "Epoch 9 Step 914/1563 Loss: 1.352 | Acc: 51.342% (15033/29280)\n",
      "Epoch 9 Step 915/1563 Loss: 1.352 | Acc: 51.354% (15053/29312)\n",
      "Epoch 9 Step 916/1563 Loss: 1.352 | Acc: 51.343% (15066/29344)\n",
      "Epoch 9 Step 917/1563 Loss: 1.352 | Acc: 51.345% (15083/29376)\n",
      "Epoch 9 Step 918/1563 Loss: 1.352 | Acc: 51.350% (15101/29408)\n",
      "Epoch 9 Step 919/1563 Loss: 1.351 | Acc: 51.359% (15120/29440)\n",
      "Epoch 9 Step 920/1563 Loss: 1.351 | Acc: 51.361% (15137/29472)\n",
      "Epoch 9 Step 921/1563 Loss: 1.352 | Acc: 51.363% (15154/29504)\n",
      "Epoch 9 Step 922/1563 Loss: 1.351 | Acc: 51.375% (15174/29536)\n",
      "Epoch 9 Step 923/1563 Loss: 1.351 | Acc: 51.373% (15190/29568)\n",
      "Epoch 9 Step 924/1563 Loss: 1.351 | Acc: 51.378% (15208/29600)\n",
      "Epoch 9 Step 925/1563 Loss: 1.351 | Acc: 51.401% (15231/29632)\n",
      "Epoch 9 Step 926/1563 Loss: 1.351 | Acc: 51.409% (15250/29664)\n",
      "Epoch 9 Step 927/1563 Loss: 1.351 | Acc: 51.408% (15266/29696)\n",
      "Epoch 9 Step 928/1563 Loss: 1.351 | Acc: 51.413% (15284/29728)\n",
      "Epoch 9 Step 929/1563 Loss: 1.351 | Acc: 51.398% (15296/29760)\n",
      "Epoch 9 Step 930/1563 Loss: 1.350 | Acc: 51.406% (15315/29792)\n",
      "Epoch 9 Step 931/1563 Loss: 1.350 | Acc: 51.402% (15330/29824)\n",
      "Epoch 9 Step 932/1563 Loss: 1.350 | Acc: 51.403% (15347/29856)\n",
      "Epoch 9 Step 933/1563 Loss: 1.351 | Acc: 51.395% (15361/29888)\n",
      "Epoch 9 Step 934/1563 Loss: 1.351 | Acc: 51.397% (15378/29920)\n",
      "Epoch 9 Step 935/1563 Loss: 1.351 | Acc: 51.396% (15394/29952)\n",
      "Epoch 9 Step 936/1563 Loss: 1.351 | Acc: 51.391% (15409/29984)\n",
      "Epoch 9 Step 937/1563 Loss: 1.351 | Acc: 51.383% (15423/30016)\n",
      "Epoch 9 Step 938/1563 Loss: 1.351 | Acc: 51.378% (15438/30048)\n",
      "Epoch 9 Step 939/1563 Loss: 1.351 | Acc: 51.396% (15460/30080)\n",
      "Epoch 9 Step 940/1563 Loss: 1.351 | Acc: 51.388% (15474/30112)\n",
      "Epoch 9 Step 941/1563 Loss: 1.350 | Acc: 51.403% (15495/30144)\n",
      "Epoch 9 Step 942/1563 Loss: 1.351 | Acc: 51.402% (15511/30176)\n",
      "Epoch 9 Step 943/1563 Loss: 1.351 | Acc: 51.397% (15526/30208)\n",
      "Epoch 9 Step 944/1563 Loss: 1.351 | Acc: 51.412% (15547/30240)\n",
      "Epoch 9 Step 945/1563 Loss: 1.351 | Acc: 51.411% (15563/30272)\n",
      "Epoch 9 Step 946/1563 Loss: 1.350 | Acc: 51.426% (15584/30304)\n",
      "Epoch 9 Step 947/1563 Loss: 1.350 | Acc: 51.431% (15602/30336)\n",
      "Epoch 9 Step 948/1563 Loss: 1.350 | Acc: 51.442% (15622/30368)\n",
      "Epoch 9 Step 949/1563 Loss: 1.350 | Acc: 51.447% (15640/30400)\n",
      "Epoch 9 Step 950/1563 Loss: 1.350 | Acc: 51.446% (15656/30432)\n",
      "Epoch 9 Step 951/1563 Loss: 1.350 | Acc: 51.461% (15677/30464)\n",
      "Epoch 9 Step 952/1563 Loss: 1.350 | Acc: 51.472% (15697/30496)\n",
      "Epoch 9 Step 953/1563 Loss: 1.350 | Acc: 51.461% (15710/30528)\n",
      "Epoch 9 Step 954/1563 Loss: 1.350 | Acc: 51.469% (15729/30560)\n",
      "Epoch 9 Step 955/1563 Loss: 1.350 | Acc: 51.461% (15743/30592)\n",
      "Epoch 9 Step 956/1563 Loss: 1.350 | Acc: 51.453% (15757/30624)\n",
      "Epoch 9 Step 957/1563 Loss: 1.351 | Acc: 51.445% (15771/30656)\n",
      "Epoch 9 Step 958/1563 Loss: 1.351 | Acc: 51.434% (15784/30688)\n",
      "Epoch 9 Step 959/1563 Loss: 1.350 | Acc: 51.445% (15804/30720)\n",
      "Epoch 9 Step 960/1563 Loss: 1.350 | Acc: 51.444% (15820/30752)\n",
      "Epoch 9 Step 961/1563 Loss: 1.350 | Acc: 51.449% (15838/30784)\n",
      "Epoch 9 Step 962/1563 Loss: 1.350 | Acc: 51.431% (15849/30816)\n",
      "Epoch 9 Step 963/1563 Loss: 1.351 | Acc: 51.426% (15864/30848)\n",
      "Epoch 9 Step 964/1563 Loss: 1.350 | Acc: 51.441% (15885/30880)\n",
      "Epoch 9 Step 965/1563 Loss: 1.350 | Acc: 51.440% (15901/30912)\n",
      "Epoch 9 Step 966/1563 Loss: 1.350 | Acc: 51.441% (15918/30944)\n",
      "Epoch 9 Step 967/1563 Loss: 1.350 | Acc: 51.437% (15933/30976)\n",
      "Epoch 9 Step 968/1563 Loss: 1.350 | Acc: 51.445% (15952/31008)\n",
      "Epoch 9 Step 969/1563 Loss: 1.350 | Acc: 51.459% (15973/31040)\n",
      "Epoch 9 Step 970/1563 Loss: 1.350 | Acc: 51.458% (15989/31072)\n",
      "Epoch 9 Step 971/1563 Loss: 1.350 | Acc: 51.476% (16011/31104)\n",
      "Epoch 9 Step 972/1563 Loss: 1.350 | Acc: 51.474% (16027/31136)\n",
      "Epoch 9 Step 973/1563 Loss: 1.350 | Acc: 51.479% (16045/31168)\n",
      "Epoch 9 Step 974/1563 Loss: 1.350 | Acc: 51.478% (16061/31200)\n",
      "Epoch 9 Step 975/1563 Loss: 1.350 | Acc: 51.479% (16078/31232)\n",
      "Epoch 9 Step 976/1563 Loss: 1.350 | Acc: 51.468% (16091/31264)\n",
      "Epoch 9 Step 977/1563 Loss: 1.350 | Acc: 51.460% (16105/31296)\n",
      "Epoch 9 Step 978/1563 Loss: 1.350 | Acc: 51.481% (16128/31328)\n",
      "Epoch 9 Step 979/1563 Loss: 1.350 | Acc: 51.480% (16144/31360)\n",
      "Epoch 9 Step 980/1563 Loss: 1.350 | Acc: 51.488% (16163/31392)\n",
      "Epoch 9 Step 981/1563 Loss: 1.350 | Acc: 51.483% (16178/31424)\n",
      "Epoch 9 Step 982/1563 Loss: 1.350 | Acc: 51.478% (16193/31456)\n",
      "Epoch 9 Step 983/1563 Loss: 1.350 | Acc: 51.480% (16210/31488)\n",
      "Epoch 9 Step 984/1563 Loss: 1.350 | Acc: 51.469% (16223/31520)\n",
      "Epoch 9 Step 985/1563 Loss: 1.350 | Acc: 51.461% (16237/31552)\n",
      "Epoch 9 Step 986/1563 Loss: 1.350 | Acc: 51.453% (16251/31584)\n",
      "Epoch 9 Step 987/1563 Loss: 1.350 | Acc: 51.439% (16263/31616)\n",
      "Epoch 9 Step 988/1563 Loss: 1.350 | Acc: 51.463% (16287/31648)\n",
      "Epoch 9 Step 989/1563 Loss: 1.350 | Acc: 51.461% (16303/31680)\n",
      "Epoch 9 Step 990/1563 Loss: 1.350 | Acc: 51.457% (16318/31712)\n",
      "Epoch 9 Step 991/1563 Loss: 1.350 | Acc: 51.455% (16334/31744)\n",
      "Epoch 9 Step 992/1563 Loss: 1.350 | Acc: 51.444% (16347/31776)\n",
      "Epoch 9 Step 993/1563 Loss: 1.350 | Acc: 51.440% (16362/31808)\n",
      "Epoch 9 Step 994/1563 Loss: 1.351 | Acc: 51.416% (16371/31840)\n",
      "Epoch 9 Step 995/1563 Loss: 1.351 | Acc: 51.409% (16385/31872)\n",
      "Epoch 9 Step 996/1563 Loss: 1.351 | Acc: 51.404% (16400/31904)\n",
      "Epoch 9 Step 997/1563 Loss: 1.351 | Acc: 51.390% (16412/31936)\n",
      "Epoch 9 Step 998/1563 Loss: 1.352 | Acc: 51.380% (16425/31968)\n",
      "Epoch 9 Step 999/1563 Loss: 1.352 | Acc: 51.384% (16443/32000)\n",
      "Epoch 9 Step 1000/1563 Loss: 1.352 | Acc: 51.395% (16463/32032)\n",
      "Epoch 9 Step 1001/1563 Loss: 1.351 | Acc: 51.403% (16482/32064)\n",
      "Epoch 9 Step 1002/1563 Loss: 1.351 | Acc: 51.424% (16505/32096)\n",
      "Epoch 9 Step 1003/1563 Loss: 1.351 | Acc: 51.435% (16525/32128)\n",
      "Epoch 9 Step 1004/1563 Loss: 1.351 | Acc: 51.437% (16542/32160)\n",
      "Epoch 9 Step 1005/1563 Loss: 1.351 | Acc: 51.441% (16560/32192)\n",
      "Epoch 9 Step 1006/1563 Loss: 1.351 | Acc: 51.437% (16575/32224)\n",
      "Epoch 9 Step 1007/1563 Loss: 1.351 | Acc: 51.451% (16596/32256)\n",
      "Epoch 9 Step 1008/1563 Loss: 1.350 | Acc: 51.453% (16613/32288)\n",
      "Epoch 9 Step 1009/1563 Loss: 1.350 | Acc: 51.451% (16629/32320)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 1010/1563 Loss: 1.350 | Acc: 51.447% (16644/32352)\n",
      "Epoch 9 Step 1011/1563 Loss: 1.350 | Acc: 51.445% (16660/32384)\n",
      "Epoch 9 Step 1012/1563 Loss: 1.350 | Acc: 51.450% (16678/32416)\n",
      "Epoch 9 Step 1013/1563 Loss: 1.350 | Acc: 51.445% (16693/32448)\n",
      "Epoch 9 Step 1014/1563 Loss: 1.350 | Acc: 51.459% (16714/32480)\n",
      "Epoch 9 Step 1015/1563 Loss: 1.350 | Acc: 51.449% (16727/32512)\n",
      "Epoch 9 Step 1016/1563 Loss: 1.350 | Acc: 51.450% (16744/32544)\n",
      "Epoch 9 Step 1017/1563 Loss: 1.351 | Acc: 51.437% (16756/32576)\n",
      "Epoch 9 Step 1018/1563 Loss: 1.351 | Acc: 51.420% (16767/32608)\n",
      "Epoch 9 Step 1019/1563 Loss: 1.351 | Acc: 51.412% (16781/32640)\n",
      "Epoch 9 Step 1020/1563 Loss: 1.351 | Acc: 51.405% (16795/32672)\n",
      "Epoch 9 Step 1021/1563 Loss: 1.351 | Acc: 51.413% (16814/32704)\n",
      "Epoch 9 Step 1022/1563 Loss: 1.351 | Acc: 51.399% (16826/32736)\n",
      "Epoch 9 Step 1023/1563 Loss: 1.351 | Acc: 51.395% (16841/32768)\n",
      "Epoch 9 Step 1024/1563 Loss: 1.351 | Acc: 51.405% (16861/32800)\n",
      "Epoch 9 Step 1025/1563 Loss: 1.351 | Acc: 51.404% (16877/32832)\n",
      "Epoch 9 Step 1026/1563 Loss: 1.351 | Acc: 51.397% (16891/32864)\n",
      "Epoch 9 Step 1027/1563 Loss: 1.351 | Acc: 51.395% (16907/32896)\n",
      "Epoch 9 Step 1028/1563 Loss: 1.351 | Acc: 51.388% (16921/32928)\n",
      "Epoch 9 Step 1029/1563 Loss: 1.351 | Acc: 51.387% (16937/32960)\n",
      "Epoch 9 Step 1030/1563 Loss: 1.351 | Acc: 51.379% (16951/32992)\n",
      "Epoch 9 Step 1031/1563 Loss: 1.351 | Acc: 51.393% (16972/33024)\n",
      "Epoch 9 Step 1032/1563 Loss: 1.351 | Acc: 51.392% (16988/33056)\n",
      "Epoch 9 Step 1033/1563 Loss: 1.350 | Acc: 51.402% (17008/33088)\n",
      "Epoch 9 Step 1034/1563 Loss: 1.350 | Acc: 51.413% (17028/33120)\n",
      "Epoch 9 Step 1035/1563 Loss: 1.351 | Acc: 51.406% (17042/33152)\n",
      "Epoch 9 Step 1036/1563 Loss: 1.351 | Acc: 51.413% (17061/33184)\n",
      "Epoch 9 Step 1037/1563 Loss: 1.350 | Acc: 51.409% (17076/33216)\n",
      "Epoch 9 Step 1038/1563 Loss: 1.351 | Acc: 51.399% (17089/33248)\n",
      "Epoch 9 Step 1039/1563 Loss: 1.351 | Acc: 51.400% (17106/33280)\n",
      "Epoch 9 Step 1040/1563 Loss: 1.350 | Acc: 51.411% (17126/33312)\n",
      "Epoch 9 Step 1041/1563 Loss: 1.350 | Acc: 51.407% (17141/33344)\n",
      "Epoch 9 Step 1042/1563 Loss: 1.350 | Acc: 51.396% (17154/33376)\n",
      "Epoch 9 Step 1043/1563 Loss: 1.350 | Acc: 51.398% (17171/33408)\n",
      "Epoch 9 Step 1044/1563 Loss: 1.350 | Acc: 51.417% (17194/33440)\n",
      "Epoch 9 Step 1045/1563 Loss: 1.350 | Acc: 51.425% (17213/33472)\n",
      "Epoch 9 Step 1046/1563 Loss: 1.350 | Acc: 51.436% (17233/33504)\n",
      "Epoch 9 Step 1047/1563 Loss: 1.350 | Acc: 51.440% (17251/33536)\n",
      "Epoch 9 Step 1048/1563 Loss: 1.350 | Acc: 51.439% (17267/33568)\n",
      "Epoch 9 Step 1049/1563 Loss: 1.350 | Acc: 51.449% (17287/33600)\n",
      "Epoch 9 Step 1050/1563 Loss: 1.350 | Acc: 51.448% (17303/33632)\n",
      "Epoch 9 Step 1051/1563 Loss: 1.350 | Acc: 51.450% (17320/33664)\n",
      "Epoch 9 Step 1052/1563 Loss: 1.350 | Acc: 51.445% (17335/33696)\n",
      "Epoch 9 Step 1053/1563 Loss: 1.349 | Acc: 51.450% (17353/33728)\n",
      "Epoch 9 Step 1054/1563 Loss: 1.349 | Acc: 51.440% (17366/33760)\n",
      "Epoch 9 Step 1055/1563 Loss: 1.349 | Acc: 51.441% (17383/33792)\n",
      "Epoch 9 Step 1056/1563 Loss: 1.349 | Acc: 51.446% (17401/33824)\n",
      "Epoch 9 Step 1057/1563 Loss: 1.349 | Acc: 51.441% (17416/33856)\n",
      "Epoch 9 Step 1058/1563 Loss: 1.350 | Acc: 51.437% (17431/33888)\n",
      "Epoch 9 Step 1059/1563 Loss: 1.349 | Acc: 51.439% (17448/33920)\n",
      "Epoch 9 Step 1060/1563 Loss: 1.349 | Acc: 51.440% (17465/33952)\n",
      "Epoch 9 Step 1061/1563 Loss: 1.349 | Acc: 51.454% (17486/33984)\n",
      "Epoch 9 Step 1062/1563 Loss: 1.349 | Acc: 51.452% (17502/34016)\n",
      "Epoch 9 Step 1063/1563 Loss: 1.349 | Acc: 51.445% (17516/34048)\n",
      "Epoch 9 Step 1064/1563 Loss: 1.349 | Acc: 51.444% (17532/34080)\n",
      "Epoch 9 Step 1065/1563 Loss: 1.349 | Acc: 51.442% (17548/34112)\n",
      "Epoch 9 Step 1066/1563 Loss: 1.350 | Acc: 51.444% (17565/34144)\n",
      "Epoch 9 Step 1067/1563 Loss: 1.349 | Acc: 51.437% (17579/34176)\n",
      "Epoch 9 Step 1068/1563 Loss: 1.349 | Acc: 51.444% (17598/34208)\n",
      "Epoch 9 Step 1069/1563 Loss: 1.349 | Acc: 51.440% (17613/34240)\n",
      "Epoch 9 Step 1070/1563 Loss: 1.349 | Acc: 51.441% (17630/34272)\n",
      "Epoch 9 Step 1071/1563 Loss: 1.349 | Acc: 51.428% (17642/34304)\n",
      "Epoch 9 Step 1072/1563 Loss: 1.349 | Acc: 51.442% (17663/34336)\n",
      "Epoch 9 Step 1073/1563 Loss: 1.349 | Acc: 51.432% (17676/34368)\n",
      "Epoch 9 Step 1074/1563 Loss: 1.349 | Acc: 51.436% (17694/34400)\n",
      "Epoch 9 Step 1075/1563 Loss: 1.349 | Acc: 51.435% (17710/34432)\n",
      "Epoch 9 Step 1076/1563 Loss: 1.349 | Acc: 51.436% (17727/34464)\n",
      "Epoch 9 Step 1077/1563 Loss: 1.349 | Acc: 51.441% (17745/34496)\n",
      "Epoch 9 Step 1078/1563 Loss: 1.349 | Acc: 51.463% (17769/34528)\n",
      "Epoch 9 Step 1079/1563 Loss: 1.349 | Acc: 51.470% (17788/34560)\n",
      "Epoch 9 Step 1080/1563 Loss: 1.349 | Acc: 51.469% (17804/34592)\n",
      "Epoch 9 Step 1081/1563 Loss: 1.348 | Acc: 51.470% (17821/34624)\n",
      "Epoch 9 Step 1082/1563 Loss: 1.349 | Acc: 51.457% (17833/34656)\n",
      "Epoch 9 Step 1083/1563 Loss: 1.349 | Acc: 51.459% (17850/34688)\n",
      "Epoch 9 Step 1084/1563 Loss: 1.349 | Acc: 51.466% (17869/34720)\n",
      "Epoch 9 Step 1085/1563 Loss: 1.349 | Acc: 51.465% (17885/34752)\n",
      "Epoch 9 Step 1086/1563 Loss: 1.349 | Acc: 51.460% (17900/34784)\n",
      "Epoch 9 Step 1087/1563 Loss: 1.349 | Acc: 51.459% (17916/34816)\n",
      "Epoch 9 Step 1088/1563 Loss: 1.349 | Acc: 51.452% (17930/34848)\n",
      "Epoch 9 Step 1089/1563 Loss: 1.349 | Acc: 51.448% (17945/34880)\n",
      "Epoch 9 Step 1090/1563 Loss: 1.349 | Acc: 51.438% (17958/34912)\n",
      "Epoch 9 Step 1091/1563 Loss: 1.349 | Acc: 51.439% (17975/34944)\n",
      "Epoch 9 Step 1092/1563 Loss: 1.349 | Acc: 51.444% (17993/34976)\n",
      "Epoch 9 Step 1093/1563 Loss: 1.349 | Acc: 51.437% (18007/35008)\n",
      "Epoch 9 Step 1094/1563 Loss: 1.349 | Acc: 51.438% (18024/35040)\n",
      "Epoch 9 Step 1095/1563 Loss: 1.349 | Acc: 51.431% (18038/35072)\n",
      "Epoch 9 Step 1096/1563 Loss: 1.349 | Acc: 51.424% (18052/35104)\n",
      "Epoch 9 Step 1097/1563 Loss: 1.348 | Acc: 51.437% (18073/35136)\n",
      "Epoch 9 Step 1098/1563 Loss: 1.348 | Acc: 51.430% (18087/35168)\n",
      "Epoch 9 Step 1099/1563 Loss: 1.348 | Acc: 51.426% (18102/35200)\n",
      "Epoch 9 Step 1100/1563 Loss: 1.348 | Acc: 51.422% (18117/35232)\n",
      "Epoch 9 Step 1101/1563 Loss: 1.349 | Acc: 51.412% (18130/35264)\n",
      "Epoch 9 Step 1102/1563 Loss: 1.349 | Acc: 51.414% (18147/35296)\n",
      "Epoch 9 Step 1103/1563 Loss: 1.349 | Acc: 51.412% (18163/35328)\n",
      "Epoch 9 Step 1104/1563 Loss: 1.349 | Acc: 51.408% (18178/35360)\n",
      "Epoch 9 Step 1105/1563 Loss: 1.349 | Acc: 51.410% (18195/35392)\n",
      "Epoch 9 Step 1106/1563 Loss: 1.349 | Acc: 51.406% (18210/35424)\n",
      "Epoch 9 Step 1107/1563 Loss: 1.349 | Acc: 51.413% (18229/35456)\n",
      "Epoch 9 Step 1108/1563 Loss: 1.349 | Acc: 51.412% (18245/35488)\n",
      "Epoch 9 Step 1109/1563 Loss: 1.349 | Acc: 51.410% (18261/35520)\n",
      "Epoch 9 Step 1110/1563 Loss: 1.349 | Acc: 51.418% (18280/35552)\n",
      "Epoch 9 Step 1111/1563 Loss: 1.349 | Acc: 51.428% (18300/35584)\n",
      "Epoch 9 Step 1112/1563 Loss: 1.349 | Acc: 51.424% (18315/35616)\n",
      "Epoch 9 Step 1113/1563 Loss: 1.348 | Acc: 51.428% (18333/35648)\n",
      "Epoch 9 Step 1114/1563 Loss: 1.349 | Acc: 51.415% (18345/35680)\n",
      "Epoch 9 Step 1115/1563 Loss: 1.349 | Acc: 51.414% (18361/35712)\n",
      "Epoch 9 Step 1116/1563 Loss: 1.349 | Acc: 51.413% (18377/35744)\n",
      "Epoch 9 Step 1117/1563 Loss: 1.349 | Acc: 51.420% (18396/35776)\n",
      "Epoch 9 Step 1118/1563 Loss: 1.349 | Acc: 51.424% (18414/35808)\n",
      "Epoch 9 Step 1119/1563 Loss: 1.349 | Acc: 51.409% (18425/35840)\n",
      "Epoch 9 Step 1120/1563 Loss: 1.349 | Acc: 51.402% (18439/35872)\n",
      "Epoch 9 Step 1121/1563 Loss: 1.349 | Acc: 51.401% (18455/35904)\n",
      "Epoch 9 Step 1122/1563 Loss: 1.349 | Acc: 51.394% (18469/35936)\n",
      "Epoch 9 Step 1123/1563 Loss: 1.349 | Acc: 51.398% (18487/35968)\n",
      "Epoch 9 Step 1124/1563 Loss: 1.349 | Acc: 51.392% (18501/36000)\n",
      "Epoch 9 Step 1125/1563 Loss: 1.349 | Acc: 51.399% (18520/36032)\n",
      "Epoch 9 Step 1126/1563 Loss: 1.349 | Acc: 51.403% (18538/36064)\n",
      "Epoch 9 Step 1127/1563 Loss: 1.349 | Acc: 51.410% (18557/36096)\n",
      "Epoch 9 Step 1128/1563 Loss: 1.349 | Acc: 51.412% (18574/36128)\n",
      "Epoch 9 Step 1129/1563 Loss: 1.349 | Acc: 51.405% (18588/36160)\n",
      "Epoch 9 Step 1130/1563 Loss: 1.349 | Acc: 51.395% (18601/36192)\n",
      "Epoch 9 Step 1131/1563 Loss: 1.349 | Acc: 51.413% (18624/36224)\n",
      "Epoch 9 Step 1132/1563 Loss: 1.349 | Acc: 51.426% (18645/36256)\n",
      "Epoch 9 Step 1133/1563 Loss: 1.348 | Acc: 51.430% (18663/36288)\n",
      "Epoch 9 Step 1134/1563 Loss: 1.349 | Acc: 51.432% (18680/36320)\n",
      "Epoch 9 Step 1135/1563 Loss: 1.349 | Acc: 51.436% (18698/36352)\n",
      "Epoch 9 Step 1136/1563 Loss: 1.349 | Acc: 51.443% (18717/36384)\n",
      "Epoch 9 Step 1137/1563 Loss: 1.348 | Acc: 51.436% (18731/36416)\n",
      "Epoch 9 Step 1138/1563 Loss: 1.349 | Acc: 51.427% (18744/36448)\n",
      "Epoch 9 Step 1139/1563 Loss: 1.349 | Acc: 51.434% (18763/36480)\n",
      "Epoch 9 Step 1140/1563 Loss: 1.349 | Acc: 51.424% (18776/36512)\n",
      "Epoch 9 Step 1141/1563 Loss: 1.349 | Acc: 51.423% (18792/36544)\n",
      "Epoch 9 Step 1142/1563 Loss: 1.349 | Acc: 51.430% (18811/36576)\n",
      "Epoch 9 Step 1143/1563 Loss: 1.349 | Acc: 51.423% (18825/36608)\n",
      "Epoch 9 Step 1144/1563 Loss: 1.349 | Acc: 51.414% (18838/36640)\n",
      "Epoch 9 Step 1145/1563 Loss: 1.349 | Acc: 51.421% (18857/36672)\n",
      "Epoch 9 Step 1146/1563 Loss: 1.349 | Acc: 51.428% (18876/36704)\n",
      "Epoch 9 Step 1147/1563 Loss: 1.349 | Acc: 51.421% (18890/36736)\n",
      "Epoch 9 Step 1148/1563 Loss: 1.349 | Acc: 51.422% (18907/36768)\n",
      "Epoch 9 Step 1149/1563 Loss: 1.349 | Acc: 51.424% (18924/36800)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 1150/1563 Loss: 1.349 | Acc: 51.434% (18944/36832)\n",
      "Epoch 9 Step 1151/1563 Loss: 1.349 | Acc: 51.438% (18962/36864)\n",
      "Epoch 9 Step 1152/1563 Loss: 1.349 | Acc: 51.434% (18977/36896)\n",
      "Epoch 9 Step 1153/1563 Loss: 1.349 | Acc: 51.427% (18991/36928)\n",
      "Epoch 9 Step 1154/1563 Loss: 1.349 | Acc: 51.434% (19010/36960)\n",
      "Epoch 9 Step 1155/1563 Loss: 1.349 | Acc: 51.419% (19021/36992)\n",
      "Epoch 9 Step 1156/1563 Loss: 1.349 | Acc: 51.415% (19036/37024)\n",
      "Epoch 9 Step 1157/1563 Loss: 1.349 | Acc: 51.425% (19056/37056)\n",
      "Epoch 9 Step 1158/1563 Loss: 1.349 | Acc: 51.429% (19074/37088)\n",
      "Epoch 9 Step 1159/1563 Loss: 1.349 | Acc: 51.428% (19090/37120)\n",
      "Epoch 9 Step 1160/1563 Loss: 1.349 | Acc: 51.440% (19111/37152)\n",
      "Epoch 9 Step 1161/1563 Loss: 1.349 | Acc: 51.431% (19124/37184)\n",
      "Epoch 9 Step 1162/1563 Loss: 1.349 | Acc: 51.435% (19142/37216)\n",
      "Epoch 9 Step 1163/1563 Loss: 1.349 | Acc: 51.436% (19159/37248)\n",
      "Epoch 9 Step 1164/1563 Loss: 1.349 | Acc: 51.443% (19178/37280)\n",
      "Epoch 9 Step 1165/1563 Loss: 1.349 | Acc: 51.447% (19196/37312)\n",
      "Epoch 9 Step 1166/1563 Loss: 1.349 | Acc: 51.441% (19210/37344)\n",
      "Epoch 9 Step 1167/1563 Loss: 1.349 | Acc: 51.437% (19225/37376)\n",
      "Epoch 9 Step 1168/1563 Loss: 1.349 | Acc: 51.444% (19244/37408)\n",
      "Epoch 9 Step 1169/1563 Loss: 1.349 | Acc: 51.437% (19258/37440)\n",
      "Epoch 9 Step 1170/1563 Loss: 1.349 | Acc: 51.438% (19275/37472)\n",
      "Epoch 9 Step 1171/1563 Loss: 1.349 | Acc: 51.440% (19292/37504)\n",
      "Epoch 9 Step 1172/1563 Loss: 1.349 | Acc: 51.441% (19309/37536)\n",
      "Epoch 9 Step 1173/1563 Loss: 1.349 | Acc: 51.435% (19323/37568)\n",
      "Epoch 9 Step 1174/1563 Loss: 1.349 | Acc: 51.428% (19337/37600)\n",
      "Epoch 9 Step 1175/1563 Loss: 1.349 | Acc: 51.432% (19355/37632)\n",
      "Epoch 9 Step 1176/1563 Loss: 1.349 | Acc: 51.444% (19376/37664)\n",
      "Epoch 9 Step 1177/1563 Loss: 1.349 | Acc: 51.438% (19390/37696)\n",
      "Epoch 9 Step 1178/1563 Loss: 1.349 | Acc: 51.426% (19402/37728)\n",
      "Epoch 9 Step 1179/1563 Loss: 1.349 | Acc: 51.427% (19419/37760)\n",
      "Epoch 9 Step 1180/1563 Loss: 1.349 | Acc: 51.424% (19434/37792)\n",
      "Epoch 9 Step 1181/1563 Loss: 1.349 | Acc: 51.422% (19450/37824)\n",
      "Epoch 9 Step 1182/1563 Loss: 1.349 | Acc: 51.416% (19464/37856)\n",
      "Epoch 9 Step 1183/1563 Loss: 1.349 | Acc: 51.423% (19483/37888)\n",
      "Epoch 9 Step 1184/1563 Loss: 1.349 | Acc: 51.416% (19497/37920)\n",
      "Epoch 9 Step 1185/1563 Loss: 1.349 | Acc: 51.412% (19512/37952)\n",
      "Epoch 9 Step 1186/1563 Loss: 1.349 | Acc: 51.411% (19528/37984)\n",
      "Epoch 9 Step 1187/1563 Loss: 1.349 | Acc: 51.407% (19543/38016)\n",
      "Epoch 9 Step 1188/1563 Loss: 1.349 | Acc: 51.409% (19560/38048)\n",
      "Epoch 9 Step 1189/1563 Loss: 1.349 | Acc: 51.408% (19576/38080)\n",
      "Epoch 9 Step 1190/1563 Loss: 1.349 | Acc: 51.414% (19595/38112)\n",
      "Epoch 9 Step 1191/1563 Loss: 1.349 | Acc: 51.403% (19607/38144)\n",
      "Epoch 9 Step 1192/1563 Loss: 1.349 | Acc: 51.412% (19627/38176)\n",
      "Epoch 9 Step 1193/1563 Loss: 1.349 | Acc: 51.419% (19646/38208)\n",
      "Epoch 9 Step 1194/1563 Loss: 1.349 | Acc: 51.410% (19659/38240)\n",
      "Epoch 9 Step 1195/1563 Loss: 1.349 | Acc: 51.411% (19676/38272)\n",
      "Epoch 9 Step 1196/1563 Loss: 1.349 | Acc: 51.418% (19695/38304)\n",
      "Epoch 9 Step 1197/1563 Loss: 1.349 | Acc: 51.429% (19716/38336)\n",
      "Epoch 9 Step 1198/1563 Loss: 1.348 | Acc: 51.431% (19733/38368)\n",
      "Epoch 9 Step 1199/1563 Loss: 1.349 | Acc: 51.427% (19748/38400)\n",
      "Epoch 9 Step 1200/1563 Loss: 1.348 | Acc: 51.423% (19763/38432)\n",
      "Epoch 9 Step 1201/1563 Loss: 1.349 | Acc: 51.412% (19775/38464)\n",
      "Epoch 9 Step 1202/1563 Loss: 1.349 | Acc: 51.421% (19795/38496)\n",
      "Epoch 9 Step 1203/1563 Loss: 1.349 | Acc: 51.417% (19810/38528)\n",
      "Epoch 9 Step 1204/1563 Loss: 1.349 | Acc: 51.416% (19826/38560)\n",
      "Epoch 9 Step 1205/1563 Loss: 1.348 | Acc: 51.420% (19844/38592)\n",
      "Epoch 9 Step 1206/1563 Loss: 1.348 | Acc: 51.414% (19858/38624)\n",
      "Epoch 9 Step 1207/1563 Loss: 1.348 | Acc: 51.415% (19875/38656)\n",
      "Epoch 9 Step 1208/1563 Loss: 1.348 | Acc: 51.416% (19892/38688)\n",
      "Epoch 9 Step 1209/1563 Loss: 1.348 | Acc: 51.423% (19911/38720)\n",
      "Epoch 9 Step 1210/1563 Loss: 1.348 | Acc: 51.435% (19932/38752)\n",
      "Epoch 9 Step 1211/1563 Loss: 1.348 | Acc: 51.431% (19947/38784)\n",
      "Epoch 9 Step 1212/1563 Loss: 1.348 | Acc: 51.440% (19967/38816)\n",
      "Epoch 9 Step 1213/1563 Loss: 1.348 | Acc: 51.439% (19983/38848)\n",
      "Epoch 9 Step 1214/1563 Loss: 1.348 | Acc: 51.440% (20000/38880)\n",
      "Epoch 9 Step 1215/1563 Loss: 1.348 | Acc: 51.442% (20017/38912)\n",
      "Epoch 9 Step 1216/1563 Loss: 1.348 | Acc: 51.435% (20031/38944)\n",
      "Epoch 9 Step 1217/1563 Loss: 1.348 | Acc: 51.434% (20047/38976)\n",
      "Epoch 9 Step 1218/1563 Loss: 1.348 | Acc: 51.438% (20065/39008)\n",
      "Epoch 9 Step 1219/1563 Loss: 1.348 | Acc: 51.452% (20087/39040)\n",
      "Epoch 9 Step 1220/1563 Loss: 1.348 | Acc: 51.461% (20107/39072)\n",
      "Epoch 9 Step 1221/1563 Loss: 1.348 | Acc: 51.453% (20120/39104)\n",
      "Epoch 9 Step 1222/1563 Loss: 1.348 | Acc: 51.446% (20134/39136)\n",
      "Epoch 9 Step 1223/1563 Loss: 1.348 | Acc: 51.448% (20151/39168)\n",
      "Epoch 9 Step 1224/1563 Loss: 1.348 | Acc: 51.431% (20161/39200)\n",
      "Epoch 9 Step 1225/1563 Loss: 1.348 | Acc: 51.448% (20184/39232)\n",
      "Epoch 9 Step 1226/1563 Loss: 1.348 | Acc: 51.454% (20203/39264)\n",
      "Epoch 9 Step 1227/1563 Loss: 1.348 | Acc: 51.458% (20221/39296)\n",
      "Epoch 9 Step 1228/1563 Loss: 1.348 | Acc: 51.454% (20236/39328)\n",
      "Epoch 9 Step 1229/1563 Loss: 1.348 | Acc: 51.456% (20253/39360)\n",
      "Epoch 9 Step 1230/1563 Loss: 1.348 | Acc: 51.465% (20273/39392)\n",
      "Epoch 9 Step 1231/1563 Loss: 1.348 | Acc: 51.474% (20293/39424)\n",
      "Epoch 9 Step 1232/1563 Loss: 1.348 | Acc: 51.473% (20309/39456)\n",
      "Epoch 9 Step 1233/1563 Loss: 1.348 | Acc: 51.469% (20324/39488)\n",
      "Epoch 9 Step 1234/1563 Loss: 1.348 | Acc: 51.465% (20339/39520)\n",
      "Epoch 9 Step 1235/1563 Loss: 1.348 | Acc: 51.466% (20356/39552)\n",
      "Epoch 9 Step 1236/1563 Loss: 1.348 | Acc: 51.465% (20372/39584)\n",
      "Epoch 9 Step 1237/1563 Loss: 1.347 | Acc: 51.472% (20391/39616)\n",
      "Epoch 9 Step 1238/1563 Loss: 1.348 | Acc: 51.463% (20404/39648)\n",
      "Epoch 9 Step 1239/1563 Loss: 1.348 | Acc: 51.469% (20423/39680)\n",
      "Epoch 9 Step 1240/1563 Loss: 1.348 | Acc: 51.468% (20439/39712)\n",
      "Epoch 9 Step 1241/1563 Loss: 1.348 | Acc: 51.462% (20453/39744)\n",
      "Epoch 9 Step 1242/1563 Loss: 1.348 | Acc: 51.466% (20471/39776)\n",
      "Epoch 9 Step 1243/1563 Loss: 1.348 | Acc: 51.470% (20489/39808)\n",
      "Epoch 9 Step 1244/1563 Loss: 1.348 | Acc: 51.473% (20507/39840)\n",
      "Epoch 9 Step 1245/1563 Loss: 1.348 | Acc: 51.470% (20522/39872)\n",
      "Epoch 9 Step 1246/1563 Loss: 1.348 | Acc: 51.476% (20541/39904)\n",
      "Epoch 9 Step 1247/1563 Loss: 1.348 | Acc: 51.465% (20553/39936)\n",
      "Epoch 9 Step 1248/1563 Loss: 1.348 | Acc: 51.459% (20567/39968)\n",
      "Epoch 9 Step 1249/1563 Loss: 1.348 | Acc: 51.465% (20586/40000)\n",
      "Epoch 9 Step 1250/1563 Loss: 1.348 | Acc: 51.474% (20606/40032)\n",
      "Epoch 9 Step 1251/1563 Loss: 1.348 | Acc: 51.480% (20625/40064)\n",
      "Epoch 9 Step 1252/1563 Loss: 1.348 | Acc: 51.484% (20643/40096)\n",
      "Epoch 9 Step 1253/1563 Loss: 1.348 | Acc: 51.493% (20663/40128)\n",
      "Epoch 9 Step 1254/1563 Loss: 1.348 | Acc: 51.487% (20677/40160)\n",
      "Epoch 9 Step 1255/1563 Loss: 1.348 | Acc: 51.485% (20693/40192)\n",
      "Epoch 9 Step 1256/1563 Loss: 1.348 | Acc: 51.469% (20703/40224)\n",
      "Epoch 9 Step 1257/1563 Loss: 1.348 | Acc: 51.468% (20719/40256)\n",
      "Epoch 9 Step 1258/1563 Loss: 1.348 | Acc: 51.467% (20735/40288)\n",
      "Epoch 9 Step 1259/1563 Loss: 1.348 | Acc: 51.471% (20753/40320)\n",
      "Epoch 9 Step 1260/1563 Loss: 1.348 | Acc: 51.475% (20771/40352)\n",
      "Epoch 9 Step 1261/1563 Loss: 1.348 | Acc: 51.468% (20785/40384)\n",
      "Epoch 9 Step 1262/1563 Loss: 1.348 | Acc: 51.467% (20801/40416)\n",
      "Epoch 9 Step 1263/1563 Loss: 1.348 | Acc: 51.466% (20817/40448)\n",
      "Epoch 9 Step 1264/1563 Loss: 1.348 | Acc: 51.472% (20836/40480)\n",
      "Epoch 9 Step 1265/1563 Loss: 1.348 | Acc: 51.481% (20856/40512)\n",
      "Epoch 9 Step 1266/1563 Loss: 1.348 | Acc: 51.465% (20866/40544)\n",
      "Epoch 9 Step 1267/1563 Loss: 1.348 | Acc: 51.461% (20881/40576)\n",
      "Epoch 9 Step 1268/1563 Loss: 1.348 | Acc: 51.473% (20902/40608)\n",
      "Epoch 9 Step 1269/1563 Loss: 1.348 | Acc: 51.474% (20919/40640)\n",
      "Epoch 9 Step 1270/1563 Loss: 1.348 | Acc: 51.473% (20935/40672)\n",
      "Epoch 9 Step 1271/1563 Loss: 1.348 | Acc: 51.479% (20954/40704)\n",
      "Epoch 9 Step 1272/1563 Loss: 1.348 | Acc: 51.483% (20972/40736)\n",
      "Epoch 9 Step 1273/1563 Loss: 1.348 | Acc: 51.469% (20983/40768)\n",
      "Epoch 9 Step 1274/1563 Loss: 1.348 | Acc: 51.471% (21000/40800)\n",
      "Epoch 9 Step 1275/1563 Loss: 1.348 | Acc: 51.474% (21018/40832)\n",
      "Epoch 9 Step 1276/1563 Loss: 1.348 | Acc: 51.471% (21033/40864)\n",
      "Epoch 9 Step 1277/1563 Loss: 1.348 | Acc: 51.482% (21054/40896)\n",
      "Epoch 9 Step 1278/1563 Loss: 1.348 | Acc: 51.481% (21070/40928)\n",
      "Epoch 9 Step 1279/1563 Loss: 1.348 | Acc: 51.477% (21085/40960)\n",
      "Epoch 9 Step 1280/1563 Loss: 1.348 | Acc: 51.495% (21109/40992)\n",
      "Epoch 9 Step 1281/1563 Loss: 1.348 | Acc: 51.489% (21123/41024)\n",
      "Epoch 9 Step 1282/1563 Loss: 1.348 | Acc: 51.476% (21134/41056)\n",
      "Epoch 9 Step 1283/1563 Loss: 1.348 | Acc: 51.480% (21152/41088)\n",
      "Epoch 9 Step 1284/1563 Loss: 1.348 | Acc: 51.479% (21168/41120)\n",
      "Epoch 9 Step 1285/1563 Loss: 1.349 | Acc: 51.468% (21180/41152)\n",
      "Epoch 9 Step 1286/1563 Loss: 1.349 | Acc: 51.471% (21198/41184)\n",
      "Epoch 9 Step 1287/1563 Loss: 1.349 | Acc: 51.470% (21214/41216)\n",
      "Epoch 9 Step 1288/1563 Loss: 1.349 | Acc: 51.469% (21230/41248)\n",
      "Epoch 9 Step 1289/1563 Loss: 1.348 | Acc: 51.473% (21248/41280)\n",
      "Epoch 9 Step 1290/1563 Loss: 1.348 | Acc: 51.481% (21268/41312)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 1291/1563 Loss: 1.348 | Acc: 51.475% (21282/41344)\n",
      "Epoch 9 Step 1292/1563 Loss: 1.348 | Acc: 51.472% (21297/41376)\n",
      "Epoch 9 Step 1293/1563 Loss: 1.348 | Acc: 51.463% (21310/41408)\n",
      "Epoch 9 Step 1294/1563 Loss: 1.348 | Acc: 51.462% (21326/41440)\n",
      "Epoch 9 Step 1295/1563 Loss: 1.349 | Acc: 51.454% (21339/41472)\n",
      "Epoch 9 Step 1296/1563 Loss: 1.348 | Acc: 51.460% (21358/41504)\n",
      "Epoch 9 Step 1297/1563 Loss: 1.348 | Acc: 51.457% (21373/41536)\n",
      "Epoch 9 Step 1298/1563 Loss: 1.348 | Acc: 51.451% (21387/41568)\n",
      "Epoch 9 Step 1299/1563 Loss: 1.349 | Acc: 51.452% (21404/41600)\n",
      "Epoch 9 Step 1300/1563 Loss: 1.349 | Acc: 51.448% (21419/41632)\n",
      "Epoch 9 Step 1301/1563 Loss: 1.349 | Acc: 51.445% (21434/41664)\n",
      "Epoch 9 Step 1302/1563 Loss: 1.349 | Acc: 51.446% (21451/41696)\n",
      "Epoch 9 Step 1303/1563 Loss: 1.349 | Acc: 51.450% (21469/41728)\n",
      "Epoch 9 Step 1304/1563 Loss: 1.349 | Acc: 51.456% (21488/41760)\n",
      "Epoch 9 Step 1305/1563 Loss: 1.349 | Acc: 51.467% (21509/41792)\n",
      "Epoch 9 Step 1306/1563 Loss: 1.348 | Acc: 51.468% (21526/41824)\n",
      "Epoch 9 Step 1307/1563 Loss: 1.349 | Acc: 51.462% (21540/41856)\n",
      "Epoch 9 Step 1308/1563 Loss: 1.349 | Acc: 51.463% (21557/41888)\n",
      "Epoch 9 Step 1309/1563 Loss: 1.349 | Acc: 51.455% (21570/41920)\n",
      "Epoch 9 Step 1310/1563 Loss: 1.349 | Acc: 51.461% (21589/41952)\n",
      "Epoch 9 Step 1311/1563 Loss: 1.349 | Acc: 51.458% (21604/41984)\n",
      "Epoch 9 Step 1312/1563 Loss: 1.349 | Acc: 51.468% (21625/42016)\n",
      "Epoch 9 Step 1313/1563 Loss: 1.349 | Acc: 51.472% (21643/42048)\n",
      "Epoch 9 Step 1314/1563 Loss: 1.349 | Acc: 51.473% (21660/42080)\n",
      "Epoch 9 Step 1315/1563 Loss: 1.349 | Acc: 51.475% (21677/42112)\n",
      "Epoch 9 Step 1316/1563 Loss: 1.349 | Acc: 51.481% (21696/42144)\n",
      "Epoch 9 Step 1317/1563 Loss: 1.349 | Acc: 51.472% (21709/42176)\n",
      "Epoch 9 Step 1318/1563 Loss: 1.349 | Acc: 51.469% (21724/42208)\n",
      "Epoch 9 Step 1319/1563 Loss: 1.349 | Acc: 51.477% (21744/42240)\n",
      "Epoch 9 Step 1320/1563 Loss: 1.349 | Acc: 51.479% (21761/42272)\n",
      "Epoch 9 Step 1321/1563 Loss: 1.349 | Acc: 51.475% (21776/42304)\n",
      "Epoch 9 Step 1322/1563 Loss: 1.349 | Acc: 51.476% (21793/42336)\n",
      "Epoch 9 Step 1323/1563 Loss: 1.348 | Acc: 51.499% (21819/42368)\n",
      "Epoch 9 Step 1324/1563 Loss: 1.348 | Acc: 51.493% (21833/42400)\n",
      "Epoch 9 Step 1325/1563 Loss: 1.348 | Acc: 51.504% (21854/42432)\n",
      "Epoch 9 Step 1326/1563 Loss: 1.348 | Acc: 51.507% (21872/42464)\n",
      "Epoch 9 Step 1327/1563 Loss: 1.348 | Acc: 51.504% (21887/42496)\n",
      "Epoch 9 Step 1328/1563 Loss: 1.348 | Acc: 51.500% (21902/42528)\n",
      "Epoch 9 Step 1329/1563 Loss: 1.348 | Acc: 51.506% (21921/42560)\n",
      "Epoch 9 Step 1330/1563 Loss: 1.348 | Acc: 51.512% (21940/42592)\n",
      "Epoch 9 Step 1331/1563 Loss: 1.348 | Acc: 51.513% (21957/42624)\n",
      "Epoch 9 Step 1332/1563 Loss: 1.348 | Acc: 51.512% (21973/42656)\n",
      "Epoch 9 Step 1333/1563 Loss: 1.348 | Acc: 51.513% (21990/42688)\n",
      "Epoch 9 Step 1334/1563 Loss: 1.348 | Acc: 51.515% (22007/42720)\n",
      "Epoch 9 Step 1335/1563 Loss: 1.348 | Acc: 51.516% (22024/42752)\n",
      "Epoch 9 Step 1336/1563 Loss: 1.348 | Acc: 51.515% (22040/42784)\n",
      "Epoch 9 Step 1337/1563 Loss: 1.349 | Acc: 51.506% (22053/42816)\n",
      "Epoch 9 Step 1338/1563 Loss: 1.349 | Acc: 51.503% (22068/42848)\n",
      "Epoch 9 Step 1339/1563 Loss: 1.349 | Acc: 51.497% (22082/42880)\n",
      "Epoch 9 Step 1340/1563 Loss: 1.349 | Acc: 51.503% (22101/42912)\n",
      "Epoch 9 Step 1341/1563 Loss: 1.349 | Acc: 51.502% (22117/42944)\n",
      "Epoch 9 Step 1342/1563 Loss: 1.349 | Acc: 51.494% (22130/42976)\n",
      "Epoch 9 Step 1343/1563 Loss: 1.349 | Acc: 51.490% (22145/43008)\n",
      "Epoch 9 Step 1344/1563 Loss: 1.349 | Acc: 51.487% (22160/43040)\n",
      "Epoch 9 Step 1345/1563 Loss: 1.349 | Acc: 51.493% (22179/43072)\n",
      "Epoch 9 Step 1346/1563 Loss: 1.349 | Acc: 51.496% (22197/43104)\n",
      "Epoch 9 Step 1347/1563 Loss: 1.349 | Acc: 51.488% (22210/43136)\n",
      "Epoch 9 Step 1348/1563 Loss: 1.349 | Acc: 51.490% (22227/43168)\n",
      "Epoch 9 Step 1349/1563 Loss: 1.349 | Acc: 51.498% (22247/43200)\n",
      "Epoch 9 Step 1350/1563 Loss: 1.349 | Acc: 51.494% (22262/43232)\n",
      "Epoch 9 Step 1351/1563 Loss: 1.349 | Acc: 51.491% (22277/43264)\n",
      "Epoch 9 Step 1352/1563 Loss: 1.349 | Acc: 51.513% (22303/43296)\n",
      "Epoch 9 Step 1353/1563 Loss: 1.349 | Acc: 51.509% (22318/43328)\n",
      "Epoch 9 Step 1354/1563 Loss: 1.349 | Acc: 51.506% (22333/43360)\n",
      "Epoch 9 Step 1355/1563 Loss: 1.349 | Acc: 51.512% (22352/43392)\n",
      "Epoch 9 Step 1356/1563 Loss: 1.349 | Acc: 51.515% (22370/43424)\n",
      "Epoch 9 Step 1357/1563 Loss: 1.349 | Acc: 51.521% (22389/43456)\n",
      "Epoch 9 Step 1358/1563 Loss: 1.349 | Acc: 51.525% (22407/43488)\n",
      "Epoch 9 Step 1359/1563 Loss: 1.348 | Acc: 51.533% (22427/43520)\n",
      "Epoch 9 Step 1360/1563 Loss: 1.348 | Acc: 51.538% (22446/43552)\n",
      "Epoch 9 Step 1361/1563 Loss: 1.348 | Acc: 51.535% (22461/43584)\n",
      "Epoch 9 Step 1362/1563 Loss: 1.348 | Acc: 51.532% (22476/43616)\n",
      "Epoch 9 Step 1363/1563 Loss: 1.349 | Acc: 51.521% (22488/43648)\n",
      "Epoch 9 Step 1364/1563 Loss: 1.348 | Acc: 51.534% (22510/43680)\n",
      "Epoch 9 Step 1365/1563 Loss: 1.348 | Acc: 51.533% (22526/43712)\n",
      "Epoch 9 Step 1366/1563 Loss: 1.348 | Acc: 51.541% (22546/43744)\n",
      "Epoch 9 Step 1367/1563 Loss: 1.348 | Acc: 51.535% (22560/43776)\n",
      "Epoch 9 Step 1368/1563 Loss: 1.348 | Acc: 51.545% (22581/43808)\n",
      "Epoch 9 Step 1369/1563 Loss: 1.348 | Acc: 51.549% (22599/43840)\n",
      "Epoch 9 Step 1370/1563 Loss: 1.348 | Acc: 51.548% (22615/43872)\n",
      "Epoch 9 Step 1371/1563 Loss: 1.348 | Acc: 51.549% (22632/43904)\n",
      "Epoch 9 Step 1372/1563 Loss: 1.348 | Acc: 51.545% (22647/43936)\n",
      "Epoch 9 Step 1373/1563 Loss: 1.348 | Acc: 51.547% (22664/43968)\n",
      "Epoch 9 Step 1374/1563 Loss: 1.348 | Acc: 51.543% (22679/44000)\n",
      "Epoch 9 Step 1375/1563 Loss: 1.348 | Acc: 51.547% (22697/44032)\n",
      "Epoch 9 Step 1376/1563 Loss: 1.348 | Acc: 51.561% (22720/44064)\n",
      "Epoch 9 Step 1377/1563 Loss: 1.347 | Acc: 51.567% (22739/44096)\n",
      "Epoch 9 Step 1378/1563 Loss: 1.347 | Acc: 51.566% (22755/44128)\n",
      "Epoch 9 Step 1379/1563 Loss: 1.347 | Acc: 51.567% (22772/44160)\n",
      "Epoch 9 Step 1380/1563 Loss: 1.347 | Acc: 51.564% (22787/44192)\n",
      "Epoch 9 Step 1381/1563 Loss: 1.347 | Acc: 51.567% (22805/44224)\n",
      "Epoch 9 Step 1382/1563 Loss: 1.347 | Acc: 51.577% (22826/44256)\n",
      "Epoch 9 Step 1383/1563 Loss: 1.347 | Acc: 51.572% (22840/44288)\n",
      "Epoch 9 Step 1384/1563 Loss: 1.347 | Acc: 51.579% (22860/44320)\n",
      "Epoch 9 Step 1385/1563 Loss: 1.347 | Acc: 51.581% (22877/44352)\n",
      "Epoch 9 Step 1386/1563 Loss: 1.347 | Acc: 51.577% (22892/44384)\n",
      "Epoch 9 Step 1387/1563 Loss: 1.347 | Acc: 51.565% (22903/44416)\n",
      "Epoch 9 Step 1388/1563 Loss: 1.348 | Acc: 51.550% (22913/44448)\n",
      "Epoch 9 Step 1389/1563 Loss: 1.348 | Acc: 51.558% (22933/44480)\n",
      "Epoch 9 Step 1390/1563 Loss: 1.347 | Acc: 51.561% (22951/44512)\n",
      "Epoch 9 Step 1391/1563 Loss: 1.347 | Acc: 51.567% (22970/44544)\n",
      "Epoch 9 Step 1392/1563 Loss: 1.347 | Acc: 51.568% (22987/44576)\n",
      "Epoch 9 Step 1393/1563 Loss: 1.347 | Acc: 51.574% (23006/44608)\n",
      "Epoch 9 Step 1394/1563 Loss: 1.347 | Acc: 51.591% (23030/44640)\n",
      "Epoch 9 Step 1395/1563 Loss: 1.347 | Acc: 51.580% (23042/44672)\n",
      "Epoch 9 Step 1396/1563 Loss: 1.347 | Acc: 51.586% (23061/44704)\n",
      "Epoch 9 Step 1397/1563 Loss: 1.347 | Acc: 51.569% (23070/44736)\n",
      "Epoch 9 Step 1398/1563 Loss: 1.347 | Acc: 51.561% (23083/44768)\n",
      "Epoch 9 Step 1399/1563 Loss: 1.348 | Acc: 51.551% (23095/44800)\n",
      "Epoch 9 Step 1400/1563 Loss: 1.348 | Acc: 51.552% (23112/44832)\n",
      "Epoch 9 Step 1401/1563 Loss: 1.348 | Acc: 51.551% (23128/44864)\n",
      "Epoch 9 Step 1402/1563 Loss: 1.348 | Acc: 51.555% (23146/44896)\n",
      "Epoch 9 Step 1403/1563 Loss: 1.348 | Acc: 51.565% (23167/44928)\n",
      "Epoch 9 Step 1404/1563 Loss: 1.348 | Acc: 51.566% (23184/44960)\n",
      "Epoch 9 Step 1405/1563 Loss: 1.348 | Acc: 51.547% (23192/44992)\n",
      "Epoch 9 Step 1406/1563 Loss: 1.348 | Acc: 51.548% (23209/45024)\n",
      "Epoch 9 Step 1407/1563 Loss: 1.348 | Acc: 51.547% (23225/45056)\n",
      "Epoch 9 Step 1408/1563 Loss: 1.348 | Acc: 51.544% (23240/45088)\n",
      "Epoch 9 Step 1409/1563 Loss: 1.348 | Acc: 51.543% (23256/45120)\n",
      "Epoch 9 Step 1410/1563 Loss: 1.348 | Acc: 51.537% (23270/45152)\n",
      "Epoch 9 Step 1411/1563 Loss: 1.348 | Acc: 51.545% (23290/45184)\n",
      "Epoch 9 Step 1412/1563 Loss: 1.348 | Acc: 51.546% (23307/45216)\n",
      "Epoch 9 Step 1413/1563 Loss: 1.348 | Acc: 51.545% (23323/45248)\n",
      "Epoch 9 Step 1414/1563 Loss: 1.348 | Acc: 51.537% (23336/45280)\n",
      "Epoch 9 Step 1415/1563 Loss: 1.348 | Acc: 51.543% (23355/45312)\n",
      "Epoch 9 Step 1416/1563 Loss: 1.348 | Acc: 51.533% (23367/45344)\n",
      "Epoch 9 Step 1417/1563 Loss: 1.349 | Acc: 51.527% (23381/45376)\n",
      "Epoch 9 Step 1418/1563 Loss: 1.349 | Acc: 51.524% (23396/45408)\n",
      "Epoch 9 Step 1419/1563 Loss: 1.349 | Acc: 51.512% (23407/45440)\n",
      "Epoch 9 Step 1420/1563 Loss: 1.349 | Acc: 51.509% (23422/45472)\n",
      "Epoch 9 Step 1421/1563 Loss: 1.349 | Acc: 51.499% (23434/45504)\n",
      "Epoch 9 Step 1422/1563 Loss: 1.349 | Acc: 51.509% (23455/45536)\n",
      "Epoch 9 Step 1423/1563 Loss: 1.349 | Acc: 51.512% (23473/45568)\n",
      "Epoch 9 Step 1424/1563 Loss: 1.349 | Acc: 51.511% (23489/45600)\n",
      "Epoch 9 Step 1425/1563 Loss: 1.349 | Acc: 51.516% (23508/45632)\n",
      "Epoch 9 Step 1426/1563 Loss: 1.349 | Acc: 51.520% (23526/45664)\n",
      "Epoch 9 Step 1427/1563 Loss: 1.349 | Acc: 51.521% (23543/45696)\n",
      "Epoch 9 Step 1428/1563 Loss: 1.349 | Acc: 51.529% (23563/45728)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 1429/1563 Loss: 1.349 | Acc: 51.525% (23578/45760)\n",
      "Epoch 9 Step 1430/1563 Loss: 1.349 | Acc: 51.522% (23593/45792)\n",
      "Epoch 9 Step 1431/1563 Loss: 1.349 | Acc: 51.541% (23618/45824)\n",
      "Epoch 9 Step 1432/1563 Loss: 1.349 | Acc: 51.546% (23637/45856)\n",
      "Epoch 9 Step 1433/1563 Loss: 1.349 | Acc: 51.554% (23657/45888)\n",
      "Epoch 9 Step 1434/1563 Loss: 1.349 | Acc: 51.559% (23676/45920)\n",
      "Epoch 9 Step 1435/1563 Loss: 1.349 | Acc: 51.558% (23692/45952)\n",
      "Epoch 9 Step 1436/1563 Loss: 1.349 | Acc: 51.559% (23709/45984)\n",
      "Epoch 9 Step 1437/1563 Loss: 1.349 | Acc: 51.554% (23723/46016)\n",
      "Epoch 9 Step 1438/1563 Loss: 1.348 | Acc: 51.566% (23745/46048)\n",
      "Epoch 9 Step 1439/1563 Loss: 1.348 | Acc: 51.573% (23765/46080)\n",
      "Epoch 9 Step 1440/1563 Loss: 1.348 | Acc: 51.572% (23781/46112)\n",
      "Epoch 9 Step 1441/1563 Loss: 1.348 | Acc: 51.582% (23802/46144)\n",
      "Epoch 9 Step 1442/1563 Loss: 1.348 | Acc: 51.577% (23816/46176)\n",
      "Epoch 9 Step 1443/1563 Loss: 1.348 | Acc: 51.573% (23831/46208)\n",
      "Epoch 9 Step 1444/1563 Loss: 1.348 | Acc: 51.577% (23849/46240)\n",
      "Epoch 9 Step 1445/1563 Loss: 1.348 | Acc: 51.573% (23864/46272)\n",
      "Epoch 9 Step 1446/1563 Loss: 1.348 | Acc: 51.579% (23883/46304)\n",
      "Epoch 9 Step 1447/1563 Loss: 1.348 | Acc: 51.591% (23905/46336)\n",
      "Epoch 9 Step 1448/1563 Loss: 1.348 | Acc: 51.585% (23919/46368)\n",
      "Epoch 9 Step 1449/1563 Loss: 1.348 | Acc: 51.584% (23935/46400)\n",
      "Epoch 9 Step 1450/1563 Loss: 1.348 | Acc: 51.589% (23954/46432)\n",
      "Epoch 9 Step 1451/1563 Loss: 1.348 | Acc: 51.595% (23973/46464)\n",
      "Epoch 9 Step 1452/1563 Loss: 1.348 | Acc: 51.589% (23987/46496)\n",
      "Epoch 9 Step 1453/1563 Loss: 1.348 | Acc: 51.588% (24003/46528)\n",
      "Epoch 9 Step 1454/1563 Loss: 1.348 | Acc: 51.583% (24017/46560)\n",
      "Epoch 9 Step 1455/1563 Loss: 1.348 | Acc: 51.588% (24036/46592)\n",
      "Epoch 9 Step 1456/1563 Loss: 1.348 | Acc: 51.594% (24055/46624)\n",
      "Epoch 9 Step 1457/1563 Loss: 1.348 | Acc: 51.590% (24070/46656)\n",
      "Epoch 9 Step 1458/1563 Loss: 1.348 | Acc: 51.589% (24086/46688)\n",
      "Epoch 9 Step 1459/1563 Loss: 1.348 | Acc: 51.597% (24106/46720)\n",
      "Epoch 9 Step 1460/1563 Loss: 1.348 | Acc: 51.596% (24122/46752)\n",
      "Epoch 9 Step 1461/1563 Loss: 1.348 | Acc: 51.599% (24140/46784)\n",
      "Epoch 9 Step 1462/1563 Loss: 1.348 | Acc: 51.598% (24156/46816)\n",
      "Epoch 9 Step 1463/1563 Loss: 1.348 | Acc: 51.601% (24174/46848)\n",
      "Epoch 9 Step 1464/1563 Loss: 1.348 | Acc: 51.593% (24187/46880)\n",
      "Epoch 9 Step 1465/1563 Loss: 1.348 | Acc: 51.584% (24199/46912)\n",
      "Epoch 9 Step 1466/1563 Loss: 1.348 | Acc: 51.583% (24215/46944)\n",
      "Epoch 9 Step 1467/1563 Loss: 1.348 | Acc: 51.573% (24227/46976)\n",
      "Epoch 9 Step 1468/1563 Loss: 1.349 | Acc: 51.570% (24242/47008)\n",
      "Epoch 9 Step 1469/1563 Loss: 1.349 | Acc: 51.569% (24258/47040)\n",
      "Epoch 9 Step 1470/1563 Loss: 1.348 | Acc: 51.572% (24276/47072)\n",
      "Epoch 9 Step 1471/1563 Loss: 1.348 | Acc: 51.569% (24291/47104)\n",
      "Epoch 9 Step 1472/1563 Loss: 1.348 | Acc: 51.568% (24307/47136)\n",
      "Epoch 9 Step 1473/1563 Loss: 1.348 | Acc: 51.567% (24323/47168)\n",
      "Epoch 9 Step 1474/1563 Loss: 1.348 | Acc: 51.566% (24339/47200)\n",
      "Epoch 9 Step 1475/1563 Loss: 1.348 | Acc: 51.560% (24353/47232)\n",
      "Epoch 9 Step 1476/1563 Loss: 1.348 | Acc: 51.566% (24372/47264)\n",
      "Epoch 9 Step 1477/1563 Loss: 1.348 | Acc: 51.565% (24388/47296)\n",
      "Epoch 9 Step 1478/1563 Loss: 1.348 | Acc: 51.564% (24404/47328)\n",
      "Epoch 9 Step 1479/1563 Loss: 1.348 | Acc: 51.560% (24419/47360)\n",
      "Epoch 9 Step 1480/1563 Loss: 1.348 | Acc: 51.559% (24435/47392)\n",
      "Epoch 9 Step 1481/1563 Loss: 1.348 | Acc: 51.552% (24448/47424)\n",
      "Epoch 9 Step 1482/1563 Loss: 1.349 | Acc: 51.545% (24461/47456)\n",
      "Epoch 9 Step 1483/1563 Loss: 1.349 | Acc: 51.535% (24473/47488)\n",
      "Epoch 9 Step 1484/1563 Loss: 1.349 | Acc: 51.530% (24487/47520)\n",
      "Epoch 9 Step 1485/1563 Loss: 1.349 | Acc: 51.531% (24504/47552)\n",
      "Epoch 9 Step 1486/1563 Loss: 1.349 | Acc: 51.524% (24517/47584)\n",
      "Epoch 9 Step 1487/1563 Loss: 1.349 | Acc: 51.523% (24533/47616)\n",
      "Epoch 9 Step 1488/1563 Loss: 1.349 | Acc: 51.524% (24550/47648)\n",
      "Epoch 9 Step 1489/1563 Loss: 1.349 | Acc: 51.525% (24567/47680)\n",
      "Epoch 9 Step 1490/1563 Loss: 1.349 | Acc: 51.526% (24584/47712)\n",
      "Epoch 9 Step 1491/1563 Loss: 1.350 | Acc: 51.521% (24598/47744)\n",
      "Epoch 9 Step 1492/1563 Loss: 1.350 | Acc: 51.522% (24615/47776)\n",
      "Epoch 9 Step 1493/1563 Loss: 1.350 | Acc: 51.516% (24629/47808)\n",
      "Epoch 9 Step 1494/1563 Loss: 1.350 | Acc: 51.511% (24643/47840)\n",
      "Epoch 9 Step 1495/1563 Loss: 1.350 | Acc: 51.517% (24662/47872)\n",
      "Epoch 9 Step 1496/1563 Loss: 1.350 | Acc: 51.516% (24678/47904)\n",
      "Epoch 9 Step 1497/1563 Loss: 1.350 | Acc: 51.510% (24692/47936)\n",
      "Epoch 9 Step 1498/1563 Loss: 1.350 | Acc: 51.509% (24708/47968)\n",
      "Epoch 9 Step 1499/1563 Loss: 1.350 | Acc: 51.517% (24728/48000)\n",
      "Epoch 9 Step 1500/1563 Loss: 1.350 | Acc: 51.511% (24742/48032)\n",
      "Epoch 9 Step 1501/1563 Loss: 1.350 | Acc: 51.502% (24754/48064)\n",
      "Epoch 9 Step 1502/1563 Loss: 1.350 | Acc: 51.497% (24768/48096)\n",
      "Epoch 9 Step 1503/1563 Loss: 1.350 | Acc: 51.504% (24788/48128)\n",
      "Epoch 9 Step 1504/1563 Loss: 1.351 | Acc: 51.491% (24798/48160)\n",
      "Epoch 9 Step 1505/1563 Loss: 1.351 | Acc: 51.490% (24814/48192)\n",
      "Epoch 9 Step 1506/1563 Loss: 1.351 | Acc: 51.493% (24832/48224)\n",
      "Epoch 9 Step 1507/1563 Loss: 1.351 | Acc: 51.490% (24847/48256)\n",
      "Epoch 9 Step 1508/1563 Loss: 1.351 | Acc: 51.485% (24861/48288)\n",
      "Epoch 9 Step 1509/1563 Loss: 1.351 | Acc: 51.482% (24876/48320)\n",
      "Epoch 9 Step 1510/1563 Loss: 1.351 | Acc: 51.483% (24893/48352)\n",
      "Epoch 9 Step 1511/1563 Loss: 1.351 | Acc: 51.482% (24909/48384)\n",
      "Epoch 9 Step 1512/1563 Loss: 1.351 | Acc: 51.481% (24925/48416)\n",
      "Epoch 9 Step 1513/1563 Loss: 1.351 | Acc: 51.472% (24937/48448)\n",
      "Epoch 9 Step 1514/1563 Loss: 1.351 | Acc: 51.473% (24954/48480)\n",
      "Epoch 9 Step 1515/1563 Loss: 1.351 | Acc: 51.482% (24975/48512)\n",
      "Epoch 9 Step 1516/1563 Loss: 1.351 | Acc: 51.489% (24995/48544)\n",
      "Epoch 9 Step 1517/1563 Loss: 1.351 | Acc: 51.495% (25014/48576)\n",
      "Epoch 9 Step 1518/1563 Loss: 1.350 | Acc: 51.500% (25033/48608)\n",
      "Epoch 9 Step 1519/1563 Loss: 1.350 | Acc: 51.505% (25052/48640)\n",
      "Epoch 9 Step 1520/1563 Loss: 1.350 | Acc: 51.500% (25066/48672)\n",
      "Epoch 9 Step 1521/1563 Loss: 1.351 | Acc: 51.497% (25081/48704)\n",
      "Epoch 9 Step 1522/1563 Loss: 1.351 | Acc: 51.490% (25094/48736)\n",
      "Epoch 9 Step 1523/1563 Loss: 1.351 | Acc: 51.487% (25109/48768)\n",
      "Epoch 9 Step 1524/1563 Loss: 1.351 | Acc: 51.496% (25130/48800)\n",
      "Epoch 9 Step 1525/1563 Loss: 1.351 | Acc: 51.487% (25142/48832)\n",
      "Epoch 9 Step 1526/1563 Loss: 1.351 | Acc: 51.490% (25160/48864)\n",
      "Epoch 9 Step 1527/1563 Loss: 1.351 | Acc: 51.491% (25177/48896)\n",
      "Epoch 9 Step 1528/1563 Loss: 1.351 | Acc: 51.488% (25192/48928)\n",
      "Epoch 9 Step 1529/1563 Loss: 1.351 | Acc: 51.487% (25208/48960)\n",
      "Epoch 9 Step 1530/1563 Loss: 1.351 | Acc: 51.484% (25223/48992)\n",
      "Epoch 9 Step 1531/1563 Loss: 1.351 | Acc: 51.487% (25241/49024)\n",
      "Epoch 9 Step 1532/1563 Loss: 1.351 | Acc: 51.494% (25261/49056)\n",
      "Epoch 9 Step 1533/1563 Loss: 1.351 | Acc: 51.487% (25274/49088)\n",
      "Epoch 9 Step 1534/1563 Loss: 1.351 | Acc: 51.484% (25289/49120)\n",
      "Epoch 9 Step 1535/1563 Loss: 1.351 | Acc: 51.485% (25306/49152)\n",
      "Epoch 9 Step 1536/1563 Loss: 1.351 | Acc: 51.490% (25325/49184)\n",
      "Epoch 9 Step 1537/1563 Loss: 1.351 | Acc: 51.485% (25339/49216)\n",
      "Epoch 9 Step 1538/1563 Loss: 1.351 | Acc: 51.484% (25355/49248)\n",
      "Epoch 9 Step 1539/1563 Loss: 1.351 | Acc: 51.491% (25375/49280)\n",
      "Epoch 9 Step 1540/1563 Loss: 1.351 | Acc: 51.497% (25394/49312)\n",
      "Epoch 9 Step 1541/1563 Loss: 1.351 | Acc: 51.490% (25407/49344)\n",
      "Epoch 9 Step 1542/1563 Loss: 1.351 | Acc: 51.495% (25426/49376)\n",
      "Epoch 9 Step 1543/1563 Loss: 1.351 | Acc: 51.500% (25445/49408)\n",
      "Epoch 9 Step 1544/1563 Loss: 1.351 | Acc: 51.503% (25463/49440)\n",
      "Epoch 9 Step 1545/1563 Loss: 1.351 | Acc: 51.502% (25479/49472)\n",
      "Epoch 9 Step 1546/1563 Loss: 1.351 | Acc: 51.501% (25495/49504)\n",
      "Epoch 9 Step 1547/1563 Loss: 1.351 | Acc: 51.502% (25512/49536)\n",
      "Epoch 9 Step 1548/1563 Loss: 1.351 | Acc: 51.503% (25529/49568)\n",
      "Epoch 9 Step 1549/1563 Loss: 1.351 | Acc: 51.504% (25546/49600)\n",
      "Epoch 9 Step 1550/1563 Loss: 1.351 | Acc: 51.505% (25563/49632)\n",
      "Epoch 9 Step 1551/1563 Loss: 1.351 | Acc: 51.498% (25576/49664)\n",
      "Epoch 9 Step 1552/1563 Loss: 1.351 | Acc: 51.495% (25591/49696)\n",
      "Epoch 9 Step 1553/1563 Loss: 1.351 | Acc: 51.498% (25609/49728)\n",
      "Epoch 9 Step 1554/1563 Loss: 1.351 | Acc: 51.501% (25627/49760)\n",
      "Epoch 9 Step 1555/1563 Loss: 1.351 | Acc: 51.494% (25640/49792)\n",
      "Epoch 9 Step 1556/1563 Loss: 1.351 | Acc: 51.499% (25659/49824)\n",
      "Epoch 9 Step 1557/1563 Loss: 1.351 | Acc: 51.492% (25672/49856)\n",
      "Epoch 9 Step 1558/1563 Loss: 1.351 | Acc: 51.491% (25688/49888)\n",
      "Epoch 9 Step 1559/1563 Loss: 1.351 | Acc: 51.490% (25704/49920)\n",
      "Epoch 9 Step 1560/1563 Loss: 1.351 | Acc: 51.481% (25716/49952)\n",
      "Epoch 9 Step 1561/1563 Loss: 1.351 | Acc: 51.488% (25736/49984)\n",
      "Epoch 9 Step 1562/1563 Loss: 1.351 | Acc: 51.494% (25747/50000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 0/313 Test Loss: 1.018 | Test Acc: 59.375% (19/32)\n",
      "Epoch 9 Step 1/313 Test Loss: 1.181 | Test Acc: 54.688% (35/64)\n",
      "Epoch 9 Step 2/313 Test Loss: 1.198 | Test Acc: 58.333% (56/96)\n",
      "Epoch 9 Step 3/313 Test Loss: 1.182 | Test Acc: 58.594% (75/128)\n",
      "Epoch 9 Step 4/313 Test Loss: 1.204 | Test Acc: 58.125% (93/160)\n",
      "Epoch 9 Step 5/313 Test Loss: 1.221 | Test Acc: 56.771% (109/192)\n",
      "Epoch 9 Step 6/313 Test Loss: 1.287 | Test Acc: 54.018% (121/224)\n",
      "Epoch 9 Step 7/313 Test Loss: 1.281 | Test Acc: 55.078% (141/256)\n",
      "Epoch 9 Step 8/313 Test Loss: 1.276 | Test Acc: 54.861% (158/288)\n",
      "Epoch 9 Step 9/313 Test Loss: 1.266 | Test Acc: 54.688% (175/320)\n",
      "Epoch 9 Step 10/313 Test Loss: 1.263 | Test Acc: 54.261% (191/352)\n",
      "Epoch 9 Step 11/313 Test Loss: 1.282 | Test Acc: 52.865% (203/384)\n",
      "Epoch 9 Step 12/313 Test Loss: 1.269 | Test Acc: 53.606% (223/416)\n",
      "Epoch 9 Step 13/313 Test Loss: 1.286 | Test Acc: 53.795% (241/448)\n",
      "Epoch 9 Step 14/313 Test Loss: 1.292 | Test Acc: 53.542% (257/480)\n",
      "Epoch 9 Step 15/313 Test Loss: 1.281 | Test Acc: 54.297% (278/512)\n",
      "Epoch 9 Step 16/313 Test Loss: 1.277 | Test Acc: 54.596% (297/544)\n",
      "Epoch 9 Step 17/313 Test Loss: 1.272 | Test Acc: 54.861% (316/576)\n",
      "Epoch 9 Step 18/313 Test Loss: 1.267 | Test Acc: 55.263% (336/608)\n",
      "Epoch 9 Step 19/313 Test Loss: 1.251 | Test Acc: 55.625% (356/640)\n",
      "Epoch 9 Step 20/313 Test Loss: 1.240 | Test Acc: 55.655% (374/672)\n",
      "Epoch 9 Step 21/313 Test Loss: 1.259 | Test Acc: 54.545% (384/704)\n",
      "Epoch 9 Step 22/313 Test Loss: 1.263 | Test Acc: 54.212% (399/736)\n",
      "Epoch 9 Step 23/313 Test Loss: 1.261 | Test Acc: 54.427% (418/768)\n",
      "Epoch 9 Step 24/313 Test Loss: 1.266 | Test Acc: 54.125% (433/800)\n",
      "Epoch 9 Step 25/313 Test Loss: 1.265 | Test Acc: 54.567% (454/832)\n",
      "Epoch 9 Step 26/313 Test Loss: 1.265 | Test Acc: 54.745% (473/864)\n",
      "Epoch 9 Step 27/313 Test Loss: 1.255 | Test Acc: 55.357% (496/896)\n",
      "Epoch 9 Step 28/313 Test Loss: 1.249 | Test Acc: 55.388% (514/928)\n",
      "Epoch 9 Step 29/313 Test Loss: 1.239 | Test Acc: 55.417% (532/960)\n",
      "Epoch 9 Step 30/313 Test Loss: 1.236 | Test Acc: 55.746% (553/992)\n",
      "Epoch 9 Step 31/313 Test Loss: 1.227 | Test Acc: 56.055% (574/1024)\n",
      "Epoch 9 Step 32/313 Test Loss: 1.234 | Test Acc: 55.871% (590/1056)\n",
      "Epoch 9 Step 33/313 Test Loss: 1.229 | Test Acc: 56.066% (610/1088)\n",
      "Epoch 9 Step 34/313 Test Loss: 1.223 | Test Acc: 56.518% (633/1120)\n",
      "Epoch 9 Step 35/313 Test Loss: 1.230 | Test Acc: 56.337% (649/1152)\n",
      "Epoch 9 Step 36/313 Test Loss: 1.226 | Test Acc: 56.166% (665/1184)\n",
      "Epoch 9 Step 37/313 Test Loss: 1.229 | Test Acc: 56.414% (686/1216)\n",
      "Epoch 9 Step 38/313 Test Loss: 1.236 | Test Acc: 56.090% (700/1248)\n",
      "Epoch 9 Step 39/313 Test Loss: 1.237 | Test Acc: 55.703% (713/1280)\n",
      "Epoch 9 Step 40/313 Test Loss: 1.240 | Test Acc: 55.640% (730/1312)\n",
      "Epoch 9 Step 41/313 Test Loss: 1.241 | Test Acc: 55.729% (749/1344)\n",
      "Epoch 9 Step 42/313 Test Loss: 1.237 | Test Acc: 55.887% (769/1376)\n",
      "Epoch 9 Step 43/313 Test Loss: 1.244 | Test Acc: 55.611% (783/1408)\n",
      "Epoch 9 Step 44/313 Test Loss: 1.246 | Test Acc: 55.347% (797/1440)\n",
      "Epoch 9 Step 45/313 Test Loss: 1.244 | Test Acc: 55.367% (815/1472)\n",
      "Epoch 9 Step 46/313 Test Loss: 1.246 | Test Acc: 55.319% (832/1504)\n",
      "Epoch 9 Step 47/313 Test Loss: 1.245 | Test Acc: 55.469% (852/1536)\n",
      "Epoch 9 Step 48/313 Test Loss: 1.243 | Test Acc: 55.421% (869/1568)\n",
      "Epoch 9 Step 49/313 Test Loss: 1.252 | Test Acc: 55.250% (884/1600)\n",
      "Epoch 9 Step 50/313 Test Loss: 1.263 | Test Acc: 54.779% (894/1632)\n",
      "Epoch 9 Step 51/313 Test Loss: 1.258 | Test Acc: 54.928% (914/1664)\n",
      "Epoch 9 Step 52/313 Test Loss: 1.260 | Test Acc: 55.012% (933/1696)\n",
      "Epoch 9 Step 53/313 Test Loss: 1.266 | Test Acc: 54.861% (948/1728)\n",
      "Epoch 9 Step 54/313 Test Loss: 1.265 | Test Acc: 54.773% (964/1760)\n",
      "Epoch 9 Step 55/313 Test Loss: 1.262 | Test Acc: 54.743% (981/1792)\n",
      "Epoch 9 Step 56/313 Test Loss: 1.264 | Test Acc: 54.550% (995/1824)\n",
      "Epoch 9 Step 57/313 Test Loss: 1.268 | Test Acc: 54.418% (1010/1856)\n",
      "Epoch 9 Step 58/313 Test Loss: 1.271 | Test Acc: 54.396% (1027/1888)\n",
      "Epoch 9 Step 59/313 Test Loss: 1.273 | Test Acc: 54.375% (1044/1920)\n",
      "Epoch 9 Step 60/313 Test Loss: 1.273 | Test Acc: 54.355% (1061/1952)\n",
      "Epoch 9 Step 61/313 Test Loss: 1.274 | Test Acc: 54.486% (1081/1984)\n",
      "Epoch 9 Step 62/313 Test Loss: 1.276 | Test Acc: 54.365% (1096/2016)\n",
      "Epoch 9 Step 63/313 Test Loss: 1.277 | Test Acc: 54.395% (1114/2048)\n",
      "Epoch 9 Step 64/313 Test Loss: 1.273 | Test Acc: 54.519% (1134/2080)\n",
      "Epoch 9 Step 65/313 Test Loss: 1.270 | Test Acc: 54.593% (1153/2112)\n",
      "Epoch 9 Step 66/313 Test Loss: 1.272 | Test Acc: 54.524% (1169/2144)\n",
      "Epoch 9 Step 67/313 Test Loss: 1.275 | Test Acc: 54.320% (1182/2176)\n",
      "Epoch 9 Step 68/313 Test Loss: 1.276 | Test Acc: 54.303% (1199/2208)\n",
      "Epoch 9 Step 69/313 Test Loss: 1.274 | Test Acc: 54.420% (1219/2240)\n",
      "Epoch 9 Step 70/313 Test Loss: 1.275 | Test Acc: 54.489% (1238/2272)\n",
      "Epoch 9 Step 71/313 Test Loss: 1.277 | Test Acc: 54.340% (1252/2304)\n",
      "Epoch 9 Step 72/313 Test Loss: 1.277 | Test Acc: 54.366% (1270/2336)\n",
      "Epoch 9 Step 73/313 Test Loss: 1.275 | Test Acc: 54.476% (1290/2368)\n",
      "Epoch 9 Step 74/313 Test Loss: 1.277 | Test Acc: 54.500% (1308/2400)\n",
      "Epoch 9 Step 75/313 Test Loss: 1.278 | Test Acc: 54.441% (1324/2432)\n",
      "Epoch 9 Step 76/313 Test Loss: 1.276 | Test Acc: 54.586% (1345/2464)\n",
      "Epoch 9 Step 77/313 Test Loss: 1.277 | Test Acc: 54.647% (1364/2496)\n",
      "Epoch 9 Step 78/313 Test Loss: 1.281 | Test Acc: 54.430% (1376/2528)\n",
      "Epoch 9 Step 79/313 Test Loss: 1.283 | Test Acc: 54.453% (1394/2560)\n",
      "Epoch 9 Step 80/313 Test Loss: 1.282 | Test Acc: 54.321% (1408/2592)\n",
      "Epoch 9 Step 81/313 Test Loss: 1.279 | Test Acc: 54.383% (1427/2624)\n",
      "Epoch 9 Step 82/313 Test Loss: 1.280 | Test Acc: 54.443% (1446/2656)\n",
      "Epoch 9 Step 83/313 Test Loss: 1.277 | Test Acc: 54.613% (1468/2688)\n",
      "Epoch 9 Step 84/313 Test Loss: 1.280 | Test Acc: 54.632% (1486/2720)\n",
      "Epoch 9 Step 85/313 Test Loss: 1.281 | Test Acc: 54.469% (1499/2752)\n",
      "Epoch 9 Step 86/313 Test Loss: 1.282 | Test Acc: 54.382% (1514/2784)\n",
      "Epoch 9 Step 87/313 Test Loss: 1.282 | Test Acc: 54.474% (1534/2816)\n",
      "Epoch 9 Step 88/313 Test Loss: 1.281 | Test Acc: 54.459% (1551/2848)\n",
      "Epoch 9 Step 89/313 Test Loss: 1.281 | Test Acc: 54.410% (1567/2880)\n",
      "Epoch 9 Step 90/313 Test Loss: 1.281 | Test Acc: 54.464% (1586/2912)\n",
      "Epoch 9 Step 91/313 Test Loss: 1.277 | Test Acc: 54.620% (1608/2944)\n",
      "Epoch 9 Step 92/313 Test Loss: 1.276 | Test Acc: 54.671% (1627/2976)\n",
      "Epoch 9 Step 93/313 Test Loss: 1.275 | Test Acc: 54.721% (1646/3008)\n",
      "Epoch 9 Step 94/313 Test Loss: 1.275 | Test Acc: 54.737% (1664/3040)\n",
      "Epoch 9 Step 95/313 Test Loss: 1.274 | Test Acc: 54.785% (1683/3072)\n",
      "Epoch 9 Step 96/313 Test Loss: 1.271 | Test Acc: 54.865% (1703/3104)\n",
      "Epoch 9 Step 97/313 Test Loss: 1.273 | Test Acc: 54.847% (1720/3136)\n",
      "Epoch 9 Step 98/313 Test Loss: 1.272 | Test Acc: 54.861% (1738/3168)\n",
      "Epoch 9 Step 99/313 Test Loss: 1.274 | Test Acc: 54.938% (1758/3200)\n",
      "Epoch 9 Step 100/313 Test Loss: 1.276 | Test Acc: 54.796% (1771/3232)\n",
      "Epoch 9 Step 101/313 Test Loss: 1.275 | Test Acc: 54.841% (1790/3264)\n",
      "Epoch 9 Step 102/313 Test Loss: 1.274 | Test Acc: 54.945% (1811/3296)\n",
      "Epoch 9 Step 103/313 Test Loss: 1.275 | Test Acc: 54.928% (1828/3328)\n",
      "Epoch 9 Step 104/313 Test Loss: 1.275 | Test Acc: 54.911% (1845/3360)\n",
      "Epoch 9 Step 105/313 Test Loss: 1.272 | Test Acc: 54.923% (1863/3392)\n",
      "Epoch 9 Step 106/313 Test Loss: 1.272 | Test Acc: 54.907% (1880/3424)\n",
      "Epoch 9 Step 107/313 Test Loss: 1.273 | Test Acc: 54.832% (1895/3456)\n",
      "Epoch 9 Step 108/313 Test Loss: 1.271 | Test Acc: 54.931% (1916/3488)\n",
      "Epoch 9 Step 109/313 Test Loss: 1.273 | Test Acc: 54.858% (1931/3520)\n",
      "Epoch 9 Step 110/313 Test Loss: 1.271 | Test Acc: 54.955% (1952/3552)\n",
      "Epoch 9 Step 111/313 Test Loss: 1.270 | Test Acc: 54.967% (1970/3584)\n",
      "Epoch 9 Step 112/313 Test Loss: 1.270 | Test Acc: 55.033% (1990/3616)\n",
      "Epoch 9 Step 113/313 Test Loss: 1.270 | Test Acc: 55.016% (2007/3648)\n",
      "Epoch 9 Step 114/313 Test Loss: 1.269 | Test Acc: 55.027% (2025/3680)\n",
      "Epoch 9 Step 115/313 Test Loss: 1.267 | Test Acc: 55.038% (2043/3712)\n",
      "Epoch 9 Step 116/313 Test Loss: 1.267 | Test Acc: 54.968% (2058/3744)\n",
      "Epoch 9 Step 117/313 Test Loss: 1.268 | Test Acc: 54.952% (2075/3776)\n",
      "Epoch 9 Step 118/313 Test Loss: 1.268 | Test Acc: 54.989% (2094/3808)\n",
      "Epoch 9 Step 119/313 Test Loss: 1.267 | Test Acc: 55.026% (2113/3840)\n",
      "Epoch 9 Step 120/313 Test Loss: 1.265 | Test Acc: 55.062% (2132/3872)\n",
      "Epoch 9 Step 121/313 Test Loss: 1.264 | Test Acc: 55.072% (2150/3904)\n",
      "Epoch 9 Step 122/313 Test Loss: 1.266 | Test Acc: 55.005% (2165/3936)\n",
      "Epoch 9 Step 123/313 Test Loss: 1.266 | Test Acc: 54.965% (2181/3968)\n",
      "Epoch 9 Step 124/313 Test Loss: 1.268 | Test Acc: 54.850% (2194/4000)\n",
      "Epoch 9 Step 125/313 Test Loss: 1.268 | Test Acc: 54.861% (2212/4032)\n",
      "Epoch 9 Step 126/313 Test Loss: 1.272 | Test Acc: 54.749% (2225/4064)\n",
      "Epoch 9 Step 127/313 Test Loss: 1.269 | Test Acc: 54.858% (2247/4096)\n",
      "Epoch 9 Step 128/313 Test Loss: 1.271 | Test Acc: 54.821% (2263/4128)\n",
      "Epoch 9 Step 129/313 Test Loss: 1.271 | Test Acc: 54.856% (2282/4160)\n",
      "Epoch 9 Step 130/313 Test Loss: 1.269 | Test Acc: 54.843% (2299/4192)\n",
      "Epoch 9 Step 131/313 Test Loss: 1.268 | Test Acc: 54.877% (2318/4224)\n",
      "Epoch 9 Step 132/313 Test Loss: 1.269 | Test Acc: 54.793% (2332/4256)\n",
      "Epoch 9 Step 133/313 Test Loss: 1.269 | Test Acc: 54.781% (2349/4288)\n",
      "Epoch 9 Step 134/313 Test Loss: 1.270 | Test Acc: 54.792% (2367/4320)\n",
      "Epoch 9 Step 135/313 Test Loss: 1.268 | Test Acc: 54.894% (2389/4352)\n",
      "Epoch 9 Step 136/313 Test Loss: 1.268 | Test Acc: 54.881% (2406/4384)\n",
      "Epoch 9 Step 137/313 Test Loss: 1.267 | Test Acc: 54.937% (2426/4416)\n",
      "Epoch 9 Step 138/313 Test Loss: 1.265 | Test Acc: 54.991% (2446/4448)\n",
      "Epoch 9 Step 139/313 Test Loss: 1.264 | Test Acc: 54.978% (2463/4480)\n",
      "Epoch 9 Step 140/313 Test Loss: 1.263 | Test Acc: 55.075% (2485/4512)\n",
      "Epoch 9 Step 141/313 Test Loss: 1.262 | Test Acc: 55.084% (2503/4544)\n",
      "Epoch 9 Step 142/313 Test Loss: 1.264 | Test Acc: 55.070% (2520/4576)\n",
      "Epoch 9 Step 143/313 Test Loss: 1.266 | Test Acc: 54.970% (2533/4608)\n",
      "Epoch 9 Step 144/313 Test Loss: 1.267 | Test Acc: 54.957% (2550/4640)\n",
      "Epoch 9 Step 145/313 Test Loss: 1.265 | Test Acc: 55.051% (2572/4672)\n",
      "Epoch 9 Step 146/313 Test Loss: 1.265 | Test Acc: 55.038% (2589/4704)\n",
      "Epoch 9 Step 147/313 Test Loss: 1.264 | Test Acc: 55.025% (2606/4736)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 148/313 Test Loss: 1.266 | Test Acc: 55.055% (2625/4768)\n",
      "Epoch 9 Step 149/313 Test Loss: 1.266 | Test Acc: 55.042% (2642/4800)\n",
      "Epoch 9 Step 150/313 Test Loss: 1.268 | Test Acc: 54.967% (2656/4832)\n",
      "Epoch 9 Step 151/313 Test Loss: 1.265 | Test Acc: 55.099% (2680/4864)\n",
      "Epoch 9 Step 152/313 Test Loss: 1.266 | Test Acc: 55.065% (2696/4896)\n",
      "Epoch 9 Step 153/313 Test Loss: 1.266 | Test Acc: 55.134% (2717/4928)\n",
      "Epoch 9 Step 154/313 Test Loss: 1.266 | Test Acc: 55.161% (2736/4960)\n",
      "Epoch 9 Step 155/313 Test Loss: 1.266 | Test Acc: 55.128% (2752/4992)\n",
      "Epoch 9 Step 156/313 Test Loss: 1.267 | Test Acc: 55.115% (2769/5024)\n",
      "Epoch 9 Step 157/313 Test Loss: 1.266 | Test Acc: 55.162% (2789/5056)\n",
      "Epoch 9 Step 158/313 Test Loss: 1.267 | Test Acc: 55.031% (2800/5088)\n",
      "Epoch 9 Step 159/313 Test Loss: 1.270 | Test Acc: 54.980% (2815/5120)\n",
      "Epoch 9 Step 160/313 Test Loss: 1.270 | Test Acc: 55.047% (2836/5152)\n",
      "Epoch 9 Step 161/313 Test Loss: 1.269 | Test Acc: 55.073% (2855/5184)\n",
      "Epoch 9 Step 162/313 Test Loss: 1.271 | Test Acc: 55.061% (2872/5216)\n",
      "Epoch 9 Step 163/313 Test Loss: 1.271 | Test Acc: 55.069% (2890/5248)\n",
      "Epoch 9 Step 164/313 Test Loss: 1.272 | Test Acc: 55.057% (2907/5280)\n",
      "Epoch 9 Step 165/313 Test Loss: 1.273 | Test Acc: 55.045% (2924/5312)\n",
      "Epoch 9 Step 166/313 Test Loss: 1.275 | Test Acc: 54.996% (2939/5344)\n",
      "Epoch 9 Step 167/313 Test Loss: 1.275 | Test Acc: 54.985% (2956/5376)\n",
      "Epoch 9 Step 168/313 Test Loss: 1.275 | Test Acc: 54.974% (2973/5408)\n",
      "Epoch 9 Step 169/313 Test Loss: 1.275 | Test Acc: 54.982% (2991/5440)\n",
      "Epoch 9 Step 170/313 Test Loss: 1.274 | Test Acc: 55.044% (3012/5472)\n",
      "Epoch 9 Step 171/313 Test Loss: 1.274 | Test Acc: 55.051% (3030/5504)\n",
      "Epoch 9 Step 172/313 Test Loss: 1.276 | Test Acc: 54.967% (3043/5536)\n",
      "Epoch 9 Step 173/313 Test Loss: 1.277 | Test Acc: 54.867% (3055/5568)\n",
      "Epoch 9 Step 174/313 Test Loss: 1.276 | Test Acc: 54.893% (3074/5600)\n",
      "Epoch 9 Step 175/313 Test Loss: 1.277 | Test Acc: 54.883% (3091/5632)\n",
      "Epoch 9 Step 176/313 Test Loss: 1.278 | Test Acc: 54.749% (3101/5664)\n",
      "Epoch 9 Step 177/313 Test Loss: 1.276 | Test Acc: 54.810% (3122/5696)\n",
      "Epoch 9 Step 178/313 Test Loss: 1.276 | Test Acc: 54.766% (3137/5728)\n",
      "Epoch 9 Step 179/313 Test Loss: 1.276 | Test Acc: 54.740% (3153/5760)\n",
      "Epoch 9 Step 180/313 Test Loss: 1.273 | Test Acc: 54.817% (3175/5792)\n",
      "Epoch 9 Step 181/313 Test Loss: 1.274 | Test Acc: 54.825% (3193/5824)\n",
      "Epoch 9 Step 182/313 Test Loss: 1.276 | Test Acc: 54.798% (3209/5856)\n",
      "Epoch 9 Step 183/313 Test Loss: 1.276 | Test Acc: 54.755% (3224/5888)\n",
      "Epoch 9 Step 184/313 Test Loss: 1.278 | Test Acc: 54.645% (3235/5920)\n",
      "Epoch 9 Step 185/313 Test Loss: 1.278 | Test Acc: 54.620% (3251/5952)\n",
      "Epoch 9 Step 186/313 Test Loss: 1.278 | Test Acc: 54.662% (3271/5984)\n",
      "Epoch 9 Step 187/313 Test Loss: 1.278 | Test Acc: 54.671% (3289/6016)\n",
      "Epoch 9 Step 188/313 Test Loss: 1.278 | Test Acc: 54.679% (3307/6048)\n",
      "Epoch 9 Step 189/313 Test Loss: 1.279 | Test Acc: 54.605% (3320/6080)\n",
      "Epoch 9 Step 190/313 Test Loss: 1.278 | Test Acc: 54.598% (3337/6112)\n",
      "Epoch 9 Step 191/313 Test Loss: 1.277 | Test Acc: 54.606% (3355/6144)\n",
      "Epoch 9 Step 192/313 Test Loss: 1.279 | Test Acc: 54.566% (3370/6176)\n",
      "Epoch 9 Step 193/313 Test Loss: 1.278 | Test Acc: 54.639% (3392/6208)\n",
      "Epoch 9 Step 194/313 Test Loss: 1.278 | Test Acc: 54.679% (3412/6240)\n",
      "Epoch 9 Step 195/313 Test Loss: 1.280 | Test Acc: 54.640% (3427/6272)\n",
      "Epoch 9 Step 196/313 Test Loss: 1.280 | Test Acc: 54.695% (3448/6304)\n",
      "Epoch 9 Step 197/313 Test Loss: 1.279 | Test Acc: 54.735% (3468/6336)\n",
      "Epoch 9 Step 198/313 Test Loss: 1.278 | Test Acc: 54.805% (3490/6368)\n",
      "Epoch 9 Step 199/313 Test Loss: 1.278 | Test Acc: 54.766% (3505/6400)\n",
      "Epoch 9 Step 200/313 Test Loss: 1.279 | Test Acc: 54.804% (3525/6432)\n",
      "Epoch 9 Step 201/313 Test Loss: 1.279 | Test Acc: 54.796% (3542/6464)\n",
      "Epoch 9 Step 202/313 Test Loss: 1.279 | Test Acc: 54.772% (3558/6496)\n",
      "Epoch 9 Step 203/313 Test Loss: 1.280 | Test Acc: 54.749% (3574/6528)\n",
      "Epoch 9 Step 204/313 Test Loss: 1.281 | Test Acc: 54.726% (3590/6560)\n",
      "Epoch 9 Step 205/313 Test Loss: 1.281 | Test Acc: 54.672% (3604/6592)\n",
      "Epoch 9 Step 206/313 Test Loss: 1.280 | Test Acc: 54.710% (3624/6624)\n",
      "Epoch 9 Step 207/313 Test Loss: 1.279 | Test Acc: 54.718% (3642/6656)\n",
      "Epoch 9 Step 208/313 Test Loss: 1.280 | Test Acc: 54.680% (3657/6688)\n",
      "Epoch 9 Step 209/313 Test Loss: 1.279 | Test Acc: 54.717% (3677/6720)\n",
      "Epoch 9 Step 210/313 Test Loss: 1.279 | Test Acc: 54.739% (3696/6752)\n",
      "Epoch 9 Step 211/313 Test Loss: 1.279 | Test Acc: 54.688% (3710/6784)\n",
      "Epoch 9 Step 212/313 Test Loss: 1.278 | Test Acc: 54.739% (3731/6816)\n",
      "Epoch 9 Step 213/313 Test Loss: 1.277 | Test Acc: 54.731% (3748/6848)\n",
      "Epoch 9 Step 214/313 Test Loss: 1.279 | Test Acc: 54.666% (3761/6880)\n",
      "Epoch 9 Step 215/313 Test Loss: 1.279 | Test Acc: 54.731% (3783/6912)\n",
      "Epoch 9 Step 216/313 Test Loss: 1.279 | Test Acc: 54.666% (3796/6944)\n",
      "Epoch 9 Step 217/313 Test Loss: 1.281 | Test Acc: 54.644% (3812/6976)\n",
      "Epoch 9 Step 218/313 Test Loss: 1.282 | Test Acc: 54.566% (3824/7008)\n",
      "Epoch 9 Step 219/313 Test Loss: 1.282 | Test Acc: 54.545% (3840/7040)\n",
      "Epoch 9 Step 220/313 Test Loss: 1.281 | Test Acc: 54.581% (3860/7072)\n",
      "Epoch 9 Step 221/313 Test Loss: 1.281 | Test Acc: 54.575% (3877/7104)\n",
      "Epoch 9 Step 222/313 Test Loss: 1.282 | Test Acc: 54.610% (3897/7136)\n",
      "Epoch 9 Step 223/313 Test Loss: 1.281 | Test Acc: 54.604% (3914/7168)\n",
      "Epoch 9 Step 224/313 Test Loss: 1.282 | Test Acc: 54.597% (3931/7200)\n",
      "Epoch 9 Step 225/313 Test Loss: 1.281 | Test Acc: 54.632% (3951/7232)\n",
      "Epoch 9 Step 226/313 Test Loss: 1.282 | Test Acc: 54.612% (3967/7264)\n",
      "Epoch 9 Step 227/313 Test Loss: 1.281 | Test Acc: 54.660% (3988/7296)\n",
      "Epoch 9 Step 228/313 Test Loss: 1.280 | Test Acc: 54.722% (4010/7328)\n",
      "Epoch 9 Step 229/313 Test Loss: 1.278 | Test Acc: 54.796% (4033/7360)\n",
      "Epoch 9 Step 230/313 Test Loss: 1.278 | Test Acc: 54.775% (4049/7392)\n",
      "Epoch 9 Step 231/313 Test Loss: 1.279 | Test Acc: 54.714% (4062/7424)\n",
      "Epoch 9 Step 232/313 Test Loss: 1.280 | Test Acc: 54.721% (4080/7456)\n",
      "Epoch 9 Step 233/313 Test Loss: 1.277 | Test Acc: 54.821% (4105/7488)\n",
      "Epoch 9 Step 234/313 Test Loss: 1.277 | Test Acc: 54.827% (4123/7520)\n",
      "Epoch 9 Step 235/313 Test Loss: 1.277 | Test Acc: 54.833% (4141/7552)\n",
      "Epoch 9 Step 236/313 Test Loss: 1.277 | Test Acc: 54.813% (4157/7584)\n",
      "Epoch 9 Step 237/313 Test Loss: 1.278 | Test Acc: 54.766% (4171/7616)\n",
      "Epoch 9 Step 238/313 Test Loss: 1.278 | Test Acc: 54.812% (4192/7648)\n",
      "Epoch 9 Step 239/313 Test Loss: 1.278 | Test Acc: 54.818% (4210/7680)\n",
      "Epoch 9 Step 240/313 Test Loss: 1.276 | Test Acc: 54.863% (4231/7712)\n",
      "Epoch 9 Step 241/313 Test Loss: 1.276 | Test Acc: 54.868% (4249/7744)\n",
      "Epoch 9 Step 242/313 Test Loss: 1.276 | Test Acc: 54.900% (4269/7776)\n",
      "Epoch 9 Step 243/313 Test Loss: 1.276 | Test Acc: 54.867% (4284/7808)\n",
      "Epoch 9 Step 244/313 Test Loss: 1.276 | Test Acc: 54.872% (4302/7840)\n",
      "Epoch 9 Step 245/313 Test Loss: 1.276 | Test Acc: 54.827% (4316/7872)\n",
      "Epoch 9 Step 246/313 Test Loss: 1.276 | Test Acc: 54.896% (4339/7904)\n",
      "Epoch 9 Step 247/313 Test Loss: 1.276 | Test Acc: 54.851% (4353/7936)\n",
      "Epoch 9 Step 248/313 Test Loss: 1.276 | Test Acc: 54.819% (4368/7968)\n",
      "Epoch 9 Step 249/313 Test Loss: 1.276 | Test Acc: 54.837% (4387/8000)\n",
      "Epoch 9 Step 250/313 Test Loss: 1.277 | Test Acc: 54.793% (4401/8032)\n",
      "Epoch 9 Step 251/313 Test Loss: 1.277 | Test Acc: 54.774% (4417/8064)\n",
      "Epoch 9 Step 252/313 Test Loss: 1.277 | Test Acc: 54.792% (4436/8096)\n",
      "Epoch 9 Step 253/313 Test Loss: 1.278 | Test Acc: 54.798% (4454/8128)\n",
      "Epoch 9 Step 254/313 Test Loss: 1.278 | Test Acc: 54.767% (4469/8160)\n",
      "Epoch 9 Step 255/313 Test Loss: 1.278 | Test Acc: 54.810% (4490/8192)\n",
      "Epoch 9 Step 256/313 Test Loss: 1.278 | Test Acc: 54.779% (4505/8224)\n",
      "Epoch 9 Step 257/313 Test Loss: 1.278 | Test Acc: 54.797% (4524/8256)\n",
      "Epoch 9 Step 258/313 Test Loss: 1.278 | Test Acc: 54.778% (4540/8288)\n",
      "Epoch 9 Step 259/313 Test Loss: 1.280 | Test Acc: 54.663% (4548/8320)\n",
      "Epoch 9 Step 260/313 Test Loss: 1.280 | Test Acc: 54.634% (4563/8352)\n",
      "Epoch 9 Step 261/313 Test Loss: 1.280 | Test Acc: 54.628% (4580/8384)\n",
      "Epoch 9 Step 262/313 Test Loss: 1.280 | Test Acc: 54.598% (4595/8416)\n",
      "Epoch 9 Step 263/313 Test Loss: 1.280 | Test Acc: 54.581% (4611/8448)\n",
      "Epoch 9 Step 264/313 Test Loss: 1.280 | Test Acc: 54.564% (4627/8480)\n",
      "Epoch 9 Step 265/313 Test Loss: 1.280 | Test Acc: 54.570% (4645/8512)\n",
      "Epoch 9 Step 266/313 Test Loss: 1.280 | Test Acc: 54.576% (4663/8544)\n",
      "Epoch 9 Step 267/313 Test Loss: 1.280 | Test Acc: 54.594% (4682/8576)\n",
      "Epoch 9 Step 268/313 Test Loss: 1.280 | Test Acc: 54.542% (4695/8608)\n",
      "Epoch 9 Step 269/313 Test Loss: 1.281 | Test Acc: 54.560% (4714/8640)\n",
      "Epoch 9 Step 270/313 Test Loss: 1.281 | Test Acc: 54.520% (4728/8672)\n",
      "Epoch 9 Step 271/313 Test Loss: 1.281 | Test Acc: 54.550% (4748/8704)\n",
      "Epoch 9 Step 272/313 Test Loss: 1.280 | Test Acc: 54.556% (4766/8736)\n",
      "Epoch 9 Step 273/313 Test Loss: 1.281 | Test Acc: 54.528% (4781/8768)\n",
      "Epoch 9 Step 274/313 Test Loss: 1.280 | Test Acc: 54.557% (4801/8800)\n",
      "Epoch 9 Step 275/313 Test Loss: 1.281 | Test Acc: 54.563% (4819/8832)\n",
      "Epoch 9 Step 276/313 Test Loss: 1.280 | Test Acc: 54.580% (4838/8864)\n",
      "Epoch 9 Step 277/313 Test Loss: 1.280 | Test Acc: 54.620% (4859/8896)\n",
      "Epoch 9 Step 278/313 Test Loss: 1.279 | Test Acc: 54.671% (4881/8928)\n",
      "Epoch 9 Step 279/313 Test Loss: 1.280 | Test Acc: 54.598% (4892/8960)\n",
      "Epoch 9 Step 280/313 Test Loss: 1.280 | Test Acc: 54.571% (4907/8992)\n",
      "Epoch 9 Step 281/313 Test Loss: 1.280 | Test Acc: 54.599% (4927/9024)\n",
      "Epoch 9 Step 282/313 Test Loss: 1.280 | Test Acc: 54.583% (4943/9056)\n",
      "Epoch 9 Step 283/313 Test Loss: 1.280 | Test Acc: 54.610% (4963/9088)\n",
      "Epoch 9 Step 284/313 Test Loss: 1.279 | Test Acc: 54.616% (4981/9120)\n",
      "Epoch 9 Step 285/313 Test Loss: 1.280 | Test Acc: 54.633% (5000/9152)\n",
      "Epoch 9 Step 286/313 Test Loss: 1.279 | Test Acc: 54.682% (5022/9184)\n",
      "Epoch 9 Step 287/313 Test Loss: 1.278 | Test Acc: 54.688% (5040/9216)\n",
      "Epoch 9 Step 288/313 Test Loss: 1.278 | Test Acc: 54.715% (5060/9248)\n",
      "Epoch 9 Step 289/313 Test Loss: 1.278 | Test Acc: 54.741% (5080/9280)\n",
      "Epoch 9 Step 290/313 Test Loss: 1.279 | Test Acc: 54.693% (5093/9312)\n",
      "Epoch 9 Step 291/313 Test Loss: 1.278 | Test Acc: 54.709% (5112/9344)\n",
      "Epoch 9 Step 292/313 Test Loss: 1.278 | Test Acc: 54.703% (5129/9376)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Step 293/313 Test Loss: 1.279 | Test Acc: 54.688% (5145/9408)\n",
      "Epoch 9 Step 294/313 Test Loss: 1.279 | Test Acc: 54.693% (5163/9440)\n",
      "Epoch 9 Step 295/313 Test Loss: 1.279 | Test Acc: 54.709% (5182/9472)\n",
      "Epoch 9 Step 296/313 Test Loss: 1.278 | Test Acc: 54.745% (5203/9504)\n",
      "Epoch 9 Step 297/313 Test Loss: 1.279 | Test Acc: 54.719% (5218/9536)\n",
      "Epoch 9 Step 298/313 Test Loss: 1.279 | Test Acc: 54.766% (5240/9568)\n",
      "Epoch 9 Step 299/313 Test Loss: 1.278 | Test Acc: 54.792% (5260/9600)\n",
      "Epoch 9 Step 300/313 Test Loss: 1.278 | Test Acc: 54.797% (5278/9632)\n",
      "Epoch 9 Step 301/313 Test Loss: 1.278 | Test Acc: 54.801% (5296/9664)\n",
      "Epoch 9 Step 302/313 Test Loss: 1.278 | Test Acc: 54.816% (5315/9696)\n",
      "Epoch 9 Step 303/313 Test Loss: 1.278 | Test Acc: 54.842% (5335/9728)\n",
      "Epoch 9 Step 304/313 Test Loss: 1.278 | Test Acc: 54.816% (5350/9760)\n",
      "Epoch 9 Step 305/313 Test Loss: 1.277 | Test Acc: 54.820% (5368/9792)\n",
      "Epoch 9 Step 306/313 Test Loss: 1.278 | Test Acc: 54.805% (5384/9824)\n",
      "Epoch 9 Step 307/313 Test Loss: 1.279 | Test Acc: 54.799% (5401/9856)\n",
      "Epoch 9 Step 308/313 Test Loss: 1.280 | Test Acc: 54.784% (5417/9888)\n",
      "Epoch 9 Step 309/313 Test Loss: 1.279 | Test Acc: 54.778% (5434/9920)\n",
      "Epoch 9 Step 310/313 Test Loss: 1.280 | Test Acc: 54.783% (5452/9952)\n",
      "Epoch 9 Step 311/313 Test Loss: 1.280 | Test Acc: 54.758% (5467/9984)\n",
      "Epoch 9 Step 312/313 Test Loss: 1.280 | Test Acc: 54.760% (5476/10000)\n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "# Training ResNet34\n",
    "for epoch in range(start_epoch, start_epoch+10):\n",
    "    train(model, epoch)\n",
    "    test(model, epoch)\n",
    "\n",
    "best_acc.append([best_train_acc, best_test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "D31XIsXAa5gU",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-80a13987adfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbest_train_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWideModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWideModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_train_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_test_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-23a35d5f914f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-759c2cdb6e62>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf-gpu/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtens_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "# Training Wide_ResNet16\n",
    "best_train_acc = best_test_acc = 0\n",
    "for epoch in range(start_epoch, start_epoch+10):\n",
    "  train(WideModel, epoch)\n",
    "  test(WideModel, epoch)\n",
    "best_acc.append([best_train_acc, best_test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gOznWHW8HfNe"
   },
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "URPD4HtQWPYZ"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "G0eMZNd_GDwO",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "              Tanh-2            [-1, 6, 28, 28]               0\n",
      "         AvgPool2d-3            [-1, 6, 14, 14]               0\n",
      "            Conv2d-4           [-1, 16, 10, 10]           2,416\n",
      "              Tanh-5           [-1, 16, 10, 10]               0\n",
      "         AvgPool2d-6             [-1, 16, 5, 5]               0\n",
      "            Conv2d-7            [-1, 120, 1, 1]          48,120\n",
      "              Tanh-8            [-1, 120, 1, 1]               0\n",
      "            Linear-9                   [-1, 84]          10,164\n",
      "             Tanh-10                   [-1, 84]               0\n",
      "           Linear-11                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(WideModel, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "HxGvViLOdtnh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[65.625, 54.76]]\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBVW-sqokHiX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Deep vs Shallow",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
